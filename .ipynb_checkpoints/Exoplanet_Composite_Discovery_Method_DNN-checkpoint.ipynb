{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for Exoplanet Discovery Method Classification\n",
    "## Identifying Patterns in Exoplanet Characteristics to Determine Discovery Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import optuna as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Number of Planets</th>\n",
       "      <th>Number of Moons</th>\n",
       "      <th>Galactic Latitude [deg]</th>\n",
       "      <th>Galactic Longitude [deg]</th>\n",
       "      <th>Ecliptic Latitude [deg]</th>\n",
       "      <th>Ecliptic Longitude [deg]</th>\n",
       "      <th>Number of Photometry Time Series</th>\n",
       "      <th>Number of Radial Velocity Time Series</th>\n",
       "      <th>Number of Stellar Spectra Measurements</th>\n",
       "      <th>Number of Emission Spectroscopy Measurements</th>\n",
       "      <th>Number of Transmission Spectroscopy Measurements</th>\n",
       "      <th>Circumbinary Flag</th>\n",
       "      <th>Controversial Flag</th>\n",
       "      <th>Discovery Year</th>\n",
       "      <th>Detected by Transits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.094076</td>\n",
       "      <td>-0.666894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.424559</td>\n",
       "      <td>1.234306</td>\n",
       "      <td>-0.145901</td>\n",
       "      <td>-0.624689</td>\n",
       "      <td>0.613405</td>\n",
       "      <td>1.731519</td>\n",
       "      <td>-0.261600</td>\n",
       "      <td>-0.012466</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.256668</td>\n",
       "      <td>-0.666894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186720</td>\n",
       "      <td>-0.283545</td>\n",
       "      <td>1.148661</td>\n",
       "      <td>-0.992906</td>\n",
       "      <td>0.613405</td>\n",
       "      <td>0.729626</td>\n",
       "      <td>-0.261600</td>\n",
       "      <td>-0.012466</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.256668</td>\n",
       "      <td>-0.666894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.877523</td>\n",
       "      <td>-0.306068</td>\n",
       "      <td>0.308947</td>\n",
       "      <td>-2.327878</td>\n",
       "      <td>0.613405</td>\n",
       "      <td>0.729626</td>\n",
       "      <td>-0.261600</td>\n",
       "      <td>-0.012466</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.256668</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.382856</td>\n",
       "      <td>-0.669803</td>\n",
       "      <td>0.872499</td>\n",
       "      <td>-0.152934</td>\n",
       "      <td>0.613405</td>\n",
       "      <td>3.735304</td>\n",
       "      <td>0.591749</td>\n",
       "      <td>-0.012466</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.444820</td>\n",
       "      <td>-0.666894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261241</td>\n",
       "      <td>-0.531444</td>\n",
       "      <td>1.023143</td>\n",
       "      <td>0.855489</td>\n",
       "      <td>0.613405</td>\n",
       "      <td>3.735304</td>\n",
       "      <td>2.298449</td>\n",
       "      <td>-0.012466</td>\n",
       "      <td>-0.044364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars  Number of Planets  Number of Moons  \\\n",
       "0         3.094076          -0.666894              0.0   \n",
       "1        -0.256668          -0.666894              0.0   \n",
       "2        -0.256668          -0.666894              0.0   \n",
       "3        -0.256668           0.216988              0.0   \n",
       "4         6.444820          -0.666894              0.0   \n",
       "\n",
       "   Galactic Latitude [deg]  Galactic Longitude [deg]  Ecliptic Latitude [deg]  \\\n",
       "0                 2.424559                  1.234306                -0.145901   \n",
       "1                 1.186720                 -0.283545                 1.148661   \n",
       "2                -0.877523                 -0.306068                 0.308947   \n",
       "3                 1.382856                 -0.669803                 0.872499   \n",
       "4                 0.261241                 -0.531444                 1.023143   \n",
       "\n",
       "   Ecliptic Longitude [deg]  Number of Photometry Time Series  \\\n",
       "0                 -0.624689                          0.613405   \n",
       "1                 -0.992906                          0.613405   \n",
       "2                 -2.327878                          0.613405   \n",
       "3                 -0.152934                          0.613405   \n",
       "4                  0.855489                          0.613405   \n",
       "\n",
       "   Number of Radial Velocity Time Series  \\\n",
       "0                               1.731519   \n",
       "1                               0.729626   \n",
       "2                               0.729626   \n",
       "3                               3.735304   \n",
       "4                               3.735304   \n",
       "\n",
       "   Number of Stellar Spectra Measurements  \\\n",
       "0                               -0.261600   \n",
       "1                               -0.261600   \n",
       "2                               -0.261600   \n",
       "3                                0.591749   \n",
       "4                                2.298449   \n",
       "\n",
       "   Number of Emission Spectroscopy Measurements  \\\n",
       "0                                     -0.012466   \n",
       "1                                     -0.012466   \n",
       "2                                     -0.012466   \n",
       "3                                     -0.012466   \n",
       "4                                     -0.012466   \n",
       "\n",
       "   Number of Transmission Spectroscopy Measurements  Circumbinary Flag  \\\n",
       "0                                         -0.044364                  0   \n",
       "1                                         -0.044364                  0   \n",
       "2                                         -0.044364                  0   \n",
       "3                                         -0.044364                  0   \n",
       "4                                         -0.044364                  0   \n",
       "\n",
       "   Controversial Flag  Discovery Year  Detected by Transits  \n",
       "0                   0            2007                     0  \n",
       "1                   0            2009                     0  \n",
       "2                   0            2008                     0  \n",
       "3                   0            2002                     0  \n",
       "4                   0            1996                     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessed in another jupytr nb \n",
    "\n",
    "composite_preprocessed = pd.read_csv('Composite_preprocessed_NO_MV_BALANCED.csv')\n",
    "composite_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 possible results ; Either the exoplanet was discovered by transits (1) or it wasn't (0) ; binary classification\n",
    "### so we have 1 neuron in the output layer  \n",
    "### We will use the features from the XGBoost refined features model \n",
    "### This ensures consistency, reduces complexity, and leverages the feature selection process that has already been validated with my refined features XGBoost model\n",
    "### This would also allow for a fair comparison between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['Number of Radial Velocity Time Series',\n",
    "          'Number of Stellar Spectra Measurements',\n",
    "          'Controversial Flag',\n",
    "          'Circumbinary Flag',\n",
    "          'Number of Moons']\n",
    "\n",
    "composite_unnecessary_removed = composite_preprocessed.drop(remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are trying to predict whether an exoplanet has been detected by transits (0 or 1)\n",
    "# target variable is if the exoplanet was discovered by transits\n",
    "\n",
    "targets = composite_unnecessary_removed['Detected by Transits']\n",
    "\n",
    "# training features are all variables except the targets\n",
    "\n",
    "features = composite_unnecessary_removed.drop(['Detected by Transits'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Number of Planets</th>\n",
       "      <th>Galactic Latitude [deg]</th>\n",
       "      <th>Galactic Longitude [deg]</th>\n",
       "      <th>Ecliptic Latitude [deg]</th>\n",
       "      <th>Ecliptic Longitude [deg]</th>\n",
       "      <th>Number of Photometry Time Series</th>\n",
       "      <th>Number of Emission Spectroscopy Measurements</th>\n",
       "      <th>Number of Transmission Spectroscopy Measurements</th>\n",
       "      <th>Discovery Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of Stars</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109074</td>\n",
       "      <td>-0.044988</td>\n",
       "      <td>0.104236</td>\n",
       "      <td>-0.087528</td>\n",
       "      <td>-0.069450</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.147575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Planets</th>\n",
       "      <td>0.109074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055511</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.026680</td>\n",
       "      <td>-0.023926</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>-0.072274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galactic Latitude [deg]</th>\n",
       "      <td>-0.044988</td>\n",
       "      <td>-0.055511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019213</td>\n",
       "      <td>0.463063</td>\n",
       "      <td>0.174632</td>\n",
       "      <td>-0.090369</td>\n",
       "      <td>-0.025691</td>\n",
       "      <td>-0.008918</td>\n",
       "      <td>0.031820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galactic Longitude [deg]</th>\n",
       "      <td>0.104236</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>-0.019213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.657044</td>\n",
       "      <td>-0.408779</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>-0.008283</td>\n",
       "      <td>-0.026088</td>\n",
       "      <td>-0.106558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecliptic Latitude [deg]</th>\n",
       "      <td>-0.087528</td>\n",
       "      <td>0.026680</td>\n",
       "      <td>0.463063</td>\n",
       "      <td>-0.657044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498442</td>\n",
       "      <td>-0.222283</td>\n",
       "      <td>-0.006864</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>0.081113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecliptic Longitude [deg]</th>\n",
       "      <td>-0.069450</td>\n",
       "      <td>-0.023926</td>\n",
       "      <td>0.174632</td>\n",
       "      <td>-0.408779</td>\n",
       "      <td>0.498442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119612</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.031078</td>\n",
       "      <td>0.058041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Photometry Time Series</th>\n",
       "      <td>0.057734</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>-0.090369</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>-0.222283</td>\n",
       "      <td>-0.119612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004172</td>\n",
       "      <td>-0.014848</td>\n",
       "      <td>-0.252983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Emission Spectroscopy Measurements</th>\n",
       "      <td>-0.003200</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>-0.025691</td>\n",
       "      <td>-0.008283</td>\n",
       "      <td>-0.006864</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>-0.004172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Transmission Spectroscopy Measurements</th>\n",
       "      <td>-0.002096</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>-0.008918</td>\n",
       "      <td>-0.026088</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>0.031078</td>\n",
       "      <td>-0.014848</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery Year</th>\n",
       "      <td>-0.147575</td>\n",
       "      <td>-0.072274</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>-0.106558</td>\n",
       "      <td>0.081113</td>\n",
       "      <td>0.058041</td>\n",
       "      <td>-0.252983</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.015425</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Number of Stars  \\\n",
       "Number of Stars                                          1.000000   \n",
       "Number of Planets                                        0.109074   \n",
       "Galactic Latitude [deg]                                 -0.044988   \n",
       "Galactic Longitude [deg]                                 0.104236   \n",
       "Ecliptic Latitude [deg]                                 -0.087528   \n",
       "Ecliptic Longitude [deg]                                -0.069450   \n",
       "Number of Photometry Time Series                         0.057734   \n",
       "Number of Emission Spectroscopy Measurements            -0.003200   \n",
       "Number of Transmission Spectroscopy Measurements        -0.002096   \n",
       "Discovery Year                                          -0.147575   \n",
       "\n",
       "                                                  Number of Planets  \\\n",
       "Number of Stars                                            0.109074   \n",
       "Number of Planets                                          1.000000   \n",
       "Galactic Latitude [deg]                                   -0.055511   \n",
       "Galactic Longitude [deg]                                   0.008589   \n",
       "Ecliptic Latitude [deg]                                    0.026680   \n",
       "Ecliptic Longitude [deg]                                  -0.023926   \n",
       "Number of Photometry Time Series                          -0.002505   \n",
       "Number of Emission Spectroscopy Measurements               0.057797   \n",
       "Number of Transmission Spectroscopy Measurements           0.076409   \n",
       "Discovery Year                                            -0.072274   \n",
       "\n",
       "                                                  Galactic Latitude [deg]  \\\n",
       "Number of Stars                                                 -0.044988   \n",
       "Number of Planets                                               -0.055511   \n",
       "Galactic Latitude [deg]                                          1.000000   \n",
       "Galactic Longitude [deg]                                        -0.019213   \n",
       "Ecliptic Latitude [deg]                                          0.463063   \n",
       "Ecliptic Longitude [deg]                                         0.174632   \n",
       "Number of Photometry Time Series                                -0.090369   \n",
       "Number of Emission Spectroscopy Measurements                    -0.025691   \n",
       "Number of Transmission Spectroscopy Measurements                -0.008918   \n",
       "Discovery Year                                                   0.031820   \n",
       "\n",
       "                                                  Galactic Longitude [deg]  \\\n",
       "Number of Stars                                                   0.104236   \n",
       "Number of Planets                                                 0.008589   \n",
       "Galactic Latitude [deg]                                          -0.019213   \n",
       "Galactic Longitude [deg]                                          1.000000   \n",
       "Ecliptic Latitude [deg]                                          -0.657044   \n",
       "Ecliptic Longitude [deg]                                         -0.408779   \n",
       "Number of Photometry Time Series                                  0.131333   \n",
       "Number of Emission Spectroscopy Measurements                     -0.008283   \n",
       "Number of Transmission Spectroscopy Measurements                 -0.026088   \n",
       "Discovery Year                                                   -0.106558   \n",
       "\n",
       "                                                  Ecliptic Latitude [deg]  \\\n",
       "Number of Stars                                                 -0.087528   \n",
       "Number of Planets                                                0.026680   \n",
       "Galactic Latitude [deg]                                          0.463063   \n",
       "Galactic Longitude [deg]                                        -0.657044   \n",
       "Ecliptic Latitude [deg]                                          1.000000   \n",
       "Ecliptic Longitude [deg]                                         0.498442   \n",
       "Number of Photometry Time Series                                -0.222283   \n",
       "Number of Emission Spectroscopy Measurements                    -0.006864   \n",
       "Number of Transmission Spectroscopy Measurements                 0.025212   \n",
       "Discovery Year                                                   0.081113   \n",
       "\n",
       "                                                  Ecliptic Longitude [deg]  \\\n",
       "Number of Stars                                                  -0.069450   \n",
       "Number of Planets                                                -0.023926   \n",
       "Galactic Latitude [deg]                                           0.174632   \n",
       "Galactic Longitude [deg]                                         -0.408779   \n",
       "Ecliptic Latitude [deg]                                           0.498442   \n",
       "Ecliptic Longitude [deg]                                          1.000000   \n",
       "Number of Photometry Time Series                                 -0.119612   \n",
       "Number of Emission Spectroscopy Measurements                      0.013811   \n",
       "Number of Transmission Spectroscopy Measurements                  0.031078   \n",
       "Discovery Year                                                    0.058041   \n",
       "\n",
       "                                                  Number of Photometry Time Series  \\\n",
       "Number of Stars                                                           0.057734   \n",
       "Number of Planets                                                        -0.002505   \n",
       "Galactic Latitude [deg]                                                  -0.090369   \n",
       "Galactic Longitude [deg]                                                  0.131333   \n",
       "Ecliptic Latitude [deg]                                                  -0.222283   \n",
       "Ecliptic Longitude [deg]                                                 -0.119612   \n",
       "Number of Photometry Time Series                                          1.000000   \n",
       "Number of Emission Spectroscopy Measurements                             -0.004172   \n",
       "Number of Transmission Spectroscopy Measurements                         -0.014848   \n",
       "Discovery Year                                                           -0.252983   \n",
       "\n",
       "                                                  Number of Emission Spectroscopy Measurements  \\\n",
       "Number of Stars                                                                      -0.003200   \n",
       "Number of Planets                                                                     0.057797   \n",
       "Galactic Latitude [deg]                                                              -0.025691   \n",
       "Galactic Longitude [deg]                                                             -0.008283   \n",
       "Ecliptic Latitude [deg]                                                              -0.006864   \n",
       "Ecliptic Longitude [deg]                                                              0.013811   \n",
       "Number of Photometry Time Series                                                     -0.004172   \n",
       "Number of Emission Spectroscopy Measurements                                          1.000000   \n",
       "Number of Transmission Spectroscopy Measurements                                     -0.000553   \n",
       "Discovery Year                                                                        0.000791   \n",
       "\n",
       "                                                  Number of Transmission Spectroscopy Measurements  \\\n",
       "Number of Stars                                                                          -0.002096   \n",
       "Number of Planets                                                                         0.076409   \n",
       "Galactic Latitude [deg]                                                                  -0.008918   \n",
       "Galactic Longitude [deg]                                                                 -0.026088   \n",
       "Ecliptic Latitude [deg]                                                                   0.025212   \n",
       "Ecliptic Longitude [deg]                                                                  0.031078   \n",
       "Number of Photometry Time Series                                                         -0.014848   \n",
       "Number of Emission Spectroscopy Measurements                                             -0.000553   \n",
       "Number of Transmission Spectroscopy Measurements                                          1.000000   \n",
       "Discovery Year                                                                           -0.015425   \n",
       "\n",
       "                                                  Discovery Year  \n",
       "Number of Stars                                        -0.147575  \n",
       "Number of Planets                                      -0.072274  \n",
       "Galactic Latitude [deg]                                 0.031820  \n",
       "Galactic Longitude [deg]                               -0.106558  \n",
       "Ecliptic Latitude [deg]                                 0.081113  \n",
       "Ecliptic Longitude [deg]                                0.058041  \n",
       "Number of Photometry Time Series                       -0.252983  \n",
       "Number of Emission Spectroscopy Measurements            0.000791  \n",
       "Number of Transmission Spectroscopy Measurements       -0.015425  \n",
       "Discovery Year                                          1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderate correlation between Ecliptic Longtiude aand Ecliptic Latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training, testing and validation addresses overfitting\n",
    "# shuffling is necessary to remove dependencies that come from order of data\n",
    "\n",
    "\n",
    "# 80:10:10 split ; Training ; Validation ; Testing\n",
    "# so we split twice; once into 80:20, then 50:50 (so 50% of the designated testing portion is for validation)\n",
    "\n",
    "# first split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(features, targets, test_size = 0.2, random_state = 42, shuffle=True)\n",
    "\n",
    "# second split\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size = 0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# tensorflow models expect data in the form of a np array; NOT a pd dataframe \n",
    "# so we have to convert\n",
    "\n",
    "def conv_nparr(df):\n",
    "    return np.array(df)\n",
    "\n",
    "data_splits = [x_train, x_val, x_test, y_train, y_val, y_test]\n",
    "\n",
    "# list comprehension to transform all the dfs into nparr\n",
    "x_train_nparr, x_val_nparr, x_test_nparr, y_train_nparr, y_val_nparr, y_test_nparr = [conv_nparr(split) for split in data_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# learning rate scheduler; LR is reduced when it stops improving \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# we use optuna for hyperparameter optimization\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "\n",
    "# k cross validation to ensure consistent model performance and is not dependent on a single train-test split\n",
    "# robustness, generalizability, and assists in hyperparameter tuning\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:26:26,680] A new study created in memory with name: no-name-12af9d59-9eda-44be-b7ef-281d60b1bb7c\n",
      "2024-08-07 21:26:26.718451: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 21:26:26.719525: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 4s - loss: 207.7560 - accuracy: 0.5010 - val_loss: 150.9292 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "5148/5148 - 3s - loss: 130.8034 - accuracy: 0.4874 - val_loss: 68.7129 - val_accuracy: 0.5078\n",
      "Epoch 3/5\n",
      "5148/5148 - 2s - loss: 88.2945 - accuracy: 0.5080 - val_loss: 27.3035 - val_accuracy: 0.5078\n",
      "Epoch 4/5\n",
      "5148/5148 - 2s - loss: 84.1831 - accuracy: 0.4951 - val_loss: 11.5796 - val_accuracy: 0.5078\n",
      "Epoch 5/5\n",
      "5148/5148 - 2s - loss: 79.5459 - accuracy: 0.4955 - val_loss: 7.5419 - val_accuracy: 0.5078\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 3s - loss: 82.6062 - accuracy: 0.4981 - val_loss: 32.2839 - val_accuracy: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "5148/5148 - 2s - loss: 59.6275 - accuracy: 0.5031 - val_loss: 6.3034 - val_accuracy: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "5148/5148 - 2s - loss: 55.6999 - accuracy: 0.5033 - val_loss: 2.6211 - val_accuracy: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "5148/5148 - 2s - loss: 53.4079 - accuracy: 0.4938 - val_loss: 1.3581 - val_accuracy: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "5148/5148 - 2s - loss: 50.9128 - accuracy: 0.5134 - val_loss: 0.7867 - val_accuracy: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 3s - loss: 102.6038 - accuracy: 0.4876 - val_loss: 33.8560 - val_accuracy: 0.4922\n",
      "Epoch 2/5\n",
      "5148/5148 - 2s - loss: 81.0151 - accuracy: 0.4971 - val_loss: 4.3849 - val_accuracy: 0.4922\n",
      "Epoch 3/5\n",
      "5148/5148 - 3s - loss: 79.8464 - accuracy: 0.4920 - val_loss: 3.7774 - val_accuracy: 0.5078\n",
      "Epoch 4/5\n",
      "5148/5148 - 4s - loss: 75.3665 - accuracy: 0.5045 - val_loss: 1.1272 - val_accuracy: 0.5062\n",
      "Epoch 5/5\n",
      "5148/5148 - 3s - loss: 72.4403 - accuracy: 0.5008 - val_loss: 1.1098 - val_accuracy: 0.5062\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 3s - loss: 113.4176 - accuracy: 0.5014 - val_loss: 43.8922 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "5148/5148 - 3s - loss: 91.7441 - accuracy: 0.4971 - val_loss: 10.8058 - val_accuracy: 0.5078\n",
      "Epoch 3/5\n",
      "5148/5148 - 3s - loss: 84.3746 - accuracy: 0.5068 - val_loss: 5.3698 - val_accuracy: 0.5078\n",
      "Epoch 4/5\n",
      "5148/5148 - 2s - loss: 83.9738 - accuracy: 0.4959 - val_loss: 1.0478 - val_accuracy: 0.5171\n",
      "Epoch 5/5\n",
      "5148/5148 - 2s - loss: 79.3713 - accuracy: 0.5101 - val_loss: 1.8203 - val_accuracy: 0.5140\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 4s - loss: 93.7534 - accuracy: 0.4944 - val_loss: 20.4136 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "5148/5148 - 3s - loss: 78.6737 - accuracy: 0.5183 - val_loss: 5.1903 - val_accuracy: 0.5078\n",
      "Epoch 3/5\n",
      "5148/5148 - 3s - loss: 79.8719 - accuracy: 0.5031 - val_loss: 3.9747 - val_accuracy: 0.5078\n",
      "Epoch 4/5\n",
      "5148/5148 - 2s - loss: 79.1131 - accuracy: 0.4915 - val_loss: 2.0620 - val_accuracy: 0.5078\n",
      "Epoch 5/5\n",
      "5148/5148 - 3s - loss: 74.8443 - accuracy: 0.4988 - val_loss: 1.7232 - val_accuracy: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:27:37,889] Trial 0 finished with value: 0.5096273422241211 and parameters: {'units': 50, 'dropout': 0.25, 'learning_rate': 1.593352116249386e-05, 'epochs': 5, 'batch_size': 5, 'patience': 8, 'factor': 0.2}. Best is trial 0 with value: 0.5096273422241211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 20.7020 - accuracy: 0.5185 - val_loss: 0.6355 - val_accuracy: 0.6056\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.8214 - accuracy: 0.5260 - val_loss: 0.7004 - val_accuracy: 0.4922\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.6662 - accuracy: 0.6121 - val_loss: 0.5695 - val_accuracy: 0.7671\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.6043 - accuracy: 0.6700 - val_loss: 0.5656 - val_accuracy: 0.7252\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5887 - accuracy: 0.7053 - val_loss: 0.5979 - val_accuracy: 0.7422\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.6282 - accuracy: 0.6414 - val_loss: 0.6368 - val_accuracy: 0.8494\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.6268 - accuracy: 0.6449 - val_loss: 0.6923 - val_accuracy: 0.5093\n",
      "Epoch 8/50\n",
      "5148/5148 - 2s - loss: 0.6791 - accuracy: 0.5400 - val_loss: 0.6767 - val_accuracy: 0.5776\n",
      "Epoch 9/50\n",
      "5148/5148 - 2s - loss: 0.6878 - accuracy: 0.5212 - val_loss: 0.5942 - val_accuracy: 0.8121\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.6658 - accuracy: 0.5833 - val_loss: 0.6937 - val_accuracy: 0.5093\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.6909 - accuracy: 0.5107 - val_loss: 0.6930 - val_accuracy: 0.4922\n",
      "Epoch 12/50\n",
      "5148/5148 - 2s - loss: 0.6924 - accuracy: 0.4955 - val_loss: 0.6906 - val_accuracy: 0.5124\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.6674 - accuracy: 0.5581 - val_loss: 0.6923 - val_accuracy: 0.5093\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.6931 - accuracy: 0.5016 - val_loss: 0.6922 - val_accuracy: 0.5093\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.6927 - accuracy: 0.4922 - val_loss: 0.6921 - val_accuracy: 0.5093\n",
      "Epoch 16/50\n",
      "5148/5148 - 2s - loss: 0.6923 - accuracy: 0.4975 - val_loss: 0.6922 - val_accuracy: 0.4953\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.6898 - accuracy: 0.4994 - val_loss: 0.6621 - val_accuracy: 0.5637\n",
      "Epoch 18/50\n",
      "5148/5148 - 2s - loss: 0.6390 - accuracy: 0.6140 - val_loss: 0.5606 - val_accuracy: 0.8556\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.5881 - accuracy: 0.7098 - val_loss: 0.5231 - val_accuracy: 0.8339\n",
      "Epoch 20/50\n",
      "5148/5148 - 2s - loss: 0.5793 - accuracy: 0.7111 - val_loss: 0.5107 - val_accuracy: 0.8276\n",
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.5771 - accuracy: 0.7148 - val_loss: 0.5061 - val_accuracy: 0.8339\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.5696 - accuracy: 0.7230 - val_loss: 0.4927 - val_accuracy: 0.8354\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.5615 - accuracy: 0.7314 - val_loss: 0.5223 - val_accuracy: 0.7842\n",
      "Epoch 24/50\n",
      "5148/5148 - 2s - loss: 0.5584 - accuracy: 0.7312 - val_loss: 0.4900 - val_accuracy: 0.8463\n",
      "Epoch 25/50\n",
      "5148/5148 - 2s - loss: 0.5579 - accuracy: 0.7317 - val_loss: 0.6044 - val_accuracy: 0.6755\n",
      "Epoch 26/50\n",
      "5148/5148 - 2s - loss: 0.5478 - accuracy: 0.7399 - val_loss: 0.4846 - val_accuracy: 0.8432\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.5441 - accuracy: 0.7444 - val_loss: 0.4886 - val_accuracy: 0.8028\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.5509 - accuracy: 0.7327 - val_loss: 0.4655 - val_accuracy: 0.8540\n",
      "Epoch 29/50\n",
      "5148/5148 - 3s - loss: 0.5387 - accuracy: 0.7475 - val_loss: 0.4626 - val_accuracy: 0.8525\n",
      "Epoch 30/50\n",
      "5148/5148 - 2s - loss: 0.5395 - accuracy: 0.7471 - val_loss: 0.4611 - val_accuracy: 0.8571\n",
      "Epoch 31/50\n",
      "5148/5148 - 2s - loss: 0.5459 - accuracy: 0.7368 - val_loss: 0.4620 - val_accuracy: 0.8556\n",
      "Epoch 32/50\n",
      "5148/5148 - 2s - loss: 0.5408 - accuracy: 0.7405 - val_loss: 0.4575 - val_accuracy: 0.8587\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.5364 - accuracy: 0.7494 - val_loss: 0.4527 - val_accuracy: 0.8602\n",
      "Epoch 34/50\n",
      "5148/5148 - 2s - loss: 0.5428 - accuracy: 0.7382 - val_loss: 0.4489 - val_accuracy: 0.8665\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.5316 - accuracy: 0.7469 - val_loss: 0.4634 - val_accuracy: 0.8571\n",
      "Epoch 36/50\n",
      "5148/5148 - 2s - loss: 0.5373 - accuracy: 0.7420 - val_loss: 0.4698 - val_accuracy: 0.8339\n",
      "Epoch 37/50\n",
      "5148/5148 - 2s - loss: 0.5336 - accuracy: 0.7473 - val_loss: 0.4960 - val_accuracy: 0.7717\n",
      "Epoch 38/50\n",
      "5148/5148 - 2s - loss: 0.5346 - accuracy: 0.7436 - val_loss: 0.4410 - val_accuracy: 0.8680\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.5285 - accuracy: 0.7475 - val_loss: 0.4466 - val_accuracy: 0.8525\n",
      "Epoch 40/50\n",
      "5148/5148 - 2s - loss: 0.5328 - accuracy: 0.7453 - val_loss: 0.4555 - val_accuracy: 0.8339\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.5419 - accuracy: 0.7329 - val_loss: 0.4393 - val_accuracy: 0.8665\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.5273 - accuracy: 0.7517 - val_loss: 0.4589 - val_accuracy: 0.8339\n",
      "Epoch 43/50\n",
      "5148/5148 - 2s - loss: 0.5222 - accuracy: 0.7477 - val_loss: 0.4382 - val_accuracy: 0.8649\n",
      "Epoch 44/50\n",
      "5148/5148 - 2s - loss: 0.5320 - accuracy: 0.7446 - val_loss: 0.4362 - val_accuracy: 0.8680\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.5354 - accuracy: 0.7364 - val_loss: 0.4432 - val_accuracy: 0.8494\n",
      "Epoch 46/50\n",
      "5148/5148 - 2s - loss: 0.5182 - accuracy: 0.7438 - val_loss: 0.4123 - val_accuracy: 0.8634\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.5020 - accuracy: 0.7444 - val_loss: 0.3916 - val_accuracy: 0.8602\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.4886 - accuracy: 0.7444 - val_loss: 0.3874 - val_accuracy: 0.8509\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.4709 - accuracy: 0.7486 - val_loss: 0.3685 - val_accuracy: 0.8634\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.4730 - accuracy: 0.7343 - val_loss: 0.3692 - val_accuracy: 0.8634\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 19.2864 - accuracy: 0.5472 - val_loss: 0.7878 - val_accuracy: 0.5109\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.6518 - accuracy: 0.6375 - val_loss: 0.7899 - val_accuracy: 0.4922\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5876 - accuracy: 0.6950 - val_loss: 0.5300 - val_accuracy: 0.7314\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.6033 - accuracy: 0.6717 - val_loss: 0.5691 - val_accuracy: 0.7345\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.6169 - accuracy: 0.6430 - val_loss: 0.5138 - val_accuracy: 0.8385\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.5754 - accuracy: 0.6832 - val_loss: 0.5476 - val_accuracy: 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.5769 - accuracy: 0.7053 - val_loss: 0.6053 - val_accuracy: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 6 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.5835 - accuracy: 0.6999 - val_loss: 0.6149 - val_accuracy: 0.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 7 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.6468 - accuracy: 0.5998 - val_loss: 0.6775 - val_accuracy: 0.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 8 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.6589 - accuracy: 0.5670 - val_loss: 0.5805 - val_accuracy: 0.7748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 9 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.6815 - accuracy: 0.5258 - val_loss: 0.6897 - val_accuracy: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 10 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.6119 - accuracy: 0.6575 - val_loss: 0.6824 - val_accuracy: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 11 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.6210 - accuracy: 0.6523 - val_loss: 0.5324 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 12 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "5148/5148 - 2s - loss: 0.5836 - accuracy: 0.7096 - val_loss: 0.4978 - val_accuracy: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 13 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.5686 - accuracy: 0.7211 - val_loss: 0.4858 - val_accuracy: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 14 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "5148/5148 - 2s - loss: 0.5584 - accuracy: 0.7335 - val_loss: 0.4839 - val_accuracy: 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 15 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.5680 - accuracy: 0.7141 - val_loss: 0.5054 - val_accuracy: 0.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 16 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.5601 - accuracy: 0.7312 - val_loss: 0.4879 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 17 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "5148/5148 - 2s - loss: 0.5703 - accuracy: 0.7073 - val_loss: 0.5174 - val_accuracy: 0.7702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 18 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.5659 - accuracy: 0.7205 - val_loss: 0.4561 - val_accuracy: 0.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 19 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.5436 - accuracy: 0.7403 - val_loss: 0.4701 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 20 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.5346 - accuracy: 0.7463 - val_loss: 0.4563 - val_accuracy: 0.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 21 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "5148/5148 - 2s - loss: 0.5349 - accuracy: 0.7475 - val_loss: 0.5018 - val_accuracy: 0.7686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 22 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "5148/5148 - 2s - loss: 0.5400 - accuracy: 0.7368 - val_loss: 0.4517 - val_accuracy: 0.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 23 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.5421 - accuracy: 0.7366 - val_loss: 0.5335 - val_accuracy: 0.7484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 24 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.5399 - accuracy: 0.7383 - val_loss: 0.4391 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 25 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.5358 - accuracy: 0.7405 - val_loss: 0.5103 - val_accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 26 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.5305 - accuracy: 0.7422 - val_loss: 0.4358 - val_accuracy: 0.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 27 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.5410 - accuracy: 0.7306 - val_loss: 0.4821 - val_accuracy: 0.8199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 28 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.5219 - accuracy: 0.7564 - val_loss: 0.4312 - val_accuracy: 0.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 29 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.5418 - accuracy: 0.7341 - val_loss: 0.5716 - val_accuracy: 0.7189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 30 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.5357 - accuracy: 0.7350 - val_loss: 0.4459 - val_accuracy: 0.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 31 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.5305 - accuracy: 0.7432 - val_loss: 0.4341 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 32 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.5315 - accuracy: 0.7380 - val_loss: 0.4287 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 33 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.5339 - accuracy: 0.7360 - val_loss: 0.4402 - val_accuracy: 0.8323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 34 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.5252 - accuracy: 0.7415 - val_loss: 0.4295 - val_accuracy: 0.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 35 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.5287 - accuracy: 0.7362 - val_loss: 0.4773 - val_accuracy: 0.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 36 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.5192 - accuracy: 0.7473 - val_loss: 0.4534 - val_accuracy: 0.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 37 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.5296 - accuracy: 0.7391 - val_loss: 0.4253 - val_accuracy: 0.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 38 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.5232 - accuracy: 0.7436 - val_loss: 0.4484 - val_accuracy: 0.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 39 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.5257 - accuracy: 0.7416 - val_loss: 0.4434 - val_accuracy: 0.8370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 40 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.5265 - accuracy: 0.7438 - val_loss: 0.4248 - val_accuracy: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 41 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.5175 - accuracy: 0.7440 - val_loss: 0.4228 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 42 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.5236 - accuracy: 0.7422 - val_loss: 0.4243 - val_accuracy: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 43 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.5286 - accuracy: 0.7385 - val_loss: 0.4292 - val_accuracy: 0.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 44 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.5244 - accuracy: 0.7426 - val_loss: 0.4369 - val_accuracy: 0.8354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 45 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.5250 - accuracy: 0.7409 - val_loss: 0.4380 - val_accuracy: 0.8370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 46 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.5097 - accuracy: 0.7539 - val_loss: 0.4598 - val_accuracy: 0.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 47 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.5172 - accuracy: 0.7490 - val_loss: 0.4225 - val_accuracy: 0.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 48 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.5164 - accuracy: 0.7469 - val_loss: 0.4240 - val_accuracy: 0.8323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/envs/tf_env/lib/python3.7/site-packages/optuna/trial/_trial.py:495: UserWarning: The reported value is ignored because this `step` 49 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 19.9989 - accuracy: 0.5433 - val_loss: 0.7664 - val_accuracy: 0.5078\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.7011 - accuracy: 0.5789 - val_loss: 0.7515 - val_accuracy: 0.4922\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.7023 - accuracy: 0.5664 - val_loss: 0.6721 - val_accuracy: 0.4922\n",
      "Epoch 4/50\n",
      "5148/5148 - 2s - loss: 0.6536 - accuracy: 0.6134 - val_loss: 0.6494 - val_accuracy: 0.6320\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.6066 - accuracy: 0.6721 - val_loss: 0.6579 - val_accuracy: 0.6413\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.6343 - accuracy: 0.6296 - val_loss: 0.6733 - val_accuracy: 0.5854\n",
      "Epoch 7/50\n",
      "5148/5148 - 2s - loss: 0.5853 - accuracy: 0.7038 - val_loss: 0.5626 - val_accuracy: 0.7593\n",
      "Epoch 8/50\n",
      "5148/5148 - 2s - loss: 0.5881 - accuracy: 0.7007 - val_loss: 0.5238 - val_accuracy: 0.8385\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.5978 - accuracy: 0.6911 - val_loss: 0.5739 - val_accuracy: 0.7422\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.5622 - accuracy: 0.7341 - val_loss: 0.5300 - val_accuracy: 0.7593\n",
      "Epoch 11/50\n",
      "5148/5148 - 2s - loss: 0.5820 - accuracy: 0.6987 - val_loss: 0.5203 - val_accuracy: 0.7935\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.5635 - accuracy: 0.7284 - val_loss: 0.5372 - val_accuracy: 0.7562\n",
      "Epoch 13/50\n",
      "5148/5148 - 2s - loss: 0.5668 - accuracy: 0.7269 - val_loss: 0.5547 - val_accuracy: 0.7360\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.5611 - accuracy: 0.7242 - val_loss: 0.4797 - val_accuracy: 0.8556\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.5610 - accuracy: 0.7220 - val_loss: 0.6241 - val_accuracy: 0.6677\n",
      "Epoch 16/50\n",
      "5148/5148 - 2s - loss: 0.5541 - accuracy: 0.7279 - val_loss: 0.6194 - val_accuracy: 0.6708\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.5504 - accuracy: 0.7370 - val_loss: 0.5041 - val_accuracy: 0.8602\n",
      "Epoch 18/50\n",
      "5148/5148 - 2s - loss: 0.5467 - accuracy: 0.7362 - val_loss: 0.4683 - val_accuracy: 0.8587\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.5534 - accuracy: 0.7280 - val_loss: 0.4723 - val_accuracy: 0.8525\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.6603 - accuracy: 0.5723 - val_loss: 0.6867 - val_accuracy: 0.5186\n",
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.6699 - accuracy: 0.5425 - val_loss: 0.6909 - val_accuracy: 0.5171\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.6591 - accuracy: 0.5641 - val_loss: 0.4986 - val_accuracy: 0.8540\n",
      "Epoch 23/50\n",
      "5148/5148 - 2s - loss: 0.5752 - accuracy: 0.7022 - val_loss: 0.4917 - val_accuracy: 0.8354\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.5604 - accuracy: 0.7146 - val_loss: 0.4618 - val_accuracy: 0.8602\n",
      "Epoch 25/50\n",
      "5148/5148 - 2s - loss: 0.5409 - accuracy: 0.7354 - val_loss: 0.4778 - val_accuracy: 0.8199\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.5336 - accuracy: 0.7455 - val_loss: 0.4599 - val_accuracy: 0.8323\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.5372 - accuracy: 0.7374 - val_loss: 0.4472 - val_accuracy: 0.8571\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.5356 - accuracy: 0.7422 - val_loss: 0.4412 - val_accuracy: 0.8634\n",
      "Epoch 29/50\n",
      "5148/5148 - 2s - loss: 0.5410 - accuracy: 0.7323 - val_loss: 0.4891 - val_accuracy: 0.7717\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.5399 - accuracy: 0.7354 - val_loss: 0.4553 - val_accuracy: 0.8370\n",
      "Epoch 31/50\n",
      "5148/5148 - 2s - loss: 0.5386 - accuracy: 0.7370 - val_loss: 0.4348 - val_accuracy: 0.8649\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.5444 - accuracy: 0.7267 - val_loss: 0.5174 - val_accuracy: 0.7624\n",
      "Epoch 33/50\n",
      "5148/5148 - 2s - loss: 0.5289 - accuracy: 0.7436 - val_loss: 0.4345 - val_accuracy: 0.8618\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.5175 - accuracy: 0.7496 - val_loss: 0.4280 - val_accuracy: 0.8618\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.5271 - accuracy: 0.7434 - val_loss: 0.4406 - val_accuracy: 0.8339\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.5249 - accuracy: 0.7428 - val_loss: 0.4273 - val_accuracy: 0.8680\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.5348 - accuracy: 0.7343 - val_loss: 0.4685 - val_accuracy: 0.8292\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.5310 - accuracy: 0.7323 - val_loss: 0.4415 - val_accuracy: 0.8680\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.5369 - accuracy: 0.7300 - val_loss: 0.4296 - val_accuracy: 0.8618\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.5284 - accuracy: 0.7382 - val_loss: 0.4397 - val_accuracy: 0.8339\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.5279 - accuracy: 0.7413 - val_loss: 0.4577 - val_accuracy: 0.8323\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.5350 - accuracy: 0.7339 - val_loss: 0.4678 - val_accuracy: 0.8323\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.5140 - accuracy: 0.7527 - val_loss: 0.4186 - val_accuracy: 0.8696\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.5233 - accuracy: 0.7449 - val_loss: 0.4446 - val_accuracy: 0.8665\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.5262 - accuracy: 0.7418 - val_loss: 0.4270 - val_accuracy: 0.8680\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.5291 - accuracy: 0.7354 - val_loss: 0.4378 - val_accuracy: 0.8370\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.5308 - accuracy: 0.7376 - val_loss: 0.4458 - val_accuracy: 0.8354\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.5348 - accuracy: 0.7352 - val_loss: 0.4567 - val_accuracy: 0.8323\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.5210 - accuracy: 0.7436 - val_loss: 0.5018 - val_accuracy: 0.7686\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.5438 - accuracy: 0.7253 - val_loss: 0.4633 - val_accuracy: 0.8323\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 18.0340 - accuracy: 0.5216 - val_loss: 0.7368 - val_accuracy: 0.5078\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.7164 - accuracy: 0.5602 - val_loss: 0.6391 - val_accuracy: 0.4922\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.6418 - accuracy: 0.6323 - val_loss: 0.5991 - val_accuracy: 0.7407\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.6340 - accuracy: 0.6301 - val_loss: 0.6374 - val_accuracy: 0.6289\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.6024 - accuracy: 0.6828 - val_loss: 0.6374 - val_accuracy: 0.6475\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.6340 - accuracy: 0.6455 - val_loss: 0.6448 - val_accuracy: 0.5637\n",
      "Epoch 7/50\n",
      "5148/5148 - 2s - loss: 0.6381 - accuracy: 0.6348 - val_loss: 0.6509 - val_accuracy: 0.6351\n",
      "Epoch 8/50\n",
      "5148/5148 - 2s - loss: 0.6962 - accuracy: 0.5021 - val_loss: 0.6922 - val_accuracy: 0.5093\n",
      "Epoch 9/50\n",
      "5148/5148 - 2s - loss: 0.6928 - accuracy: 0.4998 - val_loss: 0.6885 - val_accuracy: 0.5512\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.6302 - accuracy: 0.6385 - val_loss: 0.6500 - val_accuracy: 0.6506\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.5929 - accuracy: 0.7010 - val_loss: 0.6027 - val_accuracy: 0.7329\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.5786 - accuracy: 0.7156 - val_loss: 0.5921 - val_accuracy: 0.7267\n",
      "Epoch 13/50\n",
      "5148/5148 - 2s - loss: 0.5667 - accuracy: 0.7249 - val_loss: 0.5047 - val_accuracy: 0.8401\n",
      "Epoch 14/50\n",
      "5148/5148 - 2s - loss: 0.5766 - accuracy: 0.7189 - val_loss: 0.5046 - val_accuracy: 0.8261\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.5700 - accuracy: 0.7244 - val_loss: 0.5069 - val_accuracy: 0.8199\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.5474 - accuracy: 0.7624 - val_loss: 0.5050 - val_accuracy: 0.8463\n",
      "Epoch 17/50\n",
      "5148/5148 - 2s - loss: 0.5185 - accuracy: 0.7815 - val_loss: 0.4635 - val_accuracy: 0.8401\n",
      "Epoch 18/50\n",
      "5148/5148 - 2s - loss: 0.4984 - accuracy: 0.7986 - val_loss: 0.4720 - val_accuracy: 0.8447\n",
      "Epoch 19/50\n",
      "5148/5148 - 2s - loss: 0.5121 - accuracy: 0.7811 - val_loss: 0.4626 - val_accuracy: 0.8494\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.4984 - accuracy: 0.7890 - val_loss: 0.4404 - val_accuracy: 0.8463\n",
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.4820 - accuracy: 0.8042 - val_loss: 0.4317 - val_accuracy: 0.8494\n",
      "Epoch 22/50\n",
      "5148/5148 - 2s - loss: 0.4939 - accuracy: 0.7947 - val_loss: 0.4375 - val_accuracy: 0.8587\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.4973 - accuracy: 0.7941 - val_loss: 0.4683 - val_accuracy: 0.7671\n",
      "Epoch 24/50\n",
      "5148/5148 - 2s - loss: 0.5008 - accuracy: 0.7863 - val_loss: 0.4783 - val_accuracy: 0.8587\n",
      "Epoch 25/50\n",
      "5148/5148 - 2s - loss: 0.5182 - accuracy: 0.7706 - val_loss: 0.5476 - val_accuracy: 0.7236\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.4815 - accuracy: 0.8034 - val_loss: 0.4268 - val_accuracy: 0.8587\n",
      "Epoch 27/50\n",
      "5148/5148 - 2s - loss: 0.4637 - accuracy: 0.8139 - val_loss: 0.4391 - val_accuracy: 0.8075\n",
      "Epoch 28/50\n",
      "5148/5148 - 2s - loss: 0.4600 - accuracy: 0.8139 - val_loss: 0.4171 - val_accuracy: 0.8432\n",
      "Epoch 29/50\n",
      "5148/5148 - 3s - loss: 0.4764 - accuracy: 0.8013 - val_loss: 0.4218 - val_accuracy: 0.8634\n",
      "Epoch 30/50\n",
      "5148/5148 - 3s - loss: 0.4688 - accuracy: 0.8040 - val_loss: 0.4330 - val_accuracy: 0.8152\n",
      "Epoch 31/50\n",
      "5148/5148 - 4s - loss: 0.4739 - accuracy: 0.7976 - val_loss: 0.4361 - val_accuracy: 0.8152\n",
      "Epoch 32/50\n",
      "5148/5148 - 2s - loss: 0.4740 - accuracy: 0.7962 - val_loss: 0.4039 - val_accuracy: 0.8618\n",
      "Epoch 33/50\n",
      "5148/5148 - 4s - loss: 0.4572 - accuracy: 0.8089 - val_loss: 0.4304 - val_accuracy: 0.8168\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.4593 - accuracy: 0.8042 - val_loss: 0.4171 - val_accuracy: 0.8634\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.4603 - accuracy: 0.8069 - val_loss: 0.4455 - val_accuracy: 0.7671\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.4541 - accuracy: 0.8092 - val_loss: 0.3923 - val_accuracy: 0.8618\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.4456 - accuracy: 0.8151 - val_loss: 0.4210 - val_accuracy: 0.8292\n",
      "Epoch 38/50\n",
      "5148/5148 - 2s - loss: 0.4605 - accuracy: 0.8067 - val_loss: 0.3998 - val_accuracy: 0.8385\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.4369 - accuracy: 0.8176 - val_loss: 0.3948 - val_accuracy: 0.8696\n",
      "Epoch 40/50\n",
      "5148/5148 - 2s - loss: 0.4495 - accuracy: 0.8106 - val_loss: 0.3902 - val_accuracy: 0.8665\n",
      "Epoch 41/50\n",
      "5148/5148 - 2s - loss: 0.4494 - accuracy: 0.8083 - val_loss: 0.4253 - val_accuracy: 0.7780\n",
      "Epoch 42/50\n",
      "5148/5148 - 3s - loss: 0.4422 - accuracy: 0.8098 - val_loss: 0.3934 - val_accuracy: 0.8339\n",
      "Epoch 43/50\n",
      "5148/5148 - 3s - loss: 0.4488 - accuracy: 0.8122 - val_loss: 0.4017 - val_accuracy: 0.8665\n",
      "Epoch 44/50\n",
      "5148/5148 - 3s - loss: 0.4452 - accuracy: 0.8110 - val_loss: 0.3922 - val_accuracy: 0.8711\n",
      "Epoch 45/50\n",
      "5148/5148 - 6s - loss: 0.4465 - accuracy: 0.8131 - val_loss: 0.3911 - val_accuracy: 0.8665\n",
      "Epoch 46/50\n",
      "5148/5148 - 4s - loss: 0.4531 - accuracy: 0.8040 - val_loss: 0.4040 - val_accuracy: 0.8354\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.4625 - accuracy: 0.8030 - val_loss: 0.3904 - val_accuracy: 0.8680\n",
      "Epoch 48/50\n",
      "5148/5148 - 2s - loss: 0.4402 - accuracy: 0.8143 - val_loss: 0.4004 - val_accuracy: 0.8354\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.4362 - accuracy: 0.8170 - val_loss: 0.4097 - val_accuracy: 0.8292\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.4549 - accuracy: 0.8054 - val_loss: 0.3899 - val_accuracy: 0.8323\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 18.4949 - accuracy: 0.5532 - val_loss: 0.6882 - val_accuracy: 0.5497\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.6699 - accuracy: 0.6544 - val_loss: 0.6002 - val_accuracy: 0.5466\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.6401 - accuracy: 0.6649 - val_loss: 0.6071 - val_accuracy: 0.5528\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.5765 - accuracy: 0.6908 - val_loss: 0.5139 - val_accuracy: 0.7531\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5491 - accuracy: 0.7082 - val_loss: 0.5554 - val_accuracy: 0.6988\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.6094 - accuracy: 0.6418 - val_loss: 0.6458 - val_accuracy: 0.4922\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.6019 - accuracy: 0.6700 - val_loss: 0.6327 - val_accuracy: 0.6289\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.6778 - accuracy: 0.5503 - val_loss: 0.5832 - val_accuracy: 0.7764\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.6276 - accuracy: 0.6420 - val_loss: 0.7024 - val_accuracy: 0.5124\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.6915 - accuracy: 0.5117 - val_loss: 0.6919 - val_accuracy: 0.5093\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.6923 - accuracy: 0.5066 - val_loss: 0.6922 - val_accuracy: 0.4922\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.6840 - accuracy: 0.5171 - val_loss: 0.5682 - val_accuracy: 0.7640\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.6640 - accuracy: 0.5688 - val_loss: 0.6898 - val_accuracy: 0.5140\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.6409 - accuracy: 0.6086 - val_loss: 0.5703 - val_accuracy: 0.6382\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.5952 - accuracy: 0.6822 - val_loss: 0.7115 - val_accuracy: 0.5140\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.6807 - accuracy: 0.5427 - val_loss: 0.5613 - val_accuracy: 0.7919\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.5802 - accuracy: 0.7183 - val_loss: 0.5152 - val_accuracy: 0.8540\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.5583 - accuracy: 0.7354 - val_loss: 0.4844 - val_accuracy: 0.8447\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.5705 - accuracy: 0.7100 - val_loss: 0.5347 - val_accuracy: 0.7888\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.5692 - accuracy: 0.7187 - val_loss: 0.5155 - val_accuracy: 0.7919\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.5474 - accuracy: 0.7440 - val_loss: 0.4741 - val_accuracy: 0.8525\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.5448 - accuracy: 0.7418 - val_loss: 0.4774 - val_accuracy: 0.8354\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.5398 - accuracy: 0.7516 - val_loss: 0.4690 - val_accuracy: 0.8540\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.5489 - accuracy: 0.7335 - val_loss: 0.4791 - val_accuracy: 0.8276\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.5317 - accuracy: 0.7533 - val_loss: 0.5045 - val_accuracy: 0.7671\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.5418 - accuracy: 0.7399 - val_loss: 0.4597 - val_accuracy: 0.8571\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.5330 - accuracy: 0.7496 - val_loss: 0.4587 - val_accuracy: 0.8634\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.4911 - accuracy: 0.8061 - val_loss: 0.4585 - val_accuracy: 0.8525\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.4790 - accuracy: 0.8026 - val_loss: 0.4717 - val_accuracy: 0.8540\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.4818 - accuracy: 0.7982 - val_loss: 0.4434 - val_accuracy: 0.8245\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.4641 - accuracy: 0.8098 - val_loss: 0.4364 - val_accuracy: 0.8432\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.4749 - accuracy: 0.8007 - val_loss: 0.4345 - val_accuracy: 0.8509\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.4650 - accuracy: 0.8102 - val_loss: 0.4187 - val_accuracy: 0.8556\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.4623 - accuracy: 0.8112 - val_loss: 0.4144 - val_accuracy: 0.8602\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.4590 - accuracy: 0.8100 - val_loss: 0.4129 - val_accuracy: 0.8556\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.4626 - accuracy: 0.8044 - val_loss: 0.4169 - val_accuracy: 0.8571\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.4515 - accuracy: 0.8089 - val_loss: 0.4268 - val_accuracy: 0.8432\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.4555 - accuracy: 0.8048 - val_loss: 0.4105 - val_accuracy: 0.8665\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.4628 - accuracy: 0.8015 - val_loss: 0.4065 - val_accuracy: 0.8665\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.4496 - accuracy: 0.8085 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.4563 - accuracy: 0.8085 - val_loss: 0.4276 - val_accuracy: 0.8028\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.4573 - accuracy: 0.8106 - val_loss: 0.4059 - val_accuracy: 0.8665\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.4499 - accuracy: 0.8063 - val_loss: 0.4006 - val_accuracy: 0.8634\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.4597 - accuracy: 0.8019 - val_loss: 0.3994 - val_accuracy: 0.8649\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.4431 - accuracy: 0.8127 - val_loss: 0.4018 - val_accuracy: 0.8649\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.4472 - accuracy: 0.8139 - val_loss: 0.3990 - val_accuracy: 0.8540\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.4448 - accuracy: 0.8125 - val_loss: 0.4029 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.4335 - accuracy: 0.8153 - val_loss: 0.4167 - val_accuracy: 0.8571\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.4347 - accuracy: 0.8205 - val_loss: 0.4131 - val_accuracy: 0.8571\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.4275 - accuracy: 0.8254 - val_loss: 0.4054 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:33:08,121] Trial 1 finished with value: 0.8692547082901001 and parameters: {'units': 60, 'dropout': 0.35000000000000003, 'learning_rate': 0.005993902800717084, 'epochs': 50, 'batch_size': 20, 'patience': 7, 'factor': 0.5}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 2s - loss: 81.8407 - accuracy: 0.5035 - val_loss: 4.2724 - val_accuracy: 0.4922\n",
      "Epoch 2/5\n",
      "5148/5148 - 1s - loss: 58.8445 - accuracy: 0.5173 - val_loss: 3.6212 - val_accuracy: 0.5078\n",
      "Epoch 3/5\n",
      "5148/5148 - 1s - loss: 55.3373 - accuracy: 0.5111 - val_loss: 2.2474 - val_accuracy: 0.5109\n",
      "Epoch 4/5\n",
      "5148/5148 - 1s - loss: 55.6436 - accuracy: 0.4963 - val_loss: 0.8043 - val_accuracy: 0.6661\n",
      "Epoch 5/5\n",
      "5148/5148 - 1s - loss: 50.7595 - accuracy: 0.4963 - val_loss: 0.7579 - val_accuracy: 0.6786\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 2s - loss: 73.3466 - accuracy: 0.4932 - val_loss: 2.6790 - val_accuracy: 0.4922\n",
      "Epoch 2/5\n",
      "5148/5148 - 1s - loss: 47.9462 - accuracy: 0.4926 - val_loss: 3.3866 - val_accuracy: 0.4922\n",
      "Epoch 3/5\n",
      "5148/5148 - 1s - loss: 44.2615 - accuracy: 0.5084 - val_loss: 0.7000 - val_accuracy: 0.5668\n",
      "Epoch 4/5\n",
      "5148/5148 - 6s - loss: 40.0533 - accuracy: 0.5212 - val_loss: 0.8371 - val_accuracy: 0.5419\n",
      "Epoch 5/5\n",
      "5148/5148 - 1s - loss: 38.8779 - accuracy: 0.5076 - val_loss: 0.4761 - val_accuracy: 0.7717\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 3s - loss: 151.3857 - accuracy: 0.5023 - val_loss: 24.4963 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "5148/5148 - 2s - loss: 57.1915 - accuracy: 0.4994 - val_loss: 0.5257 - val_accuracy: 0.7314\n",
      "Epoch 3/5\n",
      "5148/5148 - 1s - loss: 50.1069 - accuracy: 0.5076 - val_loss: 4.7750 - val_accuracy: 0.5078\n",
      "Epoch 4/5\n",
      "5148/5148 - 1s - loss: 49.3174 - accuracy: 0.4992 - val_loss: 2.6162 - val_accuracy: 0.5109\n",
      "Epoch 5/5\n",
      "5148/5148 - 2s - loss: 46.6318 - accuracy: 0.5029 - val_loss: 0.9004 - val_accuracy: 0.4953\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 2s - loss: 82.8287 - accuracy: 0.4949 - val_loss: 1.6280 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "5148/5148 - 1s - loss: 42.7587 - accuracy: 0.5070 - val_loss: 1.9122 - val_accuracy: 0.5078\n",
      "Epoch 3/5\n",
      "5148/5148 - 1s - loss: 39.6513 - accuracy: 0.5064 - val_loss: 1.0579 - val_accuracy: 0.4953\n",
      "Epoch 4/5\n",
      "5148/5148 - 1s - loss: 38.0423 - accuracy: 0.5072 - val_loss: 0.6997 - val_accuracy: 0.6258\n",
      "Epoch 5/5\n",
      "5148/5148 - 1s - loss: 34.5624 - accuracy: 0.5117 - val_loss: 0.5021 - val_accuracy: 0.7609\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 2s - loss: 56.8839 - accuracy: 0.5087 - val_loss: 5.7867 - val_accuracy: 0.4922\n",
      "Epoch 2/5\n",
      "5148/5148 - 1s - loss: 53.9889 - accuracy: 0.5054 - val_loss: 1.7238 - val_accuracy: 0.4922\n",
      "Epoch 3/5\n",
      "5148/5148 - 1s - loss: 47.6726 - accuracy: 0.5058 - val_loss: 1.6972 - val_accuracy: 0.5093\n",
      "Epoch 4/5\n",
      "5148/5148 - 1s - loss: 45.7519 - accuracy: 0.5049 - val_loss: 0.9285 - val_accuracy: 0.4922\n",
      "Epoch 5/5\n",
      "5148/5148 - 1s - loss: 42.0904 - accuracy: 0.5138 - val_loss: 1.2495 - val_accuracy: 0.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:33:41,887] Trial 2 finished with value: 0.694720447063446 and parameters: {'units': 65, 'dropout': 0.15000000000000002, 'learning_rate': 0.00012574542285984544, 'epochs': 5, 'batch_size': 20, 'patience': 8, 'factor': 0.1}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n",
      "5148/5148 - 3s - loss: 397.9292 - accuracy: 0.4986 - val_loss: 203.1567 - val_accuracy: 0.4922\n",
      "Epoch 2/15\n",
      "5148/5148 - 2s - loss: 129.6117 - accuracy: 0.5043 - val_loss: 11.8029 - val_accuracy: 0.4922\n",
      "Epoch 3/15\n",
      "5148/5148 - 3s - loss: 93.3887 - accuracy: 0.5045 - val_loss: 0.4812 - val_accuracy: 0.7376\n",
      "Epoch 4/15\n",
      "5148/5148 - 4s - loss: 79.2768 - accuracy: 0.5060 - val_loss: 2.1792 - val_accuracy: 0.5124\n",
      "Epoch 5/15\n",
      "5148/5148 - 5s - loss: 69.4919 - accuracy: 0.5126 - val_loss: 1.9680 - val_accuracy: 0.5124\n",
      "Epoch 6/15\n",
      "5148/5148 - 5s - loss: 59.1588 - accuracy: 0.5072 - val_loss: 7.1945 - val_accuracy: 0.4922\n",
      "Epoch 7/15\n",
      "5148/5148 - 5s - loss: 50.1394 - accuracy: 0.5062 - val_loss: 0.4864 - val_accuracy: 0.7640\n",
      "Epoch 8/15\n",
      "5148/5148 - 5s - loss: 41.1515 - accuracy: 0.5037 - val_loss: 1.3531 - val_accuracy: 0.5947\n",
      "Epoch 9/15\n",
      "5148/5148 - 6s - loss: 32.3115 - accuracy: 0.4953 - val_loss: 0.8248 - val_accuracy: 0.6134\n",
      "Epoch 10/15\n",
      "5148/5148 - 5s - loss: 24.8538 - accuracy: 0.5087 - val_loss: 0.7324 - val_accuracy: 0.7329\n",
      "Epoch 11/15\n",
      "5148/5148 - 7s - loss: 17.0669 - accuracy: 0.5245 - val_loss: 0.6936 - val_accuracy: 0.7407\n",
      "Epoch 12/15\n",
      "5148/5148 - 5s - loss: 12.3868 - accuracy: 0.5220 - val_loss: 0.5630 - val_accuracy: 0.7562\n",
      "Epoch 13/15\n",
      "5148/5148 - 5s - loss: 9.7038 - accuracy: 0.5307 - val_loss: 0.6025 - val_accuracy: 0.7422\n",
      "Epoch 14/15\n",
      "5148/5148 - 5s - loss: 9.1252 - accuracy: 0.5295 - val_loss: 0.5603 - val_accuracy: 0.7640\n",
      "Epoch 15/15\n",
      "5148/5148 - 5s - loss: 8.1236 - accuracy: 0.5490 - val_loss: 0.5582 - val_accuracy: 0.8230\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n",
      "5148/5148 - 3s - loss: 120.6223 - accuracy: 0.5062 - val_loss: 13.9721 - val_accuracy: 0.5078\n",
      "Epoch 2/15\n",
      "5148/5148 - 3s - loss: 91.1092 - accuracy: 0.5051 - val_loss: 0.8984 - val_accuracy: 0.5093\n",
      "Epoch 3/15\n",
      "5148/5148 - 2s - loss: 78.5937 - accuracy: 0.5016 - val_loss: 0.8487 - val_accuracy: 0.5124\n",
      "Epoch 4/15\n",
      "5148/5148 - 3s - loss: 65.3915 - accuracy: 0.5023 - val_loss: 3.2721 - val_accuracy: 0.4922\n",
      "Epoch 5/15\n",
      "5148/5148 - 3s - loss: 55.2379 - accuracy: 0.4949 - val_loss: 0.8012 - val_accuracy: 0.5264\n",
      "Epoch 6/15\n",
      "5148/5148 - 2s - loss: 44.0834 - accuracy: 0.5072 - val_loss: 3.8117 - val_accuracy: 0.4922\n",
      "Epoch 7/15\n",
      "5148/5148 - 2s - loss: 35.2317 - accuracy: 0.5035 - val_loss: 0.5305 - val_accuracy: 0.7267\n",
      "Epoch 8/15\n",
      "5148/5148 - 4s - loss: 27.0332 - accuracy: 0.5117 - val_loss: 0.5100 - val_accuracy: 0.7158\n",
      "Epoch 9/15\n",
      "5148/5148 - 5s - loss: 19.9888 - accuracy: 0.5186 - val_loss: 0.5599 - val_accuracy: 0.8401\n",
      "Epoch 10/15\n",
      "5148/5148 - 6s - loss: 14.4073 - accuracy: 0.5023 - val_loss: 0.5362 - val_accuracy: 0.8292\n",
      "Epoch 11/15\n",
      "5148/5148 - 5s - loss: 8.3776 - accuracy: 0.5293 - val_loss: 0.6116 - val_accuracy: 0.6693\n",
      "Epoch 12/15\n",
      "5148/5148 - 7s - loss: 4.2594 - accuracy: 0.5429 - val_loss: 0.5634 - val_accuracy: 0.7189\n",
      "Epoch 13/15\n",
      "5148/5148 - 12s - loss: 1.6018 - accuracy: 0.5861 - val_loss: 0.4980 - val_accuracy: 0.7329\n",
      "Epoch 14/15\n",
      "5148/5148 - 6s - loss: 0.6678 - accuracy: 0.6733 - val_loss: 0.4867 - val_accuracy: 0.8137\n",
      "Epoch 15/15\n",
      "5148/5148 - 5s - loss: 0.5490 - accuracy: 0.7325 - val_loss: 0.4840 - val_accuracy: 0.7500\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n",
      "5148/5148 - 3s - loss: 246.3816 - accuracy: 0.5035 - val_loss: 51.8915 - val_accuracy: 0.5078\n",
      "Epoch 2/15\n",
      "5148/5148 - 5s - loss: 145.6194 - accuracy: 0.5056 - val_loss: 0.7958 - val_accuracy: 0.5031\n",
      "Epoch 3/15\n",
      "5148/5148 - 5s - loss: 129.0271 - accuracy: 0.5052 - val_loss: 9.6281 - val_accuracy: 0.5078\n",
      "Epoch 4/15\n",
      "5148/5148 - 3s - loss: 116.6034 - accuracy: 0.5051 - val_loss: 0.7811 - val_accuracy: 0.5450\n",
      "Epoch 5/15\n",
      "5148/5148 - 3s - loss: 103.9740 - accuracy: 0.5049 - val_loss: 2.2923 - val_accuracy: 0.5140\n",
      "Epoch 6/15\n",
      "5148/5148 - 2s - loss: 96.0295 - accuracy: 0.4994 - val_loss: 7.8615 - val_accuracy: 0.4922\n",
      "Epoch 7/15\n",
      "5148/5148 - 2s - loss: 85.3204 - accuracy: 0.4870 - val_loss: 0.5557 - val_accuracy: 0.8525\n",
      "Epoch 8/15\n",
      "5148/5148 - 3s - loss: 70.0332 - accuracy: 0.5033 - val_loss: 1.3624 - val_accuracy: 0.6087\n",
      "Epoch 9/15\n",
      "5148/5148 - 2s - loss: 59.3031 - accuracy: 0.5153 - val_loss: 0.9996 - val_accuracy: 0.6894\n",
      "Epoch 10/15\n",
      "5148/5148 - 2s - loss: 49.7374 - accuracy: 0.5060 - val_loss: 1.6117 - val_accuracy: 0.6056\n",
      "Epoch 11/15\n",
      "5148/5148 - 4s - loss: 41.8043 - accuracy: 0.5140 - val_loss: 0.7717 - val_accuracy: 0.7314\n",
      "Epoch 12/15\n",
      "5148/5148 - 7s - loss: 34.7533 - accuracy: 0.5171 - val_loss: 0.6467 - val_accuracy: 0.8401\n",
      "Epoch 13/15\n",
      "5148/5148 - 11s - loss: 29.5253 - accuracy: 0.5198 - val_loss: 0.6290 - val_accuracy: 0.7842\n",
      "Epoch 14/15\n",
      "5148/5148 - 8s - loss: 28.6016 - accuracy: 0.5229 - val_loss: 0.7459 - val_accuracy: 0.7345\n",
      "Epoch 15/15\n",
      "5148/5148 - 14s - loss: 28.0879 - accuracy: 0.5291 - val_loss: 0.7732 - val_accuracy: 0.7329\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n",
      "5148/5148 - 3s - loss: 156.0040 - accuracy: 0.5089 - val_loss: 12.8398 - val_accuracy: 0.5078\n",
      "Epoch 2/15\n",
      "5148/5148 - 2s - loss: 126.0891 - accuracy: 0.4977 - val_loss: 1.8354 - val_accuracy: 0.5109\n",
      "Epoch 3/15\n",
      "5148/5148 - 2s - loss: 111.8063 - accuracy: 0.4918 - val_loss: 0.8941 - val_accuracy: 0.5326\n",
      "Epoch 4/15\n",
      "5148/5148 - 3s - loss: 93.5590 - accuracy: 0.5134 - val_loss: 1.0313 - val_accuracy: 0.5419\n",
      "Epoch 5/15\n",
      "5148/5148 - 11s - loss: 84.0369 - accuracy: 0.5023 - val_loss: 5.7983 - val_accuracy: 0.5078\n",
      "Epoch 6/15\n",
      "5148/5148 - 5s - loss: 72.2141 - accuracy: 0.4922 - val_loss: 1.0406 - val_accuracy: 0.4953\n",
      "Epoch 7/15\n",
      "5148/5148 - 4s - loss: 61.4495 - accuracy: 0.5023 - val_loss: 0.5018 - val_accuracy: 0.7345\n",
      "Epoch 8/15\n",
      "5148/5148 - 4s - loss: 52.2678 - accuracy: 0.5070 - val_loss: 1.3738 - val_accuracy: 0.5543\n",
      "Epoch 9/15\n",
      "5148/5148 - 4s - loss: 41.9486 - accuracy: 0.5157 - val_loss: 0.7671 - val_accuracy: 0.6087\n",
      "Epoch 10/15\n",
      "5148/5148 - 4s - loss: 34.4658 - accuracy: 0.5095 - val_loss: 0.5951 - val_accuracy: 0.8416\n",
      "Epoch 11/15\n",
      "5148/5148 - 4s - loss: 26.3743 - accuracy: 0.5163 - val_loss: 0.5138 - val_accuracy: 0.8168\n",
      "Epoch 12/15\n",
      "5148/5148 - 4s - loss: 20.6798 - accuracy: 0.5087 - val_loss: 0.9168 - val_accuracy: 0.6693\n",
      "Epoch 13/15\n",
      "5148/5148 - 4s - loss: 14.3475 - accuracy: 0.5258 - val_loss: 1.8458 - val_accuracy: 0.5373\n",
      "Epoch 14/15\n",
      "5148/5148 - 4s - loss: 9.6182 - accuracy: 0.5262 - val_loss: 0.6703 - val_accuracy: 0.7298\n",
      "Epoch 15/15\n",
      "5148/5148 - 4s - loss: 5.6931 - accuracy: 0.5389 - val_loss: 0.5385 - val_accuracy: 0.7531\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n",
      "5148/5148 - 6s - loss: 104.0218 - accuracy: 0.5051 - val_loss: 3.9756 - val_accuracy: 0.5078\n",
      "Epoch 2/15\n",
      "5148/5148 - 8s - loss: 85.1123 - accuracy: 0.5012 - val_loss: 1.0920 - val_accuracy: 0.4922\n",
      "Epoch 3/15\n",
      "5148/5148 - 10s - loss: 71.0917 - accuracy: 0.4891 - val_loss: 3.6883 - val_accuracy: 0.4922\n",
      "Epoch 4/15\n",
      "5148/5148 - 6s - loss: 60.8934 - accuracy: 0.4889 - val_loss: 0.5302 - val_accuracy: 0.7391\n",
      "Epoch 5/15\n",
      "5148/5148 - 5s - loss: 48.2453 - accuracy: 0.5049 - val_loss: 0.5146 - val_accuracy: 0.7314\n",
      "Epoch 6/15\n",
      "5148/5148 - 10s - loss: 36.9041 - accuracy: 0.5274 - val_loss: 3.1892 - val_accuracy: 0.4922\n",
      "Epoch 7/15\n",
      "5148/5148 - 10s - loss: 30.7441 - accuracy: 0.5066 - val_loss: 0.7221 - val_accuracy: 0.6382\n",
      "Epoch 8/15\n",
      "5148/5148 - 10s - loss: 23.1576 - accuracy: 0.5017 - val_loss: 0.4938 - val_accuracy: 0.7547\n",
      "Epoch 9/15\n",
      "5148/5148 - 11s - loss: 17.1630 - accuracy: 0.5208 - val_loss: 0.4949 - val_accuracy: 0.7686\n",
      "Epoch 10/15\n",
      "5148/5148 - 6s - loss: 11.7726 - accuracy: 0.5161 - val_loss: 0.4894 - val_accuracy: 0.7438\n",
      "Epoch 11/15\n",
      "5148/5148 - 6s - loss: 7.0978 - accuracy: 0.5237 - val_loss: 0.5139 - val_accuracy: 0.7267\n",
      "Epoch 12/15\n",
      "5148/5148 - 10s - loss: 3.6405 - accuracy: 0.5443 - val_loss: 0.5094 - val_accuracy: 0.7298\n",
      "Epoch 13/15\n",
      "5148/5148 - 9s - loss: 1.5583 - accuracy: 0.5987 - val_loss: 0.5332 - val_accuracy: 0.7329\n",
      "Epoch 14/15\n",
      "5148/5148 - 13s - loss: 0.6731 - accuracy: 0.6997 - val_loss: 0.4714 - val_accuracy: 0.7717\n",
      "Epoch 15/15\n",
      "5148/5148 - 11s - loss: 0.5065 - accuracy: 0.7745 - val_loss: 0.4763 - val_accuracy: 0.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:40:32,102] Trial 3 finished with value: 0.8257763981819153 and parameters: {'units': 35, 'dropout': 0.35000000000000003, 'learning_rate': 6.385629676439278e-05, 'epochs': 15, 'batch_size': 5, 'patience': 5, 'factor': 0.1}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 3.0153 - accuracy: 0.6909 - val_loss: 1.4304 - val_accuracy: 0.5202\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.9665 - accuracy: 0.7510 - val_loss: 0.9452 - val_accuracy: 0.7205\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 1.0136 - accuracy: 0.7661 - val_loss: 1.2243 - val_accuracy: 0.7065\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 1.0751 - accuracy: 0.7652 - val_loss: 1.5090 - val_accuracy: 0.5994\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 1.6079 - accuracy: 0.7339 - val_loss: 6.9119 - val_accuracy: 0.4922\n",
      "Epoch 6/45\n",
      "5148/5148 - 2s - loss: 1.1593 - accuracy: 0.7846 - val_loss: 1.2883 - val_accuracy: 0.7469\n",
      "Epoch 7/45\n",
      "5148/5148 - 2s - loss: 1.3715 - accuracy: 0.7791 - val_loss: 1.5329 - val_accuracy: 0.7283\n",
      "Epoch 8/45\n",
      "5148/5148 - 2s - loss: 0.8190 - accuracy: 0.8355 - val_loss: 1.4726 - val_accuracy: 0.6227\n",
      "Epoch 9/45\n",
      "5148/5148 - 2s - loss: 1.0583 - accuracy: 0.7887 - val_loss: 1.0240 - val_accuracy: 0.7624\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 1.0767 - accuracy: 0.7958 - val_loss: 0.8162 - val_accuracy: 0.8230\n",
      "Epoch 11/45\n",
      "5148/5148 - 2s - loss: 0.8813 - accuracy: 0.8205 - val_loss: 1.1632 - val_accuracy: 0.7748\n",
      "Epoch 12/45\n",
      "5148/5148 - 2s - loss: 0.8245 - accuracy: 0.8248 - val_loss: 0.7407 - val_accuracy: 0.8307\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.8260 - accuracy: 0.8188 - val_loss: 0.6424 - val_accuracy: 0.8571\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 1.4311 - accuracy: 0.7644 - val_loss: 3.2337 - val_accuracy: 0.6630\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 1.3061 - accuracy: 0.7914 - val_loss: 0.8238 - val_accuracy: 0.8634\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 1.3207 - accuracy: 0.7955 - val_loss: 0.8233 - val_accuracy: 0.8354\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.9773 - accuracy: 0.8180 - val_loss: 0.8304 - val_accuracy: 0.8571\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.8898 - accuracy: 0.8230 - val_loss: 1.2557 - val_accuracy: 0.7686\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 1.0032 - accuracy: 0.8069 - val_loss: 1.3090 - val_accuracy: 0.7640\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 1.7527 - accuracy: 0.7772 - val_loss: 1.2862 - val_accuracy: 0.8571\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.9678 - accuracy: 0.8211 - val_loss: 0.7800 - val_accuracy: 0.8540\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.9087 - accuracy: 0.8310 - val_loss: 1.6256 - val_accuracy: 0.6071\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.7654 - accuracy: 0.8304 - val_loss: 0.6790 - val_accuracy: 0.8339\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.9917 - accuracy: 0.8135 - val_loss: 0.9703 - val_accuracy: 0.7842\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.9328 - accuracy: 0.8118 - val_loss: 1.6065 - val_accuracy: 0.6071\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.7539 - accuracy: 0.8355 - val_loss: 0.6372 - val_accuracy: 0.8385\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.6977 - accuracy: 0.8386 - val_loss: 1.0862 - val_accuracy: 0.7795\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.5682 - accuracy: 0.8438 - val_loss: 0.5626 - val_accuracy: 0.8307\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.7561 - accuracy: 0.8207 - val_loss: 0.9248 - val_accuracy: 0.7795\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.6120 - accuracy: 0.8372 - val_loss: 0.7403 - val_accuracy: 0.8323\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.6335 - accuracy: 0.8316 - val_loss: 1.0450 - val_accuracy: 0.7019\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.7840 - accuracy: 0.8073 - val_loss: 1.1282 - val_accuracy: 0.7671\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.7635 - accuracy: 0.8213 - val_loss: 1.4672 - val_accuracy: 0.5823\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.6316 - accuracy: 0.8397 - val_loss: 0.5689 - val_accuracy: 0.8339\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.6894 - accuracy: 0.8166 - val_loss: 0.5403 - val_accuracy: 0.8323\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.5117 - accuracy: 0.8493 - val_loss: 0.9114 - val_accuracy: 0.7748\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.4897 - accuracy: 0.8557 - val_loss: 0.5152 - val_accuracy: 0.8618\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.4742 - accuracy: 0.8458 - val_loss: 0.4810 - val_accuracy: 0.8261\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.4681 - accuracy: 0.8485 - val_loss: 0.6947 - val_accuracy: 0.7888\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.4892 - accuracy: 0.8386 - val_loss: 0.5738 - val_accuracy: 0.8447\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.4534 - accuracy: 0.8514 - val_loss: 0.4645 - val_accuracy: 0.8323\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.5293 - accuracy: 0.8343 - val_loss: 0.4717 - val_accuracy: 0.8339\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.4799 - accuracy: 0.8479 - val_loss: 0.5787 - val_accuracy: 0.8587\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.5152 - accuracy: 0.8382 - val_loss: 0.4655 - val_accuracy: 0.8556\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.4550 - accuracy: 0.8512 - val_loss: 0.4648 - val_accuracy: 0.8370\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 2.4690 - accuracy: 0.6906 - val_loss: 0.6010 - val_accuracy: 0.8571\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.7783 - accuracy: 0.7628 - val_loss: 0.6543 - val_accuracy: 0.7252\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.6621 - accuracy: 0.7774 - val_loss: 0.4483 - val_accuracy: 0.8571\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.6492 - accuracy: 0.7772 - val_loss: 1.4973 - val_accuracy: 0.5124\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.8204 - accuracy: 0.7626 - val_loss: 2.5787 - val_accuracy: 0.4984\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.6057 - accuracy: 0.8098 - val_loss: 0.4765 - val_accuracy: 0.8665\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.7714 - accuracy: 0.7918 - val_loss: 0.7795 - val_accuracy: 0.7516\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.5051 - accuracy: 0.8320 - val_loss: 0.7287 - val_accuracy: 0.8292\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4868 - accuracy: 0.8353 - val_loss: 0.6809 - val_accuracy: 0.7640\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.5565 - accuracy: 0.8098 - val_loss: 1.0631 - val_accuracy: 0.7189\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.5954 - accuracy: 0.8159 - val_loss: 0.4724 - val_accuracy: 0.8556\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4684 - accuracy: 0.8427 - val_loss: 0.6086 - val_accuracy: 0.7702\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.6143 - accuracy: 0.8001 - val_loss: 0.9777 - val_accuracy: 0.7360\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.5734 - accuracy: 0.8170 - val_loss: 0.5471 - val_accuracy: 0.7842\n",
      "Epoch 15/45\n",
      "5148/5148 - 3s - loss: 0.6048 - accuracy: 0.8026 - val_loss: 0.4577 - val_accuracy: 0.8649\n",
      "Epoch 16/45\n",
      "5148/5148 - 2s - loss: 0.5973 - accuracy: 0.8160 - val_loss: 0.5021 - val_accuracy: 0.8323\n",
      "Epoch 17/45\n",
      "5148/5148 - 2s - loss: 0.4430 - accuracy: 0.8438 - val_loss: 0.4288 - val_accuracy: 0.8494\n",
      "Epoch 18/45\n",
      "5148/5148 - 2s - loss: 0.4480 - accuracy: 0.8415 - val_loss: 0.5358 - val_accuracy: 0.8602\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4478 - accuracy: 0.8446 - val_loss: 0.4533 - val_accuracy: 0.8556\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4214 - accuracy: 0.8456 - val_loss: 0.4551 - val_accuracy: 0.8276\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.4920 - accuracy: 0.8254 - val_loss: 0.4312 - val_accuracy: 0.8276\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.4267 - accuracy: 0.8399 - val_loss: 0.4944 - val_accuracy: 0.8168\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3909 - accuracy: 0.8454 - val_loss: 0.3981 - val_accuracy: 0.8602\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.4088 - accuracy: 0.8425 - val_loss: 0.6044 - val_accuracy: 0.8540\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4088 - accuracy: 0.8475 - val_loss: 0.4497 - val_accuracy: 0.8230\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4175 - accuracy: 0.8407 - val_loss: 0.4355 - val_accuracy: 0.8587\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3838 - accuracy: 0.8491 - val_loss: 0.4445 - val_accuracy: 0.8292\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3570 - accuracy: 0.8531 - val_loss: 0.5510 - val_accuracy: 0.7748\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3808 - accuracy: 0.8539 - val_loss: 0.3988 - val_accuracy: 0.8571\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3749 - accuracy: 0.8512 - val_loss: 0.3822 - val_accuracy: 0.8354\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3526 - accuracy: 0.8566 - val_loss: 0.4245 - val_accuracy: 0.8556\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3738 - accuracy: 0.8485 - val_loss: 0.3793 - val_accuracy: 0.8354\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3651 - accuracy: 0.8516 - val_loss: 0.3817 - val_accuracy: 0.8463\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3476 - accuracy: 0.8574 - val_loss: 0.4833 - val_accuracy: 0.7857\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3706 - accuracy: 0.8559 - val_loss: 0.5432 - val_accuracy: 0.7733\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3677 - accuracy: 0.8495 - val_loss: 0.5051 - val_accuracy: 0.7826\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3505 - accuracy: 0.8563 - val_loss: 0.3765 - val_accuracy: 0.8323\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3475 - accuracy: 0.8590 - val_loss: 0.3767 - val_accuracy: 0.8307\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3302 - accuracy: 0.8596 - val_loss: 0.3784 - val_accuracy: 0.8307\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3376 - accuracy: 0.8601 - val_loss: 0.4141 - val_accuracy: 0.8292\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3440 - accuracy: 0.8572 - val_loss: 0.3994 - val_accuracy: 0.8556\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3428 - accuracy: 0.8572 - val_loss: 0.4091 - val_accuracy: 0.8261\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3405 - accuracy: 0.8623 - val_loss: 0.3879 - val_accuracy: 0.8571\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3353 - accuracy: 0.8568 - val_loss: 0.3897 - val_accuracy: 0.8556\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3352 - accuracy: 0.8584 - val_loss: 0.3867 - val_accuracy: 0.8571\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 3s - loss: 5.1809 - accuracy: 0.6647 - val_loss: 0.6718 - val_accuracy: 0.8618\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.8387 - accuracy: 0.7574 - val_loss: 0.6870 - val_accuracy: 0.7407\n",
      "Epoch 3/45\n",
      "5148/5148 - 2s - loss: 0.7663 - accuracy: 0.7686 - val_loss: 0.4486 - val_accuracy: 0.8665\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.7571 - accuracy: 0.7747 - val_loss: 1.6994 - val_accuracy: 0.5124\n",
      "Epoch 5/45\n",
      "5148/5148 - 2s - loss: 0.9649 - accuracy: 0.7572 - val_loss: 1.2467 - val_accuracy: 0.6366\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.6244 - accuracy: 0.8159 - val_loss: 2.0095 - val_accuracy: 0.6429\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.9437 - accuracy: 0.7760 - val_loss: 0.7710 - val_accuracy: 0.7562\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.6158 - accuracy: 0.8318 - val_loss: 0.9691 - val_accuracy: 0.7174\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.6705 - accuracy: 0.8079 - val_loss: 1.2291 - val_accuracy: 0.7267\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.7372 - accuracy: 0.8048 - val_loss: 1.1625 - val_accuracy: 0.7407\n",
      "Epoch 11/45\n",
      "5148/5148 - 2s - loss: 0.6701 - accuracy: 0.8230 - val_loss: 0.8416 - val_accuracy: 0.8214\n",
      "Epoch 12/45\n",
      "5148/5148 - 2s - loss: 0.5508 - accuracy: 0.8394 - val_loss: 0.4876 - val_accuracy: 0.8618\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.5838 - accuracy: 0.8238 - val_loss: 0.4908 - val_accuracy: 0.8339\n",
      "Epoch 14/45\n",
      "5148/5148 - 2s - loss: 0.5434 - accuracy: 0.8335 - val_loss: 0.5170 - val_accuracy: 0.8276\n",
      "Epoch 15/45\n",
      "5148/5148 - 2s - loss: 0.5765 - accuracy: 0.8186 - val_loss: 0.9874 - val_accuracy: 0.6646\n",
      "Epoch 16/45\n",
      "5148/5148 - 2s - loss: 0.5395 - accuracy: 0.8351 - val_loss: 0.7716 - val_accuracy: 0.7686\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.5174 - accuracy: 0.8349 - val_loss: 1.1601 - val_accuracy: 0.5776\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.5644 - accuracy: 0.8261 - val_loss: 0.7160 - val_accuracy: 0.8525\n",
      "Epoch 19/45\n",
      "5148/5148 - 2s - loss: 0.5913 - accuracy: 0.8127 - val_loss: 0.4788 - val_accuracy: 0.8618\n",
      "Epoch 20/45\n",
      "5148/5148 - 2s - loss: 0.6416 - accuracy: 0.8226 - val_loss: 0.5118 - val_accuracy: 0.8276\n",
      "Epoch 21/45\n",
      "5148/5148 - 3s - loss: 0.5068 - accuracy: 0.8382 - val_loss: 0.5518 - val_accuracy: 0.8602\n",
      "Epoch 22/45\n",
      "5148/5148 - 3s - loss: 0.5694 - accuracy: 0.8265 - val_loss: 0.4801 - val_accuracy: 0.8571\n",
      "Epoch 23/45\n",
      "5148/5148 - 3s - loss: 0.5804 - accuracy: 0.8285 - val_loss: 0.4656 - val_accuracy: 0.8370\n",
      "Epoch 24/45\n",
      "5148/5148 - 4s - loss: 0.4235 - accuracy: 0.8594 - val_loss: 0.9996 - val_accuracy: 0.6056\n",
      "Epoch 25/45\n",
      "5148/5148 - 4s - loss: 0.4436 - accuracy: 0.8481 - val_loss: 0.4444 - val_accuracy: 0.8323\n",
      "Epoch 26/45\n",
      "5148/5148 - 4s - loss: 0.4316 - accuracy: 0.8450 - val_loss: 0.4291 - val_accuracy: 0.8323\n",
      "Epoch 27/45\n",
      "5148/5148 - 4s - loss: 0.4084 - accuracy: 0.8502 - val_loss: 0.6804 - val_accuracy: 0.7795\n",
      "Epoch 28/45\n",
      "5148/5148 - 4s - loss: 0.4158 - accuracy: 0.8518 - val_loss: 0.6933 - val_accuracy: 0.7780\n",
      "Epoch 29/45\n",
      "5148/5148 - 4s - loss: 0.4188 - accuracy: 0.8483 - val_loss: 1.3328 - val_accuracy: 0.5295\n",
      "Epoch 30/45\n",
      "5148/5148 - 4s - loss: 0.5031 - accuracy: 0.8267 - val_loss: 0.4521 - val_accuracy: 0.8556\n",
      "Epoch 31/45\n",
      "5148/5148 - 4s - loss: 0.4314 - accuracy: 0.8564 - val_loss: 0.4865 - val_accuracy: 0.8571\n",
      "Epoch 32/45\n",
      "5148/5148 - 3s - loss: 0.4153 - accuracy: 0.8522 - val_loss: 0.5560 - val_accuracy: 0.7873\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.4296 - accuracy: 0.8485 - val_loss: 0.4676 - val_accuracy: 0.8556\n",
      "Epoch 34/45\n",
      "5148/5148 - 2s - loss: 0.3649 - accuracy: 0.8613 - val_loss: 0.4551 - val_accuracy: 0.8261\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.4082 - accuracy: 0.8479 - val_loss: 0.4621 - val_accuracy: 0.8292\n",
      "Epoch 36/45\n",
      "5148/5148 - 2s - loss: 0.3784 - accuracy: 0.8533 - val_loss: 0.4056 - val_accuracy: 0.8292\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3640 - accuracy: 0.8598 - val_loss: 0.4075 - val_accuracy: 0.8323\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3790 - accuracy: 0.8528 - val_loss: 0.3995 - val_accuracy: 0.8276\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3673 - accuracy: 0.8568 - val_loss: 0.3990 - val_accuracy: 0.8307\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3596 - accuracy: 0.8568 - val_loss: 0.4012 - val_accuracy: 0.8354\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3714 - accuracy: 0.8516 - val_loss: 0.3959 - val_accuracy: 0.8323\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3963 - accuracy: 0.8531 - val_loss: 0.4257 - val_accuracy: 0.8276\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3721 - accuracy: 0.8559 - val_loss: 0.4333 - val_accuracy: 0.8261\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3405 - accuracy: 0.8582 - val_loss: 0.4371 - val_accuracy: 0.8556\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3473 - accuracy: 0.8563 - val_loss: 0.3922 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 3s - loss: 1.9379 - accuracy: 0.6777 - val_loss: 0.9767 - val_accuracy: 0.6071\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.8590 - accuracy: 0.7562 - val_loss: 0.5057 - val_accuracy: 0.8478\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.9282 - accuracy: 0.7665 - val_loss: 0.6069 - val_accuracy: 0.8618\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 1.0178 - accuracy: 0.7653 - val_loss: 2.1363 - val_accuracy: 0.5124\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 1.1304 - accuracy: 0.7584 - val_loss: 0.6613 - val_accuracy: 0.8602\n",
      "Epoch 6/45\n",
      "5148/5148 - 2s - loss: 0.6646 - accuracy: 0.8201 - val_loss: 1.3767 - val_accuracy: 0.7174\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 1.2804 - accuracy: 0.7506 - val_loss: 0.9986 - val_accuracy: 0.7500\n",
      "Epoch 8/45\n",
      "5148/5148 - 2s - loss: 0.7386 - accuracy: 0.8302 - val_loss: 1.1293 - val_accuracy: 0.7127\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.9568 - accuracy: 0.7912 - val_loss: 1.0952 - val_accuracy: 0.7562\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.9026 - accuracy: 0.7999 - val_loss: 1.5559 - val_accuracy: 0.7329\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.8265 - accuracy: 0.8195 - val_loss: 1.0677 - val_accuracy: 0.7686\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.6195 - accuracy: 0.8425 - val_loss: 0.5412 - val_accuracy: 0.8571\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.8505 - accuracy: 0.8019 - val_loss: 0.6276 - val_accuracy: 0.8276\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.7543 - accuracy: 0.8190 - val_loss: 0.7194 - val_accuracy: 0.8587\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.6642 - accuracy: 0.8281 - val_loss: 2.4100 - val_accuracy: 0.5062\n",
      "Epoch 16/45\n",
      "5148/5148 - 2s - loss: 0.6559 - accuracy: 0.8324 - val_loss: 0.9808 - val_accuracy: 0.7655\n",
      "Epoch 17/45\n",
      "5148/5148 - 2s - loss: 0.5909 - accuracy: 0.8345 - val_loss: 1.3719 - val_accuracy: 0.5730\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.6308 - accuracy: 0.8279 - val_loss: 0.6823 - val_accuracy: 0.8602\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.6426 - accuracy: 0.8193 - val_loss: 0.5362 - val_accuracy: 0.8571\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.7209 - accuracy: 0.8184 - val_loss: 0.5217 - val_accuracy: 0.8447\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.5671 - accuracy: 0.8364 - val_loss: 0.5992 - val_accuracy: 0.8618\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.6532 - accuracy: 0.8209 - val_loss: 0.5440 - val_accuracy: 0.8571\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.6663 - accuracy: 0.8228 - val_loss: 0.5207 - val_accuracy: 0.8339\n",
      "Epoch 24/45\n",
      "5148/5148 - 2s - loss: 0.4708 - accuracy: 0.8582 - val_loss: 1.1340 - val_accuracy: 0.6056\n",
      "Epoch 25/45\n",
      "5148/5148 - 4s - loss: 0.4915 - accuracy: 0.8460 - val_loss: 0.4967 - val_accuracy: 0.8354\n",
      "Epoch 26/45\n",
      "5148/5148 - 3s - loss: 0.4688 - accuracy: 0.8460 - val_loss: 0.4590 - val_accuracy: 0.8292\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.4436 - accuracy: 0.8471 - val_loss: 0.7059 - val_accuracy: 0.7842\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.4393 - accuracy: 0.8463 - val_loss: 0.5785 - val_accuracy: 0.8339\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.4398 - accuracy: 0.8458 - val_loss: 1.3511 - val_accuracy: 0.5419\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.5559 - accuracy: 0.8164 - val_loss: 0.4655 - val_accuracy: 0.8525\n",
      "Epoch 31/45\n",
      "5148/5148 - 2s - loss: 0.4563 - accuracy: 0.8479 - val_loss: 0.6015 - val_accuracy: 0.8571\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.4644 - accuracy: 0.8378 - val_loss: 0.6588 - val_accuracy: 0.7842\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.4720 - accuracy: 0.8411 - val_loss: 0.4879 - val_accuracy: 0.8556\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3828 - accuracy: 0.8607 - val_loss: 0.5536 - val_accuracy: 0.8214\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.4439 - accuracy: 0.8448 - val_loss: 0.5205 - val_accuracy: 0.8370\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3946 - accuracy: 0.8535 - val_loss: 0.4395 - val_accuracy: 0.8339\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3804 - accuracy: 0.8594 - val_loss: 0.4161 - val_accuracy: 0.8323\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3842 - accuracy: 0.8563 - val_loss: 0.4151 - val_accuracy: 0.8307\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3898 - accuracy: 0.8537 - val_loss: 0.4384 - val_accuracy: 0.8276\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3779 - accuracy: 0.8530 - val_loss: 0.4138 - val_accuracy: 0.8354\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3905 - accuracy: 0.8489 - val_loss: 0.4074 - val_accuracy: 0.8307\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.4126 - accuracy: 0.8483 - val_loss: 0.4346 - val_accuracy: 0.8323\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3815 - accuracy: 0.8555 - val_loss: 0.4402 - val_accuracy: 0.8230\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3487 - accuracy: 0.8586 - val_loss: 0.4344 - val_accuracy: 0.8571\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3551 - accuracy: 0.8601 - val_loss: 0.4114 - val_accuracy: 0.8665\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 1s - loss: 4.9124 - accuracy: 0.6461 - val_loss: 0.9139 - val_accuracy: 0.5683\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.7110 - accuracy: 0.7597 - val_loss: 0.6243 - val_accuracy: 0.7329\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.7587 - accuracy: 0.7640 - val_loss: 0.7296 - val_accuracy: 0.7252\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.8429 - accuracy: 0.7578 - val_loss: 2.0045 - val_accuracy: 0.4984\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.8972 - accuracy: 0.7622 - val_loss: 0.5480 - val_accuracy: 0.8587\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.5659 - accuracy: 0.8160 - val_loss: 2.1414 - val_accuracy: 0.5932\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.8513 - accuracy: 0.7803 - val_loss: 1.7045 - val_accuracy: 0.6801\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.6620 - accuracy: 0.8192 - val_loss: 0.7411 - val_accuracy: 0.8587\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.6873 - accuracy: 0.8112 - val_loss: 1.0005 - val_accuracy: 0.7376\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.7636 - accuracy: 0.7939 - val_loss: 2.1764 - val_accuracy: 0.6413\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.9127 - accuracy: 0.7914 - val_loss: 0.5740 - val_accuracy: 0.8571\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.7203 - accuracy: 0.8102 - val_loss: 0.7856 - val_accuracy: 0.7609\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.7573 - accuracy: 0.8034 - val_loss: 1.3025 - val_accuracy: 0.7360\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.7840 - accuracy: 0.8032 - val_loss: 0.7335 - val_accuracy: 0.7717\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.8342 - accuracy: 0.7997 - val_loss: 0.6029 - val_accuracy: 0.8276\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.5401 - accuracy: 0.8520 - val_loss: 0.5247 - val_accuracy: 0.8385\n",
      "Epoch 17/45\n",
      "5148/5148 - 2s - loss: 0.4958 - accuracy: 0.8508 - val_loss: 0.9172 - val_accuracy: 0.7376\n",
      "Epoch 18/45\n",
      "5148/5148 - 3s - loss: 0.5267 - accuracy: 0.8419 - val_loss: 0.6982 - val_accuracy: 0.8540\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.5847 - accuracy: 0.8201 - val_loss: 0.5009 - val_accuracy: 0.8276\n",
      "Epoch 20/45\n",
      "5148/5148 - 2s - loss: 0.6029 - accuracy: 0.8260 - val_loss: 0.5211 - val_accuracy: 0.8323\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.5238 - accuracy: 0.8355 - val_loss: 0.6665 - val_accuracy: 0.8571\n",
      "Epoch 22/45\n",
      "5148/5148 - 3s - loss: 0.5425 - accuracy: 0.8329 - val_loss: 0.4900 - val_accuracy: 0.8245\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.5456 - accuracy: 0.8300 - val_loss: 0.4594 - val_accuracy: 0.8556\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.4794 - accuracy: 0.8380 - val_loss: 0.5743 - val_accuracy: 0.8602\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4705 - accuracy: 0.8458 - val_loss: 0.4427 - val_accuracy: 0.8370\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4703 - accuracy: 0.8378 - val_loss: 0.4889 - val_accuracy: 0.8587\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.5093 - accuracy: 0.8265 - val_loss: 0.4664 - val_accuracy: 0.8556\n",
      "Epoch 28/45\n",
      "5148/5148 - 2s - loss: 0.4443 - accuracy: 0.8425 - val_loss: 0.4250 - val_accuracy: 0.8416\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.5532 - accuracy: 0.8145 - val_loss: 1.0838 - val_accuracy: 0.5792\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.5278 - accuracy: 0.8261 - val_loss: 0.5251 - val_accuracy: 0.8587\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.4721 - accuracy: 0.8390 - val_loss: 0.8372 - val_accuracy: 0.6988\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.5760 - accuracy: 0.8137 - val_loss: 0.8143 - val_accuracy: 0.7655\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.5638 - accuracy: 0.8246 - val_loss: 1.0616 - val_accuracy: 0.6009\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.4589 - accuracy: 0.8462 - val_loss: 0.4795 - val_accuracy: 0.8245\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.4278 - accuracy: 0.8502 - val_loss: 0.6559 - val_accuracy: 0.7811\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.4063 - accuracy: 0.8481 - val_loss: 0.6423 - val_accuracy: 0.7811\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.4006 - accuracy: 0.8547 - val_loss: 0.4254 - val_accuracy: 0.8618\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3894 - accuracy: 0.8520 - val_loss: 0.4053 - val_accuracy: 0.8261\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.4058 - accuracy: 0.8450 - val_loss: 0.5239 - val_accuracy: 0.8214\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3904 - accuracy: 0.8485 - val_loss: 0.5511 - val_accuracy: 0.7857\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3937 - accuracy: 0.8504 - val_loss: 0.4385 - val_accuracy: 0.8245\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.4299 - accuracy: 0.8401 - val_loss: 0.4172 - val_accuracy: 0.8634\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3843 - accuracy: 0.8508 - val_loss: 0.4259 - val_accuracy: 0.8556\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.4070 - accuracy: 0.8473 - val_loss: 0.4033 - val_accuracy: 0.8370\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3857 - accuracy: 0.8524 - val_loss: 0.4981 - val_accuracy: 0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:25,446] Trial 4 finished with value: 0.865217387676239 and parameters: {'units': 25, 'dropout': 0.0, 'learning_rate': 0.004713485953166379, 'epochs': 45, 'batch_size': 20, 'patience': 10, 'factor': 0.5}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:28,154] Trial 5 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:31,031] Trial 6 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:33,402] Trial 7 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 3s - loss: 419.5196 - accuracy: 0.5043 - val_loss: 405.8313 - val_accuracy: 0.5078\n",
      "Epoch 2/5\n",
      "5148/5148 - 2s - loss: 397.2800 - accuracy: 0.5014 - val_loss: 382.3069 - val_accuracy: 0.5078\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:40,745] Trial 8 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:42,778] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 14.1445 - accuracy: 0.5144 - val_loss: 0.7241 - val_accuracy: 0.5078\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.6958 - accuracy: 0.5478 - val_loss: 0.6482 - val_accuracy: 0.4984\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:45:45,535] Trial 10 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 2.5659 - accuracy: 0.6445 - val_loss: 0.9608 - val_accuracy: 0.5854\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.5547 - accuracy: 0.7492 - val_loss: 0.4699 - val_accuracy: 0.8416\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5500 - accuracy: 0.7721 - val_loss: 0.5237 - val_accuracy: 0.7314\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4703 - accuracy: 0.8061 - val_loss: 0.4648 - val_accuracy: 0.8634\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.4788 - accuracy: 0.8102 - val_loss: 0.4259 - val_accuracy: 0.8587\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4597 - accuracy: 0.8106 - val_loss: 0.5351 - val_accuracy: 0.8634\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4222 - accuracy: 0.8293 - val_loss: 0.6735 - val_accuracy: 0.7127\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4145 - accuracy: 0.8359 - val_loss: 0.5807 - val_accuracy: 0.7267\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4022 - accuracy: 0.8306 - val_loss: 0.4075 - val_accuracy: 0.8556\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3900 - accuracy: 0.8394 - val_loss: 0.4506 - val_accuracy: 0.7578\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3867 - accuracy: 0.8364 - val_loss: 0.5581 - val_accuracy: 0.7407\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3593 - accuracy: 0.8559 - val_loss: 0.4402 - val_accuracy: 0.8618\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3536 - accuracy: 0.8551 - val_loss: 0.3846 - val_accuracy: 0.8556\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3599 - accuracy: 0.8586 - val_loss: 0.4926 - val_accuracy: 0.8602\n",
      "Epoch 15/50\n",
      "5148/5148 - 0s - loss: 0.3403 - accuracy: 0.8619 - val_loss: 0.3842 - val_accuracy: 0.8245\n",
      "Epoch 16/50\n",
      "5148/5148 - 0s - loss: 0.3359 - accuracy: 0.8605 - val_loss: 0.3716 - val_accuracy: 0.8385\n",
      "Epoch 17/50\n",
      "5148/5148 - 0s - loss: 0.3377 - accuracy: 0.8574 - val_loss: 0.3927 - val_accuracy: 0.8571\n",
      "Epoch 18/50\n",
      "5148/5148 - 0s - loss: 0.3463 - accuracy: 0.8584 - val_loss: 0.3721 - val_accuracy: 0.8463\n",
      "Epoch 19/50\n",
      "5148/5148 - 0s - loss: 0.3433 - accuracy: 0.8545 - val_loss: 0.3689 - val_accuracy: 0.8323\n",
      "Epoch 20/50\n",
      "5148/5148 - 0s - loss: 0.3534 - accuracy: 0.8526 - val_loss: 0.4286 - val_accuracy: 0.8028\n",
      "Epoch 21/50\n",
      "5148/5148 - 0s - loss: 0.3385 - accuracy: 0.8638 - val_loss: 0.3684 - val_accuracy: 0.8385\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3421 - accuracy: 0.8590 - val_loss: 0.3710 - val_accuracy: 0.8354\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3557 - accuracy: 0.8510 - val_loss: 0.3741 - val_accuracy: 0.8323\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3396 - accuracy: 0.8590 - val_loss: 0.3643 - val_accuracy: 0.8556\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3243 - accuracy: 0.8658 - val_loss: 0.4319 - val_accuracy: 0.8075\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3252 - accuracy: 0.8619 - val_loss: 0.3673 - val_accuracy: 0.8556\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3235 - accuracy: 0.8609 - val_loss: 0.3636 - val_accuracy: 0.8509\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3270 - accuracy: 0.8619 - val_loss: 0.3652 - val_accuracy: 0.8525\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3289 - accuracy: 0.8631 - val_loss: 0.3827 - val_accuracy: 0.8571\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3251 - accuracy: 0.8652 - val_loss: 0.3726 - val_accuracy: 0.8556\n",
      "Epoch 31/50\n",
      "5148/5148 - 2s - loss: 0.3243 - accuracy: 0.8700 - val_loss: 0.3812 - val_accuracy: 0.8307\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3288 - accuracy: 0.8666 - val_loss: 0.3653 - val_accuracy: 0.8276\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3209 - accuracy: 0.8720 - val_loss: 0.3986 - val_accuracy: 0.8587\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3174 - accuracy: 0.8710 - val_loss: 0.3464 - val_accuracy: 0.8556\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3076 - accuracy: 0.8809 - val_loss: 0.3503 - val_accuracy: 0.8525\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3034 - accuracy: 0.8788 - val_loss: 0.3558 - val_accuracy: 0.8556\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3018 - accuracy: 0.8796 - val_loss: 0.3535 - val_accuracy: 0.8587\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3047 - accuracy: 0.8788 - val_loss: 0.3389 - val_accuracy: 0.8587\n",
      "Epoch 39/50\n",
      "5148/5148 - 2s - loss: 0.2990 - accuracy: 0.8807 - val_loss: 0.3411 - val_accuracy: 0.8556\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2993 - accuracy: 0.8811 - val_loss: 0.3382 - val_accuracy: 0.8556\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2965 - accuracy: 0.8823 - val_loss: 0.3480 - val_accuracy: 0.8587\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3007 - accuracy: 0.8821 - val_loss: 0.3457 - val_accuracy: 0.8602\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2977 - accuracy: 0.8798 - val_loss: 0.3462 - val_accuracy: 0.8540\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2952 - accuracy: 0.8819 - val_loss: 0.3442 - val_accuracy: 0.8618\n",
      "Epoch 45/50\n",
      "5148/5148 - 2s - loss: 0.2908 - accuracy: 0.8833 - val_loss: 0.3326 - val_accuracy: 0.8571\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2907 - accuracy: 0.8829 - val_loss: 0.3329 - val_accuracy: 0.8602\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2913 - accuracy: 0.8829 - val_loss: 0.3335 - val_accuracy: 0.8571\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2890 - accuracy: 0.8834 - val_loss: 0.3341 - val_accuracy: 0.8587\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2888 - accuracy: 0.8836 - val_loss: 0.3316 - val_accuracy: 0.8571\n",
      "Epoch 50/50\n",
      "5148/5148 - 2s - loss: 0.2884 - accuracy: 0.8838 - val_loss: 0.3361 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 17.9828 - accuracy: 0.6305 - val_loss: 1.3394 - val_accuracy: 0.6630\n",
      "Epoch 2/50\n",
      "5148/5148 - 0s - loss: 1.0075 - accuracy: 0.7321 - val_loss: 0.9713 - val_accuracy: 0.7189\n",
      "Epoch 3/50\n",
      "5148/5148 - 0s - loss: 0.8921 - accuracy: 0.7578 - val_loss: 0.6131 - val_accuracy: 0.7857\n",
      "Epoch 4/50\n",
      "5148/5148 - 0s - loss: 0.8745 - accuracy: 0.7861 - val_loss: 0.7445 - val_accuracy: 0.8634\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 1.0083 - accuracy: 0.7642 - val_loss: 1.8147 - val_accuracy: 0.5466\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 1.0051 - accuracy: 0.7741 - val_loss: 0.6654 - val_accuracy: 0.8602\n",
      "Epoch 7/50\n",
      "5148/5148 - 0s - loss: 1.0006 - accuracy: 0.7791 - val_loss: 1.3046 - val_accuracy: 0.7283\n",
      "Epoch 8/50\n",
      "5148/5148 - 0s - loss: 0.6820 - accuracy: 0.8223 - val_loss: 0.8438 - val_accuracy: 0.8602\n",
      "Epoch 9/50\n",
      "5148/5148 - 0s - loss: 0.7908 - accuracy: 0.8040 - val_loss: 0.7644 - val_accuracy: 0.7671\n",
      "Epoch 10/50\n",
      "5148/5148 - 0s - loss: 1.2250 - accuracy: 0.7642 - val_loss: 0.8966 - val_accuracy: 0.8602\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.9393 - accuracy: 0.8048 - val_loss: 3.8471 - val_accuracy: 0.5761\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.8357 - accuracy: 0.8141 - val_loss: 0.8756 - val_accuracy: 0.7655\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 1.0319 - accuracy: 0.7793 - val_loss: 3.3815 - val_accuracy: 0.6056\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.8849 - accuracy: 0.8120 - val_loss: 0.7001 - val_accuracy: 0.8245\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.6662 - accuracy: 0.8359 - val_loss: 0.7475 - val_accuracy: 0.8261\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.5572 - accuracy: 0.8551 - val_loss: 0.5519 - val_accuracy: 0.8354\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.6623 - accuracy: 0.8155 - val_loss: 0.6980 - val_accuracy: 0.8401\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.5934 - accuracy: 0.8326 - val_loss: 0.6982 - val_accuracy: 0.8339\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.5665 - accuracy: 0.8316 - val_loss: 0.6060 - val_accuracy: 0.8556\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.5327 - accuracy: 0.8454 - val_loss: 0.5520 - val_accuracy: 0.8261\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.6015 - accuracy: 0.8217 - val_loss: 0.9126 - val_accuracy: 0.7686\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.5532 - accuracy: 0.8289 - val_loss: 0.5078 - val_accuracy: 0.8292\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.4588 - accuracy: 0.8582 - val_loss: 0.4608 - val_accuracy: 0.8307\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.5220 - accuracy: 0.8283 - val_loss: 1.2048 - val_accuracy: 0.5683\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.4084 - accuracy: 0.8582 - val_loss: 0.5131 - val_accuracy: 0.8587\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.4068 - accuracy: 0.8557 - val_loss: 0.5486 - val_accuracy: 0.8587\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.4516 - accuracy: 0.8430 - val_loss: 0.4383 - val_accuracy: 0.8323\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3854 - accuracy: 0.8578 - val_loss: 0.4898 - val_accuracy: 0.8354\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.4153 - accuracy: 0.8471 - val_loss: 0.4271 - val_accuracy: 0.8307\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.4034 - accuracy: 0.8506 - val_loss: 0.4397 - val_accuracy: 0.8540\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3809 - accuracy: 0.8592 - val_loss: 0.4203 - val_accuracy: 0.8370\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.4416 - accuracy: 0.8403 - val_loss: 0.4672 - val_accuracy: 0.8556\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3985 - accuracy: 0.8559 - val_loss: 0.4187 - val_accuracy: 0.8525\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3875 - accuracy: 0.8588 - val_loss: 0.7367 - val_accuracy: 0.7702\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3734 - accuracy: 0.8580 - val_loss: 0.4139 - val_accuracy: 0.8556\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3556 - accuracy: 0.8555 - val_loss: 0.4059 - val_accuracy: 0.8323\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3629 - accuracy: 0.8598 - val_loss: 0.4401 - val_accuracy: 0.8276\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3667 - accuracy: 0.8568 - val_loss: 0.4324 - val_accuracy: 0.8556\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3486 - accuracy: 0.8623 - val_loss: 0.4035 - val_accuracy: 0.8354\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3518 - accuracy: 0.8545 - val_loss: 0.3980 - val_accuracy: 0.8307\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3571 - accuracy: 0.8590 - val_loss: 0.4162 - val_accuracy: 0.8602\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3525 - accuracy: 0.8613 - val_loss: 0.4404 - val_accuracy: 0.8339\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3505 - accuracy: 0.8588 - val_loss: 0.4705 - val_accuracy: 0.8525\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3479 - accuracy: 0.8599 - val_loss: 0.4193 - val_accuracy: 0.8571\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3369 - accuracy: 0.8557 - val_loss: 0.3918 - val_accuracy: 0.8276\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3382 - accuracy: 0.8586 - val_loss: 0.3911 - val_accuracy: 0.8323\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3438 - accuracy: 0.8551 - val_loss: 0.3921 - val_accuracy: 0.8307\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3307 - accuracy: 0.8566 - val_loss: 0.4016 - val_accuracy: 0.8354\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3361 - accuracy: 0.8590 - val_loss: 0.3935 - val_accuracy: 0.8370\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3342 - accuracy: 0.8524 - val_loss: 0.4089 - val_accuracy: 0.8292\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 25.0317 - accuracy: 0.6307 - val_loss: 1.2113 - val_accuracy: 0.6506\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 0.8191 - accuracy: 0.7391 - val_loss: 1.1812 - val_accuracy: 0.6630\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.7242 - accuracy: 0.7611 - val_loss: 0.6620 - val_accuracy: 0.8618\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.6829 - accuracy: 0.7846 - val_loss: 1.0342 - val_accuracy: 0.5916\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 1.0419 - accuracy: 0.7420 - val_loss: 0.7701 - val_accuracy: 0.8618\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.9226 - accuracy: 0.7739 - val_loss: 0.6250 - val_accuracy: 0.8618\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.7152 - accuracy: 0.7962 - val_loss: 0.5661 - val_accuracy: 0.8571\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.7455 - accuracy: 0.7947 - val_loss: 0.7660 - val_accuracy: 0.8602\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.7326 - accuracy: 0.8023 - val_loss: 0.7024 - val_accuracy: 0.7671\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.7389 - accuracy: 0.8023 - val_loss: 0.8371 - val_accuracy: 0.7531\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.7060 - accuracy: 0.8098 - val_loss: 1.7969 - val_accuracy: 0.6677\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.7730 - accuracy: 0.7970 - val_loss: 0.6754 - val_accuracy: 0.7857\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.7815 - accuracy: 0.7871 - val_loss: 1.1316 - val_accuracy: 0.7422\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.4978 - accuracy: 0.8559 - val_loss: 0.8653 - val_accuracy: 0.8137\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.5017 - accuracy: 0.8479 - val_loss: 0.7762 - val_accuracy: 0.7655\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.5279 - accuracy: 0.8368 - val_loss: 0.4758 - val_accuracy: 0.8323\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.5115 - accuracy: 0.8273 - val_loss: 0.5732 - val_accuracy: 0.8292\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.5310 - accuracy: 0.8267 - val_loss: 0.4561 - val_accuracy: 0.8354\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.4867 - accuracy: 0.8341 - val_loss: 0.7097 - val_accuracy: 0.8385\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.4688 - accuracy: 0.8427 - val_loss: 0.4779 - val_accuracy: 0.8276\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.5413 - accuracy: 0.8230 - val_loss: 0.7595 - val_accuracy: 0.7655\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.4967 - accuracy: 0.8287 - val_loss: 0.4515 - val_accuracy: 0.8292\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.4154 - accuracy: 0.8582 - val_loss: 0.4190 - val_accuracy: 0.8276\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3949 - accuracy: 0.8555 - val_loss: 0.4371 - val_accuracy: 0.8323\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3556 - accuracy: 0.8625 - val_loss: 0.4367 - val_accuracy: 0.8556\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3753 - accuracy: 0.8563 - val_loss: 0.4801 - val_accuracy: 0.8556\n",
      "Epoch 27/50\n",
      "5148/5148 - 2s - loss: 0.4197 - accuracy: 0.8413 - val_loss: 0.4040 - val_accuracy: 0.8339\n",
      "Epoch 28/50\n",
      "5148/5148 - 2s - loss: 0.3609 - accuracy: 0.8582 - val_loss: 0.4486 - val_accuracy: 0.8292\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3842 - accuracy: 0.8485 - val_loss: 0.4007 - val_accuracy: 0.8385\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3762 - accuracy: 0.8524 - val_loss: 0.4126 - val_accuracy: 0.8509\n",
      "Epoch 31/50\n",
      "5148/5148 - 2s - loss: 0.3613 - accuracy: 0.8592 - val_loss: 0.3928 - val_accuracy: 0.8292\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.4130 - accuracy: 0.8413 - val_loss: 0.4180 - val_accuracy: 0.8556\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3756 - accuracy: 0.8531 - val_loss: 0.3916 - val_accuracy: 0.8276\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3354 - accuracy: 0.8566 - val_loss: 0.3982 - val_accuracy: 0.8587\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3418 - accuracy: 0.8627 - val_loss: 0.3959 - val_accuracy: 0.8571\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3424 - accuracy: 0.8553 - val_loss: 0.3877 - val_accuracy: 0.8323\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3487 - accuracy: 0.8584 - val_loss: 0.4315 - val_accuracy: 0.8307\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3512 - accuracy: 0.8580 - val_loss: 0.4208 - val_accuracy: 0.8556\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3378 - accuracy: 0.8648 - val_loss: 0.3920 - val_accuracy: 0.8571\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3392 - accuracy: 0.8570 - val_loss: 0.3841 - val_accuracy: 0.8307\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3446 - accuracy: 0.8576 - val_loss: 0.4001 - val_accuracy: 0.8587\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3399 - accuracy: 0.8632 - val_loss: 0.4291 - val_accuracy: 0.8354\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3389 - accuracy: 0.8566 - val_loss: 0.4828 - val_accuracy: 0.8602\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3306 - accuracy: 0.8566 - val_loss: 0.3811 - val_accuracy: 0.8261\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3272 - accuracy: 0.8561 - val_loss: 0.3810 - val_accuracy: 0.8276\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3298 - accuracy: 0.8594 - val_loss: 0.3804 - val_accuracy: 0.8354\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3337 - accuracy: 0.8564 - val_loss: 0.3811 - val_accuracy: 0.8323\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3236 - accuracy: 0.8568 - val_loss: 0.3897 - val_accuracy: 0.8354\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3290 - accuracy: 0.8592 - val_loss: 0.3852 - val_accuracy: 0.8494\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3262 - accuracy: 0.8522 - val_loss: 0.4017 - val_accuracy: 0.8261\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 5.7827 - accuracy: 0.6702 - val_loss: 0.9238 - val_accuracy: 0.7189\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.0252 - accuracy: 0.7358 - val_loss: 0.8867 - val_accuracy: 0.7360\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 1.3020 - accuracy: 0.7539 - val_loss: 0.6639 - val_accuracy: 0.8525\n",
      "Epoch 4/50\n",
      "5148/5148 - 2s - loss: 0.8910 - accuracy: 0.7964 - val_loss: 0.7928 - val_accuracy: 0.8680\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 1.7948 - accuracy: 0.7461 - val_loss: 1.1771 - val_accuracy: 0.8634\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 1.2103 - accuracy: 0.7945 - val_loss: 0.9508 - val_accuracy: 0.8618\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 1.1564 - accuracy: 0.7929 - val_loss: 0.9433 - val_accuracy: 0.7609\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 1.2754 - accuracy: 0.7793 - val_loss: 1.0817 - val_accuracy: 0.8602\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 1.1586 - accuracy: 0.7974 - val_loss: 1.5630 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 1.2607 - accuracy: 0.7805 - val_loss: 1.0046 - val_accuracy: 0.8571\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 1.1393 - accuracy: 0.8044 - val_loss: 5.2042 - val_accuracy: 0.5637\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 1.2997 - accuracy: 0.7881 - val_loss: 1.3523 - val_accuracy: 0.7655\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 1.1850 - accuracy: 0.7920 - val_loss: 1.8893 - val_accuracy: 0.7469\n",
      "Epoch 14/50\n",
      "5148/5148 - 2s - loss: 1.1795 - accuracy: 0.8092 - val_loss: 0.8581 - val_accuracy: 0.8292\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.8590 - accuracy: 0.8333 - val_loss: 0.9483 - val_accuracy: 0.8323\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.7155 - accuracy: 0.8493 - val_loss: 0.6918 - val_accuracy: 0.8307\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.8032 - accuracy: 0.8186 - val_loss: 1.0640 - val_accuracy: 0.7826\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.7931 - accuracy: 0.8234 - val_loss: 0.7412 - val_accuracy: 0.8276\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.7269 - accuracy: 0.8277 - val_loss: 0.9041 - val_accuracy: 0.8571\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.7143 - accuracy: 0.8357 - val_loss: 0.7337 - val_accuracy: 0.8354\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.7739 - accuracy: 0.8195 - val_loss: 1.2615 - val_accuracy: 0.7593\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.6846 - accuracy: 0.8267 - val_loss: 0.7171 - val_accuracy: 0.8307\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.5643 - accuracy: 0.8530 - val_loss: 0.5503 - val_accuracy: 0.8276\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.6876 - accuracy: 0.8186 - val_loss: 1.7979 - val_accuracy: 0.5419\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.5033 - accuracy: 0.8555 - val_loss: 0.6288 - val_accuracy: 0.8571\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.4834 - accuracy: 0.8539 - val_loss: 0.6300 - val_accuracy: 0.8571\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.5720 - accuracy: 0.8339 - val_loss: 0.5185 - val_accuracy: 0.8261\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.4554 - accuracy: 0.8516 - val_loss: 0.6631 - val_accuracy: 0.8416\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.5151 - accuracy: 0.8380 - val_loss: 0.4980 - val_accuracy: 0.8276\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.4812 - accuracy: 0.8456 - val_loss: 0.5050 - val_accuracy: 0.8571\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.4384 - accuracy: 0.8590 - val_loss: 0.4995 - val_accuracy: 0.8571\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.4954 - accuracy: 0.8409 - val_loss: 0.5517 - val_accuracy: 0.8509\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.4655 - accuracy: 0.8452 - val_loss: 0.5118 - val_accuracy: 0.8556\n",
      "Epoch 34/50\n",
      "5148/5148 - 3s - loss: 0.4398 - accuracy: 0.8580 - val_loss: 0.7523 - val_accuracy: 0.7764\n",
      "Epoch 35/50\n",
      "5148/5148 - 2s - loss: 0.4161 - accuracy: 0.8568 - val_loss: 0.4574 - val_accuracy: 0.8276\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3983 - accuracy: 0.8526 - val_loss: 0.4757 - val_accuracy: 0.8602\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.4109 - accuracy: 0.8578 - val_loss: 0.4520 - val_accuracy: 0.8323\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.4149 - accuracy: 0.8553 - val_loss: 0.4446 - val_accuracy: 0.8307\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3798 - accuracy: 0.8596 - val_loss: 0.4417 - val_accuracy: 0.8307\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3884 - accuracy: 0.8543 - val_loss: 0.4406 - val_accuracy: 0.8323\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3983 - accuracy: 0.8520 - val_loss: 0.4779 - val_accuracy: 0.8571\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3944 - accuracy: 0.8553 - val_loss: 0.5202 - val_accuracy: 0.8432\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3942 - accuracy: 0.8590 - val_loss: 0.4755 - val_accuracy: 0.8556\n",
      "Epoch 44/50\n",
      "5148/5148 - 2s - loss: 0.3840 - accuracy: 0.8590 - val_loss: 0.4489 - val_accuracy: 0.8618\n",
      "Epoch 45/50\n",
      "5148/5148 - 2s - loss: 0.3656 - accuracy: 0.8553 - val_loss: 0.4287 - val_accuracy: 0.8307\n",
      "Epoch 46/50\n",
      "5148/5148 - 2s - loss: 0.3669 - accuracy: 0.8566 - val_loss: 0.4278 - val_accuracy: 0.8292\n",
      "Epoch 47/50\n",
      "5148/5148 - 2s - loss: 0.3704 - accuracy: 0.8533 - val_loss: 0.4306 - val_accuracy: 0.8323\n",
      "Epoch 48/50\n",
      "5148/5148 - 2s - loss: 0.3554 - accuracy: 0.8561 - val_loss: 0.4425 - val_accuracy: 0.8354\n",
      "Epoch 49/50\n",
      "5148/5148 - 2s - loss: 0.3607 - accuracy: 0.8586 - val_loss: 0.4247 - val_accuracy: 0.8339\n",
      "Epoch 50/50\n",
      "5148/5148 - 2s - loss: 0.3607 - accuracy: 0.8531 - val_loss: 0.4356 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 15.5126 - accuracy: 0.6519 - val_loss: 1.1746 - val_accuracy: 0.6630\n",
      "Epoch 2/50\n",
      "5148/5148 - 0s - loss: 0.7926 - accuracy: 0.7574 - val_loss: 1.0671 - val_accuracy: 0.6910\n",
      "Epoch 3/50\n",
      "5148/5148 - 0s - loss: 0.8597 - accuracy: 0.7745 - val_loss: 0.4966 - val_accuracy: 0.8540\n",
      "Epoch 4/50\n",
      "5148/5148 - 0s - loss: 0.6397 - accuracy: 0.8023 - val_loss: 0.6556 - val_accuracy: 0.8649\n",
      "Epoch 5/50\n",
      "5148/5148 - 0s - loss: 0.7961 - accuracy: 0.7811 - val_loss: 1.2961 - val_accuracy: 0.5916\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.8007 - accuracy: 0.7914 - val_loss: 0.5901 - val_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "5148/5148 - 0s - loss: 0.7558 - accuracy: 0.7962 - val_loss: 0.5676 - val_accuracy: 0.8587\n",
      "Epoch 8/50\n",
      "5148/5148 - 0s - loss: 0.7337 - accuracy: 0.8015 - val_loss: 0.9214 - val_accuracy: 0.7935\n",
      "Epoch 9/50\n",
      "5148/5148 - 0s - loss: 0.6508 - accuracy: 0.8190 - val_loss: 0.9115 - val_accuracy: 0.7531\n",
      "Epoch 10/50\n",
      "5148/5148 - 0s - loss: 0.8842 - accuracy: 0.7813 - val_loss: 0.5906 - val_accuracy: 0.8261\n",
      "Epoch 11/50\n",
      "5148/5148 - 0s - loss: 0.8232 - accuracy: 0.8081 - val_loss: 1.9192 - val_accuracy: 0.6724\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.7287 - accuracy: 0.8110 - val_loss: 0.6597 - val_accuracy: 0.8199\n",
      "Epoch 13/50\n",
      "5148/5148 - 0s - loss: 0.8741 - accuracy: 0.7822 - val_loss: 2.5000 - val_accuracy: 0.6444\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.7759 - accuracy: 0.8172 - val_loss: 0.5926 - val_accuracy: 0.8276\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.5938 - accuracy: 0.8351 - val_loss: 0.6896 - val_accuracy: 0.8261\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.5017 - accuracy: 0.8547 - val_loss: 0.5053 - val_accuracy: 0.8370\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.5942 - accuracy: 0.8213 - val_loss: 0.6163 - val_accuracy: 0.8339\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.5329 - accuracy: 0.8364 - val_loss: 0.6955 - val_accuracy: 0.7888\n",
      "Epoch 19/50\n",
      "5148/5148 - 0s - loss: 0.5115 - accuracy: 0.8376 - val_loss: 0.4759 - val_accuracy: 0.8447\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.4964 - accuracy: 0.8483 - val_loss: 0.5087 - val_accuracy: 0.8245\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.5428 - accuracy: 0.8242 - val_loss: 0.8973 - val_accuracy: 0.7578\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.5360 - accuracy: 0.8263 - val_loss: 0.5130 - val_accuracy: 0.8556\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.4397 - accuracy: 0.8568 - val_loss: 0.4470 - val_accuracy: 0.8385\n",
      "Epoch 24/50\n",
      "5148/5148 - 3s - loss: 0.4698 - accuracy: 0.8427 - val_loss: 0.9467 - val_accuracy: 0.6180\n",
      "Epoch 25/50\n",
      "5148/5148 - 3s - loss: 0.3840 - accuracy: 0.8566 - val_loss: 0.4942 - val_accuracy: 0.8587\n",
      "Epoch 26/50\n",
      "5148/5148 - 4s - loss: 0.3898 - accuracy: 0.8563 - val_loss: 0.5217 - val_accuracy: 0.8587\n",
      "Epoch 27/50\n",
      "5148/5148 - 4s - loss: 0.4151 - accuracy: 0.8500 - val_loss: 0.4322 - val_accuracy: 0.8370\n",
      "Epoch 28/50\n",
      "5148/5148 - 4s - loss: 0.3709 - accuracy: 0.8582 - val_loss: 0.4410 - val_accuracy: 0.8292\n",
      "Epoch 29/50\n",
      "5148/5148 - 3s - loss: 0.3911 - accuracy: 0.8506 - val_loss: 0.4165 - val_accuracy: 0.8354\n",
      "Epoch 30/50\n",
      "5148/5148 - 3s - loss: 0.3887 - accuracy: 0.8514 - val_loss: 0.4238 - val_accuracy: 0.8602\n",
      "Epoch 31/50\n",
      "5148/5148 - 4s - loss: 0.3690 - accuracy: 0.8594 - val_loss: 0.4063 - val_accuracy: 0.8323\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.4188 - accuracy: 0.8454 - val_loss: 0.4258 - val_accuracy: 0.8556\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3839 - accuracy: 0.8533 - val_loss: 0.4046 - val_accuracy: 0.8339\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3778 - accuracy: 0.8609 - val_loss: 0.5428 - val_accuracy: 0.7857\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3575 - accuracy: 0.8580 - val_loss: 0.4120 - val_accuracy: 0.8618\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3496 - accuracy: 0.8578 - val_loss: 0.3976 - val_accuracy: 0.8339\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3522 - accuracy: 0.8590 - val_loss: 0.4625 - val_accuracy: 0.8432\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3547 - accuracy: 0.8576 - val_loss: 0.4306 - val_accuracy: 0.8556\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8654 - val_loss: 0.4018 - val_accuracy: 0.8571\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3444 - accuracy: 0.8570 - val_loss: 0.3929 - val_accuracy: 0.8323\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3500 - accuracy: 0.8570 - val_loss: 0.4081 - val_accuracy: 0.8602\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3453 - accuracy: 0.8658 - val_loss: 0.4415 - val_accuracy: 0.8385\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3443 - accuracy: 0.8574 - val_loss: 0.5009 - val_accuracy: 0.8571\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3421 - accuracy: 0.8605 - val_loss: 0.4346 - val_accuracy: 0.8556\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3335 - accuracy: 0.8559 - val_loss: 0.3893 - val_accuracy: 0.8261\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3344 - accuracy: 0.8578 - val_loss: 0.3888 - val_accuracy: 0.8339\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3384 - accuracy: 0.8566 - val_loss: 0.3894 - val_accuracy: 0.8307\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3285 - accuracy: 0.8568 - val_loss: 0.3974 - val_accuracy: 0.8339\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3338 - accuracy: 0.8596 - val_loss: 0.3940 - val_accuracy: 0.8540\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3308 - accuracy: 0.8526 - val_loss: 0.4087 - val_accuracy: 0.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:50:15,995] Trial 11 finished with value: 0.8642857670783997 and parameters: {'units': 10, 'dropout': 0.0, 'learning_rate': 0.009997009950513665, 'epochs': 50, 'batch_size': 25, 'patience': 10, 'factor': 0.4}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 3s - loss: 17.3911 - accuracy: 0.5260 - val_loss: 0.6603 - val_accuracy: 0.5543\n",
      "Epoch 2/40\n",
      "5148/5148 - 1s - loss: 0.7709 - accuracy: 0.5425 - val_loss: 0.7511 - val_accuracy: 0.4922\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:50:21,821] Trial 12 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 6.3861 - accuracy: 0.6385 - val_loss: 1.2396 - val_accuracy: 0.5807\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 0.6495 - accuracy: 0.7432 - val_loss: 0.9692 - val_accuracy: 0.6599\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.6739 - accuracy: 0.7549 - val_loss: 0.4752 - val_accuracy: 0.7919\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.5623 - accuracy: 0.7955 - val_loss: 0.7416 - val_accuracy: 0.7391\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.7677 - accuracy: 0.7525 - val_loss: 0.7073 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.7602 - accuracy: 0.7727 - val_loss: 0.5122 - val_accuracy: 0.8587\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.5691 - accuracy: 0.8162 - val_loss: 0.4633 - val_accuracy: 0.8587\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.5784 - accuracy: 0.8048 - val_loss: 0.6777 - val_accuracy: 0.8634\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.5591 - accuracy: 0.8172 - val_loss: 0.7435 - val_accuracy: 0.7484\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.6809 - accuracy: 0.7863 - val_loss: 0.5178 - val_accuracy: 0.8152\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.6256 - accuracy: 0.8125 - val_loss: 2.2350 - val_accuracy: 0.5901\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.6167 - accuracy: 0.8094 - val_loss: 0.6013 - val_accuracy: 0.7748\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.6790 - accuracy: 0.7904 - val_loss: 1.5451 - val_accuracy: 0.6817\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4658 - accuracy: 0.8526 - val_loss: 0.5902 - val_accuracy: 0.8571\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4559 - accuracy: 0.8518 - val_loss: 0.5316 - val_accuracy: 0.8245\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4117 - accuracy: 0.8566 - val_loss: 0.4616 - val_accuracy: 0.8540\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4838 - accuracy: 0.8302 - val_loss: 0.6460 - val_accuracy: 0.7686\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4200 - accuracy: 0.8442 - val_loss: 0.5012 - val_accuracy: 0.8307\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4087 - accuracy: 0.8539 - val_loss: 0.4702 - val_accuracy: 0.8276\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4535 - accuracy: 0.8458 - val_loss: 0.4148 - val_accuracy: 0.8339\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4227 - accuracy: 0.8452 - val_loss: 0.4111 - val_accuracy: 0.8307\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3505 - accuracy: 0.8594 - val_loss: 0.4083 - val_accuracy: 0.8307\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3468 - accuracy: 0.8549 - val_loss: 0.4179 - val_accuracy: 0.8323\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3556 - accuracy: 0.8531 - val_loss: 0.4007 - val_accuracy: 0.8307\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3393 - accuracy: 0.8545 - val_loss: 0.3993 - val_accuracy: 0.8292\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3461 - accuracy: 0.8561 - val_loss: 0.3967 - val_accuracy: 0.8323\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3478 - accuracy: 0.8578 - val_loss: 0.4451 - val_accuracy: 0.8292\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3416 - accuracy: 0.8555 - val_loss: 0.4768 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3662 - accuracy: 0.8561 - val_loss: 0.3979 - val_accuracy: 0.8323\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3293 - accuracy: 0.8539 - val_loss: 0.3937 - val_accuracy: 0.8292\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 2.0754 - accuracy: 0.6542 - val_loss: 0.9749 - val_accuracy: 0.6335\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 0.6572 - accuracy: 0.7539 - val_loss: 0.9116 - val_accuracy: 0.6739\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.6259 - accuracy: 0.7720 - val_loss: 0.4654 - val_accuracy: 0.8649\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.6031 - accuracy: 0.7937 - val_loss: 0.6130 - val_accuracy: 0.8634\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.7435 - accuracy: 0.7646 - val_loss: 0.8380 - val_accuracy: 0.8043\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 0.8100 - accuracy: 0.7774 - val_loss: 0.5416 - val_accuracy: 0.8556\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.5853 - accuracy: 0.8197 - val_loss: 0.4808 - val_accuracy: 0.8602\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.6006 - accuracy: 0.8069 - val_loss: 0.7328 - val_accuracy: 0.8649\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.6038 - accuracy: 0.8151 - val_loss: 0.6605 - val_accuracy: 0.7609\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.6908 - accuracy: 0.7943 - val_loss: 0.5631 - val_accuracy: 0.8121\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.6550 - accuracy: 0.8178 - val_loss: 1.9858 - val_accuracy: 0.6273\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4832 - accuracy: 0.8465 - val_loss: 0.5003 - val_accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4006 - accuracy: 0.8625 - val_loss: 0.4817 - val_accuracy: 0.8587\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4176 - accuracy: 0.8543 - val_loss: 0.6624 - val_accuracy: 0.8478\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4302 - accuracy: 0.8483 - val_loss: 0.6780 - val_accuracy: 0.7686\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4690 - accuracy: 0.8370 - val_loss: 0.4275 - val_accuracy: 0.8385\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4899 - accuracy: 0.8254 - val_loss: 0.5256 - val_accuracy: 0.8292\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4501 - accuracy: 0.8388 - val_loss: 0.4902 - val_accuracy: 0.8245\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4237 - accuracy: 0.8477 - val_loss: 0.4333 - val_accuracy: 0.8307\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3603 - accuracy: 0.8586 - val_loss: 0.4129 - val_accuracy: 0.8339\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3541 - accuracy: 0.8578 - val_loss: 0.4188 - val_accuracy: 0.8323\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3541 - accuracy: 0.8586 - val_loss: 0.4070 - val_accuracy: 0.8292\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3521 - accuracy: 0.8563 - val_loss: 0.4087 - val_accuracy: 0.8339\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3568 - accuracy: 0.8531 - val_loss: 0.4000 - val_accuracy: 0.8323\n",
      "Epoch 25/30\n",
      "5148/5148 - 2s - loss: 0.3383 - accuracy: 0.8518 - val_loss: 0.4193 - val_accuracy: 0.8540\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3525 - accuracy: 0.8535 - val_loss: 0.3943 - val_accuracy: 0.8261\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3515 - accuracy: 0.8576 - val_loss: 0.4583 - val_accuracy: 0.8385\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3308 - accuracy: 0.8555 - val_loss: 0.4086 - val_accuracy: 0.8587\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3343 - accuracy: 0.8551 - val_loss: 0.4108 - val_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3307 - accuracy: 0.8559 - val_loss: 0.3926 - val_accuracy: 0.8292\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 2.4283 - accuracy: 0.6688 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 0.7500 - accuracy: 0.7347 - val_loss: 0.9148 - val_accuracy: 0.6832\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.6195 - accuracy: 0.7828 - val_loss: 0.7029 - val_accuracy: 0.8339\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.6115 - accuracy: 0.7912 - val_loss: 0.7928 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.8855 - accuracy: 0.7492 - val_loss: 0.7422 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "5148/5148 - 0s - loss: 0.8649 - accuracy: 0.7706 - val_loss: 0.5747 - val_accuracy: 0.8587\n",
      "Epoch 7/30\n",
      "5148/5148 - 0s - loss: 0.6314 - accuracy: 0.8160 - val_loss: 0.5253 - val_accuracy: 0.8602\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.6730 - accuracy: 0.8019 - val_loss: 0.8244 - val_accuracy: 0.8339\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.6148 - accuracy: 0.8178 - val_loss: 0.7644 - val_accuracy: 0.7578\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.7129 - accuracy: 0.8009 - val_loss: 0.7514 - val_accuracy: 0.7562\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.6616 - accuracy: 0.8120 - val_loss: 1.7168 - val_accuracy: 0.6708\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.7477 - accuracy: 0.7941 - val_loss: 0.5966 - val_accuracy: 0.8245\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.8016 - accuracy: 0.7855 - val_loss: 2.1204 - val_accuracy: 0.6630\n",
      "Epoch 14/30\n",
      "5148/5148 - 0s - loss: 0.5255 - accuracy: 0.8506 - val_loss: 0.6557 - val_accuracy: 0.8571\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4994 - accuracy: 0.8528 - val_loss: 0.5740 - val_accuracy: 0.8292\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4455 - accuracy: 0.8557 - val_loss: 0.4971 - val_accuracy: 0.8556\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5144 - accuracy: 0.8310 - val_loss: 0.6330 - val_accuracy: 0.8075\n",
      "Epoch 18/30\n",
      "5148/5148 - 0s - loss: 0.4518 - accuracy: 0.8425 - val_loss: 0.5396 - val_accuracy: 0.8307\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4320 - accuracy: 0.8549 - val_loss: 0.4749 - val_accuracy: 0.8292\n",
      "Epoch 20/30\n",
      "5148/5148 - 3s - loss: 0.4911 - accuracy: 0.8394 - val_loss: 0.4357 - val_accuracy: 0.8276\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4594 - accuracy: 0.8407 - val_loss: 0.4561 - val_accuracy: 0.8339\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3684 - accuracy: 0.8584 - val_loss: 0.4291 - val_accuracy: 0.8292\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3611 - accuracy: 0.8543 - val_loss: 0.4336 - val_accuracy: 0.8339\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3698 - accuracy: 0.8537 - val_loss: 0.4186 - val_accuracy: 0.8307\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3492 - accuracy: 0.8547 - val_loss: 0.4229 - val_accuracy: 0.8385\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3595 - accuracy: 0.8549 - val_loss: 0.4112 - val_accuracy: 0.8307\n",
      "Epoch 27/30\n",
      "5148/5148 - 2s - loss: 0.3595 - accuracy: 0.8576 - val_loss: 0.4774 - val_accuracy: 0.8401\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.3516 - accuracy: 0.8547 - val_loss: 0.4540 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3785 - accuracy: 0.8531 - val_loss: 0.4130 - val_accuracy: 0.8354\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3369 - accuracy: 0.8539 - val_loss: 0.4059 - val_accuracy: 0.8292\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 2.9275 - accuracy: 0.6707 - val_loss: 0.4726 - val_accuracy: 0.7857\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 1.0500 - accuracy: 0.7213 - val_loss: 1.0538 - val_accuracy: 0.7034\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.7536 - accuracy: 0.7867 - val_loss: 1.1277 - val_accuracy: 0.5870\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 0.7370 - accuracy: 0.7852 - val_loss: 0.8480 - val_accuracy: 0.8323\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 1.0994 - accuracy: 0.7529 - val_loss: 0.7592 - val_accuracy: 0.8665\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 1.0041 - accuracy: 0.7791 - val_loss: 0.7413 - val_accuracy: 0.8618\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.7826 - accuracy: 0.8046 - val_loss: 0.6214 - val_accuracy: 0.8602\n",
      "Epoch 8/30\n",
      "5148/5148 - 3s - loss: 0.6673 - accuracy: 0.8201 - val_loss: 0.5397 - val_accuracy: 0.8370\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.7586 - accuracy: 0.8036 - val_loss: 0.7102 - val_accuracy: 0.7702\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.9290 - accuracy: 0.7908 - val_loss: 1.2117 - val_accuracy: 0.7469\n",
      "Epoch 11/30\n",
      "5148/5148 - 0s - loss: 0.7709 - accuracy: 0.8182 - val_loss: 1.0725 - val_accuracy: 0.7578\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.8593 - accuracy: 0.7982 - val_loss: 1.4654 - val_accuracy: 0.7298\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.9069 - accuracy: 0.8071 - val_loss: 1.1140 - val_accuracy: 0.7562\n",
      "Epoch 14/30\n",
      "5148/5148 - 0s - loss: 0.5900 - accuracy: 0.8467 - val_loss: 0.8802 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.6260 - accuracy: 0.8353 - val_loss: 0.6683 - val_accuracy: 0.8323\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.5130 - accuracy: 0.8551 - val_loss: 0.5457 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5783 - accuracy: 0.8339 - val_loss: 0.6249 - val_accuracy: 0.8323\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.5434 - accuracy: 0.8397 - val_loss: 0.6870 - val_accuracy: 0.8292\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.5191 - accuracy: 0.8413 - val_loss: 0.4900 - val_accuracy: 0.8354\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.5214 - accuracy: 0.8477 - val_loss: 0.5158 - val_accuracy: 0.8339\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.5653 - accuracy: 0.8240 - val_loss: 0.7999 - val_accuracy: 0.7811\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4157 - accuracy: 0.8586 - val_loss: 0.4745 - val_accuracy: 0.8307\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3957 - accuracy: 0.8553 - val_loss: 0.4668 - val_accuracy: 0.8292\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4020 - accuracy: 0.8528 - val_loss: 0.4588 - val_accuracy: 0.8307\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3733 - accuracy: 0.8531 - val_loss: 0.4892 - val_accuracy: 0.8556\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3928 - accuracy: 0.8553 - val_loss: 0.4405 - val_accuracy: 0.8292\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3883 - accuracy: 0.8615 - val_loss: 0.5334 - val_accuracy: 0.8432\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3768 - accuracy: 0.8564 - val_loss: 0.4323 - val_accuracy: 0.8276\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3929 - accuracy: 0.8533 - val_loss: 0.4297 - val_accuracy: 0.8261\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3532 - accuracy: 0.8531 - val_loss: 0.4292 - val_accuracy: 0.8261\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 5.0465 - accuracy: 0.6733 - val_loss: 0.5670 - val_accuracy: 0.8509\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.1534 - accuracy: 0.7125 - val_loss: 0.9588 - val_accuracy: 0.7189\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.8822 - accuracy: 0.7652 - val_loss: 0.6015 - val_accuracy: 0.8370\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.8765 - accuracy: 0.7869 - val_loss: 0.7076 - val_accuracy: 0.8634\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 1.0100 - accuracy: 0.7636 - val_loss: 1.7563 - val_accuracy: 0.5559\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 1.0138 - accuracy: 0.7865 - val_loss: 0.7634 - val_accuracy: 0.8649\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.0156 - accuracy: 0.7871 - val_loss: 0.6613 - val_accuracy: 0.8602\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.9152 - accuracy: 0.7993 - val_loss: 0.8554 - val_accuracy: 0.8618\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.0009 - accuracy: 0.7887 - val_loss: 0.8309 - val_accuracy: 0.7764\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.9588 - accuracy: 0.8001 - val_loss: 1.3175 - val_accuracy: 0.7484\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.9346 - accuracy: 0.8108 - val_loss: 2.8661 - val_accuracy: 0.6320\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 1.1780 - accuracy: 0.7826 - val_loss: 0.7667 - val_accuracy: 0.8245\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.8731 - accuracy: 0.8153 - val_loss: 1.1428 - val_accuracy: 0.7655\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.8333 - accuracy: 0.8223 - val_loss: 1.0918 - val_accuracy: 0.7671\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.6327 - accuracy: 0.8448 - val_loss: 0.7316 - val_accuracy: 0.8323\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.5492 - accuracy: 0.8500 - val_loss: 0.5832 - val_accuracy: 0.8525\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.6113 - accuracy: 0.8331 - val_loss: 0.6407 - val_accuracy: 0.8261\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.5737 - accuracy: 0.8378 - val_loss: 0.7248 - val_accuracy: 0.8385\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.5573 - accuracy: 0.8407 - val_loss: 0.5273 - val_accuracy: 0.8354\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.5702 - accuracy: 0.8469 - val_loss: 0.5446 - val_accuracy: 0.8323\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.6111 - accuracy: 0.8228 - val_loss: 0.7937 - val_accuracy: 0.7857\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.6345 - accuracy: 0.8232 - val_loss: 1.0148 - val_accuracy: 0.6879\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4388 - accuracy: 0.8584 - val_loss: 0.5159 - val_accuracy: 0.8292\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4369 - accuracy: 0.8545 - val_loss: 0.4991 - val_accuracy: 0.8307\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.4037 - accuracy: 0.8572 - val_loss: 0.5051 - val_accuracy: 0.8525\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.4146 - accuracy: 0.8557 - val_loss: 0.4762 - val_accuracy: 0.8245\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.4104 - accuracy: 0.8599 - val_loss: 0.5810 - val_accuracy: 0.8463\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3954 - accuracy: 0.8547 - val_loss: 0.4656 - val_accuracy: 0.8276\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.4161 - accuracy: 0.8500 - val_loss: 0.4589 - val_accuracy: 0.8230\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.4294 - accuracy: 0.8574 - val_loss: 0.4618 - val_accuracy: 0.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:53:01,019] Trial 13 finished with value: 0.8645962476730347 and parameters: {'units': 75, 'dropout': 0.0, 'learning_rate': 0.002176177541944633, 'epochs': 30, 'batch_size': 25, 'patience': 8, 'factor': 0.30000000000000004}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 3s - loss: 35.0625 - accuracy: 0.5286 - val_loss: 0.5847 - val_accuracy: 0.7717\n",
      "Epoch 2/45\n",
      "5148/5148 - 2s - loss: 0.8193 - accuracy: 0.5447 - val_loss: 0.7432 - val_accuracy: 0.4922\n",
      "Epoch 3/45\n",
      "5148/5148 - 2s - loss: 0.7591 - accuracy: 0.5301 - val_loss: 0.6756 - val_accuracy: 0.7220\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.6997 - accuracy: 0.5666 - val_loss: 0.6467 - val_accuracy: 0.6475\n",
      "Epoch 5/45\n",
      "5148/5148 - 2s - loss: 0.7052 - accuracy: 0.5657 - val_loss: 0.6049 - val_accuracy: 0.7686\n",
      "Epoch 6/45\n",
      "5148/5148 - 2s - loss: 0.6400 - accuracy: 0.6228 - val_loss: 0.5930 - val_accuracy: 0.8494\n",
      "Epoch 7/45\n",
      "5148/5148 - 2s - loss: 0.6202 - accuracy: 0.6527 - val_loss: 0.6090 - val_accuracy: 0.7422\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.6239 - accuracy: 0.6447 - val_loss: 0.5601 - val_accuracy: 0.7422\n",
      "Epoch 9/45\n",
      "5148/5148 - 2s - loss: 0.6174 - accuracy: 0.6599 - val_loss: 0.5952 - val_accuracy: 0.7345\n",
      "Epoch 10/45\n",
      "5148/5148 - 2s - loss: 0.5911 - accuracy: 0.6853 - val_loss: 0.5730 - val_accuracy: 0.7469\n",
      "Epoch 11/45\n",
      "5148/5148 - 2s - loss: 0.5661 - accuracy: 0.6999 - val_loss: 0.5299 - val_accuracy: 0.7609\n",
      "Epoch 12/45\n",
      "5148/5148 - 2s - loss: 0.5673 - accuracy: 0.6983 - val_loss: 0.5070 - val_accuracy: 0.8230\n",
      "Epoch 13/45\n",
      "5148/5148 - 2s - loss: 0.5339 - accuracy: 0.7461 - val_loss: 0.4766 - val_accuracy: 0.8323\n",
      "Epoch 14/45\n",
      "5148/5148 - 2s - loss: 0.5269 - accuracy: 0.7618 - val_loss: 0.4834 - val_accuracy: 0.8292\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.5085 - accuracy: 0.7756 - val_loss: 0.4649 - val_accuracy: 0.8370\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.5053 - accuracy: 0.7727 - val_loss: 0.4806 - val_accuracy: 0.8354\n",
      "Epoch 17/45\n",
      "5148/5148 - 2s - loss: 0.5062 - accuracy: 0.7758 - val_loss: 0.4493 - val_accuracy: 0.8354\n",
      "Epoch 18/45\n",
      "5148/5148 - 2s - loss: 0.4938 - accuracy: 0.7805 - val_loss: 0.4552 - val_accuracy: 0.8416\n",
      "Epoch 19/45\n",
      "5148/5148 - 2s - loss: 0.4817 - accuracy: 0.7883 - val_loss: 0.4494 - val_accuracy: 0.8339\n",
      "Epoch 20/45\n",
      "5148/5148 - 2s - loss: 0.4898 - accuracy: 0.7832 - val_loss: 0.4440 - val_accuracy: 0.8401\n",
      "Epoch 21/45\n",
      "5148/5148 - 2s - loss: 0.4933 - accuracy: 0.7799 - val_loss: 0.4471 - val_accuracy: 0.8416\n",
      "Epoch 22/45\n",
      "5148/5148 - 2s - loss: 0.4827 - accuracy: 0.7929 - val_loss: 0.4380 - val_accuracy: 0.8416\n",
      "Epoch 23/45\n",
      "5148/5148 - 3s - loss: 0.4663 - accuracy: 0.8083 - val_loss: 0.4390 - val_accuracy: 0.8432\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.4627 - accuracy: 0.8133 - val_loss: 0.4341 - val_accuracy: 0.8354\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4615 - accuracy: 0.8079 - val_loss: 0.4410 - val_accuracy: 0.8432\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4557 - accuracy: 0.8170 - val_loss: 0.4306 - val_accuracy: 0.8416\n",
      "Epoch 27/45\n",
      "5148/5148 - 2s - loss: 0.4549 - accuracy: 0.8170 - val_loss: 0.4276 - val_accuracy: 0.8401\n",
      "Epoch 28/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:53:53,059] Trial 14 pruned. Trial was pruned at epoch 27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 49.9889 - accuracy: 0.5056 - val_loss: 0.5793 - val_accuracy: 0.7127\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 28.0541 - accuracy: 0.5097 - val_loss: 1.7222 - val_accuracy: 0.5435\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 20.4150 - accuracy: 0.5235 - val_loss: 0.6028 - val_accuracy: 0.7795\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 14.7495 - accuracy: 0.5389 - val_loss: 1.0463 - val_accuracy: 0.7267\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 9.8686 - accuracy: 0.5647 - val_loss: 0.7681 - val_accuracy: 0.7484\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:53:58,174] Trial 15 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 29.6447 - accuracy: 0.5449 - val_loss: 0.5164 - val_accuracy: 0.7252\n",
      "Epoch 2/35\n",
      "5148/5148 - 3s - loss: 0.6924 - accuracy: 0.6294 - val_loss: 0.5448 - val_accuracy: 0.8447\n",
      "Epoch 3/35\n",
      "5148/5148 - 5s - loss: 0.6183 - accuracy: 0.6723 - val_loss: 0.6033 - val_accuracy: 0.6351\n",
      "Epoch 4/35\n",
      "5148/5148 - 4s - loss: 0.5929 - accuracy: 0.6830 - val_loss: 0.5182 - val_accuracy: 0.8385\n",
      "Epoch 5/35\n",
      "5148/5148 - 5s - loss: 0.6291 - accuracy: 0.6354 - val_loss: 0.5946 - val_accuracy: 0.7360\n",
      "Epoch 6/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:54:20,959] Trial 16 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 7s - loss: 31.4397 - accuracy: 0.6028 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 2/50\n",
      "5148/5148 - 2s - loss: 18.8011 - accuracy: 0.6453 - val_loss: 0.5713 - val_accuracy: 0.8478\n",
      "Epoch 3/50\n",
      "5148/5148 - 2s - loss: 14.5096 - accuracy: 0.7214 - val_loss: 0.4719 - val_accuracy: 0.8214\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 11.6287 - accuracy: 0.7236 - val_loss: 0.5149 - val_accuracy: 0.8463\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 8.9818 - accuracy: 0.7302 - val_loss: 0.5149 - val_accuracy: 0.8463\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:54:35,638] Trial 17 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 42.8122 - accuracy: 0.5301 - val_loss: 0.4941 - val_accuracy: 0.7438\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.6998 - accuracy: 0.6311 - val_loss: 0.5888 - val_accuracy: 0.6165\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.6026 - accuracy: 0.6904 - val_loss: 0.4843 - val_accuracy: 0.7780\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.5884 - accuracy: 0.6904 - val_loss: 0.5296 - val_accuracy: 0.7376\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5940 - accuracy: 0.7001 - val_loss: 0.5369 - val_accuracy: 0.7329\n",
      "Epoch 6/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:54:40,806] Trial 18 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:54:42,657] Trial 19 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 6s - loss: 111.0314 - accuracy: 0.5066 - val_loss: 0.5521 - val_accuracy: 0.7826\n",
      "Epoch 2/45\n",
      "5148/5148 - 2s - loss: 6.8841 - accuracy: 0.6204 - val_loss: 0.5671 - val_accuracy: 0.6599\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.5538 - accuracy: 0.7279 - val_loss: 0.5281 - val_accuracy: 0.7376\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.5494 - accuracy: 0.7259 - val_loss: 0.6198 - val_accuracy: 0.6475\n",
      "Epoch 5/45\n",
      "5148/5148 - 2s - loss: 0.5986 - accuracy: 0.6558 - val_loss: 0.5816 - val_accuracy: 0.7717\n",
      "Epoch 6/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:54:55,845] Trial 20 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 1.5214 - accuracy: 0.6702 - val_loss: 0.5922 - val_accuracy: 0.7407\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.6449 - accuracy: 0.7403 - val_loss: 0.8931 - val_accuracy: 0.6693\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6523 - accuracy: 0.7624 - val_loss: 0.5435 - val_accuracy: 0.7314\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.5449 - accuracy: 0.7914 - val_loss: 0.6410 - val_accuracy: 0.8401\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.6859 - accuracy: 0.7650 - val_loss: 0.6049 - val_accuracy: 0.8618\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.6845 - accuracy: 0.7813 - val_loss: 0.4935 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.5383 - accuracy: 0.8188 - val_loss: 0.4477 - val_accuracy: 0.8354\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.5203 - accuracy: 0.8147 - val_loss: 0.6892 - val_accuracy: 0.8587\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.5363 - accuracy: 0.8174 - val_loss: 0.6595 - val_accuracy: 0.7578\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.6365 - accuracy: 0.7885 - val_loss: 0.4652 - val_accuracy: 0.8370\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.6487 - accuracy: 0.8069 - val_loss: 2.1167 - val_accuracy: 0.5932\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.5385 - accuracy: 0.8244 - val_loss: 0.5210 - val_accuracy: 0.8230\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.6405 - accuracy: 0.7935 - val_loss: 1.8191 - val_accuracy: 0.6491\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4586 - accuracy: 0.8512 - val_loss: 0.5572 - val_accuracy: 0.8618\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4385 - accuracy: 0.8518 - val_loss: 0.5133 - val_accuracy: 0.8307\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4023 - accuracy: 0.8568 - val_loss: 0.4484 - val_accuracy: 0.8540\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.4823 - accuracy: 0.8289 - val_loss: 0.7239 - val_accuracy: 0.7624\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4083 - accuracy: 0.8462 - val_loss: 0.4775 - val_accuracy: 0.8261\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4044 - accuracy: 0.8537 - val_loss: 0.4689 - val_accuracy: 0.8261\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4355 - accuracy: 0.8479 - val_loss: 0.4199 - val_accuracy: 0.8587\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4085 - accuracy: 0.8483 - val_loss: 0.4400 - val_accuracy: 0.8556\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3432 - accuracy: 0.8596 - val_loss: 0.4025 - val_accuracy: 0.8307\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3423 - accuracy: 0.8551 - val_loss: 0.4130 - val_accuracy: 0.8354\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3504 - accuracy: 0.8533 - val_loss: 0.3964 - val_accuracy: 0.8307\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3373 - accuracy: 0.8551 - val_loss: 0.3936 - val_accuracy: 0.8261\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 3.3803 - accuracy: 0.6540 - val_loss: 1.4031 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.6255 - accuracy: 0.7519 - val_loss: 0.9126 - val_accuracy: 0.6724\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6729 - accuracy: 0.7655 - val_loss: 0.5372 - val_accuracy: 0.7578\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.5580 - accuracy: 0.7933 - val_loss: 0.5692 - val_accuracy: 0.8634\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.6987 - accuracy: 0.7663 - val_loss: 0.7736 - val_accuracy: 0.8339\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.7693 - accuracy: 0.7768 - val_loss: 0.5144 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.5638 - accuracy: 0.8217 - val_loss: 0.4598 - val_accuracy: 0.8571\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.5702 - accuracy: 0.8079 - val_loss: 0.7067 - val_accuracy: 0.8649\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.5828 - accuracy: 0.8166 - val_loss: 0.6539 - val_accuracy: 0.7593\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.6762 - accuracy: 0.7918 - val_loss: 0.5253 - val_accuracy: 0.8183\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.6815 - accuracy: 0.8063 - val_loss: 2.1552 - val_accuracy: 0.6149\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.6056 - accuracy: 0.8172 - val_loss: 0.5827 - val_accuracy: 0.8168\n",
      "Epoch 13/25\n",
      "5148/5148 - 0s - loss: 0.7223 - accuracy: 0.7861 - val_loss: 2.1521 - val_accuracy: 0.6351\n",
      "Epoch 14/25\n",
      "5148/5148 - 0s - loss: 0.6326 - accuracy: 0.8279 - val_loss: 0.5818 - val_accuracy: 0.8292\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.7325 - accuracy: 0.7997 - val_loss: 0.9647 - val_accuracy: 0.7500\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.6187 - accuracy: 0.8195 - val_loss: 0.7839 - val_accuracy: 0.7686\n",
      "Epoch 17/25\n",
      "5148/5148 - 0s - loss: 0.4644 - accuracy: 0.8555 - val_loss: 0.5467 - val_accuracy: 0.8618\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4377 - accuracy: 0.8524 - val_loss: 0.4571 - val_accuracy: 0.8323\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4201 - accuracy: 0.8530 - val_loss: 0.4828 - val_accuracy: 0.8292\n",
      "Epoch 20/25\n",
      "5148/5148 - 0s - loss: 0.4429 - accuracy: 0.8508 - val_loss: 0.4751 - val_accuracy: 0.8556\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4237 - accuracy: 0.8531 - val_loss: 0.5768 - val_accuracy: 0.8571\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.4730 - accuracy: 0.8312 - val_loss: 0.5181 - val_accuracy: 0.8556\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.4004 - accuracy: 0.8547 - val_loss: 0.4635 - val_accuracy: 0.8556\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3885 - accuracy: 0.8578 - val_loss: 0.8194 - val_accuracy: 0.6599\n",
      "Epoch 25/25\n",
      "5148/5148 - 4s - loss: 0.3637 - accuracy: 0.8547 - val_loss: 0.4263 - val_accuracy: 0.8354\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 12.1578 - accuracy: 0.6412 - val_loss: 1.2787 - val_accuracy: 0.5792\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.6794 - accuracy: 0.7407 - val_loss: 1.0094 - val_accuracy: 0.6599\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6766 - accuracy: 0.7609 - val_loss: 0.4563 - val_accuracy: 0.8494\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.6136 - accuracy: 0.7881 - val_loss: 0.7018 - val_accuracy: 0.8121\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.7848 - accuracy: 0.7582 - val_loss: 0.8021 - val_accuracy: 0.8416\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.8067 - accuracy: 0.7716 - val_loss: 0.5316 - val_accuracy: 0.8602\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.5965 - accuracy: 0.8151 - val_loss: 0.4935 - val_accuracy: 0.8571\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.6334 - accuracy: 0.8017 - val_loss: 0.7523 - val_accuracy: 0.8587\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.5912 - accuracy: 0.8129 - val_loss: 0.7465 - val_accuracy: 0.7547\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.7048 - accuracy: 0.7908 - val_loss: 0.5897 - val_accuracy: 0.7935\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.6557 - accuracy: 0.8098 - val_loss: 2.5482 - val_accuracy: 0.5807\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.6562 - accuracy: 0.8063 - val_loss: 0.6806 - val_accuracy: 0.7609\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.7332 - accuracy: 0.7875 - val_loss: 1.6134 - val_accuracy: 0.6848\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.6697 - accuracy: 0.8248 - val_loss: 0.6493 - val_accuracy: 0.7966\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4597 - accuracy: 0.8526 - val_loss: 0.5428 - val_accuracy: 0.8292\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4273 - accuracy: 0.8555 - val_loss: 0.4759 - val_accuracy: 0.8540\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.5103 - accuracy: 0.8265 - val_loss: 0.7566 - val_accuracy: 0.7640\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4345 - accuracy: 0.8438 - val_loss: 0.5236 - val_accuracy: 0.8292\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4224 - accuracy: 0.8531 - val_loss: 0.4917 - val_accuracy: 0.8245\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4744 - accuracy: 0.8438 - val_loss: 0.4296 - val_accuracy: 0.8354\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4348 - accuracy: 0.8456 - val_loss: 0.4220 - val_accuracy: 0.8261\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.4607 - accuracy: 0.8302 - val_loss: 0.7023 - val_accuracy: 0.8012\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3622 - accuracy: 0.8603 - val_loss: 0.4351 - val_accuracy: 0.8339\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3639 - accuracy: 0.8551 - val_loss: 0.4171 - val_accuracy: 0.8307\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3500 - accuracy: 0.8566 - val_loss: 0.4112 - val_accuracy: 0.8245\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 4.5404 - accuracy: 0.6814 - val_loss: 0.5869 - val_accuracy: 0.7376\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.7299 - accuracy: 0.7434 - val_loss: 0.9475 - val_accuracy: 0.6832\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6258 - accuracy: 0.7836 - val_loss: 0.8726 - val_accuracy: 0.6366\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.6089 - accuracy: 0.7960 - val_loss: 0.7645 - val_accuracy: 0.7935\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.9232 - accuracy: 0.7504 - val_loss: 0.6406 - val_accuracy: 0.8649\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.7749 - accuracy: 0.7892 - val_loss: 0.5638 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.6731 - accuracy: 0.8061 - val_loss: 0.5640 - val_accuracy: 0.8618\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.7296 - accuracy: 0.7978 - val_loss: 0.8612 - val_accuracy: 0.8339\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.6306 - accuracy: 0.8197 - val_loss: 0.8356 - val_accuracy: 0.7562\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.7553 - accuracy: 0.7993 - val_loss: 0.8287 - val_accuracy: 0.7624\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.7095 - accuracy: 0.8089 - val_loss: 1.5075 - val_accuracy: 0.6988\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.8067 - accuracy: 0.7991 - val_loss: 0.6179 - val_accuracy: 0.8230\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.8680 - accuracy: 0.7830 - val_loss: 2.6351 - val_accuracy: 0.6196\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.5670 - accuracy: 0.8514 - val_loss: 0.7007 - val_accuracy: 0.8571\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.5271 - accuracy: 0.8531 - val_loss: 0.6008 - val_accuracy: 0.8292\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4701 - accuracy: 0.8541 - val_loss: 0.5189 - val_accuracy: 0.8540\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.5364 - accuracy: 0.8347 - val_loss: 0.6299 - val_accuracy: 0.8307\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4736 - accuracy: 0.8427 - val_loss: 0.5659 - val_accuracy: 0.8292\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4505 - accuracy: 0.8549 - val_loss: 0.4820 - val_accuracy: 0.8339\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.5120 - accuracy: 0.8411 - val_loss: 0.4535 - val_accuracy: 0.8307\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4858 - accuracy: 0.8392 - val_loss: 0.4902 - val_accuracy: 0.8276\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3818 - accuracy: 0.8592 - val_loss: 0.4455 - val_accuracy: 0.8292\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3726 - accuracy: 0.8543 - val_loss: 0.4471 - val_accuracy: 0.8307\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3815 - accuracy: 0.8535 - val_loss: 0.4336 - val_accuracy: 0.8292\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3583 - accuracy: 0.8530 - val_loss: 0.4414 - val_accuracy: 0.8540\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 10.8299 - accuracy: 0.6678 - val_loss: 0.5948 - val_accuracy: 0.7143\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.6327 - accuracy: 0.7481 - val_loss: 0.9031 - val_accuracy: 0.6693\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6242 - accuracy: 0.7683 - val_loss: 0.4401 - val_accuracy: 0.8509\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.5751 - accuracy: 0.7937 - val_loss: 0.6315 - val_accuracy: 0.8618\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.7299 - accuracy: 0.7650 - val_loss: 0.7107 - val_accuracy: 0.8634\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.7647 - accuracy: 0.7756 - val_loss: 0.5158 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.5684 - accuracy: 0.8201 - val_loss: 0.4634 - val_accuracy: 0.8587\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.5689 - accuracy: 0.8073 - val_loss: 0.6610 - val_accuracy: 0.8602\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.5640 - accuracy: 0.8199 - val_loss: 0.7253 - val_accuracy: 0.7547\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.6859 - accuracy: 0.7892 - val_loss: 0.5408 - val_accuracy: 0.8152\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.6267 - accuracy: 0.8139 - val_loss: 2.0711 - val_accuracy: 0.6149\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.6493 - accuracy: 0.8052 - val_loss: 0.5779 - val_accuracy: 0.8121\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.7086 - accuracy: 0.7879 - val_loss: 1.8205 - val_accuracy: 0.6677\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4841 - accuracy: 0.8518 - val_loss: 0.6027 - val_accuracy: 0.8571\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4661 - accuracy: 0.8526 - val_loss: 0.5414 - val_accuracy: 0.8292\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4207 - accuracy: 0.8555 - val_loss: 0.4715 - val_accuracy: 0.8540\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.4975 - accuracy: 0.8308 - val_loss: 0.6828 - val_accuracy: 0.7686\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4284 - accuracy: 0.8444 - val_loss: 0.5150 - val_accuracy: 0.8307\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4156 - accuracy: 0.8539 - val_loss: 0.4799 - val_accuracy: 0.8261\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4654 - accuracy: 0.8454 - val_loss: 0.4220 - val_accuracy: 0.8339\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4289 - accuracy: 0.8456 - val_loss: 0.4156 - val_accuracy: 0.8276\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3540 - accuracy: 0.8594 - val_loss: 0.4144 - val_accuracy: 0.8323\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3506 - accuracy: 0.8549 - val_loss: 0.4228 - val_accuracy: 0.8323\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3594 - accuracy: 0.8528 - val_loss: 0.4061 - val_accuracy: 0.8307\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3425 - accuracy: 0.8549 - val_loss: 0.4049 - val_accuracy: 0.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 21:56:41,677] Trial 21 finished with value: 0.863043487071991 and parameters: {'units': 75, 'dropout': 0.0, 'learning_rate': 0.0017808096297605293, 'epochs': 25, 'batch_size': 25, 'patience': 8, 'factor': 0.30000000000000004}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 14.6154 - accuracy: 0.5379 - val_loss: 1.0763 - val_accuracy: 0.8199\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.9469 - accuracy: 0.6826 - val_loss: 2.1873 - val_accuracy: 0.5124\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.8624 - accuracy: 0.7457 - val_loss: 0.4604 - val_accuracy: 0.7873\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.5283 - accuracy: 0.7813 - val_loss: 0.4661 - val_accuracy: 0.8416\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5280 - accuracy: 0.7809 - val_loss: 0.5034 - val_accuracy: 0.8587\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.5013 - accuracy: 0.7786 - val_loss: 0.8172 - val_accuracy: 0.5311\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4339 - accuracy: 0.8182 - val_loss: 0.4565 - val_accuracy: 0.7671\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4196 - accuracy: 0.8314 - val_loss: 0.4426 - val_accuracy: 0.7469\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4209 - accuracy: 0.8275 - val_loss: 0.4406 - val_accuracy: 0.8571\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4014 - accuracy: 0.8438 - val_loss: 0.4653 - val_accuracy: 0.7516\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4096 - accuracy: 0.8248 - val_loss: 0.4451 - val_accuracy: 0.8556\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4029 - accuracy: 0.8407 - val_loss: 0.4492 - val_accuracy: 0.8602\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.3867 - accuracy: 0.8471 - val_loss: 0.3820 - val_accuracy: 0.8525\n",
      "Epoch 14/30\n",
      "5148/5148 - 4s - loss: 0.3832 - accuracy: 0.8469 - val_loss: 0.4542 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 3s - loss: 0.3980 - accuracy: 0.8401 - val_loss: 0.4466 - val_accuracy: 0.7484\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3938 - accuracy: 0.8382 - val_loss: 0.3818 - val_accuracy: 0.8602\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4149 - accuracy: 0.8254 - val_loss: 0.4028 - val_accuracy: 0.8416\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.4240 - accuracy: 0.8197 - val_loss: 0.3963 - val_accuracy: 0.8618\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.3908 - accuracy: 0.8419 - val_loss: 0.4378 - val_accuracy: 0.7593\n",
      "Epoch 20/30\n",
      "5148/5148 - 2s - loss: 0.3899 - accuracy: 0.8366 - val_loss: 0.4328 - val_accuracy: 0.8587\n",
      "Epoch 21/30\n",
      "5148/5148 - 3s - loss: 0.3785 - accuracy: 0.8508 - val_loss: 0.4087 - val_accuracy: 0.8587\n",
      "Epoch 22/30\n",
      "5148/5148 - 3s - loss: 0.3893 - accuracy: 0.8452 - val_loss: 0.3701 - val_accuracy: 0.8634\n",
      "Epoch 23/30\n",
      "5148/5148 - 4s - loss: 0.3723 - accuracy: 0.8430 - val_loss: 0.3819 - val_accuracy: 0.8587\n",
      "Epoch 24/30\n",
      "5148/5148 - 3s - loss: 0.3691 - accuracy: 0.8473 - val_loss: 0.4206 - val_accuracy: 0.8587\n",
      "Epoch 25/30\n",
      "5148/5148 - 4s - loss: 0.3620 - accuracy: 0.8551 - val_loss: 0.4361 - val_accuracy: 0.8602\n",
      "Epoch 26/30\n",
      "5148/5148 - 4s - loss: 0.3772 - accuracy: 0.8469 - val_loss: 0.4303 - val_accuracy: 0.8618\n",
      "Epoch 27/30\n",
      "5148/5148 - 3s - loss: 0.3715 - accuracy: 0.8498 - val_loss: 0.4047 - val_accuracy: 0.8168\n",
      "Epoch 28/30\n",
      "5148/5148 - 5s - loss: 0.3743 - accuracy: 0.8471 - val_loss: 0.4184 - val_accuracy: 0.8354\n",
      "Epoch 29/30\n",
      "5148/5148 - 4s - loss: 0.4054 - accuracy: 0.8394 - val_loss: 0.3977 - val_accuracy: 0.8354\n",
      "Epoch 30/30\n",
      "5148/5148 - 5s - loss: 0.4067 - accuracy: 0.8341 - val_loss: 0.3871 - val_accuracy: 0.8556\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 19.0690 - accuracy: 0.5509 - val_loss: 1.7208 - val_accuracy: 0.7360\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 4.5290 - accuracy: 0.6595 - val_loss: 1.2362 - val_accuracy: 0.7780\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.3144 - accuracy: 0.7525 - val_loss: 0.6162 - val_accuracy: 0.7562\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.6393 - accuracy: 0.7754 - val_loss: 0.4830 - val_accuracy: 0.8540\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5281 - accuracy: 0.7875 - val_loss: 0.4514 - val_accuracy: 0.8556\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4951 - accuracy: 0.7900 - val_loss: 0.4508 - val_accuracy: 0.8540\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4455 - accuracy: 0.8160 - val_loss: 0.7747 - val_accuracy: 0.6537\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4456 - accuracy: 0.8193 - val_loss: 0.6480 - val_accuracy: 0.6910\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4458 - accuracy: 0.8083 - val_loss: 0.4134 - val_accuracy: 0.8556\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4056 - accuracy: 0.8362 - val_loss: 0.4901 - val_accuracy: 0.7422\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4057 - accuracy: 0.8271 - val_loss: 0.4201 - val_accuracy: 0.8354\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.3917 - accuracy: 0.8452 - val_loss: 0.4154 - val_accuracy: 0.8634\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.3888 - accuracy: 0.8446 - val_loss: 0.3956 - val_accuracy: 0.8509\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3745 - accuracy: 0.8530 - val_loss: 0.4605 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3814 - accuracy: 0.8432 - val_loss: 0.4021 - val_accuracy: 0.8199\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3867 - accuracy: 0.8394 - val_loss: 0.4115 - val_accuracy: 0.8618\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4002 - accuracy: 0.8329 - val_loss: 0.4197 - val_accuracy: 0.7547\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3911 - accuracy: 0.8361 - val_loss: 0.4006 - val_accuracy: 0.8618\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3929 - accuracy: 0.8415 - val_loss: 0.3837 - val_accuracy: 0.8401\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3901 - accuracy: 0.8467 - val_loss: 0.3833 - val_accuracy: 0.8385\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3518 - accuracy: 0.8592 - val_loss: 0.3774 - val_accuracy: 0.8385\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3544 - accuracy: 0.8477 - val_loss: 0.3809 - val_accuracy: 0.8649\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3533 - accuracy: 0.8547 - val_loss: 0.3838 - val_accuracy: 0.8230\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3545 - accuracy: 0.8463 - val_loss: 0.3728 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3351 - accuracy: 0.8598 - val_loss: 0.3717 - val_accuracy: 0.8307\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3441 - accuracy: 0.8566 - val_loss: 0.3541 - val_accuracy: 0.8634\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3365 - accuracy: 0.8603 - val_loss: 0.3797 - val_accuracy: 0.8276\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3403 - accuracy: 0.8572 - val_loss: 0.4562 - val_accuracy: 0.8618\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3292 - accuracy: 0.8656 - val_loss: 0.3304 - val_accuracy: 0.8587\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3097 - accuracy: 0.8704 - val_loss: 0.3423 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 21.2781 - accuracy: 0.5460 - val_loss: 4.0430 - val_accuracy: 0.4984\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 4.8187 - accuracy: 0.6626 - val_loss: 2.6246 - val_accuracy: 0.5419\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 1.4773 - accuracy: 0.7387 - val_loss: 0.5901 - val_accuracy: 0.7702\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 0.6086 - accuracy: 0.7657 - val_loss: 0.4917 - val_accuracy: 0.7531\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5602 - accuracy: 0.7603 - val_loss: 0.4384 - val_accuracy: 0.7748\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4989 - accuracy: 0.7855 - val_loss: 0.6685 - val_accuracy: 0.5994\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4252 - accuracy: 0.8228 - val_loss: 0.4155 - val_accuracy: 0.8447\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4015 - accuracy: 0.8462 - val_loss: 0.4295 - val_accuracy: 0.7857\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4058 - accuracy: 0.8347 - val_loss: 0.4032 - val_accuracy: 0.8478\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.3922 - accuracy: 0.8504 - val_loss: 0.4559 - val_accuracy: 0.7469\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.3871 - accuracy: 0.8436 - val_loss: 0.5004 - val_accuracy: 0.7376\n",
      "Epoch 12/30\n",
      "5148/5148 - 2s - loss: 0.3962 - accuracy: 0.8351 - val_loss: 0.4185 - val_accuracy: 0.8634\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.3735 - accuracy: 0.8553 - val_loss: 0.4014 - val_accuracy: 0.8634\n",
      "Epoch 14/30\n",
      "5148/5148 - 2s - loss: 0.3766 - accuracy: 0.8531 - val_loss: 0.4290 - val_accuracy: 0.8602\n",
      "Epoch 15/30\n",
      "5148/5148 - 2s - loss: 0.3939 - accuracy: 0.8407 - val_loss: 0.4329 - val_accuracy: 0.7562\n",
      "Epoch 16/30\n",
      "5148/5148 - 2s - loss: 0.3903 - accuracy: 0.8454 - val_loss: 0.3624 - val_accuracy: 0.8602\n",
      "Epoch 17/30\n",
      "5148/5148 - 2s - loss: 0.3753 - accuracy: 0.8456 - val_loss: 0.3920 - val_accuracy: 0.8634\n",
      "Epoch 18/30\n",
      "5148/5148 - 3s - loss: 0.3838 - accuracy: 0.8339 - val_loss: 0.3916 - val_accuracy: 0.8183\n",
      "Epoch 19/30\n",
      "5148/5148 - 3s - loss: 0.3652 - accuracy: 0.8487 - val_loss: 0.3383 - val_accuracy: 0.8649\n",
      "Epoch 20/30\n",
      "5148/5148 - 3s - loss: 0.3939 - accuracy: 0.8463 - val_loss: 0.3770 - val_accuracy: 0.8540\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3881 - accuracy: 0.8506 - val_loss: 0.4609 - val_accuracy: 0.8509\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3870 - accuracy: 0.8489 - val_loss: 0.3697 - val_accuracy: 0.8665\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3655 - accuracy: 0.8572 - val_loss: 0.3744 - val_accuracy: 0.8711\n",
      "Epoch 24/30\n",
      "5148/5148 - 2s - loss: 0.3564 - accuracy: 0.8621 - val_loss: 0.3651 - val_accuracy: 0.8587\n",
      "Epoch 25/30\n",
      "5148/5148 - 2s - loss: 0.3548 - accuracy: 0.8621 - val_loss: 0.3842 - val_accuracy: 0.8618\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3651 - accuracy: 0.8648 - val_loss: 0.3475 - val_accuracy: 0.8649\n",
      "Epoch 27/30\n",
      "5148/5148 - 3s - loss: 0.3439 - accuracy: 0.8613 - val_loss: 0.3419 - val_accuracy: 0.8634\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3289 - accuracy: 0.8631 - val_loss: 0.3881 - val_accuracy: 0.8696\n",
      "Epoch 29/30\n",
      "5148/5148 - 3s - loss: 0.4009 - accuracy: 0.8555 - val_loss: 0.3897 - val_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3799 - accuracy: 0.8644 - val_loss: 0.3696 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 19.3862 - accuracy: 0.5443 - val_loss: 7.8082 - val_accuracy: 0.4922\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 4.2934 - accuracy: 0.6636 - val_loss: 1.5241 - val_accuracy: 0.6661\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.1666 - accuracy: 0.7415 - val_loss: 0.4863 - val_accuracy: 0.7826\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 0.5169 - accuracy: 0.7900 - val_loss: 0.4329 - val_accuracy: 0.8339\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5103 - accuracy: 0.7753 - val_loss: 0.4159 - val_accuracy: 0.8416\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.5057 - accuracy: 0.7838 - val_loss: 0.5986 - val_accuracy: 0.7888\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4145 - accuracy: 0.8333 - val_loss: 0.4263 - val_accuracy: 0.7826\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4078 - accuracy: 0.8386 - val_loss: 0.4457 - val_accuracy: 0.7516\n",
      "Epoch 9/30\n",
      "5148/5148 - 2s - loss: 0.4082 - accuracy: 0.8314 - val_loss: 0.4047 - val_accuracy: 0.8494\n",
      "Epoch 10/30\n",
      "5148/5148 - 2s - loss: 0.4039 - accuracy: 0.8399 - val_loss: 0.4769 - val_accuracy: 0.7484\n",
      "Epoch 11/30\n",
      "5148/5148 - 3s - loss: 0.4079 - accuracy: 0.8283 - val_loss: 0.4546 - val_accuracy: 0.7531\n",
      "Epoch 12/30\n",
      "5148/5148 - 3s - loss: 0.4018 - accuracy: 0.8361 - val_loss: 0.4369 - val_accuracy: 0.8634\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.3870 - accuracy: 0.8477 - val_loss: 0.4175 - val_accuracy: 0.8634\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3929 - accuracy: 0.8392 - val_loss: 0.4292 - val_accuracy: 0.8649\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4037 - accuracy: 0.8351 - val_loss: 0.5008 - val_accuracy: 0.7127\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4067 - accuracy: 0.8267 - val_loss: 0.3775 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4061 - accuracy: 0.8263 - val_loss: 0.3963 - val_accuracy: 0.8261\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4065 - accuracy: 0.8287 - val_loss: 0.4044 - val_accuracy: 0.8587\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4008 - accuracy: 0.8337 - val_loss: 0.3776 - val_accuracy: 0.8680\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3965 - accuracy: 0.8302 - val_loss: 0.5092 - val_accuracy: 0.8618\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4082 - accuracy: 0.8366 - val_loss: 0.4463 - val_accuracy: 0.8292\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4243 - accuracy: 0.8347 - val_loss: 0.4094 - val_accuracy: 0.8587\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3782 - accuracy: 0.8415 - val_loss: 0.3480 - val_accuracy: 0.8634\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4101 - accuracy: 0.8312 - val_loss: 0.3816 - val_accuracy: 0.8540\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3837 - accuracy: 0.8454 - val_loss: 0.3973 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3838 - accuracy: 0.8427 - val_loss: 0.4337 - val_accuracy: 0.8602\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3951 - accuracy: 0.8380 - val_loss: 0.3915 - val_accuracy: 0.8339\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3746 - accuracy: 0.8411 - val_loss: 0.3902 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3715 - accuracy: 0.8497 - val_loss: 0.3762 - val_accuracy: 0.8634\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3661 - accuracy: 0.8471 - val_loss: 0.3925 - val_accuracy: 0.8571\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 13.6013 - accuracy: 0.5662 - val_loss: 1.0575 - val_accuracy: 0.7764\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.8135 - accuracy: 0.6847 - val_loss: 2.4151 - val_accuracy: 0.4984\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.8249 - accuracy: 0.7564 - val_loss: 0.4582 - val_accuracy: 0.7764\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4841 - accuracy: 0.7990 - val_loss: 0.4547 - val_accuracy: 0.8432\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5639 - accuracy: 0.7446 - val_loss: 0.4311 - val_accuracy: 0.8090\n",
      "Epoch 6/30\n",
      "5148/5148 - 3s - loss: 0.4642 - accuracy: 0.8024 - val_loss: 0.6647 - val_accuracy: 0.6568\n",
      "Epoch 7/30\n",
      "5148/5148 - 3s - loss: 0.4181 - accuracy: 0.8308 - val_loss: 0.4256 - val_accuracy: 0.7857\n",
      "Epoch 8/30\n",
      "5148/5148 - 4s - loss: 0.3921 - accuracy: 0.8467 - val_loss: 0.4219 - val_accuracy: 0.7950\n",
      "Epoch 9/30\n",
      "5148/5148 - 3s - loss: 0.4195 - accuracy: 0.8254 - val_loss: 0.4059 - val_accuracy: 0.8525\n",
      "Epoch 10/30\n",
      "5148/5148 - 4s - loss: 0.3865 - accuracy: 0.8518 - val_loss: 0.4889 - val_accuracy: 0.7360\n",
      "Epoch 11/30\n",
      "5148/5148 - 5s - loss: 0.3828 - accuracy: 0.8444 - val_loss: 0.4624 - val_accuracy: 0.7422\n",
      "Epoch 12/30\n",
      "5148/5148 - 3s - loss: 0.3784 - accuracy: 0.8545 - val_loss: 0.5309 - val_accuracy: 0.7795\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4221 - accuracy: 0.8228 - val_loss: 0.3899 - val_accuracy: 0.8509\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3871 - accuracy: 0.8463 - val_loss: 0.4411 - val_accuracy: 0.8634\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8314 - val_loss: 0.4230 - val_accuracy: 0.7655\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.3635 - val_accuracy: 0.8540\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3749 - accuracy: 0.8374 - val_loss: 0.3666 - val_accuracy: 0.8634\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.3524 - accuracy: 0.8555 - val_loss: 0.3396 - val_accuracy: 0.8634\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.3557 - accuracy: 0.8543 - val_loss: 0.3847 - val_accuracy: 0.8602\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3386 - accuracy: 0.8605 - val_loss: 0.3905 - val_accuracy: 0.8634\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3304 - accuracy: 0.8660 - val_loss: 0.3827 - val_accuracy: 0.8665\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3921 - accuracy: 0.8543 - val_loss: 0.3817 - val_accuracy: 0.8602\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3619 - accuracy: 0.8596 - val_loss: 0.3542 - val_accuracy: 0.8618\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3223 - accuracy: 0.8644 - val_loss: 0.3503 - val_accuracy: 0.8602\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3493 - accuracy: 0.8650 - val_loss: 0.4115 - val_accuracy: 0.8494\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3639 - accuracy: 0.8636 - val_loss: 0.3136 - val_accuracy: 0.8727\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3293 - accuracy: 0.8629 - val_loss: 0.4105 - val_accuracy: 0.8183\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3266 - accuracy: 0.8605 - val_loss: 0.3987 - val_accuracy: 0.8525\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3837 - accuracy: 0.8574 - val_loss: 0.3624 - val_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3788 - accuracy: 0.8578 - val_loss: 0.3804 - val_accuracy: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:00:33,977] Trial 22 finished with value: 0.8680124282836914 and parameters: {'units': 100, 'dropout': 0.05, 'learning_rate': 0.005819721184669565, 'epochs': 30, 'batch_size': 25, 'patience': 8, 'factor': 0.4}. Best is trial 1 with value: 0.8692547082901001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 17.1906 - accuracy: 0.5328 - val_loss: 1.5171 - val_accuracy: 0.7112\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.7252 - accuracy: 0.6702 - val_loss: 0.5425 - val_accuracy: 0.8447\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5312 - accuracy: 0.7702 - val_loss: 0.6271 - val_accuracy: 0.6910\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4637 - accuracy: 0.8007 - val_loss: 0.5404 - val_accuracy: 0.8602\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5068 - accuracy: 0.7721 - val_loss: 0.4191 - val_accuracy: 0.8494\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4498 - accuracy: 0.8127 - val_loss: 0.5335 - val_accuracy: 0.8556\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4393 - accuracy: 0.8100 - val_loss: 0.5975 - val_accuracy: 0.7065\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4354 - accuracy: 0.8174 - val_loss: 0.4095 - val_accuracy: 0.8478\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4203 - accuracy: 0.8248 - val_loss: 0.4243 - val_accuracy: 0.8385\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.3967 - accuracy: 0.8417 - val_loss: 0.4270 - val_accuracy: 0.7640\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3869 - accuracy: 0.8430 - val_loss: 0.5683 - val_accuracy: 0.5419\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4424 - accuracy: 0.8155 - val_loss: 0.4725 - val_accuracy: 0.8571\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4433 - accuracy: 0.8061 - val_loss: 0.4817 - val_accuracy: 0.7857\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3953 - accuracy: 0.8413 - val_loss: 0.3946 - val_accuracy: 0.8556\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3754 - accuracy: 0.8539 - val_loss: 0.4151 - val_accuracy: 0.8152\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3799 - accuracy: 0.8438 - val_loss: 0.3962 - val_accuracy: 0.8323\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3824 - accuracy: 0.8432 - val_loss: 0.3923 - val_accuracy: 0.8696\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3914 - accuracy: 0.8359 - val_loss: 0.3804 - val_accuracy: 0.8354\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3782 - accuracy: 0.8423 - val_loss: 0.3901 - val_accuracy: 0.8680\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8380 - val_loss: 0.3932 - val_accuracy: 0.8245\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3580 - accuracy: 0.8555 - val_loss: 0.3694 - val_accuracy: 0.8587\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3520 - accuracy: 0.8590 - val_loss: 0.3404 - val_accuracy: 0.8665\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3219 - accuracy: 0.8666 - val_loss: 0.3259 - val_accuracy: 0.8680\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3203 - accuracy: 0.8679 - val_loss: 0.3278 - val_accuracy: 0.8696\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3115 - accuracy: 0.8735 - val_loss: 0.3446 - val_accuracy: 0.8680\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3144 - accuracy: 0.8751 - val_loss: 0.3592 - val_accuracy: 0.8587\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.2981 - accuracy: 0.8763 - val_loss: 0.3242 - val_accuracy: 0.8618\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.2979 - accuracy: 0.8801 - val_loss: 0.3163 - val_accuracy: 0.8634\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.2922 - accuracy: 0.8831 - val_loss: 0.3280 - val_accuracy: 0.8634\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.2988 - accuracy: 0.8800 - val_loss: 0.3184 - val_accuracy: 0.8711\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.2950 - accuracy: 0.8794 - val_loss: 0.3134 - val_accuracy: 0.8711\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.2913 - accuracy: 0.8807 - val_loss: 0.3275 - val_accuracy: 0.8649\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.2890 - accuracy: 0.8831 - val_loss: 0.3229 - val_accuracy: 0.8649\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.2938 - accuracy: 0.8792 - val_loss: 0.3061 - val_accuracy: 0.8665\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.2899 - accuracy: 0.8833 - val_loss: 0.3215 - val_accuracy: 0.8680\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 20.7969 - accuracy: 0.5414 - val_loss: 1.3453 - val_accuracy: 0.7391\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 2.1406 - accuracy: 0.6976 - val_loss: 1.1254 - val_accuracy: 0.4984\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5512 - accuracy: 0.7562 - val_loss: 0.5631 - val_accuracy: 0.7003\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4688 - accuracy: 0.8032 - val_loss: 0.4237 - val_accuracy: 0.8463\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5063 - accuracy: 0.7753 - val_loss: 0.4104 - val_accuracy: 0.8432\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4604 - accuracy: 0.8034 - val_loss: 0.6045 - val_accuracy: 0.7531\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4381 - accuracy: 0.8125 - val_loss: 0.5103 - val_accuracy: 0.7329\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4471 - accuracy: 0.8122 - val_loss: 0.4217 - val_accuracy: 0.8463\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4610 - accuracy: 0.8015 - val_loss: 0.4230 - val_accuracy: 0.8494\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.3944 - accuracy: 0.8407 - val_loss: 0.4273 - val_accuracy: 0.7888\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3836 - accuracy: 0.8487 - val_loss: 0.6518 - val_accuracy: 0.4984\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4405 - accuracy: 0.8151 - val_loss: 0.5441 - val_accuracy: 0.8540\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4139 - accuracy: 0.8174 - val_loss: 0.4120 - val_accuracy: 0.8525\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4246 - accuracy: 0.8182 - val_loss: 0.4501 - val_accuracy: 0.8634\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3972 - accuracy: 0.8384 - val_loss: 0.4051 - val_accuracy: 0.8478\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4052 - accuracy: 0.8219 - val_loss: 0.3806 - val_accuracy: 0.8540\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4102 - accuracy: 0.8277 - val_loss: 0.3835 - val_accuracy: 0.8587\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3870 - accuracy: 0.8384 - val_loss: 0.3548 - val_accuracy: 0.8649\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4123 - accuracy: 0.8225 - val_loss: 0.4060 - val_accuracy: 0.8416\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3864 - accuracy: 0.8378 - val_loss: 0.3888 - val_accuracy: 0.8571\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3729 - accuracy: 0.8407 - val_loss: 0.4457 - val_accuracy: 0.8618\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.4001 - accuracy: 0.8434 - val_loss: 0.3714 - val_accuracy: 0.8665\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3643 - accuracy: 0.8417 - val_loss: 0.3432 - val_accuracy: 0.8680\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3681 - accuracy: 0.8477 - val_loss: 0.4379 - val_accuracy: 0.8571\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3676 - accuracy: 0.8458 - val_loss: 0.3552 - val_accuracy: 0.8602\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3499 - accuracy: 0.8471 - val_loss: 0.3399 - val_accuracy: 0.8618\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3658 - accuracy: 0.8421 - val_loss: 0.3717 - val_accuracy: 0.8540\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3565 - accuracy: 0.8429 - val_loss: 0.3635 - val_accuracy: 0.8571\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3565 - accuracy: 0.8343 - val_loss: 0.3225 - val_accuracy: 0.8618\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3520 - accuracy: 0.8413 - val_loss: 0.3345 - val_accuracy: 0.8649\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3426 - accuracy: 0.8510 - val_loss: 0.3933 - val_accuracy: 0.8649\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3439 - accuracy: 0.8448 - val_loss: 0.3213 - val_accuracy: 0.8602\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3260 - accuracy: 0.8448 - val_loss: 0.3222 - val_accuracy: 0.8618\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3324 - accuracy: 0.8460 - val_loss: 0.3485 - val_accuracy: 0.8587\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3211 - accuracy: 0.8512 - val_loss: 0.3119 - val_accuracy: 0.8727\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 28.2484 - accuracy: 0.5373 - val_loss: 4.1468 - val_accuracy: 0.6196\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 4.7255 - accuracy: 0.6529 - val_loss: 0.9094 - val_accuracy: 0.8370\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.9251 - accuracy: 0.7413 - val_loss: 0.6755 - val_accuracy: 0.6941\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4769 - accuracy: 0.7970 - val_loss: 0.4627 - val_accuracy: 0.8401\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5081 - accuracy: 0.7774 - val_loss: 0.4480 - val_accuracy: 0.8447\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4612 - accuracy: 0.8054 - val_loss: 0.5092 - val_accuracy: 0.8571\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4238 - accuracy: 0.8201 - val_loss: 0.5520 - val_accuracy: 0.7220\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4406 - accuracy: 0.8170 - val_loss: 0.4104 - val_accuracy: 0.8447\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4299 - accuracy: 0.8221 - val_loss: 0.4236 - val_accuracy: 0.8463\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.3932 - accuracy: 0.8485 - val_loss: 0.4328 - val_accuracy: 0.7764\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3898 - accuracy: 0.8454 - val_loss: 0.4609 - val_accuracy: 0.8556\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4261 - accuracy: 0.8180 - val_loss: 0.5522 - val_accuracy: 0.8261\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4084 - accuracy: 0.8300 - val_loss: 0.4039 - val_accuracy: 0.8494\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4085 - accuracy: 0.8339 - val_loss: 0.4357 - val_accuracy: 0.8587\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4092 - accuracy: 0.8328 - val_loss: 0.4763 - val_accuracy: 0.7422\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4183 - accuracy: 0.8242 - val_loss: 0.3894 - val_accuracy: 0.8432\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3915 - accuracy: 0.8423 - val_loss: 0.3823 - val_accuracy: 0.8509\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3826 - accuracy: 0.8473 - val_loss: 0.3892 - val_accuracy: 0.8463\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3933 - accuracy: 0.8427 - val_loss: 0.3738 - val_accuracy: 0.8556\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3774 - accuracy: 0.8500 - val_loss: 0.3896 - val_accuracy: 0.8634\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3790 - accuracy: 0.8450 - val_loss: 0.4202 - val_accuracy: 0.8618\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.4019 - accuracy: 0.8341 - val_loss: 0.3643 - val_accuracy: 0.8618\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.4443 - accuracy: 0.7931 - val_loss: 0.4109 - val_accuracy: 0.8634\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.4446 - accuracy: 0.8054 - val_loss: 0.4543 - val_accuracy: 0.7671\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.4174 - accuracy: 0.8275 - val_loss: 0.4169 - val_accuracy: 0.8602\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.4205 - accuracy: 0.8110 - val_loss: 0.3642 - val_accuracy: 0.8602\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.4294 - accuracy: 0.8331 - val_loss: 0.4596 - val_accuracy: 0.8307\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.4167 - accuracy: 0.8155 - val_loss: 0.3886 - val_accuracy: 0.8370\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3744 - accuracy: 0.8296 - val_loss: 0.3896 - val_accuracy: 0.8634\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3486 - accuracy: 0.8415 - val_loss: 0.3376 - val_accuracy: 0.8680\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3395 - accuracy: 0.8467 - val_loss: 0.3352 - val_accuracy: 0.8696\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3406 - accuracy: 0.8434 - val_loss: 0.3435 - val_accuracy: 0.8339\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3302 - accuracy: 0.8512 - val_loss: 0.3438 - val_accuracy: 0.8634\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3321 - accuracy: 0.8528 - val_loss: 0.3383 - val_accuracy: 0.8649\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3251 - accuracy: 0.8658 - val_loss: 0.3366 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 17.8083 - accuracy: 0.5278 - val_loss: 1.9924 - val_accuracy: 0.4953\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.7259 - accuracy: 0.6653 - val_loss: 0.5796 - val_accuracy: 0.8540\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5791 - accuracy: 0.7438 - val_loss: 0.6404 - val_accuracy: 0.7003\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.5007 - accuracy: 0.7834 - val_loss: 0.4598 - val_accuracy: 0.8416\n",
      "Epoch 5/35\n",
      "5148/5148 - 0s - loss: 0.5971 - accuracy: 0.7193 - val_loss: 0.4297 - val_accuracy: 0.8401\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4689 - accuracy: 0.7960 - val_loss: 0.5050 - val_accuracy: 0.8602\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4444 - accuracy: 0.8067 - val_loss: 0.5778 - val_accuracy: 0.6988\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4601 - accuracy: 0.8040 - val_loss: 0.3970 - val_accuracy: 0.8494\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4204 - accuracy: 0.8256 - val_loss: 0.4162 - val_accuracy: 0.8494\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4056 - accuracy: 0.8351 - val_loss: 0.4341 - val_accuracy: 0.7764\n",
      "Epoch 11/35\n",
      "5148/5148 - 0s - loss: 0.4159 - accuracy: 0.8246 - val_loss: 0.4933 - val_accuracy: 0.7267\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4283 - accuracy: 0.8180 - val_loss: 0.4780 - val_accuracy: 0.8556\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4059 - accuracy: 0.8279 - val_loss: 0.3978 - val_accuracy: 0.8168\n",
      "Epoch 14/35\n",
      "5148/5148 - 0s - loss: 0.4106 - accuracy: 0.8242 - val_loss: 0.3881 - val_accuracy: 0.8618\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4381 - accuracy: 0.8157 - val_loss: 0.4516 - val_accuracy: 0.8199\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4476 - accuracy: 0.7999 - val_loss: 0.6098 - val_accuracy: 0.6382\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4402 - accuracy: 0.8091 - val_loss: 0.4171 - val_accuracy: 0.8602\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.4397 - accuracy: 0.8162 - val_loss: 0.4409 - val_accuracy: 0.8665\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4519 - accuracy: 0.8087 - val_loss: 0.4031 - val_accuracy: 0.8680\n",
      "Epoch 20/35\n",
      "5148/5148 - 0s - loss: 0.4518 - accuracy: 0.8091 - val_loss: 0.4215 - val_accuracy: 0.8245\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.4143 - accuracy: 0.8296 - val_loss: 0.3835 - val_accuracy: 0.8649\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.4396 - accuracy: 0.8153 - val_loss: 0.3842 - val_accuracy: 0.8649\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.4232 - accuracy: 0.8217 - val_loss: 0.4046 - val_accuracy: 0.8323\n",
      "Epoch 24/35\n",
      "5148/5148 - 0s - loss: 0.4168 - accuracy: 0.8250 - val_loss: 0.3895 - val_accuracy: 0.8307\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.4202 - accuracy: 0.8269 - val_loss: 0.4117 - val_accuracy: 0.8214\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.4236 - accuracy: 0.8234 - val_loss: 0.3906 - val_accuracy: 0.8323\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.4207 - accuracy: 0.8213 - val_loss: 0.4242 - val_accuracy: 0.7997\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.4347 - accuracy: 0.8120 - val_loss: 0.4388 - val_accuracy: 0.8618\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8331 - val_loss: 0.3865 - val_accuracy: 0.8634\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.4105 - accuracy: 0.8252 - val_loss: 0.3777 - val_accuracy: 0.8665\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.4147 - accuracy: 0.8269 - val_loss: 0.3996 - val_accuracy: 0.8323\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.4155 - accuracy: 0.8236 - val_loss: 0.3981 - val_accuracy: 0.8370\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3993 - accuracy: 0.8308 - val_loss: 0.4146 - val_accuracy: 0.8602\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3971 - accuracy: 0.8302 - val_loss: 0.3881 - val_accuracy: 0.8618\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3859 - accuracy: 0.8405 - val_loss: 0.3779 - val_accuracy: 0.8478\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 18.1665 - accuracy: 0.5423 - val_loss: 2.3761 - val_accuracy: 0.5202\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.9067 - accuracy: 0.6898 - val_loss: 0.4939 - val_accuracy: 0.8432\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5630 - accuracy: 0.7481 - val_loss: 0.5820 - val_accuracy: 0.7065\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4741 - accuracy: 0.7968 - val_loss: 0.7356 - val_accuracy: 0.5668\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5168 - accuracy: 0.7622 - val_loss: 0.4522 - val_accuracy: 0.8494\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4670 - accuracy: 0.7910 - val_loss: 0.5390 - val_accuracy: 0.8587\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4279 - accuracy: 0.8225 - val_loss: 0.5011 - val_accuracy: 0.7407\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4387 - accuracy: 0.8174 - val_loss: 0.4420 - val_accuracy: 0.8571\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4260 - accuracy: 0.8219 - val_loss: 0.4258 - val_accuracy: 0.8525\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4030 - accuracy: 0.8403 - val_loss: 0.4405 - val_accuracy: 0.7578\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3975 - accuracy: 0.8331 - val_loss: 0.4584 - val_accuracy: 0.8540\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4322 - accuracy: 0.8124 - val_loss: 0.5291 - val_accuracy: 0.8339\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4165 - accuracy: 0.8318 - val_loss: 0.4045 - val_accuracy: 0.8494\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4269 - accuracy: 0.8250 - val_loss: 0.4003 - val_accuracy: 0.8463\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4185 - accuracy: 0.8234 - val_loss: 0.4361 - val_accuracy: 0.7593\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3712 - accuracy: 0.8594 - val_loss: 0.3775 - val_accuracy: 0.8540\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3693 - accuracy: 0.8559 - val_loss: 0.3894 - val_accuracy: 0.8509\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3621 - accuracy: 0.8580 - val_loss: 0.3719 - val_accuracy: 0.8571\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3762 - accuracy: 0.8465 - val_loss: 0.3797 - val_accuracy: 0.8571\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3699 - accuracy: 0.8514 - val_loss: 0.3698 - val_accuracy: 0.8571\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3546 - accuracy: 0.8594 - val_loss: 0.3573 - val_accuracy: 0.8665\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3543 - accuracy: 0.8574 - val_loss: 0.3511 - val_accuracy: 0.8587\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3389 - accuracy: 0.8650 - val_loss: 0.3541 - val_accuracy: 0.8292\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3430 - accuracy: 0.8500 - val_loss: 0.3713 - val_accuracy: 0.8665\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8504 - val_loss: 0.3821 - val_accuracy: 0.8214\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3485 - accuracy: 0.8390 - val_loss: 0.3510 - val_accuracy: 0.8680\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3391 - accuracy: 0.8611 - val_loss: 0.3321 - val_accuracy: 0.8742\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3436 - accuracy: 0.8495 - val_loss: 0.4469 - val_accuracy: 0.8509\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3352 - accuracy: 0.8563 - val_loss: 0.3312 - val_accuracy: 0.8618\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3324 - accuracy: 0.8563 - val_loss: 0.3439 - val_accuracy: 0.8525\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3314 - accuracy: 0.8578 - val_loss: 0.3239 - val_accuracy: 0.8742\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3374 - accuracy: 0.8516 - val_loss: 0.3223 - val_accuracy: 0.8727\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3146 - accuracy: 0.8609 - val_loss: 0.3316 - val_accuracy: 0.8634\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3354 - accuracy: 0.8429 - val_loss: 0.3645 - val_accuracy: 0.8354\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3414 - accuracy: 0.8162 - val_loss: 0.3425 - val_accuracy: 0.8292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:02:46,271] Trial 23 finished with value: 0.8711179494857788 and parameters: {'units': 100, 'dropout': 0.1, 'learning_rate': 0.005950059733283976, 'epochs': 35, 'batch_size': 30, 'patience': 9, 'factor': 0.4}. Best is trial 23 with value: 0.8711179494857788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 18.7446 - accuracy: 0.5552 - val_loss: 1.4307 - val_accuracy: 0.7360\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.9333 - accuracy: 0.6974 - val_loss: 0.5573 - val_accuracy: 0.8463\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5219 - accuracy: 0.7745 - val_loss: 0.4525 - val_accuracy: 0.8137\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4826 - accuracy: 0.7889 - val_loss: 0.4815 - val_accuracy: 0.8416\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5098 - accuracy: 0.7704 - val_loss: 0.4500 - val_accuracy: 0.7873\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4860 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.8540\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4463 - accuracy: 0.8172 - val_loss: 0.5775 - val_accuracy: 0.7065\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4258 - accuracy: 0.8331 - val_loss: 0.4167 - val_accuracy: 0.8463\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4244 - accuracy: 0.8294 - val_loss: 0.4430 - val_accuracy: 0.8509\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4214 - accuracy: 0.8329 - val_loss: 0.5280 - val_accuracy: 0.6894\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4269 - accuracy: 0.8164 - val_loss: 0.5347 - val_accuracy: 0.8416\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4629 - accuracy: 0.8057 - val_loss: 0.4995 - val_accuracy: 0.8602\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4652 - accuracy: 0.7997 - val_loss: 0.4505 - val_accuracy: 0.7733\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4508 - accuracy: 0.8052 - val_loss: 0.4552 - val_accuracy: 0.8494\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4590 - accuracy: 0.8089 - val_loss: 0.5304 - val_accuracy: 0.7189\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4821 - accuracy: 0.7789 - val_loss: 0.4573 - val_accuracy: 0.8509\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4689 - accuracy: 0.7762 - val_loss: 0.4244 - val_accuracy: 0.7873\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.4312 - accuracy: 0.8160 - val_loss: 0.3992 - val_accuracy: 0.8525\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4284 - accuracy: 0.8258 - val_loss: 0.4279 - val_accuracy: 0.8525\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.4210 - accuracy: 0.8291 - val_loss: 0.3873 - val_accuracy: 0.8571\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.4018 - accuracy: 0.8329 - val_loss: 0.3722 - val_accuracy: 0.8525\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3994 - accuracy: 0.8380 - val_loss: 0.3733 - val_accuracy: 0.8571\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3792 - accuracy: 0.8374 - val_loss: 0.3689 - val_accuracy: 0.8571\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3820 - accuracy: 0.8386 - val_loss: 0.4281 - val_accuracy: 0.8602\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3721 - accuracy: 0.8473 - val_loss: 0.4396 - val_accuracy: 0.8540\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3958 - accuracy: 0.8401 - val_loss: 0.4171 - val_accuracy: 0.8509\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3701 - accuracy: 0.8399 - val_loss: 0.3641 - val_accuracy: 0.8587\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3601 - accuracy: 0.8535 - val_loss: 0.3600 - val_accuracy: 0.8587\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3551 - accuracy: 0.8462 - val_loss: 0.3712 - val_accuracy: 0.8571\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3652 - accuracy: 0.8417 - val_loss: 0.3650 - val_accuracy: 0.8556\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3544 - accuracy: 0.8444 - val_loss: 0.3608 - val_accuracy: 0.8571\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3508 - accuracy: 0.8432 - val_loss: 0.3684 - val_accuracy: 0.8680\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3501 - accuracy: 0.8409 - val_loss: 0.3742 - val_accuracy: 0.8571\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3498 - accuracy: 0.8368 - val_loss: 0.3578 - val_accuracy: 0.8571\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3448 - accuracy: 0.8430 - val_loss: 0.3566 - val_accuracy: 0.8649\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 16.7864 - accuracy: 0.5624 - val_loss: 1.6767 - val_accuracy: 0.6599\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.2473 - accuracy: 0.7179 - val_loss: 0.5198 - val_accuracy: 0.8525\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.4735 - accuracy: 0.7995 - val_loss: 0.4546 - val_accuracy: 0.7733\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4411 - accuracy: 0.8112 - val_loss: 0.4736 - val_accuracy: 0.8571\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4937 - accuracy: 0.7807 - val_loss: 0.4460 - val_accuracy: 0.7857\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4752 - accuracy: 0.7883 - val_loss: 0.5577 - val_accuracy: 0.8152\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4481 - accuracy: 0.8044 - val_loss: 0.5793 - val_accuracy: 0.7065\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4427 - accuracy: 0.8172 - val_loss: 0.4280 - val_accuracy: 0.8556\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4400 - accuracy: 0.8118 - val_loss: 0.4803 - val_accuracy: 0.8602\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4151 - accuracy: 0.8279 - val_loss: 0.4281 - val_accuracy: 0.7842\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3952 - accuracy: 0.8386 - val_loss: 0.4130 - val_accuracy: 0.8556\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4195 - accuracy: 0.8236 - val_loss: 0.5391 - val_accuracy: 0.7593\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4152 - accuracy: 0.8312 - val_loss: 0.4042 - val_accuracy: 0.8556\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4327 - accuracy: 0.8182 - val_loss: 0.3971 - val_accuracy: 0.8571\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3925 - accuracy: 0.8417 - val_loss: 0.5207 - val_accuracy: 0.7298\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.5713 - accuracy: 0.6849 - val_loss: 0.6782 - val_accuracy: 0.5373\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.5164 - accuracy: 0.7632 - val_loss: 0.4607 - val_accuracy: 0.7873\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.4592 - accuracy: 0.7960 - val_loss: 0.4545 - val_accuracy: 0.8494\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4527 - accuracy: 0.7964 - val_loss: 0.4300 - val_accuracy: 0.8478\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.4341 - accuracy: 0.8065 - val_loss: 0.4225 - val_accuracy: 0.8370\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.4088 - accuracy: 0.8211 - val_loss: 0.3963 - val_accuracy: 0.8478\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3984 - accuracy: 0.8223 - val_loss: 0.3915 - val_accuracy: 0.8432\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3890 - accuracy: 0.8294 - val_loss: 0.3866 - val_accuracy: 0.8540\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3639 - accuracy: 0.8545 - val_loss: 0.3705 - val_accuracy: 0.8494\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3598 - accuracy: 0.8564 - val_loss: 0.3932 - val_accuracy: 0.8339\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3526 - accuracy: 0.8664 - val_loss: 0.3641 - val_accuracy: 0.8602\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3447 - accuracy: 0.8685 - val_loss: 0.3619 - val_accuracy: 0.8587\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3427 - accuracy: 0.8666 - val_loss: 0.3586 - val_accuracy: 0.8618\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3373 - accuracy: 0.8708 - val_loss: 0.3736 - val_accuracy: 0.8649\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3381 - accuracy: 0.8629 - val_loss: 0.3485 - val_accuracy: 0.8696\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3374 - accuracy: 0.8681 - val_loss: 0.3462 - val_accuracy: 0.8665\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3275 - accuracy: 0.8780 - val_loss: 0.3538 - val_accuracy: 0.8339\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3260 - accuracy: 0.8700 - val_loss: 0.3783 - val_accuracy: 0.8571\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3320 - accuracy: 0.8664 - val_loss: 0.3459 - val_accuracy: 0.8649\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3245 - accuracy: 0.8681 - val_loss: 0.3410 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 19.9924 - accuracy: 0.5433 - val_loss: 1.1035 - val_accuracy: 0.8307\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.6585 - accuracy: 0.6894 - val_loss: 0.5796 - val_accuracy: 0.8509\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5347 - accuracy: 0.7570 - val_loss: 0.4475 - val_accuracy: 0.7811\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4547 - accuracy: 0.8059 - val_loss: 0.4612 - val_accuracy: 0.8478\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4893 - accuracy: 0.7819 - val_loss: 0.4349 - val_accuracy: 0.8478\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4553 - accuracy: 0.8059 - val_loss: 0.5171 - val_accuracy: 0.8602\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4413 - accuracy: 0.8129 - val_loss: 0.6810 - val_accuracy: 0.6661\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4413 - accuracy: 0.8139 - val_loss: 0.4069 - val_accuracy: 0.8478\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4326 - accuracy: 0.8215 - val_loss: 0.4423 - val_accuracy: 0.8618\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4140 - accuracy: 0.8314 - val_loss: 0.4877 - val_accuracy: 0.7298\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4227 - accuracy: 0.8287 - val_loss: 0.5110 - val_accuracy: 0.7376\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4552 - accuracy: 0.8052 - val_loss: 0.5217 - val_accuracy: 0.8618\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4671 - accuracy: 0.7875 - val_loss: 0.4907 - val_accuracy: 0.7391\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4554 - accuracy: 0.8079 - val_loss: 0.5079 - val_accuracy: 0.8634\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4679 - accuracy: 0.8034 - val_loss: 0.4496 - val_accuracy: 0.8214\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4592 - accuracy: 0.8059 - val_loss: 0.4283 - val_accuracy: 0.8602\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4630 - accuracy: 0.8059 - val_loss: 0.3992 - val_accuracy: 0.8634\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.4335 - accuracy: 0.8203 - val_loss: 0.4045 - val_accuracy: 0.8587\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4223 - accuracy: 0.8242 - val_loss: 0.4103 - val_accuracy: 0.8587\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.4324 - accuracy: 0.8205 - val_loss: 0.4020 - val_accuracy: 0.8261\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3789 - accuracy: 0.8491 - val_loss: 0.3908 - val_accuracy: 0.8261\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3594 - accuracy: 0.8543 - val_loss: 0.3842 - val_accuracy: 0.8696\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3664 - accuracy: 0.8500 - val_loss: 0.3948 - val_accuracy: 0.8276\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3627 - accuracy: 0.8477 - val_loss: 0.3847 - val_accuracy: 0.8307\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3607 - accuracy: 0.8497 - val_loss: 0.4023 - val_accuracy: 0.8214\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3683 - accuracy: 0.8442 - val_loss: 0.3848 - val_accuracy: 0.8370\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3615 - accuracy: 0.8508 - val_loss: 0.3725 - val_accuracy: 0.8370\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3680 - accuracy: 0.8520 - val_loss: 0.4043 - val_accuracy: 0.8587\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3609 - accuracy: 0.8506 - val_loss: 0.4374 - val_accuracy: 0.8587\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3644 - accuracy: 0.8438 - val_loss: 0.3709 - val_accuracy: 0.8370\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3519 - accuracy: 0.8489 - val_loss: 0.3727 - val_accuracy: 0.8370\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3532 - accuracy: 0.8485 - val_loss: 0.3783 - val_accuracy: 0.8292\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3476 - accuracy: 0.8545 - val_loss: 0.3754 - val_accuracy: 0.8680\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3467 - accuracy: 0.8553 - val_loss: 0.3833 - val_accuracy: 0.8680\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3531 - accuracy: 0.8530 - val_loss: 0.3712 - val_accuracy: 0.8354\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 18.5735 - accuracy: 0.5361 - val_loss: 3.2805 - val_accuracy: 0.4953\n",
      "Epoch 2/35\n",
      "5148/5148 - 2s - loss: 1.4308 - accuracy: 0.7162 - val_loss: 0.6296 - val_accuracy: 0.8028\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.4992 - accuracy: 0.7836 - val_loss: 0.5928 - val_accuracy: 0.7065\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4891 - accuracy: 0.7782 - val_loss: 0.4910 - val_accuracy: 0.7438\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4946 - accuracy: 0.7720 - val_loss: 0.4262 - val_accuracy: 0.8385\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4703 - accuracy: 0.7923 - val_loss: 0.4690 - val_accuracy: 0.8478\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4218 - accuracy: 0.8213 - val_loss: 0.6491 - val_accuracy: 0.6848\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4395 - accuracy: 0.8182 - val_loss: 0.4262 - val_accuracy: 0.8587\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4370 - accuracy: 0.8127 - val_loss: 0.4383 - val_accuracy: 0.8525\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4209 - accuracy: 0.8242 - val_loss: 0.4641 - val_accuracy: 0.7438\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4138 - accuracy: 0.8250 - val_loss: 0.5796 - val_accuracy: 0.7345\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4630 - accuracy: 0.7990 - val_loss: 0.5362 - val_accuracy: 0.8618\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4510 - accuracy: 0.8024 - val_loss: 0.4944 - val_accuracy: 0.7283\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4331 - accuracy: 0.8209 - val_loss: 0.4856 - val_accuracy: 0.8587\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4182 - accuracy: 0.8250 - val_loss: 0.4639 - val_accuracy: 0.7531\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4501 - accuracy: 0.7933 - val_loss: 0.4277 - val_accuracy: 0.7640\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3952 - accuracy: 0.8248 - val_loss: 0.4175 - val_accuracy: 0.8634\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3898 - accuracy: 0.8275 - val_loss: 0.3636 - val_accuracy: 0.8618\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3906 - accuracy: 0.8260 - val_loss: 0.4048 - val_accuracy: 0.8043\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3605 - accuracy: 0.8434 - val_loss: 0.3696 - val_accuracy: 0.8509\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3685 - accuracy: 0.8236 - val_loss: 0.3660 - val_accuracy: 0.8649\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3974 - accuracy: 0.8087 - val_loss: 0.3723 - val_accuracy: 0.8649\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3488 - accuracy: 0.8236 - val_loss: 0.3441 - val_accuracy: 0.8292\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3551 - accuracy: 0.8199 - val_loss: 0.4857 - val_accuracy: 0.7329\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3495 - accuracy: 0.8382 - val_loss: 0.3634 - val_accuracy: 0.8525\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3411 - accuracy: 0.8419 - val_loss: 0.3176 - val_accuracy: 0.8634\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3437 - accuracy: 0.8401 - val_loss: 0.3403 - val_accuracy: 0.8618\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.5008 - accuracy: 0.7199 - val_loss: 0.6792 - val_accuracy: 0.5217\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.5949 - accuracy: 0.6999 - val_loss: 0.5287 - val_accuracy: 0.7655\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.4858 - accuracy: 0.8048 - val_loss: 0.4605 - val_accuracy: 0.8571\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.4009 - accuracy: 0.8475 - val_loss: 0.4044 - val_accuracy: 0.8323\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.4229 - accuracy: 0.8223 - val_loss: 0.4317 - val_accuracy: 0.8261\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.4038 - accuracy: 0.8316 - val_loss: 0.4052 - val_accuracy: 0.8556\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3613 - accuracy: 0.8601 - val_loss: 0.3899 - val_accuracy: 0.8602\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3606 - accuracy: 0.8555 - val_loss: 0.3655 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 21.2991 - accuracy: 0.5546 - val_loss: 2.0594 - val_accuracy: 0.7189\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.5710 - accuracy: 0.7228 - val_loss: 0.5236 - val_accuracy: 0.7516\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.6425 - accuracy: 0.7370 - val_loss: 0.6670 - val_accuracy: 0.6677\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.5022 - accuracy: 0.7861 - val_loss: 0.4918 - val_accuracy: 0.8587\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5616 - accuracy: 0.7401 - val_loss: 0.4310 - val_accuracy: 0.7904\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4869 - accuracy: 0.7819 - val_loss: 0.7465 - val_accuracy: 0.5606\n",
      "Epoch 7/35\n",
      "5148/5148 - 2s - loss: 0.4529 - accuracy: 0.8021 - val_loss: 0.7063 - val_accuracy: 0.6817\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4489 - accuracy: 0.8106 - val_loss: 0.4110 - val_accuracy: 0.8401\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4227 - accuracy: 0.8265 - val_loss: 0.4394 - val_accuracy: 0.8540\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4124 - accuracy: 0.8362 - val_loss: 0.4171 - val_accuracy: 0.8292\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4224 - accuracy: 0.8232 - val_loss: 0.5525 - val_accuracy: 0.8447\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4688 - accuracy: 0.7935 - val_loss: 0.4454 - val_accuracy: 0.8323\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4393 - accuracy: 0.8102 - val_loss: 0.4230 - val_accuracy: 0.8385\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4077 - accuracy: 0.8409 - val_loss: 0.4106 - val_accuracy: 0.8447\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4055 - accuracy: 0.8366 - val_loss: 0.4343 - val_accuracy: 0.7842\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3940 - accuracy: 0.8500 - val_loss: 0.3965 - val_accuracy: 0.8447\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3829 - accuracy: 0.8537 - val_loss: 0.4032 - val_accuracy: 0.8525\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3765 - accuracy: 0.8541 - val_loss: 0.3853 - val_accuracy: 0.8540\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3588 - accuracy: 0.8669 - val_loss: 0.3991 - val_accuracy: 0.8509\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3552 - accuracy: 0.8693 - val_loss: 0.3739 - val_accuracy: 0.8494\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3538 - accuracy: 0.8689 - val_loss: 0.3864 - val_accuracy: 0.8649\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3491 - accuracy: 0.8702 - val_loss: 0.3717 - val_accuracy: 0.8618\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3443 - accuracy: 0.8724 - val_loss: 0.3703 - val_accuracy: 0.8509\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3425 - accuracy: 0.8712 - val_loss: 0.3699 - val_accuracy: 0.8556\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3358 - accuracy: 0.8753 - val_loss: 0.4013 - val_accuracy: 0.8323\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3404 - accuracy: 0.8724 - val_loss: 0.3683 - val_accuracy: 0.8618\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3338 - accuracy: 0.8737 - val_loss: 0.3519 - val_accuracy: 0.8602\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3367 - accuracy: 0.8726 - val_loss: 0.3547 - val_accuracy: 0.8618\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3271 - accuracy: 0.8790 - val_loss: 0.3517 - val_accuracy: 0.8696\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3247 - accuracy: 0.8794 - val_loss: 0.3498 - val_accuracy: 0.8634\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3161 - accuracy: 0.8823 - val_loss: 0.3505 - val_accuracy: 0.8665\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3196 - accuracy: 0.8805 - val_loss: 0.3491 - val_accuracy: 0.8711\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3189 - accuracy: 0.8809 - val_loss: 0.3495 - val_accuracy: 0.8602\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3191 - accuracy: 0.8815 - val_loss: 0.3423 - val_accuracy: 0.8665\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3116 - accuracy: 0.8817 - val_loss: 0.3474 - val_accuracy: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:03,300] Trial 24 finished with value: 0.8686335682868958 and parameters: {'units': 100, 'dropout': 0.1, 'learning_rate': 0.007513644123232813, 'epochs': 35, 'batch_size': 30, 'patience': 7, 'factor': 0.4}. Best is trial 23 with value: 0.8711179494857788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 1s - loss: 21.4138 - accuracy: 0.5684 - val_loss: 1.5217 - val_accuracy: 0.6102\n",
      "Epoch 2/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:05,845] Trial 25 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:08,166] Trial 26 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 35.3457 - accuracy: 0.4977 - val_loss: 0.6216 - val_accuracy: 0.7143\n",
      "Epoch 2/35\n",
      "5148/5148 - 0s - loss: 18.9870 - accuracy: 0.5126 - val_loss: 0.9719 - val_accuracy: 0.6630\n",
      "Epoch 3/35\n",
      "5148/5148 - 0s - loss: 8.2457 - accuracy: 0.5418 - val_loss: 0.7013 - val_accuracy: 0.7376\n",
      "Epoch 4/35\n",
      "5148/5148 - 0s - loss: 2.6989 - accuracy: 0.6138 - val_loss: 0.5692 - val_accuracy: 0.7578\n",
      "Epoch 5/35\n",
      "5148/5148 - 0s - loss: 0.8488 - accuracy: 0.7220 - val_loss: 0.4731 - val_accuracy: 0.8323\n",
      "Epoch 6/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:12,432] Trial 27 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:16,227] Trial 28 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:25,660] Trial 29 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:05:28,882] Trial 30 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 17.8609 - accuracy: 0.5635 - val_loss: 2.1317 - val_accuracy: 0.7407\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 4.0057 - accuracy: 0.6752 - val_loss: 2.8981 - val_accuracy: 0.4984\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.2391 - accuracy: 0.7403 - val_loss: 0.5418 - val_accuracy: 0.7686\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4684 - accuracy: 0.8067 - val_loss: 0.4242 - val_accuracy: 0.8432\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4470 - accuracy: 0.8160 - val_loss: 0.4241 - val_accuracy: 0.8494\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4440 - accuracy: 0.8112 - val_loss: 0.5037 - val_accuracy: 0.8587\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4064 - accuracy: 0.8343 - val_loss: 0.4410 - val_accuracy: 0.7733\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.3932 - accuracy: 0.8423 - val_loss: 0.4369 - val_accuracy: 0.7578\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4095 - accuracy: 0.8258 - val_loss: 0.4070 - val_accuracy: 0.8478\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4007 - accuracy: 0.8409 - val_loss: 0.4943 - val_accuracy: 0.7345\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.3996 - accuracy: 0.8293 - val_loss: 0.4287 - val_accuracy: 0.8214\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4009 - accuracy: 0.8421 - val_loss: 0.4303 - val_accuracy: 0.8618\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4178 - accuracy: 0.8258 - val_loss: 0.5092 - val_accuracy: 0.8634\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3865 - accuracy: 0.8502 - val_loss: 0.4477 - val_accuracy: 0.8634\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4723 - accuracy: 0.7883 - val_loss: 0.4573 - val_accuracy: 0.7888\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4740 - accuracy: 0.7871 - val_loss: 0.4586 - val_accuracy: 0.8540\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4458 - accuracy: 0.8042 - val_loss: 0.4217 - val_accuracy: 0.7888\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4007 - accuracy: 0.8382 - val_loss: 0.3850 - val_accuracy: 0.8540\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3847 - accuracy: 0.8450 - val_loss: 0.3860 - val_accuracy: 0.8276\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3876 - accuracy: 0.8328 - val_loss: 0.3726 - val_accuracy: 0.8665\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3555 - accuracy: 0.8555 - val_loss: 0.3714 - val_accuracy: 0.8618\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3510 - accuracy: 0.8559 - val_loss: 0.3415 - val_accuracy: 0.8665\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3375 - accuracy: 0.8636 - val_loss: 0.3700 - val_accuracy: 0.8323\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3439 - accuracy: 0.8627 - val_loss: 0.3431 - val_accuracy: 0.8634\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3309 - accuracy: 0.8491 - val_loss: 0.3649 - val_accuracy: 0.8292\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3289 - accuracy: 0.8646 - val_loss: 0.3327 - val_accuracy: 0.8587\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3398 - accuracy: 0.8580 - val_loss: 0.3823 - val_accuracy: 0.8416\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3389 - accuracy: 0.8526 - val_loss: 0.3647 - val_accuracy: 0.8556\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3097 - accuracy: 0.8691 - val_loss: 0.3369 - val_accuracy: 0.8587\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3072 - accuracy: 0.8656 - val_loss: 0.3358 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 11.7870 - accuracy: 0.5565 - val_loss: 2.2159 - val_accuracy: 0.7174\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.4446 - accuracy: 0.6977 - val_loss: 0.7896 - val_accuracy: 0.8509\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.7036 - accuracy: 0.7620 - val_loss: 0.5525 - val_accuracy: 0.7034\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4678 - accuracy: 0.8034 - val_loss: 0.4438 - val_accuracy: 0.7702\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5099 - accuracy: 0.7741 - val_loss: 0.4181 - val_accuracy: 0.8478\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4416 - accuracy: 0.8114 - val_loss: 0.4854 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4017 - accuracy: 0.8380 - val_loss: 0.4171 - val_accuracy: 0.8230\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.3924 - accuracy: 0.8483 - val_loss: 0.4041 - val_accuracy: 0.8478\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4151 - accuracy: 0.8263 - val_loss: 0.4130 - val_accuracy: 0.8385\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4041 - accuracy: 0.8378 - val_loss: 0.5184 - val_accuracy: 0.7329\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4100 - accuracy: 0.8252 - val_loss: 0.4333 - val_accuracy: 0.7811\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4060 - accuracy: 0.8401 - val_loss: 0.4299 - val_accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4093 - accuracy: 0.8298 - val_loss: 0.3880 - val_accuracy: 0.8494\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4022 - accuracy: 0.8372 - val_loss: 0.4841 - val_accuracy: 0.8634\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.5142 - accuracy: 0.7599 - val_loss: 0.5546 - val_accuracy: 0.7780\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4747 - accuracy: 0.7852 - val_loss: 0.4959 - val_accuracy: 0.8634\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4639 - accuracy: 0.7885 - val_loss: 0.4157 - val_accuracy: 0.8463\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4139 - accuracy: 0.8326 - val_loss: 0.3884 - val_accuracy: 0.8463\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4011 - accuracy: 0.8293 - val_loss: 0.3871 - val_accuracy: 0.8478\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3787 - accuracy: 0.8425 - val_loss: 0.3645 - val_accuracy: 0.8587\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3514 - accuracy: 0.8518 - val_loss: 0.3628 - val_accuracy: 0.8665\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3600 - accuracy: 0.8467 - val_loss: 0.3589 - val_accuracy: 0.8618\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3495 - accuracy: 0.8524 - val_loss: 0.3726 - val_accuracy: 0.8323\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3456 - accuracy: 0.8446 - val_loss: 0.3626 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3301 - accuracy: 0.8551 - val_loss: 0.3917 - val_accuracy: 0.8618\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3326 - accuracy: 0.8467 - val_loss: 0.3457 - val_accuracy: 0.8571\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3367 - accuracy: 0.8574 - val_loss: 0.5051 - val_accuracy: 0.7407\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3315 - accuracy: 0.8601 - val_loss: 0.3722 - val_accuracy: 0.8556\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3747 - accuracy: 0.8514 - val_loss: 0.3584 - val_accuracy: 0.8556\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3048 - accuracy: 0.8683 - val_loss: 0.3351 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 23.5568 - accuracy: 0.5336 - val_loss: 6.4117 - val_accuracy: 0.4953\n",
      "Epoch 2/30\n",
      "5148/5148 - 3s - loss: 6.5086 - accuracy: 0.6517 - val_loss: 1.7213 - val_accuracy: 0.8509\n",
      "Epoch 3/30\n",
      "5148/5148 - 3s - loss: 2.0025 - accuracy: 0.7372 - val_loss: 0.8523 - val_accuracy: 0.7609\n",
      "Epoch 4/30\n",
      "5148/5148 - 3s - loss: 0.6708 - accuracy: 0.7673 - val_loss: 0.4318 - val_accuracy: 0.8416\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.4706 - accuracy: 0.8013 - val_loss: 0.4271 - val_accuracy: 0.8509\n",
      "Epoch 6/30\n",
      "5148/5148 - 3s - loss: 0.4527 - accuracy: 0.8114 - val_loss: 0.6161 - val_accuracy: 0.7469\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.4136 - accuracy: 0.8320 - val_loss: 0.4918 - val_accuracy: 0.7562\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4098 - accuracy: 0.8343 - val_loss: 0.4252 - val_accuracy: 0.7935\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4131 - accuracy: 0.8302 - val_loss: 0.4165 - val_accuracy: 0.8540\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4063 - accuracy: 0.8362 - val_loss: 0.4820 - val_accuracy: 0.7376\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.4041 - accuracy: 0.8328 - val_loss: 0.4186 - val_accuracy: 0.8494\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.3932 - accuracy: 0.8438 - val_loss: 0.4440 - val_accuracy: 0.8602\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.3859 - accuracy: 0.8460 - val_loss: 0.3996 - val_accuracy: 0.8494\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3985 - accuracy: 0.8442 - val_loss: 0.4689 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 2s - loss: 0.4176 - accuracy: 0.8287 - val_loss: 0.4853 - val_accuracy: 0.7376\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4018 - accuracy: 0.8322 - val_loss: 0.3987 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3830 - accuracy: 0.8510 - val_loss: 0.4360 - val_accuracy: 0.7547\n",
      "Epoch 18/30\n",
      "5148/5148 - 4s - loss: 0.3709 - accuracy: 0.8510 - val_loss: 0.3726 - val_accuracy: 0.8587\n",
      "Epoch 19/30\n",
      "5148/5148 - 3s - loss: 0.3758 - accuracy: 0.8528 - val_loss: 0.3649 - val_accuracy: 0.8587\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3765 - accuracy: 0.8533 - val_loss: 0.3705 - val_accuracy: 0.8587\n",
      "Epoch 21/30\n",
      "5148/5148 - 2s - loss: 0.3527 - accuracy: 0.8619 - val_loss: 0.4077 - val_accuracy: 0.8587\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3648 - accuracy: 0.8497 - val_loss: 0.3718 - val_accuracy: 0.8618\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3221 - accuracy: 0.8623 - val_loss: 0.3502 - val_accuracy: 0.8587\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3256 - accuracy: 0.8648 - val_loss: 0.3393 - val_accuracy: 0.8711\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3166 - accuracy: 0.8664 - val_loss: 0.4157 - val_accuracy: 0.8587\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3187 - accuracy: 0.8660 - val_loss: 0.3531 - val_accuracy: 0.8680\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3124 - accuracy: 0.8664 - val_loss: 0.3322 - val_accuracy: 0.8727\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3188 - accuracy: 0.8658 - val_loss: 0.3473 - val_accuracy: 0.8665\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3125 - accuracy: 0.8609 - val_loss: 0.3469 - val_accuracy: 0.8602\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3110 - accuracy: 0.8691 - val_loss: 0.3166 - val_accuracy: 0.8649\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 18.4209 - accuracy: 0.5548 - val_loss: 4.6303 - val_accuracy: 0.6087\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 5.2475 - accuracy: 0.6550 - val_loss: 2.7726 - val_accuracy: 0.5466\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.4628 - accuracy: 0.7312 - val_loss: 0.5719 - val_accuracy: 0.8043\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.5578 - accuracy: 0.7929 - val_loss: 0.4405 - val_accuracy: 0.8323\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5724 - accuracy: 0.7502 - val_loss: 0.4534 - val_accuracy: 0.7780\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 0.4900 - accuracy: 0.7949 - val_loss: 0.6618 - val_accuracy: 0.6630\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4222 - accuracy: 0.8300 - val_loss: 0.4481 - val_accuracy: 0.7702\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4053 - accuracy: 0.8382 - val_loss: 0.4476 - val_accuracy: 0.7484\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4129 - accuracy: 0.8308 - val_loss: 0.4291 - val_accuracy: 0.8571\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4064 - accuracy: 0.8388 - val_loss: 0.5315 - val_accuracy: 0.7329\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.4043 - accuracy: 0.8269 - val_loss: 0.4373 - val_accuracy: 0.8416\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.3939 - accuracy: 0.8423 - val_loss: 0.4883 - val_accuracy: 0.8602\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4003 - accuracy: 0.8353 - val_loss: 0.4063 - val_accuracy: 0.8121\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4013 - accuracy: 0.8357 - val_loss: 0.4108 - val_accuracy: 0.8571\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4056 - accuracy: 0.8351 - val_loss: 0.4283 - val_accuracy: 0.7562\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4036 - accuracy: 0.8318 - val_loss: 0.4041 - val_accuracy: 0.8602\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4090 - accuracy: 0.8283 - val_loss: 0.4017 - val_accuracy: 0.8152\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4067 - accuracy: 0.8275 - val_loss: 0.4347 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 3s - loss: 0.4126 - accuracy: 0.8310 - val_loss: 0.4424 - val_accuracy: 0.7609\n",
      "Epoch 20/30\n",
      "5148/5148 - 2s - loss: 0.4354 - accuracy: 0.7991 - val_loss: 0.4639 - val_accuracy: 0.8634\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4112 - accuracy: 0.8271 - val_loss: 0.3968 - val_accuracy: 0.8571\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4148 - accuracy: 0.8386 - val_loss: 0.4842 - val_accuracy: 0.8602\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4165 - accuracy: 0.8436 - val_loss: 0.3936 - val_accuracy: 0.8649\n",
      "Epoch 24/30\n",
      "5148/5148 - 2s - loss: 0.4148 - accuracy: 0.8316 - val_loss: 0.3865 - val_accuracy: 0.8385\n",
      "Epoch 25/30\n",
      "5148/5148 - 2s - loss: 0.3886 - accuracy: 0.8473 - val_loss: 0.4120 - val_accuracy: 0.8602\n",
      "Epoch 26/30\n",
      "5148/5148 - 2s - loss: 0.3910 - accuracy: 0.8394 - val_loss: 0.4216 - val_accuracy: 0.8618\n",
      "Epoch 27/30\n",
      "5148/5148 - 2s - loss: 0.3926 - accuracy: 0.8413 - val_loss: 0.3974 - val_accuracy: 0.8245\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.3799 - accuracy: 0.8454 - val_loss: 0.3729 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 3s - loss: 0.3995 - accuracy: 0.8370 - val_loss: 0.3872 - val_accuracy: 0.8292\n",
      "Epoch 30/30\n",
      "5148/5148 - 3s - loss: 0.3905 - accuracy: 0.8403 - val_loss: 0.3758 - val_accuracy: 0.8665\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 15.4795 - accuracy: 0.5449 - val_loss: 1.1878 - val_accuracy: 0.7780\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 3.6868 - accuracy: 0.6558 - val_loss: 3.7927 - val_accuracy: 0.4984\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.2039 - accuracy: 0.7251 - val_loss: 0.4935 - val_accuracy: 0.7593\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4837 - accuracy: 0.8019 - val_loss: 0.4482 - val_accuracy: 0.7733\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5728 - accuracy: 0.7372 - val_loss: 0.4511 - val_accuracy: 0.7686\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4709 - accuracy: 0.7978 - val_loss: 0.6433 - val_accuracy: 0.6553\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4189 - accuracy: 0.8304 - val_loss: 0.4677 - val_accuracy: 0.7655\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4013 - accuracy: 0.8430 - val_loss: 0.4350 - val_accuracy: 0.7857\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4224 - accuracy: 0.8223 - val_loss: 0.4266 - val_accuracy: 0.8540\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8394 - val_loss: 0.4662 - val_accuracy: 0.7484\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4089 - accuracy: 0.8211 - val_loss: 0.6221 - val_accuracy: 0.4984\n",
      "Epoch 12/30\n",
      "5148/5148 - 2s - loss: 0.4113 - accuracy: 0.8320 - val_loss: 0.5139 - val_accuracy: 0.8634\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.3967 - accuracy: 0.8382 - val_loss: 0.4030 - val_accuracy: 0.8525\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3967 - accuracy: 0.8372 - val_loss: 0.4074 - val_accuracy: 0.8571\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4155 - accuracy: 0.8294 - val_loss: 0.4009 - val_accuracy: 0.8183\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3960 - accuracy: 0.8337 - val_loss: 0.3919 - val_accuracy: 0.8556\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4203 - accuracy: 0.8190 - val_loss: 0.4658 - val_accuracy: 0.7531\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4087 - accuracy: 0.8265 - val_loss: 0.3760 - val_accuracy: 0.8509\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4057 - accuracy: 0.8285 - val_loss: 0.4039 - val_accuracy: 0.8587\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3981 - accuracy: 0.8337 - val_loss: 0.4276 - val_accuracy: 0.8618\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3675 - accuracy: 0.8462 - val_loss: 0.3851 - val_accuracy: 0.8339\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3670 - accuracy: 0.8432 - val_loss: 0.3727 - val_accuracy: 0.8711\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3562 - accuracy: 0.8483 - val_loss: 0.3881 - val_accuracy: 0.8168\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3640 - accuracy: 0.8407 - val_loss: 0.3928 - val_accuracy: 0.8230\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3485 - accuracy: 0.8498 - val_loss: 0.4300 - val_accuracy: 0.7624\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3489 - accuracy: 0.8462 - val_loss: 0.3558 - val_accuracy: 0.8307\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3429 - accuracy: 0.8456 - val_loss: 0.3448 - val_accuracy: 0.8478\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3448 - accuracy: 0.8409 - val_loss: 0.3871 - val_accuracy: 0.8587\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3372 - accuracy: 0.8448 - val_loss: 0.3440 - val_accuracy: 0.8634\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3230 - accuracy: 0.8531 - val_loss: 0.3544 - val_accuracy: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:08:34,758] Trial 31 finished with value: 0.8692547082901001 and parameters: {'units': 100, 'dropout': 0.05, 'learning_rate': 0.0058900721178725655, 'epochs': 30, 'batch_size': 25, 'patience': 8, 'factor': 0.4}. Best is trial 23 with value: 0.8711179494857788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 14.9650 - accuracy: 0.5546 - val_loss: 2.8492 - val_accuracy: 0.6755\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 3.1505 - accuracy: 0.6840 - val_loss: 1.1270 - val_accuracy: 0.8106\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.7733 - accuracy: 0.7426 - val_loss: 0.4652 - val_accuracy: 0.7748\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4845 - accuracy: 0.7852 - val_loss: 0.4415 - val_accuracy: 0.8401\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.5536 - accuracy: 0.7484 - val_loss: 0.4455 - val_accuracy: 0.8509\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:08:42,250] Trial 32 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:08:44,624] Trial 33 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:08:47,147] Trial 34 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n",
      "5148/5148 - 2s - loss: 21.0671 - accuracy: 0.5690 - val_loss: 3.4220 - val_accuracy: 0.7081\n",
      "Epoch 2/20\n",
      "5148/5148 - 0s - loss: 3.8057 - accuracy: 0.6972 - val_loss: 1.1182 - val_accuracy: 0.7376\n",
      "Epoch 3/20\n",
      "5148/5148 - 1s - loss: 0.9368 - accuracy: 0.7407 - val_loss: 0.5293 - val_accuracy: 0.7438\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:08:51,108] Trial 35 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 2s - loss: 19.8073 - accuracy: 0.5530 - val_loss: 1.3149 - val_accuracy: 0.7065\n",
      "Epoch 2/40\n",
      "5148/5148 - 2s - loss: 0.8931 - accuracy: 0.6925 - val_loss: 0.7231 - val_accuracy: 0.6817\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:08:56,304] Trial 36 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 3s - loss: 32.1949 - accuracy: 0.5161 - val_loss: 0.9807 - val_accuracy: 0.6071\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 1.0404 - accuracy: 0.6307 - val_loss: 0.8668 - val_accuracy: 0.5481\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.6993 - accuracy: 0.6605 - val_loss: 0.4816 - val_accuracy: 0.7640\n",
      "Epoch 4/45\n",
      "5148/5148 - 2s - loss: 0.6146 - accuracy: 0.7044 - val_loss: 0.5327 - val_accuracy: 0.8494\n",
      "Epoch 5/45\n",
      "5148/5148 - 2s - loss: 0.6471 - accuracy: 0.6812 - val_loss: 0.4796 - val_accuracy: 0.8416\n",
      "Epoch 6/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:09:06,939] Trial 37 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:09:09,184] Trial 38 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 20.3292 - accuracy: 0.5387 - val_loss: 1.0208 - val_accuracy: 0.7407\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 2.8207 - accuracy: 0.6428 - val_loss: 1.1098 - val_accuracy: 0.5342\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6073 - accuracy: 0.7558 - val_loss: 0.4415 - val_accuracy: 0.7811\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4924 - accuracy: 0.7922 - val_loss: 0.4341 - val_accuracy: 0.8370\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.5468 - accuracy: 0.7527 - val_loss: 0.5029 - val_accuracy: 0.8587\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5095 - accuracy: 0.7727 - val_loss: 0.6478 - val_accuracy: 0.7252\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4330 - accuracy: 0.8199 - val_loss: 0.6000 - val_accuracy: 0.7127\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4312 - accuracy: 0.8160 - val_loss: 0.5616 - val_accuracy: 0.6941\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4437 - accuracy: 0.8147 - val_loss: 0.4223 - val_accuracy: 0.8478\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4465 - accuracy: 0.8116 - val_loss: 0.5034 - val_accuracy: 0.7329\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3695 - accuracy: 0.8578 - val_loss: 0.4049 - val_accuracy: 0.8634\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3637 - accuracy: 0.8601 - val_loss: 0.3962 - val_accuracy: 0.8571\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3685 - accuracy: 0.8572 - val_loss: 0.3850 - val_accuracy: 0.8447\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3560 - accuracy: 0.8677 - val_loss: 0.3748 - val_accuracy: 0.8540\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3386 - accuracy: 0.8730 - val_loss: 0.3658 - val_accuracy: 0.8525\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3316 - accuracy: 0.8733 - val_loss: 0.3583 - val_accuracy: 0.8587\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3224 - accuracy: 0.8794 - val_loss: 0.3564 - val_accuracy: 0.8634\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3195 - accuracy: 0.8765 - val_loss: 0.3597 - val_accuracy: 0.8602\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3222 - accuracy: 0.8784 - val_loss: 0.3590 - val_accuracy: 0.8634\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3169 - accuracy: 0.8784 - val_loss: 0.3677 - val_accuracy: 0.8665\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3194 - accuracy: 0.8790 - val_loss: 0.3557 - val_accuracy: 0.8618\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3183 - accuracy: 0.8798 - val_loss: 0.3546 - val_accuracy: 0.8618\n",
      "Epoch 23/25\n",
      "5148/5148 - 2s - loss: 0.3183 - accuracy: 0.8813 - val_loss: 0.3524 - val_accuracy: 0.8556\n",
      "Epoch 24/25\n",
      "5148/5148 - 3s - loss: 0.3132 - accuracy: 0.8798 - val_loss: 0.3575 - val_accuracy: 0.8665\n",
      "Epoch 25/25\n",
      "5148/5148 - 3s - loss: 0.3155 - accuracy: 0.8796 - val_loss: 0.3520 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 4s - loss: 25.7114 - accuracy: 0.5163 - val_loss: 0.9427 - val_accuracy: 0.7547\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 3.7044 - accuracy: 0.6344 - val_loss: 1.4363 - val_accuracy: 0.4984\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6932 - accuracy: 0.7494 - val_loss: 0.5102 - val_accuracy: 0.7376\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4952 - accuracy: 0.7815 - val_loss: 0.4612 - val_accuracy: 0.7748\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.5237 - accuracy: 0.7638 - val_loss: 0.4288 - val_accuracy: 0.8416\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5276 - accuracy: 0.7671 - val_loss: 0.6368 - val_accuracy: 0.6444\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4370 - accuracy: 0.8160 - val_loss: 0.5168 - val_accuracy: 0.7252\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4400 - accuracy: 0.8139 - val_loss: 0.4347 - val_accuracy: 0.7857\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4282 - accuracy: 0.8203 - val_loss: 0.4654 - val_accuracy: 0.8634\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4331 - accuracy: 0.8131 - val_loss: 0.4542 - val_accuracy: 0.7407\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4289 - accuracy: 0.8151 - val_loss: 0.4301 - val_accuracy: 0.8540\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4076 - accuracy: 0.8335 - val_loss: 0.4239 - val_accuracy: 0.8618\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3867 - accuracy: 0.8409 - val_loss: 0.4071 - val_accuracy: 0.8478\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4165 - accuracy: 0.8283 - val_loss: 0.4222 - val_accuracy: 0.8509\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3574 - accuracy: 0.8640 - val_loss: 0.3864 - val_accuracy: 0.8571\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3527 - accuracy: 0.8656 - val_loss: 0.3842 - val_accuracy: 0.8634\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3509 - accuracy: 0.8664 - val_loss: 0.3833 - val_accuracy: 0.8525\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3495 - accuracy: 0.8650 - val_loss: 0.3785 - val_accuracy: 0.8587\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3547 - accuracy: 0.8568 - val_loss: 0.3908 - val_accuracy: 0.8168\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3413 - accuracy: 0.8656 - val_loss: 0.3847 - val_accuracy: 0.8571\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3402 - accuracy: 0.8664 - val_loss: 0.3722 - val_accuracy: 0.8665\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3397 - accuracy: 0.8627 - val_loss: 0.3722 - val_accuracy: 0.8618\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3332 - accuracy: 0.8675 - val_loss: 0.3704 - val_accuracy: 0.8696\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3310 - accuracy: 0.8687 - val_loss: 0.3714 - val_accuracy: 0.8602\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3353 - accuracy: 0.8656 - val_loss: 0.3700 - val_accuracy: 0.8665\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 29.2040 - accuracy: 0.5313 - val_loss: 1.5762 - val_accuracy: 0.7531\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 4.0848 - accuracy: 0.6455 - val_loss: 0.8587 - val_accuracy: 0.8339\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.8270 - accuracy: 0.7247 - val_loss: 0.6429 - val_accuracy: 0.6941\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.5778 - accuracy: 0.7418 - val_loss: 0.4693 - val_accuracy: 0.8416\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.5693 - accuracy: 0.7391 - val_loss: 0.4608 - val_accuracy: 0.8385\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5173 - accuracy: 0.7745 - val_loss: 0.4467 - val_accuracy: 0.8370\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4876 - accuracy: 0.7927 - val_loss: 0.8813 - val_accuracy: 0.6320\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4787 - accuracy: 0.8032 - val_loss: 0.7655 - val_accuracy: 0.6677\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4632 - accuracy: 0.8073 - val_loss: 0.4506 - val_accuracy: 0.8556\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4321 - accuracy: 0.8254 - val_loss: 0.5574 - val_accuracy: 0.7096\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4414 - accuracy: 0.8118 - val_loss: 0.4513 - val_accuracy: 0.7919\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3884 - accuracy: 0.8498 - val_loss: 0.4363 - val_accuracy: 0.8618\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3772 - accuracy: 0.8508 - val_loss: 0.3918 - val_accuracy: 0.8307\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3931 - accuracy: 0.8394 - val_loss: 0.4219 - val_accuracy: 0.8587\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4131 - accuracy: 0.8314 - val_loss: 0.4238 - val_accuracy: 0.7873\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4136 - accuracy: 0.8269 - val_loss: 0.4008 - val_accuracy: 0.8602\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.4454 - accuracy: 0.8083 - val_loss: 0.4686 - val_accuracy: 0.7484\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3709 - accuracy: 0.8537 - val_loss: 0.3909 - val_accuracy: 0.8556\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3698 - accuracy: 0.8547 - val_loss: 0.3987 - val_accuracy: 0.8214\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3649 - accuracy: 0.8530 - val_loss: 0.3934 - val_accuracy: 0.8602\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3648 - accuracy: 0.8504 - val_loss: 0.4128 - val_accuracy: 0.8587\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3625 - accuracy: 0.8530 - val_loss: 0.3872 - val_accuracy: 0.8571\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3495 - accuracy: 0.8607 - val_loss: 0.3779 - val_accuracy: 0.8649\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3509 - accuracy: 0.8596 - val_loss: 0.3813 - val_accuracy: 0.8602\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3430 - accuracy: 0.8631 - val_loss: 0.3760 - val_accuracy: 0.8680\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 28.2026 - accuracy: 0.5338 - val_loss: 1.4930 - val_accuracy: 0.7283\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 5.3390 - accuracy: 0.6346 - val_loss: 2.6711 - val_accuracy: 0.4984\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.8096 - accuracy: 0.7547 - val_loss: 0.5077 - val_accuracy: 0.7593\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.5465 - accuracy: 0.7632 - val_loss: 0.4876 - val_accuracy: 0.7422\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.5424 - accuracy: 0.7694 - val_loss: 0.4502 - val_accuracy: 0.8463\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5238 - accuracy: 0.7778 - val_loss: 0.5147 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4866 - accuracy: 0.7881 - val_loss: 0.6841 - val_accuracy: 0.6801\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4456 - accuracy: 0.8162 - val_loss: 0.4584 - val_accuracy: 0.7702\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4445 - accuracy: 0.8021 - val_loss: 0.4541 - val_accuracy: 0.8556\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4210 - accuracy: 0.8308 - val_loss: 0.4703 - val_accuracy: 0.7453\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4249 - accuracy: 0.8153 - val_loss: 0.4793 - val_accuracy: 0.8509\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3921 - accuracy: 0.8487 - val_loss: 0.4273 - val_accuracy: 0.7702\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3822 - accuracy: 0.8469 - val_loss: 0.3925 - val_accuracy: 0.8478\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3683 - accuracy: 0.8566 - val_loss: 0.3804 - val_accuracy: 0.8525\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3449 - accuracy: 0.8691 - val_loss: 0.3739 - val_accuracy: 0.8509\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3409 - accuracy: 0.8732 - val_loss: 0.3677 - val_accuracy: 0.8556\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3309 - accuracy: 0.8765 - val_loss: 0.3654 - val_accuracy: 0.8556\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3273 - accuracy: 0.8751 - val_loss: 0.3679 - val_accuracy: 0.8587\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3290 - accuracy: 0.8772 - val_loss: 0.3680 - val_accuracy: 0.8602\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3266 - accuracy: 0.8767 - val_loss: 0.3794 - val_accuracy: 0.8649\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3303 - accuracy: 0.8776 - val_loss: 0.3648 - val_accuracy: 0.8602\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3260 - accuracy: 0.8772 - val_loss: 0.3627 - val_accuracy: 0.8634\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3259 - accuracy: 0.8792 - val_loss: 0.3618 - val_accuracy: 0.8602\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3249 - accuracy: 0.8755 - val_loss: 0.3678 - val_accuracy: 0.8680\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3265 - accuracy: 0.8768 - val_loss: 0.3623 - val_accuracy: 0.8649\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 26.3976 - accuracy: 0.5167 - val_loss: 1.5839 - val_accuracy: 0.5885\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 4.1232 - accuracy: 0.6338 - val_loss: 3.4208 - val_accuracy: 0.4953\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.7596 - accuracy: 0.7541 - val_loss: 0.4836 - val_accuracy: 0.7686\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4896 - accuracy: 0.8001 - val_loss: 0.4396 - val_accuracy: 0.7826\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.5492 - accuracy: 0.7587 - val_loss: 0.4994 - val_accuracy: 0.8587\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5231 - accuracy: 0.7677 - val_loss: 0.9529 - val_accuracy: 0.4984\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4457 - accuracy: 0.8087 - val_loss: 0.5635 - val_accuracy: 0.7019\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4338 - accuracy: 0.8184 - val_loss: 0.4236 - val_accuracy: 0.7950\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4454 - accuracy: 0.8081 - val_loss: 0.4174 - val_accuracy: 0.8525\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4133 - accuracy: 0.8362 - val_loss: 0.5014 - val_accuracy: 0.7345\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3745 - accuracy: 0.8576 - val_loss: 0.4117 - val_accuracy: 0.8509\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3733 - accuracy: 0.8574 - val_loss: 0.4212 - val_accuracy: 0.7919\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3728 - accuracy: 0.8514 - val_loss: 0.4024 - val_accuracy: 0.8509\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3638 - accuracy: 0.8627 - val_loss: 0.3989 - val_accuracy: 0.8540\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3588 - accuracy: 0.8631 - val_loss: 0.3908 - val_accuracy: 0.8494\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8700 - val_loss: 0.3860 - val_accuracy: 0.8602\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3486 - accuracy: 0.8691 - val_loss: 0.3812 - val_accuracy: 0.8494\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3428 - accuracy: 0.8689 - val_loss: 0.3815 - val_accuracy: 0.8494\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3407 - accuracy: 0.8710 - val_loss: 0.3864 - val_accuracy: 0.8618\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3428 - accuracy: 0.8699 - val_loss: 0.4004 - val_accuracy: 0.8634\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3380 - accuracy: 0.8708 - val_loss: 0.3821 - val_accuracy: 0.8571\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3402 - accuracy: 0.8677 - val_loss: 0.3760 - val_accuracy: 0.8509\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3350 - accuracy: 0.8733 - val_loss: 0.3755 - val_accuracy: 0.8540\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3364 - accuracy: 0.8714 - val_loss: 0.3894 - val_accuracy: 0.8447\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3367 - accuracy: 0.8737 - val_loss: 0.3816 - val_accuracy: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:11:08,372] Trial 39 finished with value: 0.867080807685852 and parameters: {'units': 90, 'dropout': 0.1, 'learning_rate': 0.004638670790031164, 'epochs': 25, 'batch_size': 25, 'patience': 5, 'factor': 0.2}. Best is trial 23 with value: 0.8711179494857788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:11:10,818] Trial 40 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 5s - loss: 13.0444 - accuracy: 0.5890 - val_loss: 1.2134 - val_accuracy: 0.8230\n",
      "Epoch 2/30\n",
      "5148/5148 - 4s - loss: 1.7237 - accuracy: 0.7051 - val_loss: 0.7109 - val_accuracy: 0.6382\n",
      "Epoch 3/30\n",
      "5148/5148 - 4s - loss: 0.4956 - accuracy: 0.7908 - val_loss: 0.5392 - val_accuracy: 0.7112\n",
      "Epoch 4/30\n",
      "5148/5148 - 3s - loss: 0.5343 - accuracy: 0.7718 - val_loss: 0.5002 - val_accuracy: 0.8602\n",
      "Epoch 5/30\n",
      "5148/5148 - 3s - loss: 0.4973 - accuracy: 0.7723 - val_loss: 0.4446 - val_accuracy: 0.8432\n",
      "Epoch 6/30\n",
      "5148/5148 - 5s - loss: 0.4519 - accuracy: 0.8069 - val_loss: 0.5431 - val_accuracy: 0.8556\n",
      "Epoch 7/30\n",
      "5148/5148 - 5s - loss: 0.4343 - accuracy: 0.8205 - val_loss: 0.5829 - val_accuracy: 0.7081\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4347 - accuracy: 0.8184 - val_loss: 0.4911 - val_accuracy: 0.7345\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4436 - accuracy: 0.8122 - val_loss: 0.4279 - val_accuracy: 0.8432\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4334 - accuracy: 0.8182 - val_loss: 0.4218 - val_accuracy: 0.8463\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4091 - accuracy: 0.8312 - val_loss: 0.6624 - val_accuracy: 0.6801\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4068 - accuracy: 0.8386 - val_loss: 0.4894 - val_accuracy: 0.8618\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4263 - accuracy: 0.8133 - val_loss: 0.5447 - val_accuracy: 0.7174\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4183 - accuracy: 0.8293 - val_loss: 0.4195 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4177 - accuracy: 0.8287 - val_loss: 0.4107 - val_accuracy: 0.8168\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4132 - accuracy: 0.8261 - val_loss: 0.3997 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4027 - accuracy: 0.8322 - val_loss: 0.3963 - val_accuracy: 0.8602\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4055 - accuracy: 0.8353 - val_loss: 0.4257 - val_accuracy: 0.8618\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4080 - accuracy: 0.8409 - val_loss: 0.4191 - val_accuracy: 0.8199\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4202 - accuracy: 0.8263 - val_loss: 0.3942 - val_accuracy: 0.8571\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3724 - accuracy: 0.8559 - val_loss: 0.3974 - val_accuracy: 0.8214\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3685 - accuracy: 0.8485 - val_loss: 0.3781 - val_accuracy: 0.8634\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3557 - accuracy: 0.8512 - val_loss: 0.3789 - val_accuracy: 0.8230\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3567 - accuracy: 0.8498 - val_loss: 0.3859 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8526 - val_loss: 0.3745 - val_accuracy: 0.8478\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3553 - accuracy: 0.8545 - val_loss: 0.3829 - val_accuracy: 0.8649\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3463 - accuracy: 0.8539 - val_loss: 0.4059 - val_accuracy: 0.8214\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3536 - accuracy: 0.8528 - val_loss: 0.4040 - val_accuracy: 0.8587\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3568 - accuracy: 0.8502 - val_loss: 0.3823 - val_accuracy: 0.8323\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3480 - accuracy: 0.8605 - val_loss: 0.3741 - val_accuracy: 0.8323\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 16.8990 - accuracy: 0.5655 - val_loss: 1.4538 - val_accuracy: 0.7516\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.2655 - accuracy: 0.7104 - val_loss: 1.1713 - val_accuracy: 0.6273\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.5194 - accuracy: 0.7986 - val_loss: 0.4532 - val_accuracy: 0.7702\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4278 - accuracy: 0.8242 - val_loss: 0.4336 - val_accuracy: 0.8571\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4554 - accuracy: 0.8050 - val_loss: 0.4201 - val_accuracy: 0.8463\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4487 - accuracy: 0.8073 - val_loss: 0.5252 - val_accuracy: 0.8618\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4239 - accuracy: 0.8209 - val_loss: 0.5505 - val_accuracy: 0.7019\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4165 - accuracy: 0.8261 - val_loss: 0.4745 - val_accuracy: 0.7453\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4249 - accuracy: 0.8215 - val_loss: 0.4087 - val_accuracy: 0.8571\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4527 - accuracy: 0.8079 - val_loss: 0.4595 - val_accuracy: 0.7547\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4184 - accuracy: 0.8246 - val_loss: 0.7638 - val_accuracy: 0.6568\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4179 - accuracy: 0.8275 - val_loss: 0.4940 - val_accuracy: 0.8618\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4348 - accuracy: 0.8151 - val_loss: 0.5264 - val_accuracy: 0.7252\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3992 - accuracy: 0.8382 - val_loss: 0.4111 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3637 - accuracy: 0.8557 - val_loss: 0.3887 - val_accuracy: 0.8168\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3536 - accuracy: 0.8555 - val_loss: 0.3629 - val_accuracy: 0.8602\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3562 - accuracy: 0.8514 - val_loss: 0.3636 - val_accuracy: 0.8571\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3487 - accuracy: 0.8522 - val_loss: 0.3523 - val_accuracy: 0.8711\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3435 - accuracy: 0.8530 - val_loss: 0.3549 - val_accuracy: 0.8354\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3318 - accuracy: 0.8596 - val_loss: 0.3652 - val_accuracy: 0.8618\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3293 - accuracy: 0.8588 - val_loss: 0.3893 - val_accuracy: 0.8618\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3321 - accuracy: 0.8605 - val_loss: 0.3379 - val_accuracy: 0.8649\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3211 - accuracy: 0.8640 - val_loss: 0.3506 - val_accuracy: 0.8339\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3191 - accuracy: 0.8598 - val_loss: 0.3708 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3150 - accuracy: 0.8724 - val_loss: 0.3336 - val_accuracy: 0.8602\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3120 - accuracy: 0.8671 - val_loss: 0.3303 - val_accuracy: 0.8370\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.2993 - accuracy: 0.8776 - val_loss: 0.3184 - val_accuracy: 0.8758\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3024 - accuracy: 0.8751 - val_loss: 0.3273 - val_accuracy: 0.8665\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.2986 - accuracy: 0.8765 - val_loss: 0.3327 - val_accuracy: 0.8649\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3009 - accuracy: 0.8739 - val_loss: 0.3207 - val_accuracy: 0.8742\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 18.0729 - accuracy: 0.5781 - val_loss: 8.0809 - val_accuracy: 0.5637\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 3.5459 - accuracy: 0.6977 - val_loss: 1.0680 - val_accuracy: 0.8463\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.6992 - accuracy: 0.7887 - val_loss: 0.4444 - val_accuracy: 0.7888\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4387 - accuracy: 0.8190 - val_loss: 0.4611 - val_accuracy: 0.8509\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4517 - accuracy: 0.8096 - val_loss: 0.4248 - val_accuracy: 0.8540\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4568 - accuracy: 0.8067 - val_loss: 0.4916 - val_accuracy: 0.8571\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4310 - accuracy: 0.8172 - val_loss: 0.6321 - val_accuracy: 0.6848\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4278 - accuracy: 0.8221 - val_loss: 0.4211 - val_accuracy: 0.7904\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4168 - accuracy: 0.8238 - val_loss: 0.4154 - val_accuracy: 0.8634\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.3892 - accuracy: 0.8471 - val_loss: 0.4005 - val_accuracy: 0.8463\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.3827 - accuracy: 0.8409 - val_loss: 0.6939 - val_accuracy: 0.5916\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4113 - accuracy: 0.8263 - val_loss: 0.4017 - val_accuracy: 0.8168\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4498 - accuracy: 0.8106 - val_loss: 0.4518 - val_accuracy: 0.8276\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.5430 - accuracy: 0.7481 - val_loss: 0.6382 - val_accuracy: 0.4984\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.5443 - accuracy: 0.7329 - val_loss: 0.4698 - val_accuracy: 0.7609\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4816 - accuracy: 0.7949 - val_loss: 0.5558 - val_accuracy: 0.7143\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4511 - accuracy: 0.8209 - val_loss: 0.4560 - val_accuracy: 0.8571\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4266 - accuracy: 0.8372 - val_loss: 0.4259 - val_accuracy: 0.8432\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4203 - accuracy: 0.8339 - val_loss: 0.4179 - val_accuracy: 0.8432\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4096 - accuracy: 0.8425 - val_loss: 0.4295 - val_accuracy: 0.7904\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3999 - accuracy: 0.8489 - val_loss: 0.4266 - val_accuracy: 0.7966\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4099 - accuracy: 0.8368 - val_loss: 0.4060 - val_accuracy: 0.8509\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4013 - accuracy: 0.8448 - val_loss: 0.4152 - val_accuracy: 0.8245\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3949 - accuracy: 0.8477 - val_loss: 0.4018 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3897 - accuracy: 0.8473 - val_loss: 0.4064 - val_accuracy: 0.8168\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3813 - accuracy: 0.8551 - val_loss: 0.3891 - val_accuracy: 0.8649\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3788 - accuracy: 0.8561 - val_loss: 0.3889 - val_accuracy: 0.8587\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3779 - accuracy: 0.8522 - val_loss: 0.4129 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3769 - accuracy: 0.8570 - val_loss: 0.3932 - val_accuracy: 0.8665\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3688 - accuracy: 0.8497 - val_loss: 0.4013 - val_accuracy: 0.8727\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 8.7640 - accuracy: 0.5826 - val_loss: 0.8511 - val_accuracy: 0.7329\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 0.9789 - accuracy: 0.7119 - val_loss: 0.6929 - val_accuracy: 0.6957\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.5779 - accuracy: 0.7502 - val_loss: 0.4476 - val_accuracy: 0.7717\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4826 - accuracy: 0.7941 - val_loss: 0.8301 - val_accuracy: 0.5202\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.5055 - accuracy: 0.7840 - val_loss: 0.4507 - val_accuracy: 0.8587\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4545 - accuracy: 0.8116 - val_loss: 0.5128 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4248 - accuracy: 0.8201 - val_loss: 0.6297 - val_accuracy: 0.7003\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4282 - accuracy: 0.8242 - val_loss: 0.4919 - val_accuracy: 0.7314\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4410 - accuracy: 0.8112 - val_loss: 0.4318 - val_accuracy: 0.7888\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4301 - accuracy: 0.8178 - val_loss: 0.4624 - val_accuracy: 0.7453\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4048 - accuracy: 0.8320 - val_loss: 0.7554 - val_accuracy: 0.6584\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4191 - accuracy: 0.8298 - val_loss: 0.4295 - val_accuracy: 0.8587\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4042 - accuracy: 0.8329 - val_loss: 0.5408 - val_accuracy: 0.7391\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4090 - accuracy: 0.8392 - val_loss: 0.4798 - val_accuracy: 0.8634\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4008 - accuracy: 0.8399 - val_loss: 0.4126 - val_accuracy: 0.8183\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3806 - accuracy: 0.8399 - val_loss: 0.3926 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4155 - accuracy: 0.8294 - val_loss: 0.4334 - val_accuracy: 0.8634\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4047 - accuracy: 0.8378 - val_loss: 0.3856 - val_accuracy: 0.8680\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4034 - accuracy: 0.8331 - val_loss: 0.3811 - val_accuracy: 0.8649\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3965 - accuracy: 0.8357 - val_loss: 0.3936 - val_accuracy: 0.8587\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3953 - accuracy: 0.8399 - val_loss: 0.3737 - val_accuracy: 0.8665\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3911 - accuracy: 0.8448 - val_loss: 0.3723 - val_accuracy: 0.8649\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3807 - accuracy: 0.8456 - val_loss: 0.3708 - val_accuracy: 0.8385\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4000 - accuracy: 0.8316 - val_loss: 0.3764 - val_accuracy: 0.8665\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3733 - accuracy: 0.8473 - val_loss: 0.3926 - val_accuracy: 0.8587\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3963 - accuracy: 0.8353 - val_loss: 0.4209 - val_accuracy: 0.8618\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3689 - accuracy: 0.8465 - val_loss: 0.3787 - val_accuracy: 0.8276\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3639 - accuracy: 0.8487 - val_loss: 0.3935 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3721 - accuracy: 0.8481 - val_loss: 0.3804 - val_accuracy: 0.8385\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3682 - accuracy: 0.8438 - val_loss: 0.3898 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 12.7546 - accuracy: 0.5556 - val_loss: 2.1110 - val_accuracy: 0.6522\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.5723 - accuracy: 0.7080 - val_loss: 0.6433 - val_accuracy: 0.8587\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.4801 - accuracy: 0.7968 - val_loss: 0.4620 - val_accuracy: 0.7640\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4403 - accuracy: 0.8199 - val_loss: 0.5079 - val_accuracy: 0.8602\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4735 - accuracy: 0.7956 - val_loss: 0.4797 - val_accuracy: 0.8587\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4421 - accuracy: 0.8110 - val_loss: 0.4263 - val_accuracy: 0.8556\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4359 - accuracy: 0.8151 - val_loss: 0.9412 - val_accuracy: 0.6025\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4530 - accuracy: 0.8048 - val_loss: 0.4797 - val_accuracy: 0.7267\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4364 - accuracy: 0.8124 - val_loss: 0.4482 - val_accuracy: 0.8587\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4246 - accuracy: 0.8277 - val_loss: 0.4146 - val_accuracy: 0.8432\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4107 - accuracy: 0.8324 - val_loss: 0.5989 - val_accuracy: 0.7050\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.3980 - accuracy: 0.8432 - val_loss: 0.5374 - val_accuracy: 0.7888\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.3936 - accuracy: 0.8442 - val_loss: 0.4175 - val_accuracy: 0.8571\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3978 - accuracy: 0.8390 - val_loss: 0.5038 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3800 - accuracy: 0.8510 - val_loss: 0.3983 - val_accuracy: 0.8571\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3666 - accuracy: 0.8528 - val_loss: 0.4019 - val_accuracy: 0.8214\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3745 - accuracy: 0.8485 - val_loss: 0.3771 - val_accuracy: 0.8556\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3517 - accuracy: 0.8598 - val_loss: 0.3801 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3498 - accuracy: 0.8586 - val_loss: 0.3547 - val_accuracy: 0.8634\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3359 - accuracy: 0.8638 - val_loss: 0.3508 - val_accuracy: 0.8742\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3250 - accuracy: 0.8716 - val_loss: 0.3616 - val_accuracy: 0.8618\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3370 - accuracy: 0.8632 - val_loss: 0.3369 - val_accuracy: 0.8618\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3262 - accuracy: 0.8679 - val_loss: 0.3603 - val_accuracy: 0.8245\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3181 - accuracy: 0.8660 - val_loss: 0.4106 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3132 - accuracy: 0.8720 - val_loss: 0.3599 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3160 - accuracy: 0.8691 - val_loss: 0.3438 - val_accuracy: 0.8665\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3175 - accuracy: 0.8671 - val_loss: 0.4445 - val_accuracy: 0.7609\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3208 - accuracy: 0.8636 - val_loss: 0.3388 - val_accuracy: 0.8494\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.2993 - accuracy: 0.8761 - val_loss: 0.3366 - val_accuracy: 0.8618\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.2975 - accuracy: 0.8743 - val_loss: 0.3209 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:14:12,903] Trial 41 finished with value: 0.8711180686950684 and parameters: {'units': 100, 'dropout': 0.05, 'learning_rate': 0.006770929479486254, 'epochs': 30, 'batch_size': 20, 'patience': 8, 'factor': 0.4}. Best is trial 41 with value: 0.8711180686950684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 18.5803 - accuracy: 0.5874 - val_loss: 1.3815 - val_accuracy: 0.8354\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 2.2671 - accuracy: 0.7022 - val_loss: 0.8090 - val_accuracy: 0.7733\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5173 - accuracy: 0.7879 - val_loss: 0.4909 - val_accuracy: 0.7547\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4492 - accuracy: 0.8096 - val_loss: 0.4919 - val_accuracy: 0.8587\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4742 - accuracy: 0.7943 - val_loss: 0.4183 - val_accuracy: 0.8416\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4732 - accuracy: 0.7927 - val_loss: 0.5510 - val_accuracy: 0.8199\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4488 - accuracy: 0.8077 - val_loss: 0.5639 - val_accuracy: 0.7050\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4369 - accuracy: 0.8203 - val_loss: 0.4731 - val_accuracy: 0.7547\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4356 - accuracy: 0.8190 - val_loss: 0.4392 - val_accuracy: 0.8432\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4891 - accuracy: 0.7795 - val_loss: 0.4307 - val_accuracy: 0.8401\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4556 - accuracy: 0.8009 - val_loss: 0.6580 - val_accuracy: 0.6118\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4290 - accuracy: 0.8147 - val_loss: 0.4589 - val_accuracy: 0.8540\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.3968 - accuracy: 0.8343 - val_loss: 0.4396 - val_accuracy: 0.8587\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3924 - accuracy: 0.8450 - val_loss: 0.4549 - val_accuracy: 0.8602\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3778 - accuracy: 0.8497 - val_loss: 0.4276 - val_accuracy: 0.8199\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4206 - accuracy: 0.8296 - val_loss: 0.4125 - val_accuracy: 0.8494\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4072 - accuracy: 0.8335 - val_loss: 0.3995 - val_accuracy: 0.8494\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3892 - accuracy: 0.8427 - val_loss: 0.3862 - val_accuracy: 0.8509\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3833 - accuracy: 0.8392 - val_loss: 0.3821 - val_accuracy: 0.8587\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3678 - accuracy: 0.8429 - val_loss: 0.4015 - val_accuracy: 0.8680\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3940 - accuracy: 0.8368 - val_loss: 0.3872 - val_accuracy: 0.8618\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3828 - accuracy: 0.8436 - val_loss: 0.3803 - val_accuracy: 0.8634\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3543 - accuracy: 0.8547 - val_loss: 0.3871 - val_accuracy: 0.8168\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3404 - accuracy: 0.8578 - val_loss: 0.4253 - val_accuracy: 0.8680\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3412 - accuracy: 0.8572 - val_loss: 0.3602 - val_accuracy: 0.8276\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3397 - accuracy: 0.8471 - val_loss: 0.3520 - val_accuracy: 0.8649\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3462 - accuracy: 0.8489 - val_loss: 0.4029 - val_accuracy: 0.8168\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3220 - accuracy: 0.8528 - val_loss: 0.3382 - val_accuracy: 0.8618\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3122 - accuracy: 0.8586 - val_loss: 0.3583 - val_accuracy: 0.8370\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3090 - accuracy: 0.8615 - val_loss: 0.3397 - val_accuracy: 0.8618\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3092 - accuracy: 0.8598 - val_loss: 0.3326 - val_accuracy: 0.8649\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3104 - accuracy: 0.8578 - val_loss: 0.3428 - val_accuracy: 0.8354\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3039 - accuracy: 0.8599 - val_loss: 0.3517 - val_accuracy: 0.8587\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3077 - accuracy: 0.8563 - val_loss: 0.3369 - val_accuracy: 0.8665\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3008 - accuracy: 0.8584 - val_loss: 0.3321 - val_accuracy: 0.8680\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 7s - loss: 12.9030 - accuracy: 0.5901 - val_loss: 3.0299 - val_accuracy: 0.6724\n",
      "Epoch 2/35\n",
      "5148/5148 - 6s - loss: 2.0035 - accuracy: 0.7191 - val_loss: 0.5404 - val_accuracy: 0.8401\n",
      "Epoch 3/35\n",
      "5148/5148 - 7s - loss: 0.5737 - accuracy: 0.7529 - val_loss: 0.5297 - val_accuracy: 0.7189\n",
      "Epoch 4/35\n",
      "5148/5148 - 8s - loss: 0.4662 - accuracy: 0.8048 - val_loss: 0.5300 - val_accuracy: 0.8602\n",
      "Epoch 5/35\n",
      "5148/5148 - 4s - loss: 0.4765 - accuracy: 0.7904 - val_loss: 0.4279 - val_accuracy: 0.8401\n",
      "Epoch 6/35\n",
      "5148/5148 - 2s - loss: 0.4447 - accuracy: 0.8116 - val_loss: 0.5475 - val_accuracy: 0.8602\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4222 - accuracy: 0.8238 - val_loss: 0.5532 - val_accuracy: 0.7034\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4070 - accuracy: 0.8349 - val_loss: 0.4675 - val_accuracy: 0.7453\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4215 - accuracy: 0.8240 - val_loss: 0.4135 - val_accuracy: 0.8323\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4032 - accuracy: 0.8390 - val_loss: 0.4051 - val_accuracy: 0.8494\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3943 - accuracy: 0.8343 - val_loss: 0.6425 - val_accuracy: 0.6879\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.3697 - accuracy: 0.8510 - val_loss: 0.4234 - val_accuracy: 0.8634\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.3600 - accuracy: 0.8578 - val_loss: 0.4114 - val_accuracy: 0.8587\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3730 - accuracy: 0.8465 - val_loss: 0.4799 - val_accuracy: 0.8618\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3656 - accuracy: 0.8506 - val_loss: 0.3874 - val_accuracy: 0.8214\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3532 - accuracy: 0.8516 - val_loss: 0.3766 - val_accuracy: 0.8183\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3619 - accuracy: 0.8522 - val_loss: 0.3748 - val_accuracy: 0.8587\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3485 - accuracy: 0.8568 - val_loss: 0.3651 - val_accuracy: 0.8571\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3458 - accuracy: 0.8564 - val_loss: 0.3608 - val_accuracy: 0.8665\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3458 - accuracy: 0.8524 - val_loss: 0.4119 - val_accuracy: 0.8634\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3628 - accuracy: 0.8491 - val_loss: 0.3941 - val_accuracy: 0.8665\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3755 - accuracy: 0.8450 - val_loss: 0.3758 - val_accuracy: 0.8618\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3544 - accuracy: 0.8489 - val_loss: 0.3900 - val_accuracy: 0.8401\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3578 - accuracy: 0.8460 - val_loss: 0.3789 - val_accuracy: 0.8292\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3382 - accuracy: 0.8559 - val_loss: 0.4167 - val_accuracy: 0.8245\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3337 - accuracy: 0.8564 - val_loss: 0.3691 - val_accuracy: 0.8665\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3116 - accuracy: 0.8652 - val_loss: 0.3322 - val_accuracy: 0.8727\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3121 - accuracy: 0.8640 - val_loss: 0.3860 - val_accuracy: 0.8680\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3080 - accuracy: 0.8687 - val_loss: 0.3632 - val_accuracy: 0.8649\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3043 - accuracy: 0.8667 - val_loss: 0.3197 - val_accuracy: 0.8727\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3021 - accuracy: 0.8660 - val_loss: 0.3313 - val_accuracy: 0.8292\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3030 - accuracy: 0.8660 - val_loss: 0.3220 - val_accuracy: 0.8385\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.2986 - accuracy: 0.8687 - val_loss: 0.3304 - val_accuracy: 0.8618\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.2985 - accuracy: 0.8712 - val_loss: 0.3280 - val_accuracy: 0.8649\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.2883 - accuracy: 0.8765 - val_loss: 0.3190 - val_accuracy: 0.8789\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 21.6990 - accuracy: 0.5826 - val_loss: 5.6445 - val_accuracy: 0.5730\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 2.5944 - accuracy: 0.7047 - val_loss: 1.0242 - val_accuracy: 0.7438\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5416 - accuracy: 0.7958 - val_loss: 0.4748 - val_accuracy: 0.7593\n",
      "Epoch 4/35\n",
      "5148/5148 - 3s - loss: 0.4219 - accuracy: 0.8254 - val_loss: 0.4827 - val_accuracy: 0.8587\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4550 - accuracy: 0.8067 - val_loss: 0.4219 - val_accuracy: 0.8416\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4512 - accuracy: 0.8077 - val_loss: 0.5290 - val_accuracy: 0.8602\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4249 - accuracy: 0.8225 - val_loss: 0.6284 - val_accuracy: 0.6832\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4333 - accuracy: 0.8164 - val_loss: 0.4295 - val_accuracy: 0.7888\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4318 - accuracy: 0.8162 - val_loss: 0.4287 - val_accuracy: 0.7904\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4337 - accuracy: 0.8205 - val_loss: 0.4055 - val_accuracy: 0.8416\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3976 - accuracy: 0.8372 - val_loss: 0.5740 - val_accuracy: 0.6988\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4124 - accuracy: 0.8357 - val_loss: 0.4215 - val_accuracy: 0.8602\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4177 - accuracy: 0.8254 - val_loss: 0.5032 - val_accuracy: 0.7283\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3621 - accuracy: 0.8592 - val_loss: 0.3714 - val_accuracy: 0.8602\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3599 - accuracy: 0.8555 - val_loss: 0.4109 - val_accuracy: 0.8354\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3615 - accuracy: 0.8570 - val_loss: 0.3556 - val_accuracy: 0.8571\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3479 - accuracy: 0.8586 - val_loss: 0.3542 - val_accuracy: 0.8634\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3406 - accuracy: 0.8621 - val_loss: 0.3524 - val_accuracy: 0.8618\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3451 - accuracy: 0.8599 - val_loss: 0.3656 - val_accuracy: 0.8711\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3375 - accuracy: 0.8627 - val_loss: 0.3849 - val_accuracy: 0.8587\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3360 - accuracy: 0.8615 - val_loss: 0.3968 - val_accuracy: 0.8711\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3419 - accuracy: 0.8621 - val_loss: 0.3576 - val_accuracy: 0.8680\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3333 - accuracy: 0.8621 - val_loss: 0.3608 - val_accuracy: 0.8665\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3284 - accuracy: 0.8629 - val_loss: 0.3395 - val_accuracy: 0.8587\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3175 - accuracy: 0.8638 - val_loss: 0.3315 - val_accuracy: 0.8680\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3186 - accuracy: 0.8677 - val_loss: 0.3306 - val_accuracy: 0.8618\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3090 - accuracy: 0.8664 - val_loss: 0.3289 - val_accuracy: 0.8727\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3078 - accuracy: 0.8650 - val_loss: 0.3313 - val_accuracy: 0.8634\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3014 - accuracy: 0.8739 - val_loss: 0.3356 - val_accuracy: 0.8618\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3081 - accuracy: 0.8664 - val_loss: 0.3244 - val_accuracy: 0.8727\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3056 - accuracy: 0.8679 - val_loss: 0.3203 - val_accuracy: 0.8727\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3028 - accuracy: 0.8673 - val_loss: 0.3295 - val_accuracy: 0.8711\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3038 - accuracy: 0.8656 - val_loss: 0.3248 - val_accuracy: 0.8602\n",
      "Epoch 34/35\n",
      "5148/5148 - 4s - loss: 0.3023 - accuracy: 0.8658 - val_loss: 0.3265 - val_accuracy: 0.8618\n",
      "Epoch 35/35\n",
      "5148/5148 - 2s - loss: 0.2927 - accuracy: 0.8718 - val_loss: 0.3206 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 13.6852 - accuracy: 0.5697 - val_loss: 4.9037 - val_accuracy: 0.5450\n",
      "Epoch 2/35\n",
      "5148/5148 - 2s - loss: 1.5359 - accuracy: 0.7063 - val_loss: 0.4593 - val_accuracy: 0.8339\n",
      "Epoch 3/35\n",
      "5148/5148 - 2s - loss: 0.5081 - accuracy: 0.7776 - val_loss: 0.4982 - val_accuracy: 0.7422\n",
      "Epoch 4/35\n",
      "5148/5148 - 2s - loss: 0.4658 - accuracy: 0.7984 - val_loss: 0.5740 - val_accuracy: 0.8183\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4871 - accuracy: 0.7834 - val_loss: 0.4630 - val_accuracy: 0.8478\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4542 - accuracy: 0.8052 - val_loss: 0.5746 - val_accuracy: 0.7391\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4476 - accuracy: 0.8071 - val_loss: 0.6896 - val_accuracy: 0.6382\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4413 - accuracy: 0.8155 - val_loss: 0.4435 - val_accuracy: 0.7717\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4477 - accuracy: 0.8019 - val_loss: 0.4195 - val_accuracy: 0.8432\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4363 - accuracy: 0.8184 - val_loss: 0.4549 - val_accuracy: 0.7453\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4080 - accuracy: 0.8333 - val_loss: 0.5846 - val_accuracy: 0.6770\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4296 - accuracy: 0.8236 - val_loss: 0.5151 - val_accuracy: 0.8634\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4255 - accuracy: 0.8221 - val_loss: 0.5002 - val_accuracy: 0.7267\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4221 - accuracy: 0.8228 - val_loss: 0.4252 - val_accuracy: 0.8571\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4388 - accuracy: 0.8238 - val_loss: 0.4596 - val_accuracy: 0.8649\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.4122 - accuracy: 0.8388 - val_loss: 0.4014 - val_accuracy: 0.8556\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4103 - accuracy: 0.8310 - val_loss: 0.3920 - val_accuracy: 0.8634\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.4161 - accuracy: 0.8329 - val_loss: 0.3905 - val_accuracy: 0.8354\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4015 - accuracy: 0.8382 - val_loss: 0.3989 - val_accuracy: 0.8168\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.4003 - accuracy: 0.8361 - val_loss: 0.4206 - val_accuracy: 0.8618\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.4064 - accuracy: 0.8349 - val_loss: 0.3850 - val_accuracy: 0.8587\n",
      "Epoch 22/35\n",
      "5148/5148 - 7s - loss: 0.3989 - accuracy: 0.8425 - val_loss: 0.3816 - val_accuracy: 0.8602\n",
      "Epoch 23/35\n",
      "5148/5148 - 4s - loss: 0.3676 - accuracy: 0.8520 - val_loss: 0.3784 - val_accuracy: 0.8339\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3742 - accuracy: 0.8460 - val_loss: 0.3753 - val_accuracy: 0.8696\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3692 - accuracy: 0.8489 - val_loss: 0.3747 - val_accuracy: 0.8339\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3762 - accuracy: 0.8421 - val_loss: 0.3724 - val_accuracy: 0.8401\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3694 - accuracy: 0.8471 - val_loss: 0.4242 - val_accuracy: 0.7904\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3667 - accuracy: 0.8450 - val_loss: 0.3789 - val_accuracy: 0.8711\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3617 - accuracy: 0.8512 - val_loss: 0.3802 - val_accuracy: 0.8339\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3594 - accuracy: 0.8516 - val_loss: 0.3853 - val_accuracy: 0.8618\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3560 - accuracy: 0.8530 - val_loss: 0.3957 - val_accuracy: 0.8276\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8518 - val_loss: 0.3758 - val_accuracy: 0.8354\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3515 - accuracy: 0.8563 - val_loss: 0.3901 - val_accuracy: 0.8292\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3562 - accuracy: 0.8502 - val_loss: 0.3754 - val_accuracy: 0.8618\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3546 - accuracy: 0.8479 - val_loss: 0.3695 - val_accuracy: 0.8494\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 11.9732 - accuracy: 0.5874 - val_loss: 1.4930 - val_accuracy: 0.7236\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.3013 - accuracy: 0.7201 - val_loss: 1.1698 - val_accuracy: 0.6242\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5383 - accuracy: 0.7706 - val_loss: 0.4449 - val_accuracy: 0.7826\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4668 - accuracy: 0.7966 - val_loss: 0.8635 - val_accuracy: 0.5202\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5295 - accuracy: 0.7531 - val_loss: 0.4299 - val_accuracy: 0.8401\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4666 - accuracy: 0.7896 - val_loss: 0.5862 - val_accuracy: 0.8245\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4330 - accuracy: 0.8178 - val_loss: 0.5998 - val_accuracy: 0.6879\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4218 - accuracy: 0.8263 - val_loss: 0.4726 - val_accuracy: 0.7360\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4196 - accuracy: 0.8252 - val_loss: 0.4011 - val_accuracy: 0.8463\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4395 - accuracy: 0.8153 - val_loss: 0.4975 - val_accuracy: 0.7205\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4005 - accuracy: 0.8306 - val_loss: 0.6552 - val_accuracy: 0.6693\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4149 - accuracy: 0.8244 - val_loss: 0.4619 - val_accuracy: 0.8634\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4100 - accuracy: 0.8273 - val_loss: 0.5107 - val_accuracy: 0.7422\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4088 - accuracy: 0.8349 - val_loss: 0.4213 - val_accuracy: 0.8587\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4147 - accuracy: 0.8296 - val_loss: 0.3820 - val_accuracy: 0.8634\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3842 - accuracy: 0.8423 - val_loss: 0.4052 - val_accuracy: 0.8587\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4027 - accuracy: 0.8378 - val_loss: 0.4318 - val_accuracy: 0.8245\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.4028 - accuracy: 0.8337 - val_loss: 0.3800 - val_accuracy: 0.8696\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3986 - accuracy: 0.8345 - val_loss: 0.3913 - val_accuracy: 0.8571\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3966 - accuracy: 0.8359 - val_loss: 0.3884 - val_accuracy: 0.8571\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3949 - accuracy: 0.8415 - val_loss: 0.3745 - val_accuracy: 0.8665\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3881 - accuracy: 0.8450 - val_loss: 0.3778 - val_accuracy: 0.8618\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3833 - accuracy: 0.8436 - val_loss: 0.3766 - val_accuracy: 0.8571\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.4006 - accuracy: 0.8337 - val_loss: 0.3825 - val_accuracy: 0.8634\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3811 - accuracy: 0.8460 - val_loss: 0.4062 - val_accuracy: 0.8587\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3651 - accuracy: 0.8462 - val_loss: 0.3822 - val_accuracy: 0.8634\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3645 - accuracy: 0.8479 - val_loss: 0.3862 - val_accuracy: 0.8354\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3701 - accuracy: 0.8440 - val_loss: 0.3789 - val_accuracy: 0.8665\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3690 - accuracy: 0.8473 - val_loss: 0.3696 - val_accuracy: 0.8323\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3710 - accuracy: 0.8425 - val_loss: 0.3979 - val_accuracy: 0.8587\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3686 - accuracy: 0.8485 - val_loss: 0.3897 - val_accuracy: 0.8354\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3699 - accuracy: 0.8444 - val_loss: 0.3679 - val_accuracy: 0.8416\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3584 - accuracy: 0.8495 - val_loss: 0.3694 - val_accuracy: 0.8634\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3589 - accuracy: 0.8462 - val_loss: 0.3806 - val_accuracy: 0.8665\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3664 - accuracy: 0.8430 - val_loss: 0.3666 - val_accuracy: 0.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:04,906] Trial 42 finished with value: 0.8720496892929077 and parameters: {'units': 95, 'dropout': 0.05, 'learning_rate': 0.007537018837329913, 'epochs': 35, 'batch_size': 20, 'patience': 7, 'factor': 0.4}. Best is trial 42 with value: 0.8720496892929077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:07,966] Trial 43 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:10,716] Trial 44 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:18,845] Trial 45 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:28,354] Trial 46 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:34,322] Trial 47 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 20.7599 - accuracy: 0.5511 - val_loss: 0.4995 - val_accuracy: 0.7593\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 0.7939 - accuracy: 0.6098 - val_loss: 0.5854 - val_accuracy: 0.6755\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.7126 - accuracy: 0.6156 - val_loss: 0.5989 - val_accuracy: 0.6584\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:18:43,542] Trial 48 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 2s - loss: 23.6265 - accuracy: 0.6239 - val_loss: 0.5513 - val_accuracy: 0.7376\n",
      "Epoch 2/40\n",
      "5148/5148 - 1s - loss: 0.5346 - accuracy: 0.7543 - val_loss: 0.5913 - val_accuracy: 0.5730\n",
      "Epoch 3/40\n",
      "5148/5148 - 1s - loss: 0.4806 - accuracy: 0.7937 - val_loss: 0.4693 - val_accuracy: 0.8307\n",
      "Epoch 4/40\n",
      "5148/5148 - 1s - loss: 0.4481 - accuracy: 0.8143 - val_loss: 0.5179 - val_accuracy: 0.8587\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.4621 - accuracy: 0.8011 - val_loss: 0.4422 - val_accuracy: 0.8214\n",
      "Epoch 6/40\n",
      "5148/5148 - 1s - loss: 0.4623 - accuracy: 0.8034 - val_loss: 0.5807 - val_accuracy: 0.8199\n",
      "Epoch 7/40\n",
      "5148/5148 - 1s - loss: 0.3954 - accuracy: 0.8442 - val_loss: 0.4349 - val_accuracy: 0.8323\n",
      "Epoch 8/40\n",
      "5148/5148 - 1s - loss: 0.3929 - accuracy: 0.8460 - val_loss: 0.4335 - val_accuracy: 0.8401\n",
      "Epoch 9/40\n",
      "5148/5148 - 2s - loss: 0.3900 - accuracy: 0.8574 - val_loss: 0.4335 - val_accuracy: 0.8385\n",
      "Epoch 10/40\n",
      "5148/5148 - 1s - loss: 0.3897 - accuracy: 0.8528 - val_loss: 0.4347 - val_accuracy: 0.8385\n",
      "Epoch 11/40\n",
      "5148/5148 - 2s - loss: 0.3895 - accuracy: 0.8576 - val_loss: 0.4338 - val_accuracy: 0.8401\n",
      "Epoch 12/40\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8570 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 13/40\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8564 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 14/40\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8564 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 15/40\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8566 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 16/40\n",
      "5148/5148 - 2s - loss: 0.3891 - accuracy: 0.8566 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 17/40\n",
      "5148/5148 - 2s - loss: 0.3891 - accuracy: 0.8564 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 18/40\n",
      "5148/5148 - 2s - loss: 0.3891 - accuracy: 0.8568 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 19/40\n",
      "5148/5148 - 2s - loss: 0.3891 - accuracy: 0.8563 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 20/40\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8564 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 21/40\n",
      "5148/5148 - 1s - loss: 0.3890 - accuracy: 0.8563 - val_loss: 0.4334 - val_accuracy: 0.8385\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:19:13,863] Trial 49 pruned. Trial was pruned at epoch 21.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:19:16,818] Trial 50 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:19:19,558] Trial 51 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:19:25,275] Trial 52 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 14.7243 - accuracy: 0.5567 - val_loss: 1.1791 - val_accuracy: 0.7624\n",
      "Epoch 2/30\n",
      "5148/5148 - 3s - loss: 3.4142 - accuracy: 0.6719 - val_loss: 2.7781 - val_accuracy: 0.5093\n",
      "Epoch 3/30\n",
      "5148/5148 - 4s - loss: 0.9937 - accuracy: 0.7558 - val_loss: 0.4871 - val_accuracy: 0.8432\n",
      "Epoch 4/30\n",
      "5148/5148 - 3s - loss: 0.4580 - accuracy: 0.8182 - val_loss: 0.4264 - val_accuracy: 0.8354\n",
      "Epoch 5/30\n",
      "5148/5148 - 3s - loss: 0.4834 - accuracy: 0.7966 - val_loss: 0.4262 - val_accuracy: 0.8183\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:19:46,530] Trial 53 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 5s - loss: 9.9221 - accuracy: 0.6187 - val_loss: 0.4900 - val_accuracy: 0.7407\n",
      "Epoch 2/45\n",
      "5148/5148 - 3s - loss: 0.5667 - accuracy: 0.7244 - val_loss: 0.6471 - val_accuracy: 0.5901\n",
      "Epoch 3/45\n",
      "5148/5148 - 4s - loss: 0.5444 - accuracy: 0.7348 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 4/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:02,429] Trial 54 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:05,454] Trial 55 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:08,001] Trial 56 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:11,157] Trial 57 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:13,592] Trial 58 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:17,645] Trial 59 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:24,966] Trial 60 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 24.4450 - accuracy: 0.5416 - val_loss: 1.6989 - val_accuracy: 0.8354\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 5.8060 - accuracy: 0.6612 - val_loss: 1.6413 - val_accuracy: 0.8463\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 1.9520 - accuracy: 0.7296 - val_loss: 0.9884 - val_accuracy: 0.7314\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.6012 - accuracy: 0.7881 - val_loss: 0.4381 - val_accuracy: 0.8245\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4935 - accuracy: 0.7937 - val_loss: 0.4488 - val_accuracy: 0.8509\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:36,784] Trial 61 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:20:40,171] Trial 62 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 7.3819 - accuracy: 0.6583 - val_loss: 0.8502 - val_accuracy: 0.7531\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 1.8810 - accuracy: 0.7073 - val_loss: 2.5203 - val_accuracy: 0.6553\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.6328 - accuracy: 0.7438 - val_loss: 1.0021 - val_accuracy: 0.8587\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 1.1132 - accuracy: 0.7927 - val_loss: 0.8900 - val_accuracy: 0.8634\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 1.5523 - accuracy: 0.7407 - val_loss: 3.3396 - val_accuracy: 0.5062\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 1.4936 - accuracy: 0.7751 - val_loss: 0.8948 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.5775 - accuracy: 0.7605 - val_loss: 1.5746 - val_accuracy: 0.7422\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.8906 - accuracy: 0.8215 - val_loss: 1.4315 - val_accuracy: 0.6801\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.3454 - accuracy: 0.7795 - val_loss: 0.8858 - val_accuracy: 0.8137\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 1.1400 - accuracy: 0.7863 - val_loss: 0.9771 - val_accuracy: 0.8618\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 1.0552 - accuracy: 0.8050 - val_loss: 5.0010 - val_accuracy: 0.5528\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.7151 - accuracy: 0.8413 - val_loss: 0.9277 - val_accuracy: 0.8587\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.5679 - accuracy: 0.8504 - val_loss: 0.5944 - val_accuracy: 0.8292\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.6451 - accuracy: 0.8320 - val_loss: 0.5927 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.6254 - accuracy: 0.8329 - val_loss: 0.5771 - val_accuracy: 0.8292\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.5320 - accuracy: 0.8409 - val_loss: 0.5465 - val_accuracy: 0.8556\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5090 - accuracy: 0.8423 - val_loss: 0.6840 - val_accuracy: 0.8556\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.5657 - accuracy: 0.8258 - val_loss: 0.4899 - val_accuracy: 0.8307\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4304 - accuracy: 0.8531 - val_loss: 0.4743 - val_accuracy: 0.8494\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4479 - accuracy: 0.8512 - val_loss: 0.4873 - val_accuracy: 0.8540\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4282 - accuracy: 0.8535 - val_loss: 0.5933 - val_accuracy: 0.8571\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4710 - accuracy: 0.8409 - val_loss: 0.4574 - val_accuracy: 0.8540\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4163 - accuracy: 0.8545 - val_loss: 0.4608 - val_accuracy: 0.8540\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3979 - accuracy: 0.8561 - val_loss: 0.6725 - val_accuracy: 0.8183\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.4101 - accuracy: 0.8588 - val_loss: 0.4295 - val_accuracy: 0.8307\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3622 - accuracy: 0.8553 - val_loss: 0.4191 - val_accuracy: 0.8307\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3643 - accuracy: 0.8588 - val_loss: 0.4844 - val_accuracy: 0.8447\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3554 - accuracy: 0.8570 - val_loss: 0.4573 - val_accuracy: 0.8556\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3836 - accuracy: 0.8524 - val_loss: 0.4181 - val_accuracy: 0.8292\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3695 - accuracy: 0.8605 - val_loss: 0.4074 - val_accuracy: 0.8261\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 7.4090 - accuracy: 0.6346 - val_loss: 2.8809 - val_accuracy: 0.6258\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.4867 - accuracy: 0.7415 - val_loss: 1.7472 - val_accuracy: 0.6894\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.4676 - accuracy: 0.7525 - val_loss: 0.7834 - val_accuracy: 0.8494\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 1.0701 - accuracy: 0.7834 - val_loss: 1.0343 - val_accuracy: 0.8618\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 1.0666 - accuracy: 0.7787 - val_loss: 0.7805 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 1.0486 - accuracy: 0.7840 - val_loss: 1.6800 - val_accuracy: 0.5870\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.9795 - accuracy: 0.7927 - val_loss: 0.7212 - val_accuracy: 0.8649\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.8885 - accuracy: 0.8054 - val_loss: 0.6848 - val_accuracy: 0.8245\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.1440 - accuracy: 0.7807 - val_loss: 0.8144 - val_accuracy: 0.7655\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.8720 - accuracy: 0.8104 - val_loss: 1.0704 - val_accuracy: 0.7578\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.8452 - accuracy: 0.8046 - val_loss: 1.2294 - val_accuracy: 0.7453\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.7836 - accuracy: 0.8081 - val_loss: 1.2795 - val_accuracy: 0.7407\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.8345 - accuracy: 0.8069 - val_loss: 1.1103 - val_accuracy: 0.7531\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.6878 - accuracy: 0.8190 - val_loss: 0.6639 - val_accuracy: 0.8276\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.5379 - accuracy: 0.8434 - val_loss: 0.8578 - val_accuracy: 0.7640\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.5572 - accuracy: 0.8368 - val_loss: 0.4821 - val_accuracy: 0.8354\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5297 - accuracy: 0.8283 - val_loss: 0.5923 - val_accuracy: 0.8354\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.5421 - accuracy: 0.8269 - val_loss: 0.4716 - val_accuracy: 0.8307\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4939 - accuracy: 0.8329 - val_loss: 0.6849 - val_accuracy: 0.8540\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4738 - accuracy: 0.8415 - val_loss: 0.4787 - val_accuracy: 0.8261\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.5412 - accuracy: 0.8225 - val_loss: 0.7785 - val_accuracy: 0.7655\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3990 - accuracy: 0.8549 - val_loss: 0.4294 - val_accuracy: 0.8339\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4244 - accuracy: 0.8493 - val_loss: 0.4301 - val_accuracy: 0.8602\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4023 - accuracy: 0.8549 - val_loss: 0.4404 - val_accuracy: 0.8354\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3583 - accuracy: 0.8646 - val_loss: 0.4254 - val_accuracy: 0.8525\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3777 - accuracy: 0.8576 - val_loss: 0.4496 - val_accuracy: 0.8556\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.4287 - accuracy: 0.8384 - val_loss: 0.4015 - val_accuracy: 0.8276\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3622 - accuracy: 0.8533 - val_loss: 0.4781 - val_accuracy: 0.8370\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3529 - accuracy: 0.8576 - val_loss: 0.4051 - val_accuracy: 0.8618\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3400 - accuracy: 0.8578 - val_loss: 0.4409 - val_accuracy: 0.8556\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 10.5848 - accuracy: 0.6336 - val_loss: 3.8789 - val_accuracy: 0.5823\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.8037 - accuracy: 0.7296 - val_loss: 1.3400 - val_accuracy: 0.7329\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 1.3341 - accuracy: 0.7721 - val_loss: 1.2607 - val_accuracy: 0.7966\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 1.4281 - accuracy: 0.7688 - val_loss: 1.3365 - val_accuracy: 0.7702\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 1.8892 - accuracy: 0.7397 - val_loss: 1.2910 - val_accuracy: 0.7531\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 1.1143 - accuracy: 0.8083 - val_loss: 0.7941 - val_accuracy: 0.8634\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.1709 - accuracy: 0.7955 - val_loss: 0.7385 - val_accuracy: 0.8385\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.9649 - accuracy: 0.7997 - val_loss: 1.3101 - val_accuracy: 0.7360\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.4246 - accuracy: 0.7712 - val_loss: 0.8561 - val_accuracy: 0.8323\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 1.1983 - accuracy: 0.7809 - val_loss: 0.9335 - val_accuracy: 0.8602\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 1.1885 - accuracy: 0.8036 - val_loss: 5.1219 - val_accuracy: 0.5559\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.8474 - accuracy: 0.8234 - val_loss: 1.0960 - val_accuracy: 0.7671\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.9400 - accuracy: 0.8024 - val_loss: 1.2586 - val_accuracy: 0.7562\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.5641 - accuracy: 0.8584 - val_loss: 0.9780 - val_accuracy: 0.7873\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.5951 - accuracy: 0.8469 - val_loss: 0.8646 - val_accuracy: 0.7748\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.6099 - accuracy: 0.8388 - val_loss: 0.7237 - val_accuracy: 0.8230\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5318 - accuracy: 0.8405 - val_loss: 0.5099 - val_accuracy: 0.8571\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.5558 - accuracy: 0.8343 - val_loss: 0.5161 - val_accuracy: 0.8556\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.5331 - accuracy: 0.8397 - val_loss: 0.7453 - val_accuracy: 0.8370\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.5812 - accuracy: 0.8291 - val_loss: 0.5764 - val_accuracy: 0.8370\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8601 - val_loss: 0.4768 - val_accuracy: 0.8540\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4221 - accuracy: 0.8493 - val_loss: 0.4433 - val_accuracy: 0.8276\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4141 - accuracy: 0.8533 - val_loss: 0.4518 - val_accuracy: 0.8571\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3992 - accuracy: 0.8611 - val_loss: 0.4883 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3812 - accuracy: 0.8578 - val_loss: 0.4189 - val_accuracy: 0.8292\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.4095 - accuracy: 0.8514 - val_loss: 0.4140 - val_accuracy: 0.8261\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.4569 - accuracy: 0.8415 - val_loss: 0.6497 - val_accuracy: 0.7842\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3543 - accuracy: 0.8570 - val_loss: 0.5015 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3714 - accuracy: 0.8607 - val_loss: 0.4153 - val_accuracy: 0.8292\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3556 - accuracy: 0.8584 - val_loss: 0.4310 - val_accuracy: 0.8540\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 4.1336 - accuracy: 0.6713 - val_loss: 0.8474 - val_accuracy: 0.7873\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.0993 - accuracy: 0.6892 - val_loss: 3.1923 - val_accuracy: 0.6661\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 2.0649 - accuracy: 0.7533 - val_loss: 1.4785 - val_accuracy: 0.7314\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 1.5596 - accuracy: 0.7836 - val_loss: 0.9639 - val_accuracy: 0.8618\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 2.3018 - accuracy: 0.7490 - val_loss: 1.6000 - val_accuracy: 0.8618\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 2.2346 - accuracy: 0.7436 - val_loss: 1.2444 - val_accuracy: 0.8556\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.4955 - accuracy: 0.7995 - val_loss: 1.5173 - val_accuracy: 0.7578\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.9971 - accuracy: 0.8195 - val_loss: 0.9954 - val_accuracy: 0.8571\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.3519 - accuracy: 0.7791 - val_loss: 0.8834 - val_accuracy: 0.8307\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 1.2078 - accuracy: 0.7830 - val_loss: 0.9996 - val_accuracy: 0.8602\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 1.2292 - accuracy: 0.8040 - val_loss: 5.7433 - val_accuracy: 0.5497\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.7865 - accuracy: 0.8392 - val_loss: 1.0070 - val_accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.6172 - accuracy: 0.8498 - val_loss: 0.6528 - val_accuracy: 0.8261\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.7048 - accuracy: 0.8285 - val_loss: 0.6507 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.6680 - accuracy: 0.8298 - val_loss: 0.5819 - val_accuracy: 0.8307\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.5602 - accuracy: 0.8413 - val_loss: 0.6055 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5426 - accuracy: 0.8394 - val_loss: 0.9143 - val_accuracy: 0.7469\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.6345 - accuracy: 0.8199 - val_loss: 0.5212 - val_accuracy: 0.8307\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4543 - accuracy: 0.8530 - val_loss: 0.4967 - val_accuracy: 0.8416\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4716 - accuracy: 0.8502 - val_loss: 0.5128 - val_accuracy: 0.8556\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4489 - accuracy: 0.8539 - val_loss: 0.6513 - val_accuracy: 0.8556\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4984 - accuracy: 0.8341 - val_loss: 0.4971 - val_accuracy: 0.8556\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4332 - accuracy: 0.8547 - val_loss: 0.4807 - val_accuracy: 0.8540\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4109 - accuracy: 0.8551 - val_loss: 0.7585 - val_accuracy: 0.7438\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.4308 - accuracy: 0.8543 - val_loss: 0.4488 - val_accuracy: 0.8339\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3721 - accuracy: 0.8553 - val_loss: 0.4284 - val_accuracy: 0.8292\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3727 - accuracy: 0.8586 - val_loss: 0.5028 - val_accuracy: 0.8447\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3629 - accuracy: 0.8549 - val_loss: 0.4357 - val_accuracy: 0.8618\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3874 - accuracy: 0.8539 - val_loss: 0.4203 - val_accuracy: 0.8307\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3847 - accuracy: 0.8570 - val_loss: 0.4167 - val_accuracy: 0.8307\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 4.7842 - accuracy: 0.6342 - val_loss: 2.6568 - val_accuracy: 0.6444\n",
      "Epoch 2/30\n",
      "5148/5148 - 3s - loss: 1.6288 - accuracy: 0.7259 - val_loss: 2.6884 - val_accuracy: 0.6444\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 1.0637 - accuracy: 0.7937 - val_loss: 2.4874 - val_accuracy: 0.6056\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 1.9052 - accuracy: 0.7275 - val_loss: 1.3691 - val_accuracy: 0.8416\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 1.5255 - accuracy: 0.7640 - val_loss: 2.1670 - val_accuracy: 0.5606\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 1.1975 - accuracy: 0.7896 - val_loss: 0.8873 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.1324 - accuracy: 0.7859 - val_loss: 0.8940 - val_accuracy: 0.8602\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 1.0990 - accuracy: 0.7955 - val_loss: 1.5279 - val_accuracy: 0.6475\n",
      "Epoch 9/30\n",
      "5148/5148 - 2s - loss: 0.8629 - accuracy: 0.8188 - val_loss: 0.9705 - val_accuracy: 0.7686\n",
      "Epoch 10/30\n",
      "5148/5148 - 3s - loss: 1.2410 - accuracy: 0.7601 - val_loss: 0.8451 - val_accuracy: 0.8587\n",
      "Epoch 11/30\n",
      "5148/5148 - 3s - loss: 0.9873 - accuracy: 0.8048 - val_loss: 4.1461 - val_accuracy: 0.5606\n",
      "Epoch 12/30\n",
      "5148/5148 - 3s - loss: 0.8273 - accuracy: 0.8102 - val_loss: 0.6697 - val_accuracy: 0.8292\n",
      "Epoch 13/30\n",
      "5148/5148 - 4s - loss: 0.9223 - accuracy: 0.7889 - val_loss: 1.4172 - val_accuracy: 0.7407\n",
      "Epoch 14/30\n",
      "5148/5148 - 4s - loss: 0.5703 - accuracy: 0.8518 - val_loss: 0.9774 - val_accuracy: 0.7997\n",
      "Epoch 15/30\n",
      "5148/5148 - 3s - loss: 0.5730 - accuracy: 0.8440 - val_loss: 0.9461 - val_accuracy: 0.7640\n",
      "Epoch 16/30\n",
      "5148/5148 - 3s - loss: 0.5900 - accuracy: 0.8382 - val_loss: 0.5140 - val_accuracy: 0.8307\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5599 - accuracy: 0.8289 - val_loss: 0.6457 - val_accuracy: 0.8307\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.5737 - accuracy: 0.8279 - val_loss: 0.4859 - val_accuracy: 0.8323\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.5145 - accuracy: 0.8345 - val_loss: 0.7753 - val_accuracy: 0.8075\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4986 - accuracy: 0.8384 - val_loss: 0.5014 - val_accuracy: 0.8245\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3871 - accuracy: 0.8599 - val_loss: 0.4403 - val_accuracy: 0.8307\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3988 - accuracy: 0.8535 - val_loss: 0.4291 - val_accuracy: 0.8276\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4139 - accuracy: 0.8506 - val_loss: 0.4799 - val_accuracy: 0.8556\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4033 - accuracy: 0.8559 - val_loss: 0.4196 - val_accuracy: 0.8276\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3685 - accuracy: 0.8598 - val_loss: 0.4249 - val_accuracy: 0.8587\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3950 - accuracy: 0.8543 - val_loss: 0.4220 - val_accuracy: 0.8602\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.4548 - accuracy: 0.8351 - val_loss: 0.4196 - val_accuracy: 0.8307\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3481 - accuracy: 0.8574 - val_loss: 0.4698 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3617 - accuracy: 0.8598 - val_loss: 0.4043 - val_accuracy: 0.8292\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3480 - accuracy: 0.8568 - val_loss: 0.4511 - val_accuracy: 0.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:23:21,365] Trial 63 finished with value: 0.862733006477356 and parameters: {'units': 90, 'dropout': 0.0, 'learning_rate': 0.007481023062776878, 'epochs': 30, 'batch_size': 25, 'patience': 7, 'factor': 0.4}. Best is trial 42 with value: 0.8720496892929077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 27.3546 - accuracy: 0.5200 - val_loss: 0.9983 - val_accuracy: 0.8323\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 6.6173 - accuracy: 0.6119 - val_loss: 1.0704 - val_accuracy: 0.7780\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 1.4016 - accuracy: 0.7102 - val_loss: 0.6674 - val_accuracy: 0.7391\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:23:26,933] Trial 64 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 24.9572 - accuracy: 0.5458 - val_loss: 1.7137 - val_accuracy: 0.7733\n",
      "Epoch 2/35\n",
      "5148/5148 - 2s - loss: 6.1473 - accuracy: 0.6606 - val_loss: 3.6910 - val_accuracy: 0.5435\n",
      "Epoch 3/35\n",
      "5148/5148 - 2s - loss: 2.1683 - accuracy: 0.7329 - val_loss: 0.8357 - val_accuracy: 0.7904\n",
      "Epoch 4/35\n",
      "5148/5148 - 3s - loss: 0.8625 - accuracy: 0.7659 - val_loss: 0.5595 - val_accuracy: 0.8587\n",
      "Epoch 5/35\n",
      "5148/5148 - 3s - loss: 0.5512 - accuracy: 0.7700 - val_loss: 0.4445 - val_accuracy: 0.7686\n",
      "Epoch 6/35\n",
      "5148/5148 - 3s - loss: 0.4761 - accuracy: 0.7990 - val_loss: 0.5876 - val_accuracy: 0.8540\n",
      "Epoch 7/35\n",
      "5148/5148 - 3s - loss: 0.3994 - accuracy: 0.8397 - val_loss: 0.4284 - val_accuracy: 0.7842\n",
      "Epoch 8/35\n",
      "5148/5148 - 2s - loss: 0.3954 - accuracy: 0.8463 - val_loss: 0.4234 - val_accuracy: 0.7842\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4041 - accuracy: 0.8353 - val_loss: 0.4156 - val_accuracy: 0.8509\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4104 - accuracy: 0.8351 - val_loss: 0.4365 - val_accuracy: 0.7593\n",
      "Epoch 11/35\n",
      "5148/5148 - 2s - loss: 0.4146 - accuracy: 0.8273 - val_loss: 0.4308 - val_accuracy: 0.8540\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.3832 - accuracy: 0.8491 - val_loss: 0.4703 - val_accuracy: 0.8602\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.3770 - accuracy: 0.8533 - val_loss: 0.3949 - val_accuracy: 0.8571\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3773 - accuracy: 0.8545 - val_loss: 0.4426 - val_accuracy: 0.8602\n",
      "Epoch 15/35\n",
      "5148/5148 - 2s - loss: 0.3825 - accuracy: 0.8438 - val_loss: 0.3955 - val_accuracy: 0.8137\n",
      "Epoch 16/35\n",
      "5148/5148 - 2s - loss: 0.3823 - accuracy: 0.8446 - val_loss: 0.3856 - val_accuracy: 0.8602\n",
      "Epoch 17/35\n",
      "5148/5148 - 2s - loss: 0.3996 - accuracy: 0.8380 - val_loss: 0.4047 - val_accuracy: 0.8463\n",
      "Epoch 18/35\n",
      "5148/5148 - 2s - loss: 0.4326 - accuracy: 0.8168 - val_loss: 0.4094 - val_accuracy: 0.8478\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3975 - accuracy: 0.8454 - val_loss: 0.4141 - val_accuracy: 0.8447\n",
      "Epoch 20/35\n",
      "5148/5148 - 2s - loss: 0.3930 - accuracy: 0.8403 - val_loss: 0.4215 - val_accuracy: 0.8665\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3703 - accuracy: 0.8535 - val_loss: 0.3574 - val_accuracy: 0.8649\n",
      "Epoch 22/35\n",
      "5148/5148 - 2s - loss: 0.3637 - accuracy: 0.8584 - val_loss: 0.3677 - val_accuracy: 0.8649\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3482 - accuracy: 0.8596 - val_loss: 0.3650 - val_accuracy: 0.8525\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3360 - accuracy: 0.8605 - val_loss: 0.4174 - val_accuracy: 0.8556\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3247 - accuracy: 0.8667 - val_loss: 0.3409 - val_accuracy: 0.8665\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3190 - accuracy: 0.8629 - val_loss: 0.3335 - val_accuracy: 0.8618\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3306 - accuracy: 0.8603 - val_loss: 0.3342 - val_accuracy: 0.8665\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3280 - accuracy: 0.8568 - val_loss: 0.3583 - val_accuracy: 0.8618\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3777 - accuracy: 0.8559 - val_loss: 0.3227 - val_accuracy: 0.8602\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3038 - accuracy: 0.8695 - val_loss: 0.3225 - val_accuracy: 0.8696\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3014 - accuracy: 0.8687 - val_loss: 0.3635 - val_accuracy: 0.8649\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3109 - accuracy: 0.8642 - val_loss: 0.3184 - val_accuracy: 0.8680\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.2958 - accuracy: 0.8695 - val_loss: 0.3125 - val_accuracy: 0.8571\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3033 - accuracy: 0.8656 - val_loss: 0.3108 - val_accuracy: 0.8634\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.2981 - accuracy: 0.8675 - val_loss: 0.3052 - val_accuracy: 0.8727\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 16.7700 - accuracy: 0.5573 - val_loss: 1.3969 - val_accuracy: 0.8152\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 4.3151 - accuracy: 0.6754 - val_loss: 1.7024 - val_accuracy: 0.8478\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 1.3586 - accuracy: 0.7479 - val_loss: 0.5331 - val_accuracy: 0.7873\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4898 - accuracy: 0.8149 - val_loss: 0.4935 - val_accuracy: 0.8587\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.4828 - accuracy: 0.8028 - val_loss: 0.4120 - val_accuracy: 0.7919\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4975 - accuracy: 0.7786 - val_loss: 0.6565 - val_accuracy: 0.5994\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4194 - accuracy: 0.8279 - val_loss: 0.4316 - val_accuracy: 0.7842\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4036 - accuracy: 0.8388 - val_loss: 0.4373 - val_accuracy: 0.7562\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4187 - accuracy: 0.8252 - val_loss: 0.4091 - val_accuracy: 0.8447\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4027 - accuracy: 0.8397 - val_loss: 0.4326 - val_accuracy: 0.7593\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4058 - accuracy: 0.8265 - val_loss: 0.4201 - val_accuracy: 0.8494\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.3833 - accuracy: 0.8512 - val_loss: 0.4424 - val_accuracy: 0.8587\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.3771 - accuracy: 0.8475 - val_loss: 0.3833 - val_accuracy: 0.8540\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3492 - accuracy: 0.8710 - val_loss: 0.3927 - val_accuracy: 0.8587\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3466 - accuracy: 0.8683 - val_loss: 0.3845 - val_accuracy: 0.8463\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3411 - accuracy: 0.8660 - val_loss: 0.3689 - val_accuracy: 0.8618\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3397 - accuracy: 0.8702 - val_loss: 0.3595 - val_accuracy: 0.8618\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3375 - accuracy: 0.8681 - val_loss: 0.3542 - val_accuracy: 0.8665\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3363 - accuracy: 0.8631 - val_loss: 0.3512 - val_accuracy: 0.8649\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3380 - accuracy: 0.8646 - val_loss: 0.3523 - val_accuracy: 0.8711\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3186 - accuracy: 0.8745 - val_loss: 0.3436 - val_accuracy: 0.8696\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3290 - accuracy: 0.8700 - val_loss: 0.3410 - val_accuracy: 0.8696\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3202 - accuracy: 0.8702 - val_loss: 0.3419 - val_accuracy: 0.8401\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3202 - accuracy: 0.8685 - val_loss: 0.3455 - val_accuracy: 0.8649\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3130 - accuracy: 0.8718 - val_loss: 0.3551 - val_accuracy: 0.8602\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3262 - accuracy: 0.8650 - val_loss: 0.3534 - val_accuracy: 0.8261\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3134 - accuracy: 0.8704 - val_loss: 0.3799 - val_accuracy: 0.8261\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3187 - accuracy: 0.8601 - val_loss: 0.3879 - val_accuracy: 0.8587\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3180 - accuracy: 0.8619 - val_loss: 0.3297 - val_accuracy: 0.8634\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.2954 - accuracy: 0.8757 - val_loss: 0.3224 - val_accuracy: 0.8649\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.2975 - accuracy: 0.8768 - val_loss: 0.3221 - val_accuracy: 0.8696\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.2959 - accuracy: 0.8765 - val_loss: 0.3363 - val_accuracy: 0.8447\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.2915 - accuracy: 0.8784 - val_loss: 0.3250 - val_accuracy: 0.8618\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.2946 - accuracy: 0.8782 - val_loss: 0.3273 - val_accuracy: 0.8680\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.2932 - accuracy: 0.8772 - val_loss: 0.3139 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 14.2190 - accuracy: 0.5608 - val_loss: 1.1598 - val_accuracy: 0.8401\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 3.0517 - accuracy: 0.6791 - val_loss: 2.0486 - val_accuracy: 0.5559\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.9149 - accuracy: 0.7568 - val_loss: 0.4786 - val_accuracy: 0.7748\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.5114 - accuracy: 0.7850 - val_loss: 0.4465 - val_accuracy: 0.8525\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5109 - accuracy: 0.7875 - val_loss: 0.4001 - val_accuracy: 0.8447\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4726 - accuracy: 0.7999 - val_loss: 0.5224 - val_accuracy: 0.8618\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4440 - accuracy: 0.8141 - val_loss: 0.6151 - val_accuracy: 0.7050\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4105 - accuracy: 0.8337 - val_loss: 0.4621 - val_accuracy: 0.7484\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4218 - accuracy: 0.8219 - val_loss: 0.4053 - val_accuracy: 0.8525\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4177 - accuracy: 0.8242 - val_loss: 0.4462 - val_accuracy: 0.7578\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3986 - accuracy: 0.8308 - val_loss: 0.3948 - val_accuracy: 0.8587\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.3819 - accuracy: 0.8500 - val_loss: 0.4337 - val_accuracy: 0.8649\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.3701 - accuracy: 0.8576 - val_loss: 0.3818 - val_accuracy: 0.8571\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3883 - accuracy: 0.8465 - val_loss: 0.3848 - val_accuracy: 0.8618\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4057 - accuracy: 0.8320 - val_loss: 0.4414 - val_accuracy: 0.7516\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3741 - accuracy: 0.8483 - val_loss: 0.3704 - val_accuracy: 0.8571\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3668 - accuracy: 0.8586 - val_loss: 0.4452 - val_accuracy: 0.7904\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3663 - accuracy: 0.8578 - val_loss: 0.3592 - val_accuracy: 0.8711\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.4486 - accuracy: 0.8139 - val_loss: 0.5140 - val_accuracy: 0.8261\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.4836 - accuracy: 0.7741 - val_loss: 0.3544 - val_accuracy: 0.8587\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3665 - accuracy: 0.8603 - val_loss: 0.5206 - val_accuracy: 0.8509\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3777 - accuracy: 0.8553 - val_loss: 0.3492 - val_accuracy: 0.8618\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3530 - accuracy: 0.8627 - val_loss: 0.3488 - val_accuracy: 0.8649\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3481 - accuracy: 0.8629 - val_loss: 0.3944 - val_accuracy: 0.8494\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3366 - accuracy: 0.8683 - val_loss: 0.3532 - val_accuracy: 0.8587\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3463 - accuracy: 0.8627 - val_loss: 0.3836 - val_accuracy: 0.8571\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3381 - accuracy: 0.8599 - val_loss: 0.3311 - val_accuracy: 0.8711\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3222 - accuracy: 0.8652 - val_loss: 0.3296 - val_accuracy: 0.8665\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3162 - accuracy: 0.8706 - val_loss: 0.3463 - val_accuracy: 0.8634\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3123 - accuracy: 0.8716 - val_loss: 0.3292 - val_accuracy: 0.8696\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3095 - accuracy: 0.8735 - val_loss: 0.3304 - val_accuracy: 0.8773\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3066 - accuracy: 0.8710 - val_loss: 0.3333 - val_accuracy: 0.8742\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3032 - accuracy: 0.8700 - val_loss: 0.3433 - val_accuracy: 0.8665\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3072 - accuracy: 0.8671 - val_loss: 0.3263 - val_accuracy: 0.8680\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3025 - accuracy: 0.8689 - val_loss: 0.3183 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 17.7881 - accuracy: 0.5311 - val_loss: 2.8080 - val_accuracy: 0.6025\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 3.1114 - accuracy: 0.6603 - val_loss: 0.7519 - val_accuracy: 0.8339\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.8346 - accuracy: 0.7286 - val_loss: 0.5219 - val_accuracy: 0.7438\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4963 - accuracy: 0.7993 - val_loss: 0.4347 - val_accuracy: 0.8385\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5353 - accuracy: 0.7683 - val_loss: 0.4769 - val_accuracy: 0.8478\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4862 - accuracy: 0.7863 - val_loss: 0.5996 - val_accuracy: 0.8137\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4643 - accuracy: 0.8011 - val_loss: 0.6343 - val_accuracy: 0.6894\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4311 - accuracy: 0.8250 - val_loss: 0.4762 - val_accuracy: 0.7376\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4393 - accuracy: 0.8056 - val_loss: 0.4217 - val_accuracy: 0.8478\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.4458 - accuracy: 0.8077 - val_loss: 0.4519 - val_accuracy: 0.7655\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.4203 - accuracy: 0.8184 - val_loss: 0.4444 - val_accuracy: 0.8416\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.4050 - accuracy: 0.8364 - val_loss: 0.4356 - val_accuracy: 0.8587\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.4123 - accuracy: 0.8335 - val_loss: 0.4172 - val_accuracy: 0.7966\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.4133 - accuracy: 0.8287 - val_loss: 0.4327 - val_accuracy: 0.8618\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.4116 - accuracy: 0.8335 - val_loss: 0.4531 - val_accuracy: 0.7593\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3900 - accuracy: 0.8403 - val_loss: 0.3954 - val_accuracy: 0.8571\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.4050 - accuracy: 0.8357 - val_loss: 0.3859 - val_accuracy: 0.8463\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3831 - accuracy: 0.8407 - val_loss: 0.3866 - val_accuracy: 0.8540\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3789 - accuracy: 0.8401 - val_loss: 0.4240 - val_accuracy: 0.8447\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3892 - accuracy: 0.8454 - val_loss: 0.3883 - val_accuracy: 0.8587\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3613 - accuracy: 0.8568 - val_loss: 0.3818 - val_accuracy: 0.8634\n",
      "Epoch 22/35\n",
      "5148/5148 - 3s - loss: 0.3778 - accuracy: 0.8411 - val_loss: 0.3716 - val_accuracy: 0.8634\n",
      "Epoch 23/35\n",
      "5148/5148 - 2s - loss: 0.3827 - accuracy: 0.8382 - val_loss: 0.3712 - val_accuracy: 0.8696\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3954 - accuracy: 0.8347 - val_loss: 0.3904 - val_accuracy: 0.8354\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3653 - accuracy: 0.8475 - val_loss: 0.4014 - val_accuracy: 0.8354\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3751 - accuracy: 0.8407 - val_loss: 0.4167 - val_accuracy: 0.8618\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3640 - accuracy: 0.8462 - val_loss: 0.4046 - val_accuracy: 0.7686\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3554 - accuracy: 0.8479 - val_loss: 0.4449 - val_accuracy: 0.7609\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3687 - accuracy: 0.8483 - val_loss: 0.3813 - val_accuracy: 0.8261\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3511 - accuracy: 0.8547 - val_loss: 0.3794 - val_accuracy: 0.8587\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3505 - accuracy: 0.8541 - val_loss: 0.4013 - val_accuracy: 0.7671\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3747 - accuracy: 0.8429 - val_loss: 0.3812 - val_accuracy: 0.8307\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3454 - accuracy: 0.8533 - val_loss: 0.3752 - val_accuracy: 0.8292\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3385 - accuracy: 0.8520 - val_loss: 0.3562 - val_accuracy: 0.8649\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3399 - accuracy: 0.8574 - val_loss: 0.3714 - val_accuracy: 0.8634\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 10.6489 - accuracy: 0.5600 - val_loss: 1.2839 - val_accuracy: 0.7407\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.5966 - accuracy: 0.7047 - val_loss: 0.6536 - val_accuracy: 0.8540\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 0.5857 - accuracy: 0.7595 - val_loss: 0.4928 - val_accuracy: 0.7469\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 0.4727 - accuracy: 0.7982 - val_loss: 0.4343 - val_accuracy: 0.8354\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 0.5569 - accuracy: 0.7558 - val_loss: 0.4193 - val_accuracy: 0.8385\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.4673 - accuracy: 0.8059 - val_loss: 0.5657 - val_accuracy: 0.8230\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 0.4062 - accuracy: 0.8343 - val_loss: 0.4186 - val_accuracy: 0.8183\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.4052 - accuracy: 0.8397 - val_loss: 0.4294 - val_accuracy: 0.7811\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.4079 - accuracy: 0.8339 - val_loss: 0.3955 - val_accuracy: 0.8463\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 0.3873 - accuracy: 0.8510 - val_loss: 0.4608 - val_accuracy: 0.7469\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 0.3962 - accuracy: 0.8328 - val_loss: 0.5315 - val_accuracy: 0.7189\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.3651 - accuracy: 0.8561 - val_loss: 0.3799 - val_accuracy: 0.8525\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 0.3478 - accuracy: 0.8598 - val_loss: 0.3967 - val_accuracy: 0.8649\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.3413 - accuracy: 0.8730 - val_loss: 0.3650 - val_accuracy: 0.8618\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.3327 - accuracy: 0.8726 - val_loss: 0.3783 - val_accuracy: 0.8602\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.3304 - accuracy: 0.8691 - val_loss: 0.3680 - val_accuracy: 0.8339\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.3279 - accuracy: 0.8700 - val_loss: 0.3693 - val_accuracy: 0.8665\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.3349 - accuracy: 0.8632 - val_loss: 0.3435 - val_accuracy: 0.8587\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.3368 - accuracy: 0.8601 - val_loss: 0.3479 - val_accuracy: 0.8634\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.3300 - accuracy: 0.8722 - val_loss: 0.3542 - val_accuracy: 0.8680\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.3185 - accuracy: 0.8733 - val_loss: 0.3398 - val_accuracy: 0.8711\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.3339 - accuracy: 0.8644 - val_loss: 0.3322 - val_accuracy: 0.8696\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.3128 - accuracy: 0.8687 - val_loss: 0.3401 - val_accuracy: 0.8680\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.3199 - accuracy: 0.8697 - val_loss: 0.3337 - val_accuracy: 0.8587\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.3085 - accuracy: 0.8650 - val_loss: 0.3327 - val_accuracy: 0.8696\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.3213 - accuracy: 0.8669 - val_loss: 0.3187 - val_accuracy: 0.8665\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.3116 - accuracy: 0.8728 - val_loss: 0.3312 - val_accuracy: 0.8727\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.3178 - accuracy: 0.8636 - val_loss: 0.5279 - val_accuracy: 0.7252\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3167 - accuracy: 0.8675 - val_loss: 0.3316 - val_accuracy: 0.8634\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3173 - accuracy: 0.8654 - val_loss: 0.3626 - val_accuracy: 0.8556\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3047 - accuracy: 0.8681 - val_loss: 0.3556 - val_accuracy: 0.8680\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8551 - val_loss: 0.3409 - val_accuracy: 0.8571\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3278 - accuracy: 0.8658 - val_loss: 0.3640 - val_accuracy: 0.8540\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3335 - accuracy: 0.8594 - val_loss: 0.3316 - val_accuracy: 0.8587\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3256 - accuracy: 0.8627 - val_loss: 0.3274 - val_accuracy: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:26:43,170] Trial 65 finished with value: 0.8726708292961121 and parameters: {'units': 100, 'dropout': 0.05, 'learning_rate': 0.005779904942951997, 'epochs': 35, 'batch_size': 25, 'patience': 9, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:26:48,338] Trial 66 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:26:52,487] Trial 67 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:26:56,551] Trial 68 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:27:01,308] Trial 69 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/10\n",
      "5148/5148 - 4s - loss: 32.1872 - accuracy: 0.5107 - val_loss: 0.6094 - val_accuracy: 0.8447\n",
      "Epoch 2/10\n",
      "5148/5148 - 2s - loss: 2.1089 - accuracy: 0.6057 - val_loss: 0.7617 - val_accuracy: 0.4984\n",
      "Epoch 3/10\n",
      "5148/5148 - 2s - loss: 0.6026 - accuracy: 0.7086 - val_loss: 0.5970 - val_accuracy: 0.6848\n",
      "Epoch 4/10\n",
      "5148/5148 - 2s - loss: 0.5434 - accuracy: 0.7348 - val_loss: 0.4905 - val_accuracy: 0.8401\n",
      "Epoch 5/10\n",
      "5148/5148 - 2s - loss: 0.5891 - accuracy: 0.7117 - val_loss: 0.4590 - val_accuracy: 0.8339\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:27:15,420] Trial 70 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 14.0374 - accuracy: 0.5559 - val_loss: 1.0547 - val_accuracy: 0.7360\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 3.2543 - accuracy: 0.6505 - val_loss: 2.6968 - val_accuracy: 0.4953\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:27:20,681] Trial 71 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:27:23,736] Trial 72 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:27:26,012] Trial 73 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 19.4681 - accuracy: 0.5192 - val_loss: 1.1033 - val_accuracy: 0.7671\n",
      "Epoch 2/25\n",
      "5148/5148 - 2s - loss: 8.0314 - accuracy: 0.6064 - val_loss: 1.7780 - val_accuracy: 0.8540\n",
      "Epoch 3/25\n",
      "5148/5148 - 2s - loss: 3.6650 - accuracy: 0.6816 - val_loss: 1.2423 - val_accuracy: 0.7748\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 1.6237 - accuracy: 0.7300 - val_loss: 0.6673 - val_accuracy: 0.8416\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.9322 - accuracy: 0.7418 - val_loss: 0.4396 - val_accuracy: 0.8416\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5586 - accuracy: 0.7850 - val_loss: 0.5370 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4575 - accuracy: 0.8112 - val_loss: 0.5347 - val_accuracy: 0.7252\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4576 - accuracy: 0.8182 - val_loss: 0.3907 - val_accuracy: 0.8478\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4425 - accuracy: 0.8232 - val_loss: 0.4238 - val_accuracy: 0.8649\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4081 - accuracy: 0.8444 - val_loss: 0.6260 - val_accuracy: 0.7034\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3770 - accuracy: 0.8498 - val_loss: 0.7370 - val_accuracy: 0.6739\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4017 - accuracy: 0.8384 - val_loss: 0.4315 - val_accuracy: 0.8602\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3858 - accuracy: 0.8481 - val_loss: 0.4997 - val_accuracy: 0.7547\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3693 - accuracy: 0.8572 - val_loss: 0.4393 - val_accuracy: 0.8602\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3804 - accuracy: 0.8471 - val_loss: 0.3904 - val_accuracy: 0.8199\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3874 - accuracy: 0.8376 - val_loss: 0.3820 - val_accuracy: 0.8665\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3822 - accuracy: 0.8471 - val_loss: 0.4345 - val_accuracy: 0.7609\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3546 - accuracy: 0.8574 - val_loss: 0.3493 - val_accuracy: 0.8571\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3430 - accuracy: 0.8646 - val_loss: 0.3569 - val_accuracy: 0.8276\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3590 - accuracy: 0.8535 - val_loss: 0.3587 - val_accuracy: 0.8602\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3419 - accuracy: 0.8699 - val_loss: 0.3995 - val_accuracy: 0.8680\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8568 - val_loss: 0.3417 - val_accuracy: 0.8556\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3274 - accuracy: 0.8716 - val_loss: 0.3316 - val_accuracy: 0.8634\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3322 - accuracy: 0.8636 - val_loss: 0.4192 - val_accuracy: 0.8649\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3262 - accuracy: 0.8666 - val_loss: 0.4108 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 4s - loss: 20.4583 - accuracy: 0.5352 - val_loss: 0.7561 - val_accuracy: 0.7795\n",
      "Epoch 2/25\n",
      "5148/5148 - 3s - loss: 6.7297 - accuracy: 0.6033 - val_loss: 1.2221 - val_accuracy: 0.8525\n",
      "Epoch 3/25\n",
      "5148/5148 - 3s - loss: 3.0857 - accuracy: 0.6634 - val_loss: 0.8495 - val_accuracy: 0.7453\n",
      "Epoch 4/25\n",
      "5148/5148 - 3s - loss: 1.2097 - accuracy: 0.7183 - val_loss: 0.8742 - val_accuracy: 0.6786\n",
      "Epoch 5/25\n",
      "5148/5148 - 3s - loss: 0.6162 - accuracy: 0.7698 - val_loss: 0.4225 - val_accuracy: 0.8245\n",
      "Epoch 6/25\n",
      "5148/5148 - 2s - loss: 0.4649 - accuracy: 0.8026 - val_loss: 0.6177 - val_accuracy: 0.8075\n",
      "Epoch 7/25\n",
      "5148/5148 - 2s - loss: 0.4220 - accuracy: 0.8296 - val_loss: 0.5523 - val_accuracy: 0.7236\n",
      "Epoch 8/25\n",
      "5148/5148 - 2s - loss: 0.4315 - accuracy: 0.8244 - val_loss: 0.4087 - val_accuracy: 0.8525\n",
      "Epoch 9/25\n",
      "5148/5148 - 2s - loss: 0.4278 - accuracy: 0.8244 - val_loss: 0.4344 - val_accuracy: 0.7857\n",
      "Epoch 10/25\n",
      "5148/5148 - 2s - loss: 0.3978 - accuracy: 0.8436 - val_loss: 0.5605 - val_accuracy: 0.7096\n",
      "Epoch 11/25\n",
      "5148/5148 - 2s - loss: 0.3714 - accuracy: 0.8559 - val_loss: 0.3963 - val_accuracy: 0.8571\n",
      "Epoch 12/25\n",
      "5148/5148 - 2s - loss: 0.3753 - accuracy: 0.8570 - val_loss: 0.3968 - val_accuracy: 0.8540\n",
      "Epoch 13/25\n",
      "5148/5148 - 2s - loss: 0.3695 - accuracy: 0.8588 - val_loss: 0.4436 - val_accuracy: 0.8556\n",
      "Epoch 14/25\n",
      "5148/5148 - 2s - loss: 0.3598 - accuracy: 0.8648 - val_loss: 0.3987 - val_accuracy: 0.8587\n",
      "Epoch 15/25\n",
      "5148/5148 - 2s - loss: 0.3606 - accuracy: 0.8625 - val_loss: 0.4310 - val_accuracy: 0.7562\n",
      "Epoch 16/25\n",
      "5148/5148 - 2s - loss: 0.3650 - accuracy: 0.8631 - val_loss: 0.4533 - val_accuracy: 0.7609\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.3522 - accuracy: 0.8648 - val_loss: 0.3898 - val_accuracy: 0.8634\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3520 - accuracy: 0.8667 - val_loss: 0.3812 - val_accuracy: 0.8509\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3450 - accuracy: 0.8634 - val_loss: 0.3571 - val_accuracy: 0.8571\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3523 - accuracy: 0.8598 - val_loss: 0.3983 - val_accuracy: 0.8230\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3370 - accuracy: 0.8712 - val_loss: 0.3586 - val_accuracy: 0.8618\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3378 - accuracy: 0.8695 - val_loss: 0.3463 - val_accuracy: 0.8571\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3311 - accuracy: 0.8722 - val_loss: 0.3523 - val_accuracy: 0.8494\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3276 - accuracy: 0.8683 - val_loss: 0.3734 - val_accuracy: 0.8634\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3161 - accuracy: 0.8772 - val_loss: 0.3739 - val_accuracy: 0.8649\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 16.9746 - accuracy: 0.5480 - val_loss: 1.2058 - val_accuracy: 0.7345\n",
      "Epoch 2/25\n",
      "5148/5148 - 2s - loss: 6.8505 - accuracy: 0.6136 - val_loss: 2.1485 - val_accuracy: 0.6009\n",
      "Epoch 3/25\n",
      "5148/5148 - 2s - loss: 3.0101 - accuracy: 0.6944 - val_loss: 0.9611 - val_accuracy: 0.8370\n",
      "Epoch 4/25\n",
      "5148/5148 - 3s - loss: 1.2980 - accuracy: 0.7345 - val_loss: 1.3554 - val_accuracy: 0.6335\n",
      "Epoch 5/25\n",
      "5148/5148 - 3s - loss: 0.6453 - accuracy: 0.7770 - val_loss: 0.4136 - val_accuracy: 0.8401\n",
      "Epoch 6/25\n",
      "5148/5148 - 2s - loss: 0.4709 - accuracy: 0.8122 - val_loss: 0.6033 - val_accuracy: 0.7997\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4134 - accuracy: 0.8296 - val_loss: 0.6010 - val_accuracy: 0.7050\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4199 - accuracy: 0.8326 - val_loss: 0.4011 - val_accuracy: 0.8525\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4125 - accuracy: 0.8331 - val_loss: 0.4013 - val_accuracy: 0.8525\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.3727 - accuracy: 0.8564 - val_loss: 0.5316 - val_accuracy: 0.7376\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3850 - accuracy: 0.8423 - val_loss: 0.4611 - val_accuracy: 0.7376\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3791 - accuracy: 0.8516 - val_loss: 0.4621 - val_accuracy: 0.8634\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3777 - accuracy: 0.8508 - val_loss: 0.4196 - val_accuracy: 0.8339\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3873 - accuracy: 0.8504 - val_loss: 0.4233 - val_accuracy: 0.8602\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3906 - accuracy: 0.8444 - val_loss: 0.4086 - val_accuracy: 0.7981\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3735 - accuracy: 0.8547 - val_loss: 0.3748 - val_accuracy: 0.8571\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3656 - accuracy: 0.8588 - val_loss: 0.3674 - val_accuracy: 0.8509\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3515 - accuracy: 0.8644 - val_loss: 0.3694 - val_accuracy: 0.8525\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3540 - accuracy: 0.8609 - val_loss: 0.3685 - val_accuracy: 0.8602\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3659 - accuracy: 0.8568 - val_loss: 0.3757 - val_accuracy: 0.8556\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3525 - accuracy: 0.8687 - val_loss: 0.3710 - val_accuracy: 0.8540\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3521 - accuracy: 0.8712 - val_loss: 0.3745 - val_accuracy: 0.8556\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8728 - val_loss: 0.3626 - val_accuracy: 0.8587\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3419 - accuracy: 0.8706 - val_loss: 0.3679 - val_accuracy: 0.8618\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3372 - accuracy: 0.8747 - val_loss: 0.3900 - val_accuracy: 0.8602\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 21.7438 - accuracy: 0.5258 - val_loss: 1.9171 - val_accuracy: 0.5233\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 8.2182 - accuracy: 0.5960 - val_loss: 1.4984 - val_accuracy: 0.8540\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 3.9471 - accuracy: 0.6566 - val_loss: 2.1818 - val_accuracy: 0.6988\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 1.6358 - accuracy: 0.7415 - val_loss: 0.9065 - val_accuracy: 0.7376\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.8408 - accuracy: 0.7502 - val_loss: 0.4528 - val_accuracy: 0.8432\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4831 - accuracy: 0.8050 - val_loss: 0.6661 - val_accuracy: 0.7407\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4505 - accuracy: 0.8141 - val_loss: 0.5160 - val_accuracy: 0.7189\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4396 - accuracy: 0.8228 - val_loss: 0.4340 - val_accuracy: 0.7888\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4424 - accuracy: 0.8186 - val_loss: 0.4190 - val_accuracy: 0.8571\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4112 - accuracy: 0.8390 - val_loss: 0.5249 - val_accuracy: 0.7314\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3921 - accuracy: 0.8380 - val_loss: 0.6610 - val_accuracy: 0.6972\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3923 - accuracy: 0.8394 - val_loss: 0.4627 - val_accuracy: 0.8618\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3976 - accuracy: 0.8423 - val_loss: 0.4945 - val_accuracy: 0.7531\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3742 - accuracy: 0.8510 - val_loss: 0.3847 - val_accuracy: 0.8634\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3865 - accuracy: 0.8450 - val_loss: 0.3739 - val_accuracy: 0.8478\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3949 - accuracy: 0.8380 - val_loss: 0.3541 - val_accuracy: 0.8649\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3847 - accuracy: 0.8421 - val_loss: 0.4141 - val_accuracy: 0.8121\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3491 - accuracy: 0.8638 - val_loss: 0.3616 - val_accuracy: 0.8339\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3416 - accuracy: 0.8654 - val_loss: 0.3473 - val_accuracy: 0.8649\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3335 - accuracy: 0.8660 - val_loss: 0.3699 - val_accuracy: 0.8665\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3311 - accuracy: 0.8700 - val_loss: 0.4135 - val_accuracy: 0.8696\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3471 - accuracy: 0.8611 - val_loss: 0.3425 - val_accuracy: 0.8634\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3251 - accuracy: 0.8735 - val_loss: 0.3203 - val_accuracy: 0.8680\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3061 - accuracy: 0.8786 - val_loss: 0.3618 - val_accuracy: 0.8540\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3086 - accuracy: 0.8774 - val_loss: 0.4239 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 18.0404 - accuracy: 0.5239 - val_loss: 1.2176 - val_accuracy: 0.7842\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 7.7974 - accuracy: 0.6109 - val_loss: 1.3989 - val_accuracy: 0.8447\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 3.2733 - accuracy: 0.6752 - val_loss: 0.9450 - val_accuracy: 0.7593\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 1.4210 - accuracy: 0.7267 - val_loss: 0.6459 - val_accuracy: 0.7516\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.6928 - accuracy: 0.7512 - val_loss: 0.4393 - val_accuracy: 0.7904\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.5001 - accuracy: 0.7822 - val_loss: 0.5030 - val_accuracy: 0.8571\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4388 - accuracy: 0.8170 - val_loss: 0.7202 - val_accuracy: 0.6724\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4281 - accuracy: 0.8294 - val_loss: 0.4097 - val_accuracy: 0.8447\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4253 - val_accuracy: 0.8509\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.3902 - accuracy: 0.8442 - val_loss: 0.4262 - val_accuracy: 0.7780\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4026 - accuracy: 0.8339 - val_loss: 0.4196 - val_accuracy: 0.8540\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3925 - accuracy: 0.8438 - val_loss: 0.5970 - val_accuracy: 0.7811\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.3861 - accuracy: 0.8425 - val_loss: 0.3913 - val_accuracy: 0.8478\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.3840 - accuracy: 0.8467 - val_loss: 0.5358 - val_accuracy: 0.8634\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3905 - accuracy: 0.8386 - val_loss: 0.4335 - val_accuracy: 0.7547\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3826 - accuracy: 0.8462 - val_loss: 0.3827 - val_accuracy: 0.8634\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3755 - accuracy: 0.8522 - val_loss: 0.3876 - val_accuracy: 0.8556\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3595 - accuracy: 0.8530 - val_loss: 0.3713 - val_accuracy: 0.8587\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3667 - accuracy: 0.8504 - val_loss: 0.3955 - val_accuracy: 0.8075\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3597 - accuracy: 0.8518 - val_loss: 0.3597 - val_accuracy: 0.8556\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3473 - accuracy: 0.8619 - val_loss: 0.3688 - val_accuracy: 0.8680\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3549 - accuracy: 0.8607 - val_loss: 0.3658 - val_accuracy: 0.8602\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3382 - accuracy: 0.8650 - val_loss: 0.3500 - val_accuracy: 0.8680\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3459 - accuracy: 0.8495 - val_loss: 0.4029 - val_accuracy: 0.8618\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3197 - accuracy: 0.8693 - val_loss: 0.3617 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:29:55,313] Trial 74 finished with value: 0.8667701482772827 and parameters: {'units': 95, 'dropout': 0.05, 'learning_rate': 0.003461213747425227, 'epochs': 25, 'batch_size': 30, 'patience': 8, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:29:58,566] Trial 75 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:03,319] Trial 76 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:06,288] Trial 77 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:08,717] Trial 78 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:13,266] Trial 79 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:16,850] Trial 80 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:20,421] Trial 81 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:24,606] Trial 82 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:27,961] Trial 83 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:33,053] Trial 84 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 4s - loss: 15.8417 - accuracy: 0.5412 - val_loss: 0.8060 - val_accuracy: 0.7795\n",
      "Epoch 2/35\n",
      "5148/5148 - 2s - loss: 1.4582 - accuracy: 0.6630 - val_loss: 0.8364 - val_accuracy: 0.5311\n",
      "Epoch 3/35\n",
      "5148/5148 - 2s - loss: 0.5115 - accuracy: 0.7725 - val_loss: 0.4699 - val_accuracy: 0.7578\n",
      "Epoch 4/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:41,735] Trial 85 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:45,416] Trial 86 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:30:48,388] Trial 87 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:31:00,322] Trial 88 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/15\n",
      "5148/5148 - 7s - loss: 14.2812 - accuracy: 0.5715 - val_loss: 0.8912 - val_accuracy: 0.7484\n",
      "Epoch 2/15\n",
      "5148/5148 - 6s - loss: 0.8263 - accuracy: 0.7331 - val_loss: 0.4538 - val_accuracy: 0.7764\n",
      "Epoch 3/15\n",
      "5148/5148 - 5s - loss: 0.5048 - accuracy: 0.7793 - val_loss: 0.4375 - val_accuracy: 0.8168\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:31:22,360] Trial 89 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 4s - loss: 25.0074 - accuracy: 0.5429 - val_loss: 0.5008 - val_accuracy: 0.7748\n",
      "Epoch 2/40\n",
      "5148/5148 - 3s - loss: 0.7894 - accuracy: 0.6406 - val_loss: 0.5917 - val_accuracy: 0.5699\n",
      "Epoch 3/40\n",
      "5148/5148 - 2s - loss: 0.7123 - accuracy: 0.6261 - val_loss: 0.8092 - val_accuracy: 0.5202\n",
      "Epoch 4/40\n",
      "5148/5148 - 2s - loss: 0.6344 - accuracy: 0.6597 - val_loss: 0.5336 - val_accuracy: 0.8447\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.5956 - accuracy: 0.6896 - val_loss: 0.5005 - val_accuracy: 0.8401\n",
      "Epoch 6/40\n",
      "5148/5148 - 1s - loss: 0.5479 - accuracy: 0.7255 - val_loss: 0.5319 - val_accuracy: 0.8571\n",
      "Epoch 7/40\n",
      "5148/5148 - 1s - loss: 0.5331 - accuracy: 0.7282 - val_loss: 0.6307 - val_accuracy: 0.6708\n",
      "Epoch 8/40\n",
      "5148/5148 - 1s - loss: 0.5701 - accuracy: 0.7117 - val_loss: 0.5505 - val_accuracy: 0.7469\n",
      "Epoch 9/40\n",
      "5148/5148 - 1s - loss: 0.5600 - accuracy: 0.7213 - val_loss: 0.5432 - val_accuracy: 0.7888\n",
      "Epoch 10/40\n",
      "5148/5148 - 1s - loss: 0.5677 - accuracy: 0.7209 - val_loss: 0.6062 - val_accuracy: 0.6879\n",
      "Epoch 11/40\n",
      "5148/5148 - 1s - loss: 0.5658 - accuracy: 0.7176 - val_loss: 0.4796 - val_accuracy: 0.8525\n",
      "Epoch 12/40\n",
      "5148/5148 - 1s - loss: 0.5537 - accuracy: 0.7302 - val_loss: 0.4741 - val_accuracy: 0.8634\n",
      "Epoch 13/40\n",
      "5148/5148 - 1s - loss: 0.5628 - accuracy: 0.7179 - val_loss: 0.4655 - val_accuracy: 0.8571\n",
      "Epoch 14/40\n",
      "5148/5148 - 1s - loss: 0.5551 - accuracy: 0.7277 - val_loss: 0.5133 - val_accuracy: 0.8121\n",
      "Epoch 15/40\n",
      "5148/5148 - 1s - loss: 0.5491 - accuracy: 0.7339 - val_loss: 0.4523 - val_accuracy: 0.8680\n",
      "Epoch 16/40\n",
      "5148/5148 - 1s - loss: 0.5389 - accuracy: 0.7424 - val_loss: 0.4879 - val_accuracy: 0.7733\n",
      "Epoch 17/40\n",
      "5148/5148 - 1s - loss: 0.5638 - accuracy: 0.7082 - val_loss: 0.5367 - val_accuracy: 0.7484\n",
      "Epoch 18/40\n",
      "5148/5148 - 1s - loss: 0.5322 - accuracy: 0.7473 - val_loss: 0.4638 - val_accuracy: 0.8649\n",
      "Epoch 19/40\n",
      "5148/5148 - 1s - loss: 0.5588 - accuracy: 0.7123 - val_loss: 0.4778 - val_accuracy: 0.8137\n",
      "Epoch 20/40\n",
      "5148/5148 - 1s - loss: 0.5487 - accuracy: 0.7335 - val_loss: 0.4592 - val_accuracy: 0.8323\n",
      "Epoch 21/40\n",
      "5148/5148 - 1s - loss: 0.5526 - accuracy: 0.7269 - val_loss: 0.4468 - val_accuracy: 0.8649\n",
      "Epoch 22/40\n",
      "5148/5148 - 1s - loss: 0.5455 - accuracy: 0.7333 - val_loss: 0.4407 - val_accuracy: 0.8602\n",
      "Epoch 23/40\n",
      "5148/5148 - 1s - loss: 0.5319 - accuracy: 0.7407 - val_loss: 0.4514 - val_accuracy: 0.8323\n",
      "Epoch 24/40\n",
      "5148/5148 - 1s - loss: 0.5241 - accuracy: 0.7469 - val_loss: 0.5112 - val_accuracy: 0.7609\n",
      "Epoch 25/40\n",
      "5148/5148 - 1s - loss: 0.5351 - accuracy: 0.7374 - val_loss: 0.4988 - val_accuracy: 0.7671\n",
      "Epoch 26/40\n",
      "5148/5148 - 1s - loss: 0.5325 - accuracy: 0.7401 - val_loss: 0.4694 - val_accuracy: 0.8276\n",
      "Epoch 27/40\n",
      "5148/5148 - 1s - loss: 0.5338 - accuracy: 0.7348 - val_loss: 0.4659 - val_accuracy: 0.8339\n",
      "Epoch 28/40\n",
      "5148/5148 - 1s - loss: 0.5324 - accuracy: 0.7376 - val_loss: 0.4304 - val_accuracy: 0.8680\n",
      "Epoch 29/40\n",
      "5148/5148 - 1s - loss: 0.5328 - accuracy: 0.7356 - val_loss: 0.4337 - val_accuracy: 0.8649\n",
      "Epoch 30/40\n",
      "5148/5148 - 1s - loss: 0.5171 - accuracy: 0.7510 - val_loss: 0.4555 - val_accuracy: 0.8354\n",
      "Epoch 31/40\n",
      "5148/5148 - 1s - loss: 0.5256 - accuracy: 0.7407 - val_loss: 0.4400 - val_accuracy: 0.8339\n",
      "Epoch 32/40\n",
      "5148/5148 - 1s - loss: 0.5202 - accuracy: 0.7436 - val_loss: 0.4539 - val_accuracy: 0.8354\n",
      "Epoch 33/40\n",
      "5148/5148 - 1s - loss: 0.5145 - accuracy: 0.7523 - val_loss: 0.4252 - val_accuracy: 0.8618\n",
      "Epoch 34/40\n",
      "5148/5148 - 1s - loss: 0.5141 - accuracy: 0.7539 - val_loss: 0.4234 - val_accuracy: 0.8680\n",
      "Epoch 35/40\n",
      "5148/5148 - 1s - loss: 0.5185 - accuracy: 0.7498 - val_loss: 0.4307 - val_accuracy: 0.8323\n",
      "Epoch 36/40\n",
      "5148/5148 - 1s - loss: 0.5206 - accuracy: 0.7457 - val_loss: 0.4376 - val_accuracy: 0.8370\n",
      "Epoch 37/40\n",
      "5148/5148 - 1s - loss: 0.5117 - accuracy: 0.7545 - val_loss: 0.4406 - val_accuracy: 0.8370\n",
      "Epoch 38/40\n",
      "5148/5148 - 1s - loss: 0.5209 - accuracy: 0.7481 - val_loss: 0.4232 - val_accuracy: 0.8649\n",
      "Epoch 39/40\n",
      "5148/5148 - 1s - loss: 0.5226 - accuracy: 0.7449 - val_loss: 0.4299 - val_accuracy: 0.8323\n",
      "Epoch 40/40\n",
      "5148/5148 - 1s - loss: 0.5237 - accuracy: 0.7440 - val_loss: 0.4375 - val_accuracy: 0.8370\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 2s - loss: 16.2168 - accuracy: 0.5474 - val_loss: 0.5673 - val_accuracy: 0.7329\n",
      "Epoch 2/40\n",
      "5148/5148 - 1s - loss: 0.6795 - accuracy: 0.6509 - val_loss: 0.5264 - val_accuracy: 0.8354\n",
      "Epoch 3/40\n",
      "5148/5148 - 1s - loss: 0.6509 - accuracy: 0.6484 - val_loss: 0.5316 - val_accuracy: 0.7531\n",
      "Epoch 4/40\n",
      "5148/5148 - 1s - loss: 0.5737 - accuracy: 0.7005 - val_loss: 0.5501 - val_accuracy: 0.7329\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.6000 - accuracy: 0.6791 - val_loss: 0.6059 - val_accuracy: 0.8354\n",
      "Epoch 6/40\n",
      "5148/5148 - 1s - loss: 0.6059 - accuracy: 0.6748 - val_loss: 0.5532 - val_accuracy: 0.8261\n",
      "Epoch 7/40\n",
      "5148/5148 - 1s - loss: 0.5961 - accuracy: 0.6875 - val_loss: 0.6223 - val_accuracy: 0.6801\n",
      "Epoch 8/40\n",
      "5148/5148 - 1s - loss: 0.6730 - accuracy: 0.5600 - val_loss: 0.6214 - val_accuracy: 0.7283\n",
      "Epoch 9/40\n",
      "5148/5148 - 1s - loss: 0.5953 - accuracy: 0.6977 - val_loss: 0.5167 - val_accuracy: 0.8370\n",
      "Epoch 10/40\n",
      "5148/5148 - 1s - loss: 0.5833 - accuracy: 0.7127 - val_loss: 0.5174 - val_accuracy: 0.7981\n",
      "Epoch 11/40\n",
      "5148/5148 - 1s - loss: 0.5769 - accuracy: 0.7181 - val_loss: 0.5221 - val_accuracy: 0.7935\n",
      "Epoch 12/40\n",
      "5148/5148 - 1s - loss: 0.5627 - accuracy: 0.7372 - val_loss: 0.4915 - val_accuracy: 0.8432\n",
      "Epoch 13/40\n",
      "5148/5148 - 1s - loss: 0.5538 - accuracy: 0.7304 - val_loss: 0.5572 - val_accuracy: 0.7283\n",
      "Epoch 14/40\n",
      "5148/5148 - 1s - loss: 0.5723 - accuracy: 0.7183 - val_loss: 0.4930 - val_accuracy: 0.8618\n",
      "Epoch 15/40\n",
      "5148/5148 - 1s - loss: 0.5575 - accuracy: 0.7337 - val_loss: 0.5758 - val_accuracy: 0.7096\n",
      "Epoch 16/40\n",
      "5148/5148 - 1s - loss: 0.5574 - accuracy: 0.7298 - val_loss: 0.5394 - val_accuracy: 0.7469\n",
      "Epoch 17/40\n",
      "5148/5148 - 1s - loss: 0.5813 - accuracy: 0.7077 - val_loss: 0.4931 - val_accuracy: 0.8540\n",
      "Epoch 18/40\n",
      "5148/5148 - 1s - loss: 0.5454 - accuracy: 0.7383 - val_loss: 0.6015 - val_accuracy: 0.7950\n",
      "Epoch 19/40\n",
      "5148/5148 - 1s - loss: 0.5628 - accuracy: 0.7189 - val_loss: 0.4929 - val_accuracy: 0.8339\n",
      "Epoch 20/40\n",
      "5148/5148 - 1s - loss: 0.5577 - accuracy: 0.7253 - val_loss: 0.4478 - val_accuracy: 0.8587\n",
      "Epoch 21/40\n",
      "5148/5148 - 1s - loss: 0.5545 - accuracy: 0.7246 - val_loss: 0.4567 - val_accuracy: 0.8649\n",
      "Epoch 22/40\n",
      "5148/5148 - 1s - loss: 0.5552 - accuracy: 0.7247 - val_loss: 0.4495 - val_accuracy: 0.8587\n",
      "Epoch 23/40\n",
      "5148/5148 - 1s - loss: 0.5549 - accuracy: 0.7249 - val_loss: 0.4866 - val_accuracy: 0.8137\n",
      "Epoch 24/40\n",
      "5148/5148 - 1s - loss: 0.5516 - accuracy: 0.7226 - val_loss: 0.4646 - val_accuracy: 0.8618\n",
      "Epoch 25/40\n",
      "5148/5148 - 1s - loss: 0.5385 - accuracy: 0.7405 - val_loss: 0.5892 - val_accuracy: 0.6910\n",
      "Epoch 26/40\n",
      "5148/5148 - 1s - loss: 0.5548 - accuracy: 0.7244 - val_loss: 0.5420 - val_accuracy: 0.7531\n",
      "Epoch 27/40\n",
      "5148/5148 - 1s - loss: 0.5487 - accuracy: 0.7261 - val_loss: 0.5155 - val_accuracy: 0.7593\n",
      "Epoch 28/40\n",
      "5148/5148 - 1s - loss: 0.5423 - accuracy: 0.7331 - val_loss: 0.4766 - val_accuracy: 0.8261\n",
      "Epoch 29/40\n",
      "5148/5148 - 1s - loss: 0.5321 - accuracy: 0.7411 - val_loss: 0.4380 - val_accuracy: 0.8711\n",
      "Epoch 30/40\n",
      "5148/5148 - 1s - loss: 0.5239 - accuracy: 0.7483 - val_loss: 0.4415 - val_accuracy: 0.8339\n",
      "Epoch 31/40\n",
      "5148/5148 - 1s - loss: 0.5337 - accuracy: 0.7415 - val_loss: 0.4853 - val_accuracy: 0.7702\n",
      "Epoch 32/40\n",
      "5148/5148 - 1s - loss: 0.5293 - accuracy: 0.7449 - val_loss: 0.4577 - val_accuracy: 0.8307\n",
      "Epoch 33/40\n",
      "5148/5148 - 1s - loss: 0.5277 - accuracy: 0.7403 - val_loss: 0.4286 - val_accuracy: 0.8680\n",
      "Epoch 34/40\n",
      "5148/5148 - 1s - loss: 0.5213 - accuracy: 0.7479 - val_loss: 0.4254 - val_accuracy: 0.8680\n",
      "Epoch 35/40\n",
      "5148/5148 - 1s - loss: 0.5304 - accuracy: 0.7395 - val_loss: 0.4329 - val_accuracy: 0.8354\n",
      "Epoch 36/40\n",
      "5148/5148 - 1s - loss: 0.5146 - accuracy: 0.7475 - val_loss: 0.4308 - val_accuracy: 0.8354\n",
      "Epoch 37/40\n",
      "5148/5148 - 1s - loss: 0.5307 - accuracy: 0.7345 - val_loss: 0.4548 - val_accuracy: 0.8323\n",
      "Epoch 38/40\n",
      "5148/5148 - 1s - loss: 0.5249 - accuracy: 0.7430 - val_loss: 0.4270 - val_accuracy: 0.8649\n",
      "Epoch 39/40\n",
      "5148/5148 - 1s - loss: 0.5148 - accuracy: 0.7517 - val_loss: 0.4302 - val_accuracy: 0.8354\n",
      "Epoch 40/40\n",
      "5148/5148 - 1s - loss: 0.5264 - accuracy: 0.7411 - val_loss: 0.4522 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 2s - loss: 18.7460 - accuracy: 0.5610 - val_loss: 0.6392 - val_accuracy: 0.5978\n",
      "Epoch 2/40\n",
      "5148/5148 - 1s - loss: 0.6726 - accuracy: 0.6315 - val_loss: 0.7041 - val_accuracy: 0.4922\n",
      "Epoch 3/40\n",
      "5148/5148 - 1s - loss: 0.5704 - accuracy: 0.7119 - val_loss: 0.5079 - val_accuracy: 0.8354\n",
      "Epoch 4/40\n",
      "5148/5148 - 1s - loss: 0.5636 - accuracy: 0.7014 - val_loss: 0.5054 - val_accuracy: 0.7593\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.5791 - accuracy: 0.6717 - val_loss: 0.6916 - val_accuracy: 0.4922\n",
      "Epoch 6/40\n",
      "5148/5148 - 1s - loss: 0.6752 - accuracy: 0.5591 - val_loss: 0.6466 - val_accuracy: 0.7780\n",
      "Epoch 7/40\n",
      "5148/5148 - 1s - loss: 0.6229 - accuracy: 0.6397 - val_loss: 0.6812 - val_accuracy: 0.5124\n",
      "Epoch 8/40\n",
      "5148/5148 - 1s - loss: 0.6189 - accuracy: 0.6309 - val_loss: 0.5823 - val_accuracy: 0.7547\n",
      "Epoch 9/40\n",
      "5148/5148 - 1s - loss: 0.5888 - accuracy: 0.6900 - val_loss: 0.5199 - val_accuracy: 0.7842\n",
      "Epoch 10/40\n",
      "5148/5148 - 1s - loss: 0.5681 - accuracy: 0.7110 - val_loss: 0.4823 - val_accuracy: 0.7686\n",
      "Epoch 11/40\n",
      "5148/5148 - 1s - loss: 0.5373 - accuracy: 0.7312 - val_loss: 0.5182 - val_accuracy: 0.8618\n",
      "Epoch 12/40\n",
      "5148/5148 - 1s - loss: 0.5380 - accuracy: 0.7317 - val_loss: 0.4856 - val_accuracy: 0.8649\n",
      "Epoch 13/40\n",
      "5148/5148 - 1s - loss: 0.5226 - accuracy: 0.7376 - val_loss: 0.4734 - val_accuracy: 0.8649\n",
      "Epoch 14/40\n",
      "5148/5148 - 1s - loss: 0.5250 - accuracy: 0.7294 - val_loss: 0.4497 - val_accuracy: 0.8525\n",
      "Epoch 15/40\n",
      "5148/5148 - 1s - loss: 0.5254 - accuracy: 0.7321 - val_loss: 0.4340 - val_accuracy: 0.8525\n",
      "Epoch 16/40\n",
      "5148/5148 - 1s - loss: 0.5244 - accuracy: 0.7405 - val_loss: 0.4304 - val_accuracy: 0.8587\n",
      "Epoch 17/40\n",
      "5148/5148 - 1s - loss: 0.5166 - accuracy: 0.7440 - val_loss: 0.4261 - val_accuracy: 0.8556\n",
      "Epoch 18/40\n",
      "5148/5148 - 1s - loss: 0.5162 - accuracy: 0.7424 - val_loss: 0.3851 - val_accuracy: 0.8587\n",
      "Epoch 19/40\n",
      "5148/5148 - 1s - loss: 0.4958 - accuracy: 0.7426 - val_loss: 0.4195 - val_accuracy: 0.8540\n",
      "Epoch 20/40\n",
      "5148/5148 - 1s - loss: 0.4774 - accuracy: 0.7494 - val_loss: 0.4191 - val_accuracy: 0.8556\n",
      "Epoch 21/40\n",
      "5148/5148 - 1s - loss: 0.4602 - accuracy: 0.7519 - val_loss: 0.4014 - val_accuracy: 0.8602\n",
      "Epoch 22/40\n",
      "5148/5148 - 1s - loss: 0.4576 - accuracy: 0.7506 - val_loss: 0.3810 - val_accuracy: 0.8540\n",
      "Epoch 23/40\n",
      "5148/5148 - 1s - loss: 0.4603 - accuracy: 0.7502 - val_loss: 0.4147 - val_accuracy: 0.8602\n",
      "Epoch 24/40\n",
      "5148/5148 - 1s - loss: 0.4487 - accuracy: 0.7677 - val_loss: 0.4017 - val_accuracy: 0.8571\n",
      "Epoch 25/40\n",
      "5148/5148 - 1s - loss: 0.4601 - accuracy: 0.7459 - val_loss: 0.4244 - val_accuracy: 0.8587\n",
      "Epoch 26/40\n",
      "5148/5148 - 1s - loss: 0.4617 - accuracy: 0.7475 - val_loss: 0.3978 - val_accuracy: 0.8602\n",
      "Epoch 27/40\n",
      "5148/5148 - 1s - loss: 0.4503 - accuracy: 0.7535 - val_loss: 0.3833 - val_accuracy: 0.8556\n",
      "Epoch 28/40\n",
      "5148/5148 - 1s - loss: 0.4507 - accuracy: 0.7446 - val_loss: 0.3806 - val_accuracy: 0.8571\n",
      "Epoch 29/40\n",
      "5148/5148 - 1s - loss: 0.4492 - accuracy: 0.7506 - val_loss: 0.3842 - val_accuracy: 0.8571\n",
      "Epoch 30/40\n",
      "5148/5148 - 1s - loss: 0.4470 - accuracy: 0.7508 - val_loss: 0.3700 - val_accuracy: 0.8634\n",
      "Epoch 31/40\n",
      "5148/5148 - 1s - loss: 0.4537 - accuracy: 0.7494 - val_loss: 0.3797 - val_accuracy: 0.8602\n",
      "Epoch 32/40\n",
      "5148/5148 - 1s - loss: 0.4476 - accuracy: 0.7494 - val_loss: 0.3730 - val_accuracy: 0.8602\n",
      "Epoch 33/40\n",
      "5148/5148 - 1s - loss: 0.4470 - accuracy: 0.7490 - val_loss: 0.3705 - val_accuracy: 0.8571\n",
      "Epoch 34/40\n",
      "5148/5148 - 1s - loss: 0.4372 - accuracy: 0.7498 - val_loss: 0.3790 - val_accuracy: 0.8602\n",
      "Epoch 35/40\n",
      "5148/5148 - 1s - loss: 0.4353 - accuracy: 0.7490 - val_loss: 0.3705 - val_accuracy: 0.8556\n",
      "Epoch 36/40\n",
      "5148/5148 - 1s - loss: 0.4277 - accuracy: 0.7527 - val_loss: 0.3700 - val_accuracy: 0.8556\n",
      "Epoch 37/40\n",
      "5148/5148 - 1s - loss: 0.4337 - accuracy: 0.7479 - val_loss: 0.3621 - val_accuracy: 0.8556\n",
      "Epoch 38/40\n",
      "5148/5148 - 1s - loss: 0.4230 - accuracy: 0.8026 - val_loss: 0.3868 - val_accuracy: 0.8618\n",
      "Epoch 39/40\n",
      "5148/5148 - 1s - loss: 0.4219 - accuracy: 0.8050 - val_loss: 0.3774 - val_accuracy: 0.8602\n",
      "Epoch 40/40\n",
      "5148/5148 - 1s - loss: 0.4172 - accuracy: 0.8079 - val_loss: 0.3814 - val_accuracy: 0.8525\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 2s - loss: 25.0480 - accuracy: 0.5530 - val_loss: 0.7579 - val_accuracy: 0.5311\n",
      "Epoch 2/40\n",
      "5148/5148 - 1s - loss: 0.7865 - accuracy: 0.5781 - val_loss: 0.7864 - val_accuracy: 0.4922\n",
      "Epoch 3/40\n",
      "5148/5148 - 1s - loss: 0.5887 - accuracy: 0.6923 - val_loss: 0.5000 - val_accuracy: 0.7360\n",
      "Epoch 4/40\n",
      "5148/5148 - 1s - loss: 0.5345 - accuracy: 0.7345 - val_loss: 0.5107 - val_accuracy: 0.8447\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.5548 - accuracy: 0.7160 - val_loss: 0.5551 - val_accuracy: 0.7484\n",
      "Epoch 6/40\n",
      "5148/5148 - 1s - loss: 0.5571 - accuracy: 0.7220 - val_loss: 0.5522 - val_accuracy: 0.8432\n",
      "Epoch 7/40\n",
      "5148/5148 - 1s - loss: 0.5655 - accuracy: 0.7199 - val_loss: 0.6152 - val_accuracy: 0.6910\n",
      "Epoch 8/40\n",
      "5148/5148 - 1s - loss: 0.5589 - accuracy: 0.7426 - val_loss: 0.5767 - val_accuracy: 0.7438\n",
      "Epoch 9/40\n",
      "5148/5148 - 1s - loss: 0.5830 - accuracy: 0.6985 - val_loss: 0.5697 - val_accuracy: 0.7562\n",
      "Epoch 10/40\n",
      "5148/5148 - 1s - loss: 0.5747 - accuracy: 0.7211 - val_loss: 0.5242 - val_accuracy: 0.7671\n",
      "Epoch 11/40\n",
      "5148/5148 - 1s - loss: 0.5726 - accuracy: 0.7098 - val_loss: 0.4896 - val_accuracy: 0.8540\n",
      "Epoch 12/40\n",
      "5148/5148 - 1s - loss: 0.5330 - accuracy: 0.7702 - val_loss: 0.4627 - val_accuracy: 0.8478\n",
      "Epoch 13/40\n",
      "5148/5148 - 1s - loss: 0.5272 - accuracy: 0.7685 - val_loss: 0.5806 - val_accuracy: 0.6925\n",
      "Epoch 14/40\n",
      "5148/5148 - 1s - loss: 0.5729 - accuracy: 0.7077 - val_loss: 0.4841 - val_accuracy: 0.8602\n",
      "Epoch 15/40\n",
      "5148/5148 - 1s - loss: 0.5346 - accuracy: 0.7582 - val_loss: 0.4538 - val_accuracy: 0.7981\n",
      "Epoch 16/40\n",
      "5148/5148 - 1s - loss: 0.5351 - accuracy: 0.7554 - val_loss: 0.6217 - val_accuracy: 0.6693\n",
      "Epoch 17/40\n",
      "5148/5148 - 1s - loss: 0.5711 - accuracy: 0.7125 - val_loss: 0.4951 - val_accuracy: 0.7981\n",
      "Epoch 18/40\n",
      "5148/5148 - 1s - loss: 0.5009 - accuracy: 0.7986 - val_loss: 0.4384 - val_accuracy: 0.8556\n",
      "Epoch 19/40\n",
      "5148/5148 - 1s - loss: 0.4988 - accuracy: 0.7828 - val_loss: 0.4275 - val_accuracy: 0.8587\n",
      "Epoch 20/40\n",
      "5148/5148 - 1s - loss: 0.5115 - accuracy: 0.7729 - val_loss: 0.4476 - val_accuracy: 0.8525\n",
      "Epoch 21/40\n",
      "5148/5148 - 1s - loss: 0.4887 - accuracy: 0.7908 - val_loss: 0.4325 - val_accuracy: 0.8649\n",
      "Epoch 22/40\n",
      "5148/5148 - 1s - loss: 0.4989 - accuracy: 0.7869 - val_loss: 0.4219 - val_accuracy: 0.8540\n",
      "Epoch 23/40\n",
      "5148/5148 - 1s - loss: 0.4724 - accuracy: 0.8036 - val_loss: 0.4120 - val_accuracy: 0.8634\n",
      "Epoch 24/40\n",
      "5148/5148 - 1s - loss: 0.5186 - accuracy: 0.7582 - val_loss: 0.5217 - val_accuracy: 0.7484\n",
      "Epoch 25/40\n",
      "5148/5148 - 1s - loss: 0.5496 - accuracy: 0.7240 - val_loss: 0.4707 - val_accuracy: 0.8261\n",
      "Epoch 26/40\n",
      "5148/5148 - 1s - loss: 0.5331 - accuracy: 0.7479 - val_loss: 0.4633 - val_accuracy: 0.8571\n",
      "Epoch 27/40\n",
      "5148/5148 - 1s - loss: 0.5597 - accuracy: 0.7121 - val_loss: 0.4498 - val_accuracy: 0.8649\n",
      "Epoch 28/40\n",
      "5148/5148 - 1s - loss: 0.4878 - accuracy: 0.7912 - val_loss: 0.4572 - val_accuracy: 0.7671\n",
      "Epoch 29/40\n",
      "5148/5148 - 1s - loss: 0.4628 - accuracy: 0.8096 - val_loss: 0.4157 - val_accuracy: 0.8416\n",
      "Epoch 30/40\n",
      "5148/5148 - 1s - loss: 0.4571 - accuracy: 0.8110 - val_loss: 0.4193 - val_accuracy: 0.8587\n",
      "Epoch 31/40\n",
      "5148/5148 - 1s - loss: 0.4570 - accuracy: 0.8112 - val_loss: 0.4111 - val_accuracy: 0.8401\n",
      "Epoch 32/40\n",
      "5148/5148 - 1s - loss: 0.4594 - accuracy: 0.8042 - val_loss: 0.4163 - val_accuracy: 0.8230\n",
      "Epoch 33/40\n",
      "5148/5148 - 1s - loss: 0.4404 - accuracy: 0.8190 - val_loss: 0.4010 - val_accuracy: 0.8587\n",
      "Epoch 34/40\n",
      "5148/5148 - 1s - loss: 0.4440 - accuracy: 0.8098 - val_loss: 0.4025 - val_accuracy: 0.8571\n",
      "Epoch 35/40\n",
      "5148/5148 - 1s - loss: 0.4433 - accuracy: 0.8162 - val_loss: 0.3923 - val_accuracy: 0.8618\n",
      "Epoch 36/40\n",
      "5148/5148 - 1s - loss: 0.4311 - accuracy: 0.8254 - val_loss: 0.4005 - val_accuracy: 0.8354\n",
      "Epoch 37/40\n",
      "5148/5148 - 1s - loss: 0.4384 - accuracy: 0.8170 - val_loss: 0.3932 - val_accuracy: 0.8339\n",
      "Epoch 38/40\n",
      "5148/5148 - 1s - loss: 0.4343 - accuracy: 0.8193 - val_loss: 0.3885 - val_accuracy: 0.8463\n",
      "Epoch 39/40\n",
      "5148/5148 - 1s - loss: 0.4400 - accuracy: 0.8143 - val_loss: 0.3877 - val_accuracy: 0.8525\n",
      "Epoch 40/40\n",
      "5148/5148 - 1s - loss: 0.4379 - accuracy: 0.8133 - val_loss: 0.4182 - val_accuracy: 0.8245\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 3s - loss: 14.6986 - accuracy: 0.5571 - val_loss: 0.5272 - val_accuracy: 0.8307\n",
      "Epoch 2/40\n",
      "5148/5148 - 1s - loss: 0.6540 - accuracy: 0.6601 - val_loss: 0.7074 - val_accuracy: 0.4922\n",
      "Epoch 3/40\n",
      "5148/5148 - 1s - loss: 0.6221 - accuracy: 0.6587 - val_loss: 0.5106 - val_accuracy: 0.7702\n",
      "Epoch 4/40\n",
      "5148/5148 - 1s - loss: 0.5497 - accuracy: 0.7269 - val_loss: 0.4978 - val_accuracy: 0.8401\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.5802 - accuracy: 0.6979 - val_loss: 0.5288 - val_accuracy: 0.7360\n",
      "Epoch 6/40\n",
      "5148/5148 - 1s - loss: 0.6206 - accuracy: 0.6476 - val_loss: 0.6346 - val_accuracy: 0.8494\n",
      "Epoch 7/40\n",
      "5148/5148 - 1s - loss: 0.6409 - accuracy: 0.6138 - val_loss: 0.6500 - val_accuracy: 0.5854\n",
      "Epoch 8/40\n",
      "5148/5148 - 1s - loss: 0.6087 - accuracy: 0.6684 - val_loss: 0.6891 - val_accuracy: 0.5295\n",
      "Epoch 9/40\n",
      "5148/5148 - 1s - loss: 0.6379 - accuracy: 0.6206 - val_loss: 0.6958 - val_accuracy: 0.5124\n",
      "Epoch 10/40\n",
      "5148/5148 - 1s - loss: 0.6637 - accuracy: 0.5627 - val_loss: 0.6028 - val_accuracy: 0.7453\n",
      "Epoch 11/40\n",
      "5148/5148 - 1s - loss: 0.6712 - accuracy: 0.5540 - val_loss: 0.6896 - val_accuracy: 0.5140\n",
      "Epoch 12/40\n",
      "5148/5148 - 1s - loss: 0.6235 - accuracy: 0.6459 - val_loss: 0.6115 - val_accuracy: 0.6894\n",
      "Epoch 13/40\n",
      "5148/5148 - 1s - loss: 0.5883 - accuracy: 0.6983 - val_loss: 0.5581 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "5148/5148 - 1s - loss: 0.5625 - accuracy: 0.7317 - val_loss: 0.5040 - val_accuracy: 0.8509\n",
      "Epoch 15/40\n",
      "5148/5148 - 2s - loss: 0.5490 - accuracy: 0.7467 - val_loss: 0.4902 - val_accuracy: 0.8121\n",
      "Epoch 16/40\n",
      "5148/5148 - 2s - loss: 0.5216 - accuracy: 0.7789 - val_loss: 0.4841 - val_accuracy: 0.8509\n",
      "Epoch 17/40\n",
      "5148/5148 - 1s - loss: 0.5035 - accuracy: 0.7933 - val_loss: 0.4773 - val_accuracy: 0.7888\n",
      "Epoch 18/40\n",
      "5148/5148 - 1s - loss: 0.4972 - accuracy: 0.7997 - val_loss: 0.4519 - val_accuracy: 0.8463\n",
      "Epoch 19/40\n",
      "5148/5148 - 1s - loss: 0.4988 - accuracy: 0.7871 - val_loss: 0.4857 - val_accuracy: 0.7780\n",
      "Epoch 20/40\n",
      "5148/5148 - 1s - loss: 0.4954 - accuracy: 0.7933 - val_loss: 0.4663 - val_accuracy: 0.7950\n",
      "Epoch 21/40\n",
      "5148/5148 - 1s - loss: 0.4854 - accuracy: 0.8019 - val_loss: 0.4392 - val_accuracy: 0.8339\n",
      "Epoch 22/40\n",
      "5148/5148 - 1s - loss: 0.4629 - accuracy: 0.8164 - val_loss: 0.4236 - val_accuracy: 0.8525\n",
      "Epoch 23/40\n",
      "5148/5148 - 1s - loss: 0.4693 - accuracy: 0.8071 - val_loss: 0.4317 - val_accuracy: 0.8478\n",
      "Epoch 24/40\n",
      "5148/5148 - 1s - loss: 0.4588 - accuracy: 0.8122 - val_loss: 0.4438 - val_accuracy: 0.8028\n",
      "Epoch 25/40\n",
      "5148/5148 - 1s - loss: 0.4697 - accuracy: 0.8071 - val_loss: 0.4665 - val_accuracy: 0.7686\n",
      "Epoch 26/40\n",
      "5148/5148 - 1s - loss: 0.4641 - accuracy: 0.8110 - val_loss: 0.4274 - val_accuracy: 0.8463\n",
      "Epoch 27/40\n",
      "5148/5148 - 1s - loss: 0.4559 - accuracy: 0.8174 - val_loss: 0.4248 - val_accuracy: 0.8571\n",
      "Epoch 28/40\n",
      "5148/5148 - 1s - loss: 0.4458 - accuracy: 0.8178 - val_loss: 0.4105 - val_accuracy: 0.8618\n",
      "Epoch 29/40\n",
      "5148/5148 - 1s - loss: 0.4543 - accuracy: 0.8147 - val_loss: 0.4366 - val_accuracy: 0.8106\n",
      "Epoch 30/40\n",
      "5148/5148 - 1s - loss: 0.4572 - accuracy: 0.8061 - val_loss: 0.4103 - val_accuracy: 0.8571\n",
      "Epoch 31/40\n",
      "5148/5148 - 1s - loss: 0.4436 - accuracy: 0.8240 - val_loss: 0.4255 - val_accuracy: 0.8478\n",
      "Epoch 32/40\n",
      "5148/5148 - 1s - loss: 0.4464 - accuracy: 0.8170 - val_loss: 0.4182 - val_accuracy: 0.8525\n",
      "Epoch 33/40\n",
      "5148/5148 - 1s - loss: 0.4309 - accuracy: 0.8260 - val_loss: 0.4095 - val_accuracy: 0.8587\n",
      "Epoch 34/40\n",
      "5148/5148 - 1s - loss: 0.4463 - accuracy: 0.8168 - val_loss: 0.4123 - val_accuracy: 0.8665\n",
      "Epoch 35/40\n",
      "5148/5148 - 1s - loss: 0.4138 - accuracy: 0.8320 - val_loss: 0.3992 - val_accuracy: 0.8634\n",
      "Epoch 36/40\n",
      "5148/5148 - 1s - loss: 0.4277 - accuracy: 0.8248 - val_loss: 0.4083 - val_accuracy: 0.8602\n",
      "Epoch 37/40\n",
      "5148/5148 - 1s - loss: 0.4247 - accuracy: 0.8347 - val_loss: 0.4309 - val_accuracy: 0.7842\n",
      "Epoch 38/40\n",
      "5148/5148 - 1s - loss: 0.4203 - accuracy: 0.8335 - val_loss: 0.4111 - val_accuracy: 0.8665\n",
      "Epoch 39/40\n",
      "5148/5148 - 1s - loss: 0.4247 - accuracy: 0.8240 - val_loss: 0.4064 - val_accuracy: 0.8587\n",
      "Epoch 40/40\n",
      "5148/5148 - 1s - loss: 0.4189 - accuracy: 0.8351 - val_loss: 0.4063 - val_accuracy: 0.8494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:07,789] Trial 90 finished with value: 0.8670806884765625 and parameters: {'units': 85, 'dropout': 0.35000000000000003, 'learning_rate': 0.005786941714941621, 'epochs': 40, 'batch_size': 20, 'patience': 7, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:10,724] Trial 91 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 10.9897 - accuracy: 0.5418 - val_loss: 0.6371 - val_accuracy: 0.8447\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 0.6169 - accuracy: 0.6651 - val_loss: 0.6005 - val_accuracy: 0.5978\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.6617 - accuracy: 0.5509 - val_loss: 0.6924 - val_accuracy: 0.5093\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.6863 - accuracy: 0.5212 - val_loss: 0.6935 - val_accuracy: 0.4953\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.6911 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5078\n",
      "Epoch 6/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:19,178] Trial 92 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:26,667] Trial 93 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:31,479] Trial 94 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:36,705] Trial 95 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:41,620] Trial 96 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:46,153] Trial 97 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:48,860] Trial 98 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 30.7525 - accuracy: 0.5371 - val_loss: 0.8856 - val_accuracy: 0.7981\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.6561 - accuracy: 0.6437 - val_loss: 0.8312 - val_accuracy: 0.5155\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.5854 - accuracy: 0.7209 - val_loss: 0.6856 - val_accuracy: 0.6708\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.5212 - accuracy: 0.7545 - val_loss: 0.4922 - val_accuracy: 0.8509\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.5739 - accuracy: 0.7376 - val_loss: 0.4554 - val_accuracy: 0.7919\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:35:57,893] Trial 99 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 3s - loss: 23.5433 - accuracy: 0.5616 - val_loss: 0.5548 - val_accuracy: 0.7484\n",
      "Epoch 2/40\n",
      "5148/5148 - 2s - loss: 0.7011 - accuracy: 0.5631 - val_loss: 0.6631 - val_accuracy: 0.4922\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:36:04,536] Trial 100 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:36:06,970] Trial 101 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:36:09,731] Trial 102 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 16.1347 - accuracy: 0.5701 - val_loss: 1.6841 - val_accuracy: 0.8354\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 3.1677 - accuracy: 0.6913 - val_loss: 0.7250 - val_accuracy: 0.8370\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.7237 - accuracy: 0.7543 - val_loss: 0.7154 - val_accuracy: 0.6770\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 0.5003 - accuracy: 0.7931 - val_loss: 0.4349 - val_accuracy: 0.8463\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.5491 - accuracy: 0.7549 - val_loss: 0.4348 - val_accuracy: 0.7904\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 0.4714 - accuracy: 0.8009 - val_loss: 0.5535 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.4106 - accuracy: 0.8374 - val_loss: 0.5030 - val_accuracy: 0.7391\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4297 - accuracy: 0.8170 - val_loss: 0.4120 - val_accuracy: 0.8556\n",
      "Epoch 9/30\n",
      "5148/5148 - 2s - loss: 0.4191 - accuracy: 0.8267 - val_loss: 0.4541 - val_accuracy: 0.8602\n",
      "Epoch 10/30\n",
      "5148/5148 - 2s - loss: 0.3969 - accuracy: 0.8442 - val_loss: 0.4929 - val_accuracy: 0.7376\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.4069 - accuracy: 0.8267 - val_loss: 0.5288 - val_accuracy: 0.8618\n",
      "Epoch 12/30\n",
      "5148/5148 - 3s - loss: 0.4351 - accuracy: 0.8186 - val_loss: 0.4468 - val_accuracy: 0.8649\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.4120 - accuracy: 0.8337 - val_loss: 0.5049 - val_accuracy: 0.7329\n",
      "Epoch 14/30\n",
      "5148/5148 - 2s - loss: 0.4038 - accuracy: 0.8394 - val_loss: 0.4294 - val_accuracy: 0.8634\n",
      "Epoch 15/30\n",
      "5148/5148 - 2s - loss: 0.4311 - accuracy: 0.8172 - val_loss: 0.3943 - val_accuracy: 0.8556\n",
      "Epoch 16/30\n",
      "5148/5148 - 2s - loss: 0.4068 - accuracy: 0.8324 - val_loss: 0.4237 - val_accuracy: 0.8602\n",
      "Epoch 17/30\n",
      "5148/5148 - 2s - loss: 0.4082 - accuracy: 0.8296 - val_loss: 0.3876 - val_accuracy: 0.8587\n",
      "Epoch 18/30\n",
      "5148/5148 - 3s - loss: 0.4000 - accuracy: 0.8362 - val_loss: 0.4204 - val_accuracy: 0.8634\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.4237 - accuracy: 0.8203 - val_loss: 0.4239 - val_accuracy: 0.7578\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4257 - accuracy: 0.8226 - val_loss: 0.4584 - val_accuracy: 0.8680\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4209 - accuracy: 0.8261 - val_loss: 0.4975 - val_accuracy: 0.8618\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4063 - accuracy: 0.8357 - val_loss: 0.3868 - val_accuracy: 0.8602\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4187 - accuracy: 0.8225 - val_loss: 0.4230 - val_accuracy: 0.7997\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3880 - accuracy: 0.8355 - val_loss: 0.4445 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3645 - accuracy: 0.8483 - val_loss: 0.3876 - val_accuracy: 0.8261\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3635 - accuracy: 0.8423 - val_loss: 0.3606 - val_accuracy: 0.8602\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3810 - accuracy: 0.8376 - val_loss: 0.3923 - val_accuracy: 0.8168\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3727 - accuracy: 0.8444 - val_loss: 0.4077 - val_accuracy: 0.8292\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3920 - accuracy: 0.8421 - val_loss: 0.4352 - val_accuracy: 0.8634\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3766 - accuracy: 0.8432 - val_loss: 0.4487 - val_accuracy: 0.8649\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 13.2438 - accuracy: 0.5697 - val_loss: 2.0222 - val_accuracy: 0.7360\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 2.1998 - accuracy: 0.6970 - val_loss: 0.5621 - val_accuracy: 0.7888\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.5618 - accuracy: 0.7815 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 0.4538 - accuracy: 0.8067 - val_loss: 0.4429 - val_accuracy: 0.8571\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.4997 - accuracy: 0.7811 - val_loss: 0.4293 - val_accuracy: 0.8478\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 0.4428 - accuracy: 0.8168 - val_loss: 0.4988 - val_accuracy: 0.8618\n",
      "Epoch 7/30\n",
      "5148/5148 - 3s - loss: 0.4016 - accuracy: 0.8362 - val_loss: 0.5932 - val_accuracy: 0.7081\n",
      "Epoch 8/30\n",
      "5148/5148 - 3s - loss: 0.4210 - accuracy: 0.8267 - val_loss: 0.3977 - val_accuracy: 0.8478\n",
      "Epoch 9/30\n",
      "5148/5148 - 3s - loss: 0.4009 - accuracy: 0.8320 - val_loss: 0.3878 - val_accuracy: 0.8509\n",
      "Epoch 10/30\n",
      "5148/5148 - 3s - loss: 0.3870 - accuracy: 0.8467 - val_loss: 0.4587 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "5148/5148 - 3s - loss: 0.3743 - accuracy: 0.8504 - val_loss: 0.4522 - val_accuracy: 0.7655\n",
      "Epoch 12/30\n",
      "5148/5148 - 3s - loss: 0.4070 - accuracy: 0.8302 - val_loss: 0.4037 - val_accuracy: 0.8634\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.4137 - accuracy: 0.8285 - val_loss: 0.3914 - val_accuracy: 0.8463\n",
      "Epoch 14/30\n",
      "5148/5148 - 2s - loss: 0.3974 - accuracy: 0.8432 - val_loss: 0.4184 - val_accuracy: 0.8602\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4073 - accuracy: 0.8298 - val_loss: 0.5442 - val_accuracy: 0.7391\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3965 - accuracy: 0.8450 - val_loss: 0.3704 - val_accuracy: 0.8556\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3739 - accuracy: 0.8566 - val_loss: 0.3990 - val_accuracy: 0.8556\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3693 - accuracy: 0.8568 - val_loss: 0.3774 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3642 - accuracy: 0.8632 - val_loss: 0.3630 - val_accuracy: 0.8602\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3567 - accuracy: 0.8617 - val_loss: 0.3551 - val_accuracy: 0.8602\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3370 - accuracy: 0.8636 - val_loss: 0.3469 - val_accuracy: 0.8587\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3315 - accuracy: 0.8640 - val_loss: 0.3422 - val_accuracy: 0.8571\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3390 - accuracy: 0.8574 - val_loss: 0.3598 - val_accuracy: 0.8665\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3315 - accuracy: 0.8656 - val_loss: 0.3477 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3196 - accuracy: 0.8716 - val_loss: 0.3846 - val_accuracy: 0.8696\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3323 - accuracy: 0.8673 - val_loss: 0.3486 - val_accuracy: 0.8602\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3319 - accuracy: 0.8636 - val_loss: 0.3712 - val_accuracy: 0.8649\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3297 - accuracy: 0.8658 - val_loss: 0.4063 - val_accuracy: 0.8494\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3296 - accuracy: 0.8621 - val_loss: 0.3310 - val_accuracy: 0.8587\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3176 - accuracy: 0.8654 - val_loss: 0.3474 - val_accuracy: 0.8571\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 18.1540 - accuracy: 0.5649 - val_loss: 2.7247 - val_accuracy: 0.7174\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.8882 - accuracy: 0.6968 - val_loss: 1.2538 - val_accuracy: 0.5901\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.7495 - accuracy: 0.7370 - val_loss: 0.5152 - val_accuracy: 0.7438\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4567 - accuracy: 0.7949 - val_loss: 0.4961 - val_accuracy: 0.8571\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.4997 - accuracy: 0.7770 - val_loss: 0.4287 - val_accuracy: 0.8276\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 0.4762 - accuracy: 0.7929 - val_loss: 0.7038 - val_accuracy: 0.6056\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.4318 - accuracy: 0.8230 - val_loss: 0.6229 - val_accuracy: 0.6941\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4457 - accuracy: 0.8122 - val_loss: 0.4275 - val_accuracy: 0.8556\n",
      "Epoch 9/30\n",
      "5148/5148 - 2s - loss: 0.4202 - accuracy: 0.8279 - val_loss: 0.4094 - val_accuracy: 0.8478\n",
      "Epoch 10/30\n",
      "5148/5148 - 2s - loss: 0.3851 - accuracy: 0.8514 - val_loss: 0.4576 - val_accuracy: 0.7624\n",
      "Epoch 11/30\n",
      "5148/5148 - 3s - loss: 0.3936 - accuracy: 0.8353 - val_loss: 0.4624 - val_accuracy: 0.8618\n",
      "Epoch 12/30\n",
      "5148/5148 - 2s - loss: 0.3883 - accuracy: 0.8450 - val_loss: 0.4538 - val_accuracy: 0.8602\n",
      "Epoch 13/30\n",
      "5148/5148 - 3s - loss: 0.4045 - accuracy: 0.8289 - val_loss: 0.5071 - val_accuracy: 0.7391\n",
      "Epoch 14/30\n",
      "5148/5148 - 3s - loss: 0.3858 - accuracy: 0.8497 - val_loss: 0.4158 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 3s - loss: 0.3960 - accuracy: 0.8310 - val_loss: 0.4210 - val_accuracy: 0.7935\n",
      "Epoch 16/30\n",
      "5148/5148 - 2s - loss: 0.3828 - accuracy: 0.8386 - val_loss: 0.3942 - val_accuracy: 0.8727\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4131 - accuracy: 0.8310 - val_loss: 0.3956 - val_accuracy: 0.8634\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4007 - accuracy: 0.8361 - val_loss: 0.4041 - val_accuracy: 0.8587\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3863 - accuracy: 0.8322 - val_loss: 0.3867 - val_accuracy: 0.8276\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4428 - accuracy: 0.8019 - val_loss: 0.4616 - val_accuracy: 0.8323\n",
      "Epoch 21/30\n",
      "5148/5148 - 2s - loss: 0.4061 - accuracy: 0.8329 - val_loss: 0.4055 - val_accuracy: 0.8571\n",
      "Epoch 22/30\n",
      "5148/5148 - 2s - loss: 0.4055 - accuracy: 0.8355 - val_loss: 0.3872 - val_accuracy: 0.8571\n",
      "Epoch 23/30\n",
      "5148/5148 - 2s - loss: 0.3851 - accuracy: 0.8347 - val_loss: 0.3678 - val_accuracy: 0.8525\n",
      "Epoch 24/30\n",
      "5148/5148 - 2s - loss: 0.3787 - accuracy: 0.8329 - val_loss: 0.3965 - val_accuracy: 0.8634\n",
      "Epoch 25/30\n",
      "5148/5148 - 2s - loss: 0.3441 - accuracy: 0.8504 - val_loss: 0.3963 - val_accuracy: 0.8106\n",
      "Epoch 26/30\n",
      "5148/5148 - 2s - loss: 0.3377 - accuracy: 0.8553 - val_loss: 0.3526 - val_accuracy: 0.8370\n",
      "Epoch 27/30\n",
      "5148/5148 - 2s - loss: 0.3343 - accuracy: 0.8481 - val_loss: 0.3418 - val_accuracy: 0.8758\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.3326 - accuracy: 0.8495 - val_loss: 0.3812 - val_accuracy: 0.8602\n",
      "Epoch 29/30\n",
      "5148/5148 - 2s - loss: 0.3347 - accuracy: 0.8483 - val_loss: 0.3470 - val_accuracy: 0.8665\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3254 - accuracy: 0.8489 - val_loss: 0.3323 - val_accuracy: 0.8649\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 15.9713 - accuracy: 0.5606 - val_loss: 1.7292 - val_accuracy: 0.7453\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 3.0129 - accuracy: 0.7044 - val_loss: 0.9663 - val_accuracy: 0.8509\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.8034 - accuracy: 0.7411 - val_loss: 0.4393 - val_accuracy: 0.8401\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4568 - accuracy: 0.8065 - val_loss: 0.5651 - val_accuracy: 0.8090\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4704 - accuracy: 0.7966 - val_loss: 0.4563 - val_accuracy: 0.8571\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4456 - accuracy: 0.8106 - val_loss: 0.5429 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.4149 - accuracy: 0.8347 - val_loss: 0.5077 - val_accuracy: 0.7345\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4182 - accuracy: 0.8260 - val_loss: 0.3973 - val_accuracy: 0.8509\n",
      "Epoch 9/30\n",
      "5148/5148 - 2s - loss: 0.4371 - accuracy: 0.8050 - val_loss: 0.4395 - val_accuracy: 0.8556\n",
      "Epoch 10/30\n",
      "5148/5148 - 2s - loss: 0.3933 - accuracy: 0.8467 - val_loss: 0.5530 - val_accuracy: 0.7050\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.4134 - accuracy: 0.8225 - val_loss: 0.5716 - val_accuracy: 0.6770\n",
      "Epoch 12/30\n",
      "5148/5148 - 2s - loss: 0.4296 - accuracy: 0.8147 - val_loss: 0.4342 - val_accuracy: 0.8634\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.4035 - accuracy: 0.8386 - val_loss: 0.4313 - val_accuracy: 0.7562\n",
      "Epoch 14/30\n",
      "5148/5148 - 3s - loss: 0.3899 - accuracy: 0.8419 - val_loss: 0.4056 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 3s - loss: 0.4401 - accuracy: 0.8106 - val_loss: 0.4040 - val_accuracy: 0.8540\n",
      "Epoch 16/30\n",
      "5148/5148 - 3s - loss: 0.4176 - accuracy: 0.8246 - val_loss: 0.3819 - val_accuracy: 0.8571\n",
      "Epoch 17/30\n",
      "5148/5148 - 3s - loss: 0.3867 - accuracy: 0.8403 - val_loss: 0.3555 - val_accuracy: 0.8618\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.3613 - accuracy: 0.8462 - val_loss: 0.3498 - val_accuracy: 0.8649\n",
      "Epoch 19/30\n",
      "5148/5148 - 3s - loss: 0.3499 - accuracy: 0.8498 - val_loss: 0.3698 - val_accuracy: 0.8727\n",
      "Epoch 20/30\n",
      "5148/5148 - 4s - loss: 0.3516 - accuracy: 0.8512 - val_loss: 0.4645 - val_accuracy: 0.8634\n",
      "Epoch 21/30\n",
      "5148/5148 - 4s - loss: 0.3523 - accuracy: 0.8582 - val_loss: 0.4144 - val_accuracy: 0.8680\n",
      "Epoch 22/30\n",
      "5148/5148 - 3s - loss: 0.3439 - accuracy: 0.8631 - val_loss: 0.3592 - val_accuracy: 0.8634\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3253 - accuracy: 0.8629 - val_loss: 0.3273 - val_accuracy: 0.8680\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3300 - accuracy: 0.8617 - val_loss: 0.3872 - val_accuracy: 0.8540\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3226 - accuracy: 0.8666 - val_loss: 0.3382 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3240 - accuracy: 0.8656 - val_loss: 0.3239 - val_accuracy: 0.8634\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3304 - accuracy: 0.8632 - val_loss: 0.3551 - val_accuracy: 0.8649\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3057 - accuracy: 0.8695 - val_loss: 0.3095 - val_accuracy: 0.8649\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3054 - accuracy: 0.8673 - val_loss: 0.3590 - val_accuracy: 0.8556\n",
      "Epoch 30/30\n",
      "5148/5148 - 2s - loss: 0.3086 - accuracy: 0.8654 - val_loss: 0.3124 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 12.3591 - accuracy: 0.5684 - val_loss: 2.9930 - val_accuracy: 0.6584\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.9394 - accuracy: 0.7131 - val_loss: 0.4836 - val_accuracy: 0.8339\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.5253 - accuracy: 0.7735 - val_loss: 0.4535 - val_accuracy: 0.8307\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4430 - accuracy: 0.8102 - val_loss: 0.6091 - val_accuracy: 0.6630\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4726 - accuracy: 0.7943 - val_loss: 0.4377 - val_accuracy: 0.8556\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4710 - accuracy: 0.7937 - val_loss: 0.5177 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4321 - accuracy: 0.8221 - val_loss: 0.6618 - val_accuracy: 0.6832\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4277 - accuracy: 0.8271 - val_loss: 0.4282 - val_accuracy: 0.8556\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4305 - accuracy: 0.8153 - val_loss: 0.4225 - val_accuracy: 0.8447\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4033 - accuracy: 0.8397 - val_loss: 0.4839 - val_accuracy: 0.7329\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4159 - accuracy: 0.8256 - val_loss: 0.5760 - val_accuracy: 0.7019\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4086 - accuracy: 0.8349 - val_loss: 0.4106 - val_accuracy: 0.8587\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4040 - accuracy: 0.8343 - val_loss: 0.4121 - val_accuracy: 0.8075\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3978 - accuracy: 0.8397 - val_loss: 0.4118 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3935 - accuracy: 0.8378 - val_loss: 0.4910 - val_accuracy: 0.7189\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3979 - accuracy: 0.8310 - val_loss: 0.4058 - val_accuracy: 0.8168\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4119 - accuracy: 0.8314 - val_loss: 0.4825 - val_accuracy: 0.8602\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4277 - accuracy: 0.8166 - val_loss: 0.4234 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4052 - accuracy: 0.8347 - val_loss: 0.4564 - val_accuracy: 0.7593\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4471 - accuracy: 0.8057 - val_loss: 0.4631 - val_accuracy: 0.8665\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4024 - accuracy: 0.8566 - val_loss: 0.4125 - val_accuracy: 0.8696\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3959 - accuracy: 0.8417 - val_loss: 0.3879 - val_accuracy: 0.8634\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3919 - accuracy: 0.8392 - val_loss: 0.4238 - val_accuracy: 0.8618\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4294 - accuracy: 0.8207 - val_loss: 0.4000 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.4044 - accuracy: 0.8370 - val_loss: 0.3895 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3871 - accuracy: 0.8411 - val_loss: 0.4295 - val_accuracy: 0.8649\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3792 - accuracy: 0.8429 - val_loss: 0.4058 - val_accuracy: 0.8183\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3771 - accuracy: 0.8438 - val_loss: 0.3710 - val_accuracy: 0.8385\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3876 - accuracy: 0.8417 - val_loss: 0.3846 - val_accuracy: 0.8245\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3709 - accuracy: 0.8481 - val_loss: 0.3785 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:10,260] Trial 103 finished with value: 0.8711180686950684 and parameters: {'units': 95, 'dropout': 0.05, 'learning_rate': 0.008563449791370992, 'epochs': 30, 'batch_size': 30, 'patience': 8, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:13,656] Trial 104 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 9.9653 - accuracy: 0.6331 - val_loss: 0.8033 - val_accuracy: 0.7593\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.2248 - accuracy: 0.7310 - val_loss: 1.4964 - val_accuracy: 0.5870\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 1.4726 - accuracy: 0.7601 - val_loss: 0.8181 - val_accuracy: 0.7578\n",
      "Epoch 4/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:19,620] Trial 105 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:23,011] Trial 106 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 16.2418 - accuracy: 0.5767 - val_loss: 1.0874 - val_accuracy: 0.8354\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.0856 - accuracy: 0.7024 - val_loss: 0.6718 - val_accuracy: 0.5776\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.4954 - accuracy: 0.7838 - val_loss: 0.4843 - val_accuracy: 0.8416\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4586 - accuracy: 0.8091 - val_loss: 0.4665 - val_accuracy: 0.8416\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4969 - accuracy: 0.7787 - val_loss: 0.4393 - val_accuracy: 0.8385\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:32,128] Trial 107 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:34,904] Trial 108 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:40:39,047] Trial 109 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 5s - loss: 16.4790 - accuracy: 0.5697 - val_loss: 0.5554 - val_accuracy: 0.8463\n",
      "Epoch 2/30\n",
      "5148/5148 - 4s - loss: 0.6965 - accuracy: 0.6704 - val_loss: 0.6686 - val_accuracy: 0.6693\n",
      "Epoch 3/30\n",
      "5148/5148 - 4s - loss: 0.6052 - accuracy: 0.7075 - val_loss: 0.6287 - val_accuracy: 0.6677\n",
      "Epoch 4/30\n",
      "5148/5148 - 4s - loss: 0.5156 - accuracy: 0.7585 - val_loss: 0.5011 - val_accuracy: 0.8509\n",
      "Epoch 5/30\n",
      "5148/5148 - 4s - loss: 0.5450 - accuracy: 0.7364 - val_loss: 0.5177 - val_accuracy: 0.7562\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:03,413] Trial 110 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:08,256] Trial 111 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 15.1820 - accuracy: 0.5210 - val_loss: 0.5091 - val_accuracy: 0.7826\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 10.7292 - accuracy: 0.5381 - val_loss: 5.1352 - val_accuracy: 0.4922\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 7.6790 - accuracy: 0.5680 - val_loss: 1.0694 - val_accuracy: 0.8525\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 4.5919 - accuracy: 0.6099 - val_loss: 0.9687 - val_accuracy: 0.7764\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 2.7773 - accuracy: 0.6672 - val_loss: 2.4338 - val_accuracy: 0.6475\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:16,098] Trial 112 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:18,563] Trial 113 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:21,055] Trial 114 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:25,576] Trial 115 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:29,715] Trial 116 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:34,070] Trial 117 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:37,788] Trial 118 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:39,997] Trial 119 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:45,183] Trial 120 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:41:48,996] Trial 121 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 4s - loss: 6.1758 - accuracy: 0.6575 - val_loss: 1.3881 - val_accuracy: 0.8214\n",
      "Epoch 2/50\n",
      "5148/5148 - 3s - loss: 1.8547 - accuracy: 0.7312 - val_loss: 1.1144 - val_accuracy: 0.7376\n",
      "Epoch 3/50\n",
      "5148/5148 - 3s - loss: 1.6909 - accuracy: 0.7446 - val_loss: 2.7146 - val_accuracy: 0.5621\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:42:01,773] Trial 122 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 5s - loss: 17.4158 - accuracy: 0.5328 - val_loss: 0.8026 - val_accuracy: 0.8370\n",
      "Epoch 2/40\n",
      "5148/5148 - 4s - loss: 1.9503 - accuracy: 0.6805 - val_loss: 0.6458 - val_accuracy: 0.7640\n",
      "Epoch 3/40\n",
      "5148/5148 - 4s - loss: 0.5541 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7407\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:42:17,817] Trial 123 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:42:20,046] Trial 124 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 2.5640 - accuracy: 0.6661 - val_loss: 1.0032 - val_accuracy: 0.7733\n",
      "Epoch 2/45\n",
      "5148/5148 - 2s - loss: 1.1285 - accuracy: 0.7463 - val_loss: 1.0156 - val_accuracy: 0.7329\n",
      "Epoch 3/45\n",
      "5148/5148 - 2s - loss: 1.2364 - accuracy: 0.7607 - val_loss: 0.7804 - val_accuracy: 0.8634\n",
      "Epoch 4/45\n",
      "5148/5148 - 2s - loss: 1.4043 - accuracy: 0.7529 - val_loss: 2.1106 - val_accuracy: 0.5575\n",
      "Epoch 5/45\n",
      "5148/5148 - 2s - loss: 1.8892 - accuracy: 0.7372 - val_loss: 7.7293 - val_accuracy: 0.4938\n",
      "Epoch 6/45\n",
      "5148/5148 - 2s - loss: 1.5193 - accuracy: 0.7832 - val_loss: 0.8486 - val_accuracy: 0.8649\n",
      "Epoch 7/45\n",
      "5148/5148 - 2s - loss: 1.3157 - accuracy: 0.7854 - val_loss: 1.2610 - val_accuracy: 0.7593\n",
      "Epoch 8/45\n",
      "5148/5148 - 2s - loss: 0.8011 - accuracy: 0.8345 - val_loss: 1.4001 - val_accuracy: 0.6366\n",
      "Epoch 9/45\n",
      "5148/5148 - 3s - loss: 0.7695 - accuracy: 0.8211 - val_loss: 1.4604 - val_accuracy: 0.7360\n",
      "Epoch 10/45\n",
      "5148/5148 - 2s - loss: 0.9959 - accuracy: 0.7916 - val_loss: 1.2947 - val_accuracy: 0.7531\n",
      "Epoch 11/45\n",
      "5148/5148 - 3s - loss: 0.8282 - accuracy: 0.8160 - val_loss: 1.0864 - val_accuracy: 0.7469\n",
      "Epoch 12/45\n",
      "5148/5148 - 3s - loss: 0.6537 - accuracy: 0.8357 - val_loss: 0.5569 - val_accuracy: 0.8556\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.6715 - accuracy: 0.8203 - val_loss: 0.5426 - val_accuracy: 0.8323\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 1.1068 - accuracy: 0.7683 - val_loss: 0.8262 - val_accuracy: 0.7717\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.7946 - accuracy: 0.8116 - val_loss: 0.9717 - val_accuracy: 0.8183\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.9642 - accuracy: 0.7900 - val_loss: 0.6068 - val_accuracy: 0.8401\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.5563 - accuracy: 0.8438 - val_loss: 0.5623 - val_accuracy: 0.8370\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.5451 - accuracy: 0.8403 - val_loss: 0.5225 - val_accuracy: 0.8540\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.5146 - accuracy: 0.8419 - val_loss: 0.5903 - val_accuracy: 0.8587\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4767 - accuracy: 0.8467 - val_loss: 0.5013 - val_accuracy: 0.8276\n",
      "Epoch 21/45\n",
      "5148/5148 - 2s - loss: 0.5585 - accuracy: 0.8225 - val_loss: 0.4607 - val_accuracy: 0.8339\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.4859 - accuracy: 0.8339 - val_loss: 0.5264 - val_accuracy: 0.8292\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.4510 - accuracy: 0.8429 - val_loss: 0.4400 - val_accuracy: 0.8587\n",
      "Epoch 24/45\n",
      "5148/5148 - 2s - loss: 0.4598 - accuracy: 0.8339 - val_loss: 0.5780 - val_accuracy: 0.8571\n",
      "Epoch 25/45\n",
      "5148/5148 - 2s - loss: 0.4392 - accuracy: 0.8495 - val_loss: 0.4426 - val_accuracy: 0.8276\n",
      "Epoch 26/45\n",
      "5148/5148 - 2s - loss: 0.4428 - accuracy: 0.8384 - val_loss: 0.4460 - val_accuracy: 0.8556\n",
      "Epoch 27/45\n",
      "5148/5148 - 2s - loss: 0.3957 - accuracy: 0.8516 - val_loss: 0.4270 - val_accuracy: 0.8292\n",
      "Epoch 28/45\n",
      "5148/5148 - 2s - loss: 0.3651 - accuracy: 0.8535 - val_loss: 0.5451 - val_accuracy: 0.7857\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3902 - accuracy: 0.8502 - val_loss: 0.4140 - val_accuracy: 0.8556\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3863 - accuracy: 0.8508 - val_loss: 0.3950 - val_accuracy: 0.8323\n",
      "Epoch 31/45\n",
      "5148/5148 - 2s - loss: 0.3602 - accuracy: 0.8594 - val_loss: 0.4338 - val_accuracy: 0.8556\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3864 - accuracy: 0.8467 - val_loss: 0.3910 - val_accuracy: 0.8276\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3743 - accuracy: 0.8528 - val_loss: 0.3917 - val_accuracy: 0.8370\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3546 - accuracy: 0.8590 - val_loss: 0.5152 - val_accuracy: 0.7873\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3805 - accuracy: 0.8555 - val_loss: 0.5619 - val_accuracy: 0.7826\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3787 - accuracy: 0.8471 - val_loss: 0.5577 - val_accuracy: 0.7826\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3469 - accuracy: 0.8576 - val_loss: 0.3943 - val_accuracy: 0.8339\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3478 - accuracy: 0.8601 - val_loss: 0.3889 - val_accuracy: 0.8587\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3799 - val_accuracy: 0.8323\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3356 - accuracy: 0.8572 - val_loss: 0.3961 - val_accuracy: 0.8339\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3390 - accuracy: 0.8586 - val_loss: 0.4031 - val_accuracy: 0.8556\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3389 - accuracy: 0.8598 - val_loss: 0.4273 - val_accuracy: 0.8307\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3373 - accuracy: 0.8603 - val_loss: 0.4022 - val_accuracy: 0.8556\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3310 - accuracy: 0.8574 - val_loss: 0.3947 - val_accuracy: 0.8587\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3347 - accuracy: 0.8594 - val_loss: 0.3763 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 4.4147 - accuracy: 0.6511 - val_loss: 0.7073 - val_accuracy: 0.8385\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 1.4676 - accuracy: 0.7403 - val_loss: 1.5532 - val_accuracy: 0.6801\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 1.3328 - accuracy: 0.7551 - val_loss: 1.1680 - val_accuracy: 0.7205\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 1.2413 - accuracy: 0.7523 - val_loss: 1.8650 - val_accuracy: 0.5590\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 1.8839 - accuracy: 0.7216 - val_loss: 1.9382 - val_accuracy: 0.6196\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 1.2111 - accuracy: 0.7943 - val_loss: 0.7488 - val_accuracy: 0.8680\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 1.4061 - accuracy: 0.7657 - val_loss: 1.0302 - val_accuracy: 0.7593\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.8857 - accuracy: 0.8164 - val_loss: 1.0919 - val_accuracy: 0.8323\n",
      "Epoch 9/45\n",
      "5148/5148 - 2s - loss: 0.7733 - accuracy: 0.8203 - val_loss: 0.5836 - val_accuracy: 0.8339\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.7962 - accuracy: 0.8096 - val_loss: 4.1915 - val_accuracy: 0.5575\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.9460 - accuracy: 0.7988 - val_loss: 0.6421 - val_accuracy: 0.8602\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.6409 - accuracy: 0.8316 - val_loss: 0.9799 - val_accuracy: 0.7593\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.7967 - accuracy: 0.8003 - val_loss: 1.1158 - val_accuracy: 0.7531\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.8023 - accuracy: 0.8001 - val_loss: 0.7172 - val_accuracy: 0.7717\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.7980 - accuracy: 0.7988 - val_loss: 0.5736 - val_accuracy: 0.8261\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.8027 - accuracy: 0.8056 - val_loss: 0.5765 - val_accuracy: 0.8323\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.4983 - accuracy: 0.8479 - val_loss: 0.5201 - val_accuracy: 0.8323\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.4861 - accuracy: 0.8456 - val_loss: 0.4643 - val_accuracy: 0.8339\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4661 - accuracy: 0.8411 - val_loss: 0.5928 - val_accuracy: 0.8602\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4282 - accuracy: 0.8504 - val_loss: 0.4764 - val_accuracy: 0.8261\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.5161 - accuracy: 0.8256 - val_loss: 0.4558 - val_accuracy: 0.8323\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.4473 - accuracy: 0.8382 - val_loss: 0.5198 - val_accuracy: 0.8307\n",
      "Epoch 23/45\n",
      "5148/5148 - 2s - loss: 0.4077 - accuracy: 0.8469 - val_loss: 0.4124 - val_accuracy: 0.8602\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.4274 - accuracy: 0.8376 - val_loss: 0.5980 - val_accuracy: 0.8540\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4188 - accuracy: 0.8504 - val_loss: 0.4664 - val_accuracy: 0.8292\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4237 - accuracy: 0.8388 - val_loss: 0.4510 - val_accuracy: 0.8602\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3774 - accuracy: 0.8564 - val_loss: 0.4003 - val_accuracy: 0.8323\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3512 - accuracy: 0.8574 - val_loss: 0.4688 - val_accuracy: 0.8323\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3654 - accuracy: 0.8568 - val_loss: 0.3967 - val_accuracy: 0.8602\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3686 - accuracy: 0.8541 - val_loss: 0.3839 - val_accuracy: 0.8276\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3474 - accuracy: 0.8580 - val_loss: 0.4118 - val_accuracy: 0.8556\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3768 - accuracy: 0.8469 - val_loss: 0.3856 - val_accuracy: 0.8556\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3629 - accuracy: 0.8557 - val_loss: 0.3796 - val_accuracy: 0.8276\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3471 - accuracy: 0.8596 - val_loss: 0.5783 - val_accuracy: 0.7811\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3963 - accuracy: 0.8446 - val_loss: 0.5600 - val_accuracy: 0.7795\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3616 - accuracy: 0.8506 - val_loss: 0.4300 - val_accuracy: 0.8292\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3357 - accuracy: 0.8588 - val_loss: 0.4134 - val_accuracy: 0.8261\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3383 - accuracy: 0.8586 - val_loss: 0.3967 - val_accuracy: 0.8540\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3281 - accuracy: 0.8660 - val_loss: 0.3766 - val_accuracy: 0.8385\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3292 - accuracy: 0.8590 - val_loss: 0.3836 - val_accuracy: 0.8323\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3319 - accuracy: 0.8596 - val_loss: 0.3905 - val_accuracy: 0.8571\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3311 - accuracy: 0.8623 - val_loss: 0.4187 - val_accuracy: 0.8292\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3302 - accuracy: 0.8599 - val_loss: 0.4194 - val_accuracy: 0.8556\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3255 - accuracy: 0.8584 - val_loss: 0.3975 - val_accuracy: 0.8556\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3299 - accuracy: 0.8564 - val_loss: 0.3664 - val_accuracy: 0.8323\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 3.3512 - accuracy: 0.6739 - val_loss: 2.1057 - val_accuracy: 0.5217\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 1.5101 - accuracy: 0.7426 - val_loss: 0.8556 - val_accuracy: 0.7578\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 1.6475 - accuracy: 0.7483 - val_loss: 0.9972 - val_accuracy: 0.8634\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 1.6050 - accuracy: 0.7681 - val_loss: 4.6276 - val_accuracy: 0.4984\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 1.8393 - accuracy: 0.7558 - val_loss: 1.0476 - val_accuracy: 0.8571\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 1.6299 - accuracy: 0.7813 - val_loss: 1.0243 - val_accuracy: 0.8602\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 1.3751 - accuracy: 0.8015 - val_loss: 2.6893 - val_accuracy: 0.7081\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 1.1706 - accuracy: 0.8145 - val_loss: 1.6154 - val_accuracy: 0.6615\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 1.6451 - accuracy: 0.7764 - val_loss: 1.7423 - val_accuracy: 0.7516\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 1.4167 - accuracy: 0.7892 - val_loss: 0.9043 - val_accuracy: 0.8618\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 1.1298 - accuracy: 0.8199 - val_loss: 2.3222 - val_accuracy: 0.5575\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.9257 - accuracy: 0.8209 - val_loss: 0.7373 - val_accuracy: 0.8649\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.9214 - accuracy: 0.8188 - val_loss: 0.7146 - val_accuracy: 0.8339\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 1.4490 - accuracy: 0.7669 - val_loss: 2.3173 - val_accuracy: 0.7220\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 1.5977 - accuracy: 0.7694 - val_loss: 0.9440 - val_accuracy: 0.8618\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 1.4176 - accuracy: 0.7947 - val_loss: 0.9522 - val_accuracy: 0.8307\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 1.0689 - accuracy: 0.8143 - val_loss: 0.8975 - val_accuracy: 0.8602\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.9978 - accuracy: 0.8201 - val_loss: 2.3853 - val_accuracy: 0.5466\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 1.7168 - accuracy: 0.7494 - val_loss: 0.9214 - val_accuracy: 0.8261\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 1.2360 - accuracy: 0.8075 - val_loss: 0.8025 - val_accuracy: 0.8292\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.8250 - accuracy: 0.8355 - val_loss: 0.7624 - val_accuracy: 0.8618\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 1.0917 - accuracy: 0.8019 - val_loss: 0.7137 - val_accuracy: 0.8416\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.6352 - accuracy: 0.8530 - val_loss: 0.6574 - val_accuracy: 0.8571\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.5490 - accuracy: 0.8588 - val_loss: 1.3907 - val_accuracy: 0.5994\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.5825 - accuracy: 0.8421 - val_loss: 0.5808 - val_accuracy: 0.8339\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.5345 - accuracy: 0.8463 - val_loss: 0.5111 - val_accuracy: 0.8261\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.5150 - accuracy: 0.8423 - val_loss: 0.7672 - val_accuracy: 0.7826\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.4568 - accuracy: 0.8510 - val_loss: 0.5659 - val_accuracy: 0.8416\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.5041 - accuracy: 0.8397 - val_loss: 1.1029 - val_accuracy: 0.5870\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.5815 - accuracy: 0.8180 - val_loss: 0.7458 - val_accuracy: 0.8276\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.4869 - accuracy: 0.8450 - val_loss: 0.8145 - val_accuracy: 0.7438\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.5545 - accuracy: 0.8215 - val_loss: 0.9502 - val_accuracy: 0.7562\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.4031 - accuracy: 0.8603 - val_loss: 0.4601 - val_accuracy: 0.8339\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3839 - accuracy: 0.8603 - val_loss: 0.5753 - val_accuracy: 0.8214\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.4500 - accuracy: 0.8434 - val_loss: 0.5401 - val_accuracy: 0.8401\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3979 - accuracy: 0.8524 - val_loss: 0.4559 - val_accuracy: 0.8245\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3832 - accuracy: 0.8592 - val_loss: 0.4148 - val_accuracy: 0.8323\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3810 - accuracy: 0.8551 - val_loss: 0.4118 - val_accuracy: 0.8323\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3904 - accuracy: 0.8528 - val_loss: 0.4595 - val_accuracy: 0.8339\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3789 - accuracy: 0.8514 - val_loss: 0.4250 - val_accuracy: 0.8323\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3878 - accuracy: 0.8495 - val_loss: 0.4050 - val_accuracy: 0.8323\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.4114 - accuracy: 0.8477 - val_loss: 0.4207 - val_accuracy: 0.8323\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8611 - val_loss: 0.4797 - val_accuracy: 0.8540\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3421 - accuracy: 0.8578 - val_loss: 0.4436 - val_accuracy: 0.8556\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3498 - accuracy: 0.8557 - val_loss: 0.3946 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 3.7525 - accuracy: 0.6461 - val_loss: 0.8917 - val_accuracy: 0.8261\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 1.8697 - accuracy: 0.7296 - val_loss: 2.1544 - val_accuracy: 0.6661\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 1.6084 - accuracy: 0.7469 - val_loss: 2.2875 - val_accuracy: 0.6584\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.9324 - accuracy: 0.8028 - val_loss: 0.8198 - val_accuracy: 0.8618\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 2.5064 - accuracy: 0.7246 - val_loss: 1.1651 - val_accuracy: 0.8602\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 1.2059 - accuracy: 0.7999 - val_loss: 3.5659 - val_accuracy: 0.6165\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 2.1799 - accuracy: 0.7385 - val_loss: 1.7543 - val_accuracy: 0.7376\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 1.1366 - accuracy: 0.8120 - val_loss: 1.5939 - val_accuracy: 0.7236\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 1.0645 - accuracy: 0.8155 - val_loss: 2.1241 - val_accuracy: 0.7127\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 1.3086 - accuracy: 0.7914 - val_loss: 0.8482 - val_accuracy: 0.8680\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 1.1603 - accuracy: 0.8098 - val_loss: 1.2118 - val_accuracy: 0.8618\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.8665 - accuracy: 0.8293 - val_loss: 0.7237 - val_accuracy: 0.8587\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 1.4719 - accuracy: 0.7760 - val_loss: 0.9573 - val_accuracy: 0.8168\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 1.2238 - accuracy: 0.8030 - val_loss: 1.0922 - val_accuracy: 0.7733\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 1.1078 - accuracy: 0.8061 - val_loss: 0.7720 - val_accuracy: 0.8401\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 1.1846 - accuracy: 0.7966 - val_loss: 0.7889 - val_accuracy: 0.8307\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.8861 - accuracy: 0.8193 - val_loss: 1.4453 - val_accuracy: 0.6584\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.7785 - accuracy: 0.8258 - val_loss: 0.6951 - val_accuracy: 0.8276\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.8942 - accuracy: 0.8102 - val_loss: 0.6307 - val_accuracy: 0.8370\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 1.3393 - accuracy: 0.7867 - val_loss: 1.1137 - val_accuracy: 0.8230\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.6322 - accuracy: 0.8481 - val_loss: 0.6010 - val_accuracy: 0.8339\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.6064 - accuracy: 0.8397 - val_loss: 0.5717 - val_accuracy: 0.8649\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.4802 - accuracy: 0.8578 - val_loss: 0.5083 - val_accuracy: 0.8276\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.5073 - accuracy: 0.8444 - val_loss: 0.8456 - val_accuracy: 0.7593\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.5125 - accuracy: 0.8469 - val_loss: 0.6022 - val_accuracy: 0.8447\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.5015 - accuracy: 0.8359 - val_loss: 0.5634 - val_accuracy: 0.8571\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.5460 - accuracy: 0.8269 - val_loss: 0.6483 - val_accuracy: 0.7950\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.4396 - accuracy: 0.8514 - val_loss: 0.4687 - val_accuracy: 0.8354\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.5556 - accuracy: 0.8238 - val_loss: 1.0147 - val_accuracy: 0.6087\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.5301 - accuracy: 0.8279 - val_loss: 0.5933 - val_accuracy: 0.8602\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3891 - accuracy: 0.8654 - val_loss: 0.4350 - val_accuracy: 0.8339\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.4204 - accuracy: 0.8489 - val_loss: 0.4351 - val_accuracy: 0.8634\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3949 - accuracy: 0.8559 - val_loss: 0.4188 - val_accuracy: 0.8276\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3723 - accuracy: 0.8584 - val_loss: 0.6122 - val_accuracy: 0.7842\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.4134 - accuracy: 0.8504 - val_loss: 0.6269 - val_accuracy: 0.7842\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.4001 - accuracy: 0.8462 - val_loss: 0.6415 - val_accuracy: 0.7811\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3951 - accuracy: 0.8561 - val_loss: 0.4132 - val_accuracy: 0.8571\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3765 - accuracy: 0.8537 - val_loss: 0.4015 - val_accuracy: 0.8339\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3942 - accuracy: 0.8514 - val_loss: 0.5015 - val_accuracy: 0.8307\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3805 - accuracy: 0.8481 - val_loss: 0.4741 - val_accuracy: 0.8432\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3492 - accuracy: 0.8598 - val_loss: 0.4147 - val_accuracy: 0.8634\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3489 - accuracy: 0.8611 - val_loss: 0.4415 - val_accuracy: 0.8354\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3470 - accuracy: 0.8599 - val_loss: 0.4184 - val_accuracy: 0.8587\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3419 - accuracy: 0.8563 - val_loss: 0.4117 - val_accuracy: 0.8587\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3464 - accuracy: 0.8598 - val_loss: 0.3999 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 6.2720 - accuracy: 0.6445 - val_loss: 1.1005 - val_accuracy: 0.8571\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 2.0016 - accuracy: 0.7290 - val_loss: 1.1215 - val_accuracy: 0.7376\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 1.8090 - accuracy: 0.7376 - val_loss: 3.3846 - val_accuracy: 0.5155\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 1.6026 - accuracy: 0.7700 - val_loss: 4.6040 - val_accuracy: 0.4984\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 2.2380 - accuracy: 0.7387 - val_loss: 1.2722 - val_accuracy: 0.8634\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 1.6150 - accuracy: 0.7735 - val_loss: 1.0823 - val_accuracy: 0.8354\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 2.0108 - accuracy: 0.7624 - val_loss: 2.8715 - val_accuracy: 0.7189\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 1.0632 - accuracy: 0.8372 - val_loss: 2.2938 - val_accuracy: 0.5699\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 1.4737 - accuracy: 0.7768 - val_loss: 2.1941 - val_accuracy: 0.7252\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 1.4253 - accuracy: 0.7859 - val_loss: 0.9635 - val_accuracy: 0.8587\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 1.1523 - accuracy: 0.8199 - val_loss: 2.0241 - val_accuracy: 0.5745\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.8856 - accuracy: 0.8314 - val_loss: 0.7358 - val_accuracy: 0.8602\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.9847 - accuracy: 0.8131 - val_loss: 0.7734 - val_accuracy: 0.8556\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 1.4162 - accuracy: 0.7727 - val_loss: 2.5930 - val_accuracy: 0.7158\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 1.2783 - accuracy: 0.8056 - val_loss: 1.2012 - val_accuracy: 0.8571\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.7219 - accuracy: 0.8580 - val_loss: 0.7409 - val_accuracy: 0.8292\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.6580 - accuracy: 0.8493 - val_loss: 1.0123 - val_accuracy: 0.8230\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.6772 - accuracy: 0.8413 - val_loss: 0.9546 - val_accuracy: 0.8090\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.8050 - accuracy: 0.8122 - val_loss: 0.6852 - val_accuracy: 0.8261\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.7558 - accuracy: 0.8285 - val_loss: 0.6391 - val_accuracy: 0.8339\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.6140 - accuracy: 0.8397 - val_loss: 0.7599 - val_accuracy: 0.8571\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.7147 - accuracy: 0.8242 - val_loss: 0.5697 - val_accuracy: 0.8385\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.6975 - accuracy: 0.8258 - val_loss: 0.5500 - val_accuracy: 0.8323\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.5339 - accuracy: 0.8458 - val_loss: 0.5909 - val_accuracy: 0.8571\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.5416 - accuracy: 0.8429 - val_loss: 0.5777 - val_accuracy: 0.8556\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4584 - accuracy: 0.8557 - val_loss: 0.4784 - val_accuracy: 0.8276\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.4537 - accuracy: 0.8533 - val_loss: 0.7688 - val_accuracy: 0.7764\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.4410 - accuracy: 0.8522 - val_loss: 0.8848 - val_accuracy: 0.7702\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.4585 - accuracy: 0.8516 - val_loss: 1.0047 - val_accuracy: 0.6087\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.5147 - accuracy: 0.8304 - val_loss: 0.4981 - val_accuracy: 0.8556\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.4497 - accuracy: 0.8553 - val_loss: 0.5107 - val_accuracy: 0.8571\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.4308 - accuracy: 0.8530 - val_loss: 0.5231 - val_accuracy: 0.8416\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.4459 - accuracy: 0.8493 - val_loss: 0.5270 - val_accuracy: 0.8556\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.4099 - accuracy: 0.8510 - val_loss: 0.5106 - val_accuracy: 0.8432\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.4259 - accuracy: 0.8471 - val_loss: 0.4445 - val_accuracy: 0.8354\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3850 - accuracy: 0.8596 - val_loss: 0.4238 - val_accuracy: 0.8307\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3769 - accuracy: 0.8619 - val_loss: 0.4209 - val_accuracy: 0.8307\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3807 - accuracy: 0.8549 - val_loss: 0.4456 - val_accuracy: 0.8587\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3656 - accuracy: 0.8611 - val_loss: 0.4210 - val_accuracy: 0.8339\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3670 - accuracy: 0.8601 - val_loss: 0.4710 - val_accuracy: 0.8401\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3752 - accuracy: 0.8504 - val_loss: 0.4360 - val_accuracy: 0.8587\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3836 - accuracy: 0.8535 - val_loss: 0.4141 - val_accuracy: 0.8307\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3699 - accuracy: 0.8582 - val_loss: 0.4086 - val_accuracy: 0.8339\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3775 - accuracy: 0.8557 - val_loss: 0.4061 - val_accuracy: 0.8307\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3605 - accuracy: 0.8555 - val_loss: 0.4518 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:46:42,362] Trial 125 finished with value: 0.8658385276794434 and parameters: {'units': 100, 'dropout': 0.0, 'learning_rate': 0.004659524530411038, 'epochs': 45, 'batch_size': 20, 'patience': 10, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 2.4650 - accuracy: 0.6626 - val_loss: 0.8423 - val_accuracy: 0.8432\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.4576 - accuracy: 0.7451 - val_loss: 1.6422 - val_accuracy: 0.6817\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 1.3988 - accuracy: 0.7360 - val_loss: 1.0702 - val_accuracy: 0.8634\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 1.4966 - accuracy: 0.7618 - val_loss: 3.7710 - val_accuracy: 0.4984\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 1.9338 - accuracy: 0.7438 - val_loss: 1.1475 - val_accuracy: 0.8634\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 1.4154 - accuracy: 0.7729 - val_loss: 1.8975 - val_accuracy: 0.7205\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 1.6345 - accuracy: 0.7725 - val_loss: 1.4332 - val_accuracy: 0.7562\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 1.0223 - accuracy: 0.8195 - val_loss: 2.0339 - val_accuracy: 0.5745\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 1.1777 - accuracy: 0.7865 - val_loss: 1.5184 - val_accuracy: 0.7516\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 1.2159 - accuracy: 0.7941 - val_loss: 3.2483 - val_accuracy: 0.6522\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 1.3559 - accuracy: 0.7916 - val_loss: 0.7964 - val_accuracy: 0.8339\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.9149 - accuracy: 0.8166 - val_loss: 1.1602 - val_accuracy: 0.7686\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 1.1284 - accuracy: 0.7929 - val_loss: 2.1072 - val_accuracy: 0.7189\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.7107 - accuracy: 0.8576 - val_loss: 0.8977 - val_accuracy: 0.8587\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.7836 - accuracy: 0.8333 - val_loss: 0.7571 - val_accuracy: 0.8571\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.6315 - accuracy: 0.8429 - val_loss: 0.6085 - val_accuracy: 0.8540\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.5993 - accuracy: 0.8347 - val_loss: 1.4590 - val_accuracy: 0.5745\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.6834 - accuracy: 0.8269 - val_loss: 0.9276 - val_accuracy: 0.7795\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.6943 - accuracy: 0.8153 - val_loss: 0.5550 - val_accuracy: 0.8339\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.7267 - accuracy: 0.8219 - val_loss: 0.5823 - val_accuracy: 0.8292\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.5717 - accuracy: 0.8397 - val_loss: 0.6834 - val_accuracy: 0.8602\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.6476 - accuracy: 0.8250 - val_loss: 0.5255 - val_accuracy: 0.8339\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.6358 - accuracy: 0.8265 - val_loss: 0.5068 - val_accuracy: 0.8292\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.4615 - accuracy: 0.8578 - val_loss: 0.7039 - val_accuracy: 0.8571\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.4267 - accuracy: 0.8588 - val_loss: 0.4844 - val_accuracy: 0.8556\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.4419 - accuracy: 0.8475 - val_loss: 0.4536 - val_accuracy: 0.8276\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.4292 - accuracy: 0.8539 - val_loss: 0.7243 - val_accuracy: 0.7764\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.4248 - accuracy: 0.8514 - val_loss: 0.8259 - val_accuracy: 0.7702\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.4452 - accuracy: 0.8500 - val_loss: 0.8427 - val_accuracy: 0.6677\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.4893 - accuracy: 0.8320 - val_loss: 0.4703 - val_accuracy: 0.8556\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.4301 - accuracy: 0.8584 - val_loss: 0.4995 - val_accuracy: 0.8556\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.4165 - accuracy: 0.8520 - val_loss: 0.4804 - val_accuracy: 0.8292\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.4260 - accuracy: 0.8516 - val_loss: 0.5275 - val_accuracy: 0.8571\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3695 - accuracy: 0.8607 - val_loss: 0.4181 - val_accuracy: 0.8261\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3728 - accuracy: 0.8568 - val_loss: 0.4269 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 4s - loss: 3.2804 - accuracy: 0.6459 - val_loss: 1.6762 - val_accuracy: 0.5419\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.1467 - accuracy: 0.7399 - val_loss: 1.0002 - val_accuracy: 0.7236\n",
      "Epoch 3/35\n",
      "5148/5148 - 2s - loss: 1.2790 - accuracy: 0.7551 - val_loss: 0.6612 - val_accuracy: 0.8494\n",
      "Epoch 4/35\n",
      "5148/5148 - 2s - loss: 1.3715 - accuracy: 0.7459 - val_loss: 3.2622 - val_accuracy: 0.4984\n",
      "Epoch 5/35\n",
      "5148/5148 - 2s - loss: 1.7929 - accuracy: 0.7362 - val_loss: 6.7670 - val_accuracy: 0.4953\n",
      "Epoch 6/35\n",
      "5148/5148 - 2s - loss: 1.5238 - accuracy: 0.7653 - val_loss: 0.8926 - val_accuracy: 0.8571\n",
      "Epoch 7/35\n",
      "5148/5148 - 3s - loss: 1.4903 - accuracy: 0.7723 - val_loss: 1.2898 - val_accuracy: 0.7516\n",
      "Epoch 8/35\n",
      "5148/5148 - 3s - loss: 1.0135 - accuracy: 0.8106 - val_loss: 1.2220 - val_accuracy: 0.8323\n",
      "Epoch 9/35\n",
      "5148/5148 - 3s - loss: 0.8796 - accuracy: 0.8215 - val_loss: 0.6829 - val_accuracy: 0.8214\n",
      "Epoch 10/35\n",
      "5148/5148 - 3s - loss: 0.8964 - accuracy: 0.8100 - val_loss: 1.3264 - val_accuracy: 0.7500\n",
      "Epoch 11/35\n",
      "5148/5148 - 3s - loss: 0.8527 - accuracy: 0.8162 - val_loss: 1.0646 - val_accuracy: 0.7764\n",
      "Epoch 12/35\n",
      "5148/5148 - 3s - loss: 0.6480 - accuracy: 0.8376 - val_loss: 0.5422 - val_accuracy: 0.8370\n",
      "Epoch 13/35\n",
      "5148/5148 - 3s - loss: 0.9185 - accuracy: 0.7960 - val_loss: 0.7764 - val_accuracy: 0.7733\n",
      "Epoch 14/35\n",
      "5148/5148 - 2s - loss: 1.0726 - accuracy: 0.7813 - val_loss: 0.8364 - val_accuracy: 0.7733\n",
      "Epoch 15/35\n",
      "5148/5148 - 3s - loss: 0.9284 - accuracy: 0.8087 - val_loss: 0.8081 - val_accuracy: 0.8571\n",
      "Epoch 16/35\n",
      "5148/5148 - 2s - loss: 1.0834 - accuracy: 0.7890 - val_loss: 0.6852 - val_accuracy: 0.8525\n",
      "Epoch 17/35\n",
      "5148/5148 - 3s - loss: 0.6451 - accuracy: 0.8417 - val_loss: 0.6516 - val_accuracy: 0.8354\n",
      "Epoch 18/35\n",
      "5148/5148 - 4s - loss: 0.6118 - accuracy: 0.8423 - val_loss: 0.5986 - val_accuracy: 0.8556\n",
      "Epoch 19/35\n",
      "5148/5148 - 2s - loss: 0.5913 - accuracy: 0.8397 - val_loss: 0.6204 - val_accuracy: 0.8556\n",
      "Epoch 20/35\n",
      "5148/5148 - 2s - loss: 0.5484 - accuracy: 0.8430 - val_loss: 0.5654 - val_accuracy: 0.8292\n",
      "Epoch 21/35\n",
      "5148/5148 - 3s - loss: 0.6299 - accuracy: 0.8221 - val_loss: 0.5055 - val_accuracy: 0.8276\n",
      "Epoch 22/35\n",
      "5148/5148 - 3s - loss: 0.5522 - accuracy: 0.8328 - val_loss: 0.5871 - val_accuracy: 0.8245\n",
      "Epoch 23/35\n",
      "5148/5148 - 3s - loss: 0.5113 - accuracy: 0.8403 - val_loss: 0.4791 - val_accuracy: 0.8571\n",
      "Epoch 24/35\n",
      "5148/5148 - 3s - loss: 0.5200 - accuracy: 0.8316 - val_loss: 0.5930 - val_accuracy: 0.8602\n",
      "Epoch 25/35\n",
      "5148/5148 - 2s - loss: 0.4894 - accuracy: 0.8498 - val_loss: 0.4625 - val_accuracy: 0.8339\n",
      "Epoch 26/35\n",
      "5148/5148 - 3s - loss: 0.4911 - accuracy: 0.8397 - val_loss: 0.4738 - val_accuracy: 0.8540\n",
      "Epoch 27/35\n",
      "5148/5148 - 4s - loss: 0.5067 - accuracy: 0.8310 - val_loss: 0.4491 - val_accuracy: 0.8571\n",
      "Epoch 28/35\n",
      "5148/5148 - 3s - loss: 0.4464 - accuracy: 0.8440 - val_loss: 0.4333 - val_accuracy: 0.8370\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.5492 - accuracy: 0.8172 - val_loss: 1.0129 - val_accuracy: 0.6087\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.5238 - accuracy: 0.8281 - val_loss: 0.5315 - val_accuracy: 0.8587\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.4776 - accuracy: 0.8380 - val_loss: 0.8582 - val_accuracy: 0.6770\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.5650 - accuracy: 0.8147 - val_loss: 0.9133 - val_accuracy: 0.7531\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.5659 - accuracy: 0.8258 - val_loss: 0.9645 - val_accuracy: 0.6351\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.4513 - accuracy: 0.8475 - val_loss: 0.4934 - val_accuracy: 0.8245\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.4254 - accuracy: 0.8481 - val_loss: 0.4842 - val_accuracy: 0.8276\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 2.4256 - accuracy: 0.6436 - val_loss: 0.8352 - val_accuracy: 0.8525\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.1388 - accuracy: 0.7506 - val_loss: 0.6282 - val_accuracy: 0.8447\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 1.2612 - accuracy: 0.7483 - val_loss: 0.7400 - val_accuracy: 0.8634\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 1.3753 - accuracy: 0.7479 - val_loss: 5.2648 - val_accuracy: 0.4953\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 1.9883 - accuracy: 0.7275 - val_loss: 5.3543 - val_accuracy: 0.4984\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 1.4162 - accuracy: 0.7900 - val_loss: 0.8469 - val_accuracy: 0.8665\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 1.4516 - accuracy: 0.7766 - val_loss: 1.8129 - val_accuracy: 0.7252\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.8629 - accuracy: 0.8316 - val_loss: 1.5844 - val_accuracy: 0.6149\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 1.1047 - accuracy: 0.7871 - val_loss: 1.2431 - val_accuracy: 0.7562\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 1.1368 - accuracy: 0.7949 - val_loss: 2.1441 - val_accuracy: 0.7158\n",
      "Epoch 11/35\n",
      "5148/5148 - 4s - loss: 1.1480 - accuracy: 0.8023 - val_loss: 0.9660 - val_accuracy: 0.8618\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.9288 - accuracy: 0.8125 - val_loss: 1.1841 - val_accuracy: 0.7686\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 1.0043 - accuracy: 0.8057 - val_loss: 1.5684 - val_accuracy: 0.7484\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 1.1651 - accuracy: 0.7877 - val_loss: 0.9582 - val_accuracy: 0.8028\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 1.0775 - accuracy: 0.8100 - val_loss: 0.7576 - val_accuracy: 0.8556\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 1.1960 - accuracy: 0.7972 - val_loss: 0.7757 - val_accuracy: 0.8323\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.7395 - accuracy: 0.8425 - val_loss: 0.7335 - val_accuracy: 0.8354\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.6860 - accuracy: 0.8419 - val_loss: 0.7022 - val_accuracy: 0.8556\n",
      "Epoch 19/35\n",
      "5148/5148 - 2s - loss: 0.6868 - accuracy: 0.8376 - val_loss: 0.7101 - val_accuracy: 0.8540\n",
      "Epoch 20/35\n",
      "5148/5148 - 2s - loss: 0.6223 - accuracy: 0.8448 - val_loss: 0.6546 - val_accuracy: 0.8261\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.7104 - accuracy: 0.8226 - val_loss: 0.5671 - val_accuracy: 0.8385\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.6198 - accuracy: 0.8326 - val_loss: 0.6692 - val_accuracy: 0.8323\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.5743 - accuracy: 0.8397 - val_loss: 0.5268 - val_accuracy: 0.8478\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.5772 - accuracy: 0.8322 - val_loss: 0.6148 - val_accuracy: 0.8540\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.5418 - accuracy: 0.8477 - val_loss: 0.4999 - val_accuracy: 0.8323\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.5427 - accuracy: 0.8392 - val_loss: 0.5183 - val_accuracy: 0.8556\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.4654 - accuracy: 0.8508 - val_loss: 0.6104 - val_accuracy: 0.8447\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.4336 - accuracy: 0.8520 - val_loss: 0.7695 - val_accuracy: 0.7764\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.4810 - accuracy: 0.8450 - val_loss: 0.5050 - val_accuracy: 0.8556\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.4607 - accuracy: 0.8469 - val_loss: 0.4580 - val_accuracy: 0.8276\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.4193 - accuracy: 0.8566 - val_loss: 0.5143 - val_accuracy: 0.8525\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.4367 - accuracy: 0.8512 - val_loss: 0.4547 - val_accuracy: 0.8323\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.4284 - accuracy: 0.8543 - val_loss: 0.4693 - val_accuracy: 0.8556\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.4012 - accuracy: 0.8553 - val_loss: 0.5623 - val_accuracy: 0.8354\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.4071 - accuracy: 0.8531 - val_loss: 0.4798 - val_accuracy: 0.8292\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 2s - loss: 2.1353 - accuracy: 0.6805 - val_loss: 1.8509 - val_accuracy: 0.5373\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.8037 - accuracy: 0.7170 - val_loss: 1.3253 - val_accuracy: 0.7298\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 1.9858 - accuracy: 0.7552 - val_loss: 1.0017 - val_accuracy: 0.8634\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 1.7312 - accuracy: 0.7591 - val_loss: 1.3560 - val_accuracy: 0.8618\n",
      "Epoch 5/35\n",
      "5148/5148 - 1s - loss: 2.8763 - accuracy: 0.7236 - val_loss: 3.1351 - val_accuracy: 0.5901\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 1.7560 - accuracy: 0.7962 - val_loss: 1.1601 - val_accuracy: 0.8587\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 1.8311 - accuracy: 0.7789 - val_loss: 2.4193 - val_accuracy: 0.7252\n",
      "Epoch 8/35\n",
      "5148/5148 - 2s - loss: 1.0877 - accuracy: 0.8316 - val_loss: 2.2119 - val_accuracy: 0.5792\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 1.7876 - accuracy: 0.7729 - val_loss: 1.2426 - val_accuracy: 0.7717\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 1.5199 - accuracy: 0.7885 - val_loss: 1.8686 - val_accuracy: 0.7516\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 1.3650 - accuracy: 0.8069 - val_loss: 1.0163 - val_accuracy: 0.8556\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 1.3450 - accuracy: 0.8026 - val_loss: 1.1165 - val_accuracy: 0.7950\n",
      "Epoch 13/35\n",
      "5148/5148 - 2s - loss: 1.1956 - accuracy: 0.8028 - val_loss: 2.5514 - val_accuracy: 0.7158\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 0.7837 - accuracy: 0.8566 - val_loss: 0.9805 - val_accuracy: 0.8571\n",
      "Epoch 15/35\n",
      "5148/5148 - 1s - loss: 0.8621 - accuracy: 0.8329 - val_loss: 0.7416 - val_accuracy: 0.8556\n",
      "Epoch 16/35\n",
      "5148/5148 - 1s - loss: 0.6837 - accuracy: 0.8442 - val_loss: 0.6376 - val_accuracy: 0.8354\n",
      "Epoch 17/35\n",
      "5148/5148 - 1s - loss: 0.6583 - accuracy: 0.8329 - val_loss: 1.6370 - val_accuracy: 0.5714\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.7433 - accuracy: 0.8289 - val_loss: 1.0622 - val_accuracy: 0.7407\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.7950 - accuracy: 0.8125 - val_loss: 0.6428 - val_accuracy: 0.8339\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.7773 - accuracy: 0.8215 - val_loss: 0.6266 - val_accuracy: 0.8323\n",
      "Epoch 21/35\n",
      "5148/5148 - 1s - loss: 0.6095 - accuracy: 0.8401 - val_loss: 0.7421 - val_accuracy: 0.8587\n",
      "Epoch 22/35\n",
      "5148/5148 - 2s - loss: 0.7049 - accuracy: 0.8256 - val_loss: 0.5614 - val_accuracy: 0.8385\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.6916 - accuracy: 0.8254 - val_loss: 0.5424 - val_accuracy: 0.8339\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.4901 - accuracy: 0.8592 - val_loss: 0.7636 - val_accuracy: 0.8540\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.4534 - accuracy: 0.8584 - val_loss: 0.5027 - val_accuracy: 0.8602\n",
      "Epoch 26/35\n",
      "5148/5148 - 1s - loss: 0.4693 - accuracy: 0.8463 - val_loss: 0.4754 - val_accuracy: 0.8292\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.4460 - accuracy: 0.8522 - val_loss: 0.7448 - val_accuracy: 0.7764\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.4439 - accuracy: 0.8502 - val_loss: 0.8607 - val_accuracy: 0.7702\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.4543 - accuracy: 0.8508 - val_loss: 1.1097 - val_accuracy: 0.5792\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.5195 - accuracy: 0.8294 - val_loss: 0.5011 - val_accuracy: 0.8556\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.4497 - accuracy: 0.8557 - val_loss: 0.5102 - val_accuracy: 0.8540\n",
      "Epoch 32/35\n",
      "5148/5148 - 2s - loss: 0.4298 - accuracy: 0.8528 - val_loss: 0.5203 - val_accuracy: 0.8416\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.4447 - accuracy: 0.8495 - val_loss: 0.5314 - val_accuracy: 0.8571\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3794 - accuracy: 0.8621 - val_loss: 0.4315 - val_accuracy: 0.8276\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3854 - accuracy: 0.8570 - val_loss: 0.4416 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 3.9083 - accuracy: 0.6369 - val_loss: 0.7536 - val_accuracy: 0.7826\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.5014 - accuracy: 0.7339 - val_loss: 1.3284 - val_accuracy: 0.6879\n",
      "Epoch 3/35\n",
      "5148/5148 - 1s - loss: 1.4431 - accuracy: 0.7331 - val_loss: 1.1301 - val_accuracy: 0.8416\n",
      "Epoch 4/35\n",
      "5148/5148 - 1s - loss: 1.2633 - accuracy: 0.7640 - val_loss: 2.5444 - val_accuracy: 0.5124\n",
      "Epoch 5/35\n",
      "5148/5148 - 2s - loss: 1.4292 - accuracy: 0.7517 - val_loss: 1.3459 - val_accuracy: 0.7888\n",
      "Epoch 6/35\n",
      "5148/5148 - 1s - loss: 0.8509 - accuracy: 0.8129 - val_loss: 1.3051 - val_accuracy: 0.7345\n",
      "Epoch 7/35\n",
      "5148/5148 - 1s - loss: 1.3470 - accuracy: 0.7603 - val_loss: 3.4975 - val_accuracy: 0.6087\n",
      "Epoch 8/35\n",
      "5148/5148 - 1s - loss: 0.9423 - accuracy: 0.8124 - val_loss: 0.8258 - val_accuracy: 0.8634\n",
      "Epoch 9/35\n",
      "5148/5148 - 1s - loss: 0.9973 - accuracy: 0.8015 - val_loss: 1.5451 - val_accuracy: 0.7283\n",
      "Epoch 10/35\n",
      "5148/5148 - 1s - loss: 1.0696 - accuracy: 0.7854 - val_loss: 4.8673 - val_accuracy: 0.5606\n",
      "Epoch 11/35\n",
      "5148/5148 - 1s - loss: 1.1916 - accuracy: 0.7951 - val_loss: 0.7154 - val_accuracy: 0.8556\n",
      "Epoch 12/35\n",
      "5148/5148 - 1s - loss: 0.6971 - accuracy: 0.8370 - val_loss: 0.5941 - val_accuracy: 0.8370\n",
      "Epoch 13/35\n",
      "5148/5148 - 1s - loss: 1.0006 - accuracy: 0.7890 - val_loss: 1.6031 - val_accuracy: 0.7376\n",
      "Epoch 14/35\n",
      "5148/5148 - 1s - loss: 1.0276 - accuracy: 0.7887 - val_loss: 0.8509 - val_accuracy: 0.7935\n",
      "Epoch 15/35\n",
      "5148/5148 - 2s - loss: 0.9839 - accuracy: 0.8028 - val_loss: 0.6876 - val_accuracy: 0.8339\n",
      "Epoch 16/35\n",
      "5148/5148 - 2s - loss: 1.0013 - accuracy: 0.7953 - val_loss: 0.6705 - val_accuracy: 0.8370\n",
      "Epoch 17/35\n",
      "5148/5148 - 2s - loss: 0.7357 - accuracy: 0.8267 - val_loss: 1.1457 - val_accuracy: 0.7345\n",
      "Epoch 18/35\n",
      "5148/5148 - 1s - loss: 0.6863 - accuracy: 0.8246 - val_loss: 0.6094 - val_accuracy: 0.8587\n",
      "Epoch 19/35\n",
      "5148/5148 - 1s - loss: 0.5498 - accuracy: 0.8473 - val_loss: 0.6151 - val_accuracy: 0.8587\n",
      "Epoch 20/35\n",
      "5148/5148 - 1s - loss: 0.4875 - accuracy: 0.8537 - val_loss: 0.5340 - val_accuracy: 0.8276\n",
      "Epoch 21/35\n",
      "5148/5148 - 2s - loss: 0.5914 - accuracy: 0.8244 - val_loss: 0.5103 - val_accuracy: 0.8307\n",
      "Epoch 22/35\n",
      "5148/5148 - 1s - loss: 0.5068 - accuracy: 0.8378 - val_loss: 0.5668 - val_accuracy: 0.8323\n",
      "Epoch 23/35\n",
      "5148/5148 - 1s - loss: 0.4633 - accuracy: 0.8456 - val_loss: 0.4609 - val_accuracy: 0.8571\n",
      "Epoch 24/35\n",
      "5148/5148 - 1s - loss: 0.4892 - accuracy: 0.8343 - val_loss: 0.5806 - val_accuracy: 0.8602\n",
      "Epoch 25/35\n",
      "5148/5148 - 1s - loss: 0.4631 - accuracy: 0.8508 - val_loss: 0.4747 - val_accuracy: 0.8292\n",
      "Epoch 26/35\n",
      "5148/5148 - 2s - loss: 0.4663 - accuracy: 0.8392 - val_loss: 0.4690 - val_accuracy: 0.8556\n",
      "Epoch 27/35\n",
      "5148/5148 - 1s - loss: 0.4779 - accuracy: 0.8322 - val_loss: 0.4411 - val_accuracy: 0.8307\n",
      "Epoch 28/35\n",
      "5148/5148 - 1s - loss: 0.4181 - accuracy: 0.8495 - val_loss: 0.4201 - val_accuracy: 0.8307\n",
      "Epoch 29/35\n",
      "5148/5148 - 1s - loss: 0.3992 - accuracy: 0.8549 - val_loss: 0.4237 - val_accuracy: 0.8602\n",
      "Epoch 30/35\n",
      "5148/5148 - 1s - loss: 0.3951 - accuracy: 0.8553 - val_loss: 0.4073 - val_accuracy: 0.8261\n",
      "Epoch 31/35\n",
      "5148/5148 - 1s - loss: 0.3656 - accuracy: 0.8605 - val_loss: 0.4408 - val_accuracy: 0.8556\n",
      "Epoch 32/35\n",
      "5148/5148 - 1s - loss: 0.3989 - accuracy: 0.8458 - val_loss: 0.4007 - val_accuracy: 0.8323\n",
      "Epoch 33/35\n",
      "5148/5148 - 1s - loss: 0.3831 - accuracy: 0.8535 - val_loss: 0.4002 - val_accuracy: 0.8354\n",
      "Epoch 34/35\n",
      "5148/5148 - 1s - loss: 0.3614 - accuracy: 0.8592 - val_loss: 0.5255 - val_accuracy: 0.7888\n",
      "Epoch 35/35\n",
      "5148/5148 - 1s - loss: 0.3858 - accuracy: 0.8570 - val_loss: 0.5573 - val_accuracy: 0.7842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:50:58,609] Trial 126 finished with value: 0.8633540272712708 and parameters: {'units': 100, 'dropout': 0.0, 'learning_rate': 0.0042711431301002715, 'epochs': 35, 'batch_size': 20, 'patience': 10, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:51:03,620] Trial 127 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 9.6801 - accuracy: 0.5866 - val_loss: 0.5039 - val_accuracy: 0.7811\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.5637 - accuracy: 0.7325 - val_loss: 0.7005 - val_accuracy: 0.5528\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.4710 - accuracy: 0.7958 - val_loss: 0.4389 - val_accuracy: 0.8121\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4513 - accuracy: 0.8108 - val_loss: 0.4631 - val_accuracy: 0.8478\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4874 - accuracy: 0.7906 - val_loss: 0.4775 - val_accuracy: 0.7531\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4746 - accuracy: 0.7939 - val_loss: 0.5206 - val_accuracy: 0.8602\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4405 - accuracy: 0.8137 - val_loss: 0.5207 - val_accuracy: 0.7329\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4832 - accuracy: 0.7918 - val_loss: 0.4515 - val_accuracy: 0.8447\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4708 - accuracy: 0.8032 - val_loss: 0.4400 - val_accuracy: 0.8447\n",
      "Epoch 10/25\n",
      "5148/5148 - 2s - loss: 0.4832 - accuracy: 0.8063 - val_loss: 0.5279 - val_accuracy: 0.7298\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4858 - accuracy: 0.7881 - val_loss: 0.4277 - val_accuracy: 0.8463\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4685 - accuracy: 0.8120 - val_loss: 0.4635 - val_accuracy: 0.7562\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.4514 - accuracy: 0.8184 - val_loss: 0.4118 - val_accuracy: 0.8571\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4209 - accuracy: 0.8376 - val_loss: 0.4039 - val_accuracy: 0.8540\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4133 - accuracy: 0.8399 - val_loss: 0.4141 - val_accuracy: 0.8183\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4305 - accuracy: 0.8258 - val_loss: 0.3959 - val_accuracy: 0.8307\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.4143 - accuracy: 0.8320 - val_loss: 0.4255 - val_accuracy: 0.8183\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4029 - accuracy: 0.8399 - val_loss: 0.3940 - val_accuracy: 0.8634\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4029 - accuracy: 0.8343 - val_loss: 0.3928 - val_accuracy: 0.8634\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4019 - accuracy: 0.8337 - val_loss: 0.3995 - val_accuracy: 0.8214\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3802 - accuracy: 0.8427 - val_loss: 0.3936 - val_accuracy: 0.8245\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3834 - accuracy: 0.8436 - val_loss: 0.3962 - val_accuracy: 0.8696\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3862 - accuracy: 0.8421 - val_loss: 0.3781 - val_accuracy: 0.8602\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3837 - accuracy: 0.8395 - val_loss: 0.3860 - val_accuracy: 0.8727\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3842 - accuracy: 0.8407 - val_loss: 0.4074 - val_accuracy: 0.8199\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 22.4554 - accuracy: 0.5744 - val_loss: 1.1663 - val_accuracy: 0.7748\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.9836 - accuracy: 0.7246 - val_loss: 0.5957 - val_accuracy: 0.7438\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.4767 - accuracy: 0.7980 - val_loss: 0.4432 - val_accuracy: 0.7748\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4388 - accuracy: 0.8188 - val_loss: 0.4341 - val_accuracy: 0.8478\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4966 - accuracy: 0.7774 - val_loss: 0.4567 - val_accuracy: 0.8416\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4842 - accuracy: 0.7834 - val_loss: 0.5457 - val_accuracy: 0.8602\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4461 - accuracy: 0.8092 - val_loss: 0.5162 - val_accuracy: 0.7220\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4471 - accuracy: 0.8157 - val_loss: 0.5093 - val_accuracy: 0.7267\n",
      "Epoch 9/25\n",
      "5148/5148 - 2s - loss: 0.4609 - accuracy: 0.7997 - val_loss: 0.4983 - val_accuracy: 0.8618\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4550 - accuracy: 0.8122 - val_loss: 0.4677 - val_accuracy: 0.7376\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4914 - accuracy: 0.7980 - val_loss: 0.5029 - val_accuracy: 0.8509\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4827 - accuracy: 0.8028 - val_loss: 0.4965 - val_accuracy: 0.8602\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.4616 - accuracy: 0.8125 - val_loss: 0.4807 - val_accuracy: 0.7562\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4569 - accuracy: 0.8135 - val_loss: 0.4021 - val_accuracy: 0.8556\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4491 - accuracy: 0.8178 - val_loss: 0.4150 - val_accuracy: 0.8339\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4375 - accuracy: 0.8166 - val_loss: 0.3946 - val_accuracy: 0.8509\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.4219 - accuracy: 0.8316 - val_loss: 0.3979 - val_accuracy: 0.8261\n",
      "Epoch 18/25\n",
      "5148/5148 - 3s - loss: 0.4238 - accuracy: 0.8267 - val_loss: 0.4003 - val_accuracy: 0.8602\n",
      "Epoch 19/25\n",
      "5148/5148 - 2s - loss: 0.4191 - accuracy: 0.8242 - val_loss: 0.3844 - val_accuracy: 0.8742\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4126 - accuracy: 0.8331 - val_loss: 0.3888 - val_accuracy: 0.8370\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4060 - accuracy: 0.8370 - val_loss: 0.3928 - val_accuracy: 0.8245\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.4102 - accuracy: 0.8349 - val_loss: 0.3819 - val_accuracy: 0.8727\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.4094 - accuracy: 0.8326 - val_loss: 0.4182 - val_accuracy: 0.8137\n",
      "Epoch 24/25\n",
      "5148/5148 - 2s - loss: 0.4281 - accuracy: 0.8192 - val_loss: 0.3864 - val_accuracy: 0.8307\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.4083 - accuracy: 0.8333 - val_loss: 0.3929 - val_accuracy: 0.8292\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 14.8580 - accuracy: 0.6030 - val_loss: 1.2217 - val_accuracy: 0.7096\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.6313 - accuracy: 0.7436 - val_loss: 0.9429 - val_accuracy: 0.4984\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.5023 - accuracy: 0.7743 - val_loss: 0.4598 - val_accuracy: 0.8354\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4554 - accuracy: 0.8065 - val_loss: 0.4697 - val_accuracy: 0.8463\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4827 - accuracy: 0.7830 - val_loss: 0.4425 - val_accuracy: 0.7811\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4964 - accuracy: 0.7749 - val_loss: 0.5128 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4823 - accuracy: 0.7799 - val_loss: 0.4203 - val_accuracy: 0.8447\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4319 - accuracy: 0.8139 - val_loss: 0.4023 - val_accuracy: 0.8478\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.5164 - accuracy: 0.7527 - val_loss: 0.4846 - val_accuracy: 0.8447\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.5115 - accuracy: 0.7859 - val_loss: 0.5190 - val_accuracy: 0.7345\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4846 - accuracy: 0.7889 - val_loss: 0.7117 - val_accuracy: 0.5171\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.5236 - accuracy: 0.7558 - val_loss: 0.4233 - val_accuracy: 0.8525\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.4449 - accuracy: 0.8238 - val_loss: 0.4404 - val_accuracy: 0.7671\n",
      "Epoch 14/25\n",
      "5148/5148 - 2s - loss: 0.4360 - accuracy: 0.8283 - val_loss: 0.4071 - val_accuracy: 0.8587\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4181 - accuracy: 0.8378 - val_loss: 0.4125 - val_accuracy: 0.8509\n",
      "Epoch 16/25\n",
      "5148/5148 - 2s - loss: 0.4203 - accuracy: 0.8312 - val_loss: 0.3994 - val_accuracy: 0.8323\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.4157 - accuracy: 0.8326 - val_loss: 0.4142 - val_accuracy: 0.8525\n",
      "Epoch 18/25\n",
      "5148/5148 - 2s - loss: 0.4138 - accuracy: 0.8329 - val_loss: 0.3872 - val_accuracy: 0.8742\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4232 - accuracy: 0.8226 - val_loss: 0.3934 - val_accuracy: 0.8649\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4247 - accuracy: 0.8238 - val_loss: 0.4068 - val_accuracy: 0.8292\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4190 - accuracy: 0.8322 - val_loss: 0.3970 - val_accuracy: 0.8261\n",
      "Epoch 22/25\n",
      "5148/5148 - 2s - loss: 0.4198 - accuracy: 0.8269 - val_loss: 0.3864 - val_accuracy: 0.8665\n",
      "Epoch 23/25\n",
      "5148/5148 - 2s - loss: 0.4183 - accuracy: 0.8244 - val_loss: 0.3962 - val_accuracy: 0.8307\n",
      "Epoch 24/25\n",
      "5148/5148 - 2s - loss: 0.4255 - accuracy: 0.8162 - val_loss: 0.3815 - val_accuracy: 0.8370\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.4236 - accuracy: 0.8193 - val_loss: 0.4562 - val_accuracy: 0.7640\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 15.7422 - accuracy: 0.5794 - val_loss: 1.1687 - val_accuracy: 0.7360\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.7213 - accuracy: 0.7420 - val_loss: 0.5463 - val_accuracy: 0.8525\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.5375 - accuracy: 0.7694 - val_loss: 0.4478 - val_accuracy: 0.7640\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4498 - accuracy: 0.8149 - val_loss: 0.4295 - val_accuracy: 0.8385\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4847 - accuracy: 0.7855 - val_loss: 0.4575 - val_accuracy: 0.8478\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4677 - accuracy: 0.7889 - val_loss: 0.4959 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4243 - accuracy: 0.8246 - val_loss: 0.4247 - val_accuracy: 0.8168\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4228 - accuracy: 0.8221 - val_loss: 0.4102 - val_accuracy: 0.8416\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4427 - accuracy: 0.8100 - val_loss: 0.4223 - val_accuracy: 0.8416\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4085 - accuracy: 0.8289 - val_loss: 0.4237 - val_accuracy: 0.8183\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4143 - accuracy: 0.8207 - val_loss: 0.5599 - val_accuracy: 0.8478\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.5044 - accuracy: 0.7690 - val_loss: 0.6239 - val_accuracy: 0.6398\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.5044 - accuracy: 0.7366 - val_loss: 0.6858 - val_accuracy: 0.5140\n",
      "Epoch 14/25\n",
      "5148/5148 - 2s - loss: 0.5419 - accuracy: 0.7001 - val_loss: 0.4698 - val_accuracy: 0.8494\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4445 - accuracy: 0.8056 - val_loss: 0.4475 - val_accuracy: 0.7780\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4192 - accuracy: 0.8219 - val_loss: 0.4239 - val_accuracy: 0.8276\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.3996 - accuracy: 0.8326 - val_loss: 0.3780 - val_accuracy: 0.8478\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.3791 - val_accuracy: 0.8494\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3834 - accuracy: 0.8388 - val_loss: 0.4147 - val_accuracy: 0.8090\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.3769 - accuracy: 0.8403 - val_loss: 0.4185 - val_accuracy: 0.8354\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.3610 - accuracy: 0.8493 - val_loss: 0.3642 - val_accuracy: 0.8634\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3516 - accuracy: 0.8539 - val_loss: 0.3593 - val_accuracy: 0.8618\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8638 - val_loss: 0.3611 - val_accuracy: 0.8665\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3419 - accuracy: 0.8619 - val_loss: 0.3661 - val_accuracy: 0.8587\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3421 - accuracy: 0.8650 - val_loss: 0.4229 - val_accuracy: 0.7935\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 17.6206 - accuracy: 0.5855 - val_loss: 1.7001 - val_accuracy: 0.6894\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.7671 - accuracy: 0.7277 - val_loss: 0.6932 - val_accuracy: 0.5668\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.4828 - accuracy: 0.7918 - val_loss: 0.4428 - val_accuracy: 0.7795\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4366 - accuracy: 0.8153 - val_loss: 0.4287 - val_accuracy: 0.8494\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4677 - accuracy: 0.7929 - val_loss: 0.4203 - val_accuracy: 0.8525\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4944 - accuracy: 0.7718 - val_loss: 0.5058 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4541 - accuracy: 0.8085 - val_loss: 0.5047 - val_accuracy: 0.7438\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4504 - accuracy: 0.8089 - val_loss: 0.4190 - val_accuracy: 0.7981\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4606 - accuracy: 0.7925 - val_loss: 0.4448 - val_accuracy: 0.8447\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4567 - accuracy: 0.8028 - val_loss: 0.4317 - val_accuracy: 0.7888\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4850 - accuracy: 0.7945 - val_loss: 0.4788 - val_accuracy: 0.7671\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4548 - accuracy: 0.8226 - val_loss: 0.4419 - val_accuracy: 0.8602\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.4305 - accuracy: 0.8267 - val_loss: 0.4177 - val_accuracy: 0.8245\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4457 - accuracy: 0.8139 - val_loss: 0.4178 - val_accuracy: 0.8587\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4398 - accuracy: 0.8164 - val_loss: 0.4579 - val_accuracy: 0.7562\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4298 - accuracy: 0.8219 - val_loss: 0.4003 - val_accuracy: 0.8587\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.4442 - accuracy: 0.8139 - val_loss: 0.4378 - val_accuracy: 0.7686\n",
      "Epoch 18/25\n",
      "5148/5148 - 1s - loss: 0.4371 - accuracy: 0.8129 - val_loss: 0.4098 - val_accuracy: 0.8602\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.4341 - accuracy: 0.8159 - val_loss: 0.3974 - val_accuracy: 0.8587\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4126 - accuracy: 0.8324 - val_loss: 0.3841 - val_accuracy: 0.8680\n",
      "Epoch 21/25\n",
      "5148/5148 - 1s - loss: 0.4064 - accuracy: 0.8343 - val_loss: 0.3960 - val_accuracy: 0.8276\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.4162 - accuracy: 0.8287 - val_loss: 0.3807 - val_accuracy: 0.8711\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.4009 - accuracy: 0.8339 - val_loss: 0.4119 - val_accuracy: 0.8183\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.4212 - accuracy: 0.8180 - val_loss: 0.3887 - val_accuracy: 0.8292\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.4045 - accuracy: 0.8304 - val_loss: 0.3867 - val_accuracy: 0.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:53:38,641] Trial 128 finished with value: 0.8717390894889832 and parameters: {'units': 95, 'dropout': 0.1, 'learning_rate': 0.009951546914523332, 'epochs': 25, 'batch_size': 25, 'patience': 7, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:53:41,474] Trial 129 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 5s - loss: 14.4887 - accuracy: 0.5567 - val_loss: 0.6160 - val_accuracy: 0.7780\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 0.8528 - accuracy: 0.6826 - val_loss: 0.6822 - val_accuracy: 0.5419\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.4846 - accuracy: 0.7801 - val_loss: 0.4443 - val_accuracy: 0.7795\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:53:50,061] Trial 130 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:53:52,748] Trial 131 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:03,454] Trial 132 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:08,860] Trial 133 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 4s - loss: 17.0176 - accuracy: 0.5651 - val_loss: 1.3080 - val_accuracy: 0.7919\n",
      "Epoch 2/25\n",
      "5148/5148 - 2s - loss: 2.8829 - accuracy: 0.6960 - val_loss: 0.8692 - val_accuracy: 0.8447\n",
      "Epoch 3/25\n",
      "5148/5148 - 2s - loss: 0.6290 - accuracy: 0.7883 - val_loss: 0.4384 - val_accuracy: 0.7857\n",
      "Epoch 4/25\n",
      "5148/5148 - 2s - loss: 0.4748 - accuracy: 0.8015 - val_loss: 0.4284 - val_accuracy: 0.8245\n",
      "Epoch 5/25\n",
      "5148/5148 - 2s - loss: 0.4865 - accuracy: 0.7881 - val_loss: 0.3988 - val_accuracy: 0.8447\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:24,115] Trial 134 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:28,828] Trial 135 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:32,365] Trial 136 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 4s - loss: 20.6231 - accuracy: 0.5313 - val_loss: 0.9287 - val_accuracy: 0.7764\n",
      "Epoch 2/35\n",
      "5148/5148 - 2s - loss: 2.4660 - accuracy: 0.6605 - val_loss: 1.1337 - val_accuracy: 0.4984\n",
      "Epoch 3/35\n",
      "5148/5148 - 3s - loss: 0.6422 - accuracy: 0.7341 - val_loss: 0.5515 - val_accuracy: 0.7407\n",
      "Epoch 4/35\n",
      "5148/5148 - 2s - loss: 0.5026 - accuracy: 0.7890 - val_loss: 0.4595 - val_accuracy: 0.8494\n",
      "Epoch 5/35\n",
      "5148/5148 - 3s - loss: 0.5752 - accuracy: 0.7395 - val_loss: 0.4110 - val_accuracy: 0.8416\n",
      "Epoch 6/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:49,413] Trial 137 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "5148/5148 - 3s - loss: 21.1387 - accuracy: 0.5412 - val_loss: 0.5730 - val_accuracy: 0.7609\n",
      "Epoch 2/5\n",
      "5148/5148 - 1s - loss: 0.8561 - accuracy: 0.5340 - val_loss: 0.8934 - val_accuracy: 0.4922\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:54:55,695] Trial 138 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 25.8541 - accuracy: 0.5554 - val_loss: 1.9328 - val_accuracy: 0.7748\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 3.7450 - accuracy: 0.7001 - val_loss: 1.2110 - val_accuracy: 0.8478\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.9717 - accuracy: 0.7620 - val_loss: 0.4822 - val_accuracy: 0.7671\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4674 - accuracy: 0.8094 - val_loss: 0.4688 - val_accuracy: 0.8571\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4882 - accuracy: 0.7906 - val_loss: 0.4205 - val_accuracy: 0.8447\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 0.4387 - accuracy: 0.8160 - val_loss: 0.4951 - val_accuracy: 0.8587\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 0.3978 - accuracy: 0.8384 - val_loss: 0.4235 - val_accuracy: 0.7919\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.3982 - accuracy: 0.8384 - val_loss: 0.4096 - val_accuracy: 0.8401\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4204 - accuracy: 0.8258 - val_loss: 0.4082 - val_accuracy: 0.8540\n",
      "Epoch 10/30\n",
      "5148/5148 - 2s - loss: 0.3882 - accuracy: 0.8465 - val_loss: 0.4743 - val_accuracy: 0.7360\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.3988 - accuracy: 0.8335 - val_loss: 0.4073 - val_accuracy: 0.8494\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4087 - accuracy: 0.8390 - val_loss: 0.4033 - val_accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.3816 - accuracy: 0.8491 - val_loss: 0.3734 - val_accuracy: 0.8556\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.3539 - accuracy: 0.8673 - val_loss: 0.3692 - val_accuracy: 0.8618\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3463 - accuracy: 0.8689 - val_loss: 0.4264 - val_accuracy: 0.7935\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3401 - accuracy: 0.8708 - val_loss: 0.3555 - val_accuracy: 0.8618\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3346 - accuracy: 0.8706 - val_loss: 0.3503 - val_accuracy: 0.8571\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3431 - accuracy: 0.8693 - val_loss: 0.3622 - val_accuracy: 0.8634\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3456 - accuracy: 0.8650 - val_loss: 0.3405 - val_accuracy: 0.8665\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3580 - accuracy: 0.8625 - val_loss: 0.3603 - val_accuracy: 0.8665\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3341 - accuracy: 0.8726 - val_loss: 0.3619 - val_accuracy: 0.8587\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3356 - accuracy: 0.8609 - val_loss: 0.3385 - val_accuracy: 0.8680\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3300 - accuracy: 0.8619 - val_loss: 0.3398 - val_accuracy: 0.8618\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3262 - accuracy: 0.8627 - val_loss: 0.3454 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 2s - loss: 0.3107 - accuracy: 0.8642 - val_loss: 0.3423 - val_accuracy: 0.8634\n",
      "Epoch 26/30\n",
      "5148/5148 - 2s - loss: 0.3141 - accuracy: 0.8666 - val_loss: 0.3292 - val_accuracy: 0.8665\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3184 - accuracy: 0.8631 - val_loss: 0.3353 - val_accuracy: 0.8634\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3181 - accuracy: 0.8634 - val_loss: 0.3175 - val_accuracy: 0.8587\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3484 - accuracy: 0.8642 - val_loss: 0.3581 - val_accuracy: 0.8525\n",
      "Epoch 30/30\n",
      "5148/5148 - 2s - loss: 0.3413 - accuracy: 0.8660 - val_loss: 0.3460 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 15.9981 - accuracy: 0.5950 - val_loss: 2.3901 - val_accuracy: 0.6724\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 1.4517 - accuracy: 0.7226 - val_loss: 0.7228 - val_accuracy: 0.6677\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.4690 - accuracy: 0.8009 - val_loss: 0.4767 - val_accuracy: 0.7531\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4400 - accuracy: 0.8151 - val_loss: 0.4243 - val_accuracy: 0.8385\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4408 - accuracy: 0.8129 - val_loss: 0.4387 - val_accuracy: 0.8571\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4807 - accuracy: 0.7863 - val_loss: 0.7079 - val_accuracy: 0.5512\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4519 - accuracy: 0.8098 - val_loss: 0.5474 - val_accuracy: 0.7174\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4354 - accuracy: 0.8127 - val_loss: 0.4658 - val_accuracy: 0.7391\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4601 - accuracy: 0.8050 - val_loss: 0.5081 - val_accuracy: 0.8618\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4608 - accuracy: 0.8362 - val_loss: 0.5078 - val_accuracy: 0.7391\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4648 - accuracy: 0.8001 - val_loss: 0.7450 - val_accuracy: 0.5885\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4244 - accuracy: 0.8364 - val_loss: 0.4149 - val_accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4049 - accuracy: 0.8432 - val_loss: 0.3965 - val_accuracy: 0.8463\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4032 - accuracy: 0.8380 - val_loss: 0.4185 - val_accuracy: 0.8587\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4145 - accuracy: 0.8318 - val_loss: 0.4321 - val_accuracy: 0.7888\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.3972 - accuracy: 0.8429 - val_loss: 0.3849 - val_accuracy: 0.8618\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3775 - accuracy: 0.8483 - val_loss: 0.3845 - val_accuracy: 0.8665\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.3812 - accuracy: 0.8444 - val_loss: 0.3810 - val_accuracy: 0.8634\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3797 - accuracy: 0.8442 - val_loss: 0.3794 - val_accuracy: 0.8339\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3836 - accuracy: 0.8427 - val_loss: 0.3788 - val_accuracy: 0.8339\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3721 - accuracy: 0.8533 - val_loss: 0.3946 - val_accuracy: 0.8261\n",
      "Epoch 22/30\n",
      "5148/5148 - 2s - loss: 0.3870 - accuracy: 0.8411 - val_loss: 0.3747 - val_accuracy: 0.8696\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3726 - accuracy: 0.8444 - val_loss: 0.3753 - val_accuracy: 0.8323\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3782 - accuracy: 0.8395 - val_loss: 0.3711 - val_accuracy: 0.8556\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3642 - accuracy: 0.8506 - val_loss: 0.3917 - val_accuracy: 0.8323\n",
      "Epoch 26/30\n",
      "5148/5148 - 2s - loss: 0.3771 - accuracy: 0.8411 - val_loss: 0.3709 - val_accuracy: 0.8401\n",
      "Epoch 27/30\n",
      "5148/5148 - 3s - loss: 0.3691 - accuracy: 0.8458 - val_loss: 0.3865 - val_accuracy: 0.8354\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.3787 - accuracy: 0.8403 - val_loss: 0.4361 - val_accuracy: 0.8602\n",
      "Epoch 29/30\n",
      "5148/5148 - 2s - loss: 0.3765 - accuracy: 0.8491 - val_loss: 0.3734 - val_accuracy: 0.8261\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3557 - accuracy: 0.8528 - val_loss: 0.3701 - val_accuracy: 0.8370\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 14.7961 - accuracy: 0.5979 - val_loss: 2.9000 - val_accuracy: 0.7314\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 2.0843 - accuracy: 0.7121 - val_loss: 0.7888 - val_accuracy: 0.6630\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.4832 - accuracy: 0.7988 - val_loss: 0.4270 - val_accuracy: 0.7904\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4291 - accuracy: 0.8234 - val_loss: 0.4180 - val_accuracy: 0.8478\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4405 - accuracy: 0.8139 - val_loss: 0.4192 - val_accuracy: 0.8509\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4253 - accuracy: 0.8275 - val_loss: 0.5304 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4037 - accuracy: 0.8347 - val_loss: 0.4514 - val_accuracy: 0.7438\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.4003 - accuracy: 0.8382 - val_loss: 0.3951 - val_accuracy: 0.8509\n",
      "Epoch 9/30\n",
      "5148/5148 - 2s - loss: 0.4029 - accuracy: 0.8310 - val_loss: 0.4134 - val_accuracy: 0.8494\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4270 - accuracy: 0.8188 - val_loss: 0.4116 - val_accuracy: 0.8556\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4297 - accuracy: 0.8147 - val_loss: 0.6501 - val_accuracy: 0.6848\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4142 - accuracy: 0.8318 - val_loss: 0.5513 - val_accuracy: 0.6444\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4633 - accuracy: 0.8197 - val_loss: 0.4807 - val_accuracy: 0.7593\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4252 - accuracy: 0.8460 - val_loss: 0.4552 - val_accuracy: 0.8634\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3941 - accuracy: 0.8547 - val_loss: 0.4062 - val_accuracy: 0.8199\n",
      "Epoch 16/30\n",
      "5148/5148 - 2s - loss: 0.3988 - accuracy: 0.8390 - val_loss: 0.4718 - val_accuracy: 0.7562\n",
      "Epoch 17/30\n",
      "5148/5148 - 2s - loss: 0.4092 - accuracy: 0.8399 - val_loss: 0.4114 - val_accuracy: 0.8602\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.3976 - accuracy: 0.8436 - val_loss: 0.3851 - val_accuracy: 0.8696\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.3843 - accuracy: 0.8407 - val_loss: 0.4058 - val_accuracy: 0.8587\n",
      "Epoch 20/30\n",
      "5148/5148 - 2s - loss: 0.4066 - accuracy: 0.8347 - val_loss: 0.4137 - val_accuracy: 0.8137\n",
      "Epoch 21/30\n",
      "5148/5148 - 2s - loss: 0.3688 - accuracy: 0.8553 - val_loss: 0.3787 - val_accuracy: 0.8370\n",
      "Epoch 22/30\n",
      "5148/5148 - 2s - loss: 0.3889 - accuracy: 0.8423 - val_loss: 0.3919 - val_accuracy: 0.8602\n",
      "Epoch 23/30\n",
      "5148/5148 - 2s - loss: 0.3931 - accuracy: 0.8357 - val_loss: 0.3852 - val_accuracy: 0.8245\n",
      "Epoch 24/30\n",
      "5148/5148 - 2s - loss: 0.3835 - accuracy: 0.8434 - val_loss: 0.3746 - val_accuracy: 0.8401\n",
      "Epoch 25/30\n",
      "5148/5148 - 2s - loss: 0.3791 - accuracy: 0.8438 - val_loss: 0.3878 - val_accuracy: 0.8292\n",
      "Epoch 26/30\n",
      "5148/5148 - 2s - loss: 0.3716 - accuracy: 0.8463 - val_loss: 0.3748 - val_accuracy: 0.8696\n",
      "Epoch 27/30\n",
      "5148/5148 - 2s - loss: 0.3603 - accuracy: 0.8516 - val_loss: 0.3747 - val_accuracy: 0.8618\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.3652 - accuracy: 0.8489 - val_loss: 0.3941 - val_accuracy: 0.8587\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3709 - accuracy: 0.8456 - val_loss: 0.3833 - val_accuracy: 0.8634\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3597 - accuracy: 0.8502 - val_loss: 0.3867 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 18.4502 - accuracy: 0.5707 - val_loss: 1.8330 - val_accuracy: 0.8354\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.3007 - accuracy: 0.7145 - val_loss: 1.0364 - val_accuracy: 0.5761\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.5348 - accuracy: 0.7916 - val_loss: 0.4271 - val_accuracy: 0.8106\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4258 - accuracy: 0.8293 - val_loss: 0.4260 - val_accuracy: 0.8478\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 0.4669 - accuracy: 0.7912 - val_loss: 0.4558 - val_accuracy: 0.8556\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4520 - accuracy: 0.8052 - val_loss: 0.5912 - val_accuracy: 0.7578\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4290 - accuracy: 0.8215 - val_loss: 0.4899 - val_accuracy: 0.7360\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.4185 - accuracy: 0.8300 - val_loss: 0.4497 - val_accuracy: 0.7531\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4248 - accuracy: 0.8242 - val_loss: 0.4529 - val_accuracy: 0.8525\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.4243 - accuracy: 0.8244 - val_loss: 0.5258 - val_accuracy: 0.7252\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4136 - accuracy: 0.8260 - val_loss: 0.4984 - val_accuracy: 0.7065\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4215 - accuracy: 0.8246 - val_loss: 0.4156 - val_accuracy: 0.8587\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4043 - accuracy: 0.8322 - val_loss: 0.4183 - val_accuracy: 0.8059\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4015 - accuracy: 0.8407 - val_loss: 0.4462 - val_accuracy: 0.8602\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4288 - accuracy: 0.8188 - val_loss: 0.4312 - val_accuracy: 0.7702\n",
      "Epoch 16/30\n",
      "5148/5148 - 3s - loss: 0.3845 - accuracy: 0.8291 - val_loss: 0.3582 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 2s - loss: 0.4211 - accuracy: 0.8083 - val_loss: 0.4358 - val_accuracy: 0.8152\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.3890 - accuracy: 0.8535 - val_loss: 0.3730 - val_accuracy: 0.8680\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.3769 - accuracy: 0.8576 - val_loss: 0.3855 - val_accuracy: 0.8649\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3761 - accuracy: 0.8572 - val_loss: 0.4359 - val_accuracy: 0.8059\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3473 - accuracy: 0.8640 - val_loss: 0.3427 - val_accuracy: 0.8587\n",
      "Epoch 22/30\n",
      "5148/5148 - 2s - loss: 0.3566 - accuracy: 0.8594 - val_loss: 0.3790 - val_accuracy: 0.8665\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3840 - accuracy: 0.8642 - val_loss: 0.3714 - val_accuracy: 0.8649\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3707 - accuracy: 0.8652 - val_loss: 0.3849 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3652 - accuracy: 0.8662 - val_loss: 0.3884 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3578 - accuracy: 0.8679 - val_loss: 0.3811 - val_accuracy: 0.8618\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3659 - accuracy: 0.8646 - val_loss: 0.3622 - val_accuracy: 0.8649\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3659 - accuracy: 0.8685 - val_loss: 0.3925 - val_accuracy: 0.8540\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3600 - accuracy: 0.8658 - val_loss: 0.3663 - val_accuracy: 0.8602\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3654 - accuracy: 0.8627 - val_loss: 0.3661 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 22.4922 - accuracy: 0.5556 - val_loss: 1.7819 - val_accuracy: 0.8416\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 3.1174 - accuracy: 0.6956 - val_loss: 1.5463 - val_accuracy: 0.5792\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 0.7016 - accuracy: 0.7786 - val_loss: 0.4325 - val_accuracy: 0.7935\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 0.4360 - accuracy: 0.8232 - val_loss: 0.4631 - val_accuracy: 0.8509\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 0.4576 - accuracy: 0.8092 - val_loss: 0.4347 - val_accuracy: 0.8540\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 0.4450 - accuracy: 0.8127 - val_loss: 0.5202 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 0.4053 - accuracy: 0.8341 - val_loss: 0.4384 - val_accuracy: 0.7562\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.3926 - accuracy: 0.8413 - val_loss: 0.4010 - val_accuracy: 0.8509\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 0.4229 - accuracy: 0.8199 - val_loss: 0.4189 - val_accuracy: 0.8525\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.3927 - accuracy: 0.8425 - val_loss: 0.4610 - val_accuracy: 0.7422\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 0.4015 - accuracy: 0.8293 - val_loss: 0.4115 - val_accuracy: 0.8509\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.4043 - accuracy: 0.8419 - val_loss: 0.4330 - val_accuracy: 0.8649\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.4118 - accuracy: 0.8273 - val_loss: 0.4439 - val_accuracy: 0.8602\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.4063 - accuracy: 0.8366 - val_loss: 0.4081 - val_accuracy: 0.8649\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.3995 - accuracy: 0.8388 - val_loss: 0.3985 - val_accuracy: 0.8478\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8361 - val_loss: 0.3703 - val_accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3882 - accuracy: 0.8520 - val_loss: 0.4285 - val_accuracy: 0.8276\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3770 - accuracy: 0.8543 - val_loss: 0.3634 - val_accuracy: 0.8665\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.3844 - accuracy: 0.8477 - val_loss: 0.4055 - val_accuracy: 0.8478\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.3625 - accuracy: 0.8576 - val_loss: 0.3511 - val_accuracy: 0.8649\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.3640 - accuracy: 0.8578 - val_loss: 0.4847 - val_accuracy: 0.8509\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.3849 - accuracy: 0.8570 - val_loss: 0.3815 - val_accuracy: 0.8634\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3684 - accuracy: 0.8656 - val_loss: 0.3658 - val_accuracy: 0.8556\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3635 - accuracy: 0.8617 - val_loss: 0.3775 - val_accuracy: 0.8556\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3633 - accuracy: 0.8642 - val_loss: 0.3760 - val_accuracy: 0.8540\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3582 - accuracy: 0.8708 - val_loss: 0.3981 - val_accuracy: 0.8525\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3702 - accuracy: 0.8621 - val_loss: 0.3649 - val_accuracy: 0.8649\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3660 - accuracy: 0.8644 - val_loss: 0.5333 - val_accuracy: 0.7997\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3690 - accuracy: 0.8642 - val_loss: 0.3663 - val_accuracy: 0.8587\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3521 - accuracy: 0.8629 - val_loss: 0.3681 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:58:21,116] Trial 139 finished with value: 0.8695651888847351 and parameters: {'units': 90, 'dropout': 0.05, 'learning_rate': 0.00989698934188975, 'epochs': 30, 'batch_size': 25, 'patience': 7, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:58:28,768] Trial 140 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:58:33,402] Trial 141 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:58:38,108] Trial 142 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 4s - loss: 14.2111 - accuracy: 0.5528 - val_loss: 1.4055 - val_accuracy: 0.7547\n",
      "Epoch 2/40\n",
      "5148/5148 - 4s - loss: 2.4764 - accuracy: 0.6999 - val_loss: 0.9703 - val_accuracy: 0.8199\n",
      "Epoch 3/40\n",
      "5148/5148 - 4s - loss: 0.6645 - accuracy: 0.7626 - val_loss: 0.4407 - val_accuracy: 0.7811\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:58:53,305] Trial 143 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 6s - loss: 23.5191 - accuracy: 0.5435 - val_loss: 1.9145 - val_accuracy: 0.7531\n",
      "Epoch 2/35\n",
      "5148/5148 - 4s - loss: 6.2396 - accuracy: 0.6480 - val_loss: 2.3136 - val_accuracy: 0.6553\n",
      "Epoch 3/35\n",
      "5148/5148 - 4s - loss: 1.7911 - accuracy: 0.7380 - val_loss: 0.6523 - val_accuracy: 0.8401\n",
      "Epoch 4/35\n",
      "5148/5148 - 4s - loss: 0.6002 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.8525\n",
      "Epoch 5/35\n",
      "5148/5148 - 5s - loss: 0.4746 - accuracy: 0.7980 - val_loss: 0.4314 - val_accuracy: 0.8370\n",
      "Epoch 6/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:21,608] Trial 144 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:26,205] Trial 145 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 30.2841 - accuracy: 0.5175 - val_loss: 0.9174 - val_accuracy: 0.8370\n",
      "Epoch 2/30\n",
      "5148/5148 - 3s - loss: 9.3206 - accuracy: 0.5849 - val_loss: 2.5241 - val_accuracy: 0.5264\n",
      "Epoch 3/30\n",
      "5148/5148 - 3s - loss: 2.3129 - accuracy: 0.7036 - val_loss: 0.9394 - val_accuracy: 0.7407\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:38,814] Trial 146 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n",
      "5148/5148 - 3s - loss: 10.7062 - accuracy: 0.6764 - val_loss: 0.6662 - val_accuracy: 0.7500\n",
      "Epoch 2/35\n",
      "5148/5148 - 1s - loss: 1.2565 - accuracy: 0.7211 - val_loss: 1.1323 - val_accuracy: 0.7127\n",
      "Epoch 3/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:44,665] Trial 147 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:47,478] Trial 148 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:50,002] Trial 149 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:53,963] Trial 150 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 22:59:58,038] Trial 151 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:00:02,192] Trial 152 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:00:07,025] Trial 153 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 4s - loss: 20.8403 - accuracy: 0.5486 - val_loss: 0.4919 - val_accuracy: 0.7655\n",
      "Epoch 2/45\n",
      "5148/5148 - 3s - loss: 0.7435 - accuracy: 0.6362 - val_loss: 0.5296 - val_accuracy: 0.8354\n",
      "Epoch 3/45\n",
      "5148/5148 - 3s - loss: 0.5938 - accuracy: 0.6974 - val_loss: 0.5174 - val_accuracy: 0.7438\n",
      "Epoch 4/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:00:19,941] Trial 154 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 10.1702 - accuracy: 0.6579 - val_loss: 1.1169 - val_accuracy: 0.7842\n",
      "Epoch 2/30\n",
      "5148/5148 - 4s - loss: 2.3339 - accuracy: 0.7411 - val_loss: 2.2708 - val_accuracy: 0.6848\n",
      "Epoch 3/30\n",
      "5148/5148 - 3s - loss: 2.1444 - accuracy: 0.7490 - val_loss: 0.9701 - val_accuracy: 0.8587\n",
      "Epoch 4/30\n",
      "5148/5148 - 3s - loss: 1.5085 - accuracy: 0.7894 - val_loss: 2.8628 - val_accuracy: 0.5217\n",
      "Epoch 5/30\n",
      "5148/5148 - 4s - loss: 1.9426 - accuracy: 0.7479 - val_loss: 1.2620 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "5148/5148 - 5s - loss: 1.0284 - accuracy: 0.8219 - val_loss: 3.8715 - val_accuracy: 0.6149\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.8375 - accuracy: 0.7455 - val_loss: 1.6085 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 0.8729 - accuracy: 0.8364 - val_loss: 1.7090 - val_accuracy: 0.5885\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.0409 - accuracy: 0.7900 - val_loss: 0.6852 - val_accuracy: 0.8261\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.9893 - accuracy: 0.7953 - val_loss: 3.7130 - val_accuracy: 0.5963\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 0.9956 - accuracy: 0.8046 - val_loss: 0.7151 - val_accuracy: 0.8587\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.6442 - accuracy: 0.8322 - val_loss: 0.9886 - val_accuracy: 0.7624\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.7688 - accuracy: 0.8054 - val_loss: 1.3880 - val_accuracy: 0.7314\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.7553 - accuracy: 0.8052 - val_loss: 0.6936 - val_accuracy: 0.7748\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.5180 - accuracy: 0.8497 - val_loss: 0.5762 - val_accuracy: 0.8323\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.4560 - accuracy: 0.8473 - val_loss: 0.4483 - val_accuracy: 0.8556\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.4175 - accuracy: 0.8528 - val_loss: 0.6495 - val_accuracy: 0.8494\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.4309 - accuracy: 0.8458 - val_loss: 0.5485 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.4922 - accuracy: 0.8269 - val_loss: 0.4585 - val_accuracy: 0.8292\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4659 - accuracy: 0.8376 - val_loss: 0.4511 - val_accuracy: 0.8245\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4993 - accuracy: 0.8252 - val_loss: 0.4108 - val_accuracy: 0.8385\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4384 - accuracy: 0.8362 - val_loss: 0.4862 - val_accuracy: 0.8152\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.4035 - accuracy: 0.8436 - val_loss: 0.4027 - val_accuracy: 0.8571\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3591 - accuracy: 0.8576 - val_loss: 0.4155 - val_accuracy: 0.8556\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3396 - accuracy: 0.8605 - val_loss: 0.4091 - val_accuracy: 0.8556\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3508 - accuracy: 0.8576 - val_loss: 0.3792 - val_accuracy: 0.8432\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3657 - accuracy: 0.8522 - val_loss: 0.4638 - val_accuracy: 0.7935\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3511 - accuracy: 0.8528 - val_loss: 0.5341 - val_accuracy: 0.7780\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3702 - accuracy: 0.8541 - val_loss: 0.3885 - val_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3651 - accuracy: 0.8520 - val_loss: 0.3736 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 5.3791 - accuracy: 0.6634 - val_loss: 2.1417 - val_accuracy: 0.5559\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 1.6858 - accuracy: 0.7387 - val_loss: 0.9629 - val_accuracy: 0.7655\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 2.1760 - accuracy: 0.7284 - val_loss: 1.8238 - val_accuracy: 0.7453\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 1.2690 - accuracy: 0.8024 - val_loss: 2.8552 - val_accuracy: 0.5202\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 1.4478 - accuracy: 0.7613 - val_loss: 1.0319 - val_accuracy: 0.8602\n",
      "Epoch 6/30\n",
      "5148/5148 - 3s - loss: 0.8822 - accuracy: 0.8087 - val_loss: 3.1335 - val_accuracy: 0.6180\n",
      "Epoch 7/30\n",
      "5148/5148 - 3s - loss: 1.1986 - accuracy: 0.7809 - val_loss: 2.0690 - val_accuracy: 0.7081\n",
      "Epoch 8/30\n",
      "5148/5148 - 3s - loss: 0.8204 - accuracy: 0.8197 - val_loss: 1.5795 - val_accuracy: 0.5621\n",
      "Epoch 9/30\n",
      "5148/5148 - 3s - loss: 1.0315 - accuracy: 0.7861 - val_loss: 0.5908 - val_accuracy: 0.8385\n",
      "Epoch 10/30\n",
      "5148/5148 - 4s - loss: 0.7861 - accuracy: 0.8073 - val_loss: 1.5384 - val_accuracy: 0.7174\n",
      "Epoch 11/30\n",
      "5148/5148 - 4s - loss: 0.7602 - accuracy: 0.8151 - val_loss: 0.6556 - val_accuracy: 0.8587\n",
      "Epoch 12/30\n",
      "5148/5148 - 5s - loss: 0.5248 - accuracy: 0.8409 - val_loss: 0.4652 - val_accuracy: 0.8339\n",
      "Epoch 13/30\n",
      "5148/5148 - 3s - loss: 0.7415 - accuracy: 0.7976 - val_loss: 1.1993 - val_accuracy: 0.7345\n",
      "Epoch 14/30\n",
      "5148/5148 - 4s - loss: 0.6278 - accuracy: 0.8166 - val_loss: 0.6068 - val_accuracy: 0.7748\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.4562 - accuracy: 0.8495 - val_loss: 0.5033 - val_accuracy: 0.8307\n",
      "Epoch 16/30\n",
      "5148/5148 - 2s - loss: 0.4162 - accuracy: 0.8465 - val_loss: 0.4102 - val_accuracy: 0.8540\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.3904 - accuracy: 0.8498 - val_loss: 0.5307 - val_accuracy: 0.8587\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.3987 - accuracy: 0.8487 - val_loss: 0.5012 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.4494 - accuracy: 0.8361 - val_loss: 0.4014 - val_accuracy: 0.8370\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4209 - accuracy: 0.8409 - val_loss: 0.4393 - val_accuracy: 0.8292\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4721 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8323\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.4105 - accuracy: 0.8384 - val_loss: 0.4797 - val_accuracy: 0.7842\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.3708 - accuracy: 0.8493 - val_loss: 0.3770 - val_accuracy: 0.8587\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3495 - accuracy: 0.8539 - val_loss: 0.3822 - val_accuracy: 0.8618\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3314 - accuracy: 0.8621 - val_loss: 0.3961 - val_accuracy: 0.8556\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3424 - accuracy: 0.8576 - val_loss: 0.3860 - val_accuracy: 0.8571\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3586 - accuracy: 0.8539 - val_loss: 0.3861 - val_accuracy: 0.8323\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.3411 - accuracy: 0.8535 - val_loss: 0.4507 - val_accuracy: 0.7919\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3512 - accuracy: 0.8551 - val_loss: 0.3726 - val_accuracy: 0.8649\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3520 - accuracy: 0.8547 - val_loss: 0.3707 - val_accuracy: 0.8354\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 8.3520 - accuracy: 0.6503 - val_loss: 2.6299 - val_accuracy: 0.5264\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.8773 - accuracy: 0.7389 - val_loss: 0.9072 - val_accuracy: 0.8463\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 2.4359 - accuracy: 0.7312 - val_loss: 1.4175 - val_accuracy: 0.8618\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 1.8661 - accuracy: 0.7650 - val_loss: 4.2576 - val_accuracy: 0.5124\n",
      "Epoch 5/30\n",
      "5148/5148 - 2s - loss: 2.2159 - accuracy: 0.7494 - val_loss: 9.8874 - val_accuracy: 0.4922\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 1.6350 - accuracy: 0.7962 - val_loss: 1.0313 - val_accuracy: 0.8587\n",
      "Epoch 7/30\n",
      "5148/5148 - 1s - loss: 1.7201 - accuracy: 0.7768 - val_loss: 1.3129 - val_accuracy: 0.7547\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 1.0666 - accuracy: 0.8219 - val_loss: 2.0131 - val_accuracy: 0.5699\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.3317 - accuracy: 0.7815 - val_loss: 0.8177 - val_accuracy: 0.8276\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 1.2259 - accuracy: 0.7980 - val_loss: 1.8238 - val_accuracy: 0.7345\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 1.1557 - accuracy: 0.8050 - val_loss: 0.9935 - val_accuracy: 0.8618\n",
      "Epoch 12/30\n",
      "5148/5148 - 1s - loss: 0.9293 - accuracy: 0.8174 - val_loss: 1.1957 - val_accuracy: 0.7686\n",
      "Epoch 13/30\n",
      "5148/5148 - 1s - loss: 0.6661 - accuracy: 0.8403 - val_loss: 0.6951 - val_accuracy: 0.8276\n",
      "Epoch 14/30\n",
      "5148/5148 - 1s - loss: 0.7122 - accuracy: 0.8314 - val_loss: 0.7420 - val_accuracy: 0.8602\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.6907 - accuracy: 0.8269 - val_loss: 2.5332 - val_accuracy: 0.4984\n",
      "Epoch 16/30\n",
      "5148/5148 - 2s - loss: 0.6131 - accuracy: 0.8351 - val_loss: 0.6566 - val_accuracy: 0.8354\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5647 - accuracy: 0.8386 - val_loss: 1.2237 - val_accuracy: 0.6025\n",
      "Epoch 18/30\n",
      "5148/5148 - 1s - loss: 0.6429 - accuracy: 0.8226 - val_loss: 0.8718 - val_accuracy: 0.7919\n",
      "Epoch 19/30\n",
      "5148/5148 - 1s - loss: 0.6764 - accuracy: 0.8104 - val_loss: 0.5293 - val_accuracy: 0.8339\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.7225 - accuracy: 0.8178 - val_loss: 0.5603 - val_accuracy: 0.8292\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.5425 - accuracy: 0.8407 - val_loss: 0.6194 - val_accuracy: 0.8634\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.6165 - accuracy: 0.8226 - val_loss: 0.5066 - val_accuracy: 0.8587\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.6138 - accuracy: 0.8277 - val_loss: 0.4875 - val_accuracy: 0.8354\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4799 - accuracy: 0.8458 - val_loss: 0.5562 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.4860 - accuracy: 0.8425 - val_loss: 0.4788 - val_accuracy: 0.8540\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.5154 - accuracy: 0.8316 - val_loss: 0.5565 - val_accuracy: 0.8602\n",
      "Epoch 27/30\n",
      "5148/5148 - 2s - loss: 0.5550 - accuracy: 0.8256 - val_loss: 0.5113 - val_accuracy: 0.8587\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.4651 - accuracy: 0.8442 - val_loss: 0.4273 - val_accuracy: 0.8385\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.5942 - accuracy: 0.8125 - val_loss: 1.1224 - val_accuracy: 0.5792\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.5349 - accuracy: 0.8256 - val_loss: 0.5092 - val_accuracy: 0.8571\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 2s - loss: 9.7303 - accuracy: 0.6544 - val_loss: 2.4961 - val_accuracy: 0.6693\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 1.6013 - accuracy: 0.7733 - val_loss: 1.4272 - val_accuracy: 0.7034\n",
      "Epoch 3/30\n",
      "5148/5148 - 1s - loss: 2.0218 - accuracy: 0.7498 - val_loss: 2.5666 - val_accuracy: 0.6801\n",
      "Epoch 4/30\n",
      "5148/5148 - 1s - loss: 1.7037 - accuracy: 0.7686 - val_loss: 3.5049 - val_accuracy: 0.5124\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 2.0171 - accuracy: 0.7465 - val_loss: 1.1924 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "5148/5148 - 2s - loss: 1.0803 - accuracy: 0.8145 - val_loss: 5.6062 - val_accuracy: 0.5606\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 1.9283 - accuracy: 0.7580 - val_loss: 1.5297 - val_accuracy: 0.7547\n",
      "Epoch 8/30\n",
      "5148/5148 - 1s - loss: 0.8988 - accuracy: 0.8322 - val_loss: 1.6092 - val_accuracy: 0.6087\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.0257 - accuracy: 0.7966 - val_loss: 0.6497 - val_accuracy: 0.8385\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 0.9041 - accuracy: 0.8079 - val_loss: 3.1106 - val_accuracy: 0.6304\n",
      "Epoch 11/30\n",
      "5148/5148 - 1s - loss: 1.0000 - accuracy: 0.8009 - val_loss: 0.7086 - val_accuracy: 0.8587\n",
      "Epoch 12/30\n",
      "5148/5148 - 2s - loss: 0.6463 - accuracy: 0.8329 - val_loss: 1.0077 - val_accuracy: 0.7609\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.7581 - accuracy: 0.8073 - val_loss: 1.3038 - val_accuracy: 0.7376\n",
      "Epoch 14/30\n",
      "5148/5148 - 2s - loss: 0.7501 - accuracy: 0.8042 - val_loss: 0.6706 - val_accuracy: 0.7733\n",
      "Epoch 15/30\n",
      "5148/5148 - 2s - loss: 0.5123 - accuracy: 0.8495 - val_loss: 0.5679 - val_accuracy: 0.8307\n",
      "Epoch 16/30\n",
      "5148/5148 - 3s - loss: 0.4526 - accuracy: 0.8469 - val_loss: 0.4475 - val_accuracy: 0.8618\n",
      "Epoch 17/30\n",
      "5148/5148 - 3s - loss: 0.4172 - accuracy: 0.8524 - val_loss: 0.6133 - val_accuracy: 0.8540\n",
      "Epoch 18/30\n",
      "5148/5148 - 3s - loss: 0.4276 - accuracy: 0.8448 - val_loss: 0.5404 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "5148/5148 - 3s - loss: 0.4869 - accuracy: 0.8279 - val_loss: 0.4574 - val_accuracy: 0.8261\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.4647 - accuracy: 0.8359 - val_loss: 0.4502 - val_accuracy: 0.8245\n",
      "Epoch 21/30\n",
      "5148/5148 - 1s - loss: 0.4960 - accuracy: 0.8248 - val_loss: 0.4117 - val_accuracy: 0.8370\n",
      "Epoch 22/30\n",
      "5148/5148 - 2s - loss: 0.4367 - accuracy: 0.8361 - val_loss: 0.4839 - val_accuracy: 0.8090\n",
      "Epoch 23/30\n",
      "5148/5148 - 2s - loss: 0.4037 - accuracy: 0.8427 - val_loss: 0.4040 - val_accuracy: 0.8540\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.3574 - accuracy: 0.8576 - val_loss: 0.4169 - val_accuracy: 0.8556\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.3383 - accuracy: 0.8605 - val_loss: 0.4070 - val_accuracy: 0.8556\n",
      "Epoch 26/30\n",
      "5148/5148 - 1s - loss: 0.3491 - accuracy: 0.8578 - val_loss: 0.3766 - val_accuracy: 0.8432\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.3641 - accuracy: 0.8528 - val_loss: 0.4665 - val_accuracy: 0.7857\n",
      "Epoch 28/30\n",
      "5148/5148 - 2s - loss: 0.3501 - accuracy: 0.8518 - val_loss: 0.5345 - val_accuracy: 0.7780\n",
      "Epoch 29/30\n",
      "5148/5148 - 1s - loss: 0.3687 - accuracy: 0.8543 - val_loss: 0.3865 - val_accuracy: 0.8556\n",
      "Epoch 30/30\n",
      "5148/5148 - 1s - loss: 0.3645 - accuracy: 0.8531 - val_loss: 0.3720 - val_accuracy: 0.8339\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 3s - loss: 3.8169 - accuracy: 0.6538 - val_loss: 2.0085 - val_accuracy: 0.6118\n",
      "Epoch 2/30\n",
      "5148/5148 - 1s - loss: 2.2806 - accuracy: 0.7220 - val_loss: 2.0300 - val_accuracy: 0.7205\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 2.7259 - accuracy: 0.7259 - val_loss: 1.8881 - val_accuracy: 0.8602\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 1.7039 - accuracy: 0.7908 - val_loss: 4.4690 - val_accuracy: 0.5031\n",
      "Epoch 5/30\n",
      "5148/5148 - 1s - loss: 2.0966 - accuracy: 0.7716 - val_loss: 1.0941 - val_accuracy: 0.8587\n",
      "Epoch 6/30\n",
      "5148/5148 - 1s - loss: 1.3417 - accuracy: 0.8096 - val_loss: 4.0717 - val_accuracy: 0.6118\n",
      "Epoch 7/30\n",
      "5148/5148 - 2s - loss: 1.5293 - accuracy: 0.7815 - val_loss: 0.9268 - val_accuracy: 0.8261\n",
      "Epoch 8/30\n",
      "5148/5148 - 2s - loss: 1.2771 - accuracy: 0.8023 - val_loss: 1.1860 - val_accuracy: 0.8587\n",
      "Epoch 9/30\n",
      "5148/5148 - 1s - loss: 1.2788 - accuracy: 0.7997 - val_loss: 2.5274 - val_accuracy: 0.7003\n",
      "Epoch 10/30\n",
      "5148/5148 - 1s - loss: 1.2165 - accuracy: 0.7964 - val_loss: 1.8474 - val_accuracy: 0.7391\n",
      "Epoch 11/30\n",
      "5148/5148 - 2s - loss: 1.0741 - accuracy: 0.8114 - val_loss: 1.3901 - val_accuracy: 0.6879\n",
      "Epoch 12/30\n",
      "5148/5148 - 2s - loss: 0.8918 - accuracy: 0.8188 - val_loss: 0.6441 - val_accuracy: 0.8323\n",
      "Epoch 13/30\n",
      "5148/5148 - 2s - loss: 0.7290 - accuracy: 0.8215 - val_loss: 0.6899 - val_accuracy: 0.8276\n",
      "Epoch 14/30\n",
      "5148/5148 - 2s - loss: 0.7099 - accuracy: 0.8326 - val_loss: 0.7180 - val_accuracy: 0.8602\n",
      "Epoch 15/30\n",
      "5148/5148 - 1s - loss: 0.6729 - accuracy: 0.8289 - val_loss: 2.3686 - val_accuracy: 0.5062\n",
      "Epoch 16/30\n",
      "5148/5148 - 1s - loss: 0.6088 - accuracy: 0.8337 - val_loss: 0.6584 - val_accuracy: 0.8401\n",
      "Epoch 17/30\n",
      "5148/5148 - 1s - loss: 0.5580 - accuracy: 0.8386 - val_loss: 1.2267 - val_accuracy: 0.5916\n",
      "Epoch 18/30\n",
      "5148/5148 - 2s - loss: 0.6141 - accuracy: 0.8261 - val_loss: 0.7890 - val_accuracy: 0.8307\n",
      "Epoch 19/30\n",
      "5148/5148 - 2s - loss: 0.6447 - accuracy: 0.8135 - val_loss: 0.5107 - val_accuracy: 0.8571\n",
      "Epoch 20/30\n",
      "5148/5148 - 1s - loss: 0.6927 - accuracy: 0.8180 - val_loss: 0.5362 - val_accuracy: 0.8276\n",
      "Epoch 21/30\n",
      "5148/5148 - 2s - loss: 0.5248 - accuracy: 0.8384 - val_loss: 0.5769 - val_accuracy: 0.8649\n",
      "Epoch 22/30\n",
      "5148/5148 - 1s - loss: 0.5838 - accuracy: 0.8258 - val_loss: 0.4849 - val_accuracy: 0.8587\n",
      "Epoch 23/30\n",
      "5148/5148 - 1s - loss: 0.5801 - accuracy: 0.8281 - val_loss: 0.4659 - val_accuracy: 0.8385\n",
      "Epoch 24/30\n",
      "5148/5148 - 1s - loss: 0.4659 - accuracy: 0.8425 - val_loss: 0.5442 - val_accuracy: 0.8587\n",
      "Epoch 25/30\n",
      "5148/5148 - 1s - loss: 0.4606 - accuracy: 0.8432 - val_loss: 0.4408 - val_accuracy: 0.8587\n",
      "Epoch 26/30\n",
      "5148/5148 - 2s - loss: 0.4655 - accuracy: 0.8345 - val_loss: 0.5178 - val_accuracy: 0.8571\n",
      "Epoch 27/30\n",
      "5148/5148 - 1s - loss: 0.5060 - accuracy: 0.8279 - val_loss: 0.4681 - val_accuracy: 0.8556\n",
      "Epoch 28/30\n",
      "5148/5148 - 1s - loss: 0.4290 - accuracy: 0.8448 - val_loss: 0.4033 - val_accuracy: 0.8323\n",
      "Epoch 29/30\n",
      "5148/5148 - 2s - loss: 0.5251 - accuracy: 0.8162 - val_loss: 1.0736 - val_accuracy: 0.5683\n",
      "Epoch 30/30\n",
      "5148/5148 - 2s - loss: 0.4960 - accuracy: 0.8232 - val_loss: 0.4939 - val_accuracy: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:04:23,941] Trial 155 finished with value: 0.8639751672744751 and parameters: {'units': 95, 'dropout': 0.0, 'learning_rate': 0.006904116123285092, 'epochs': 30, 'batch_size': 20, 'patience': 9, 'factor': 0.4}. Best is trial 65 with value: 0.8726708292961121.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 3s - loss: 11.8217 - accuracy: 0.5550 - val_loss: 1.1002 - val_accuracy: 0.7562\n",
      "Epoch 2/40\n",
      "5148/5148 - 2s - loss: 2.5347 - accuracy: 0.6962 - val_loss: 0.8997 - val_accuracy: 0.8509\n",
      "Epoch 3/40\n",
      "5148/5148 - 1s - loss: 0.7689 - accuracy: 0.7609 - val_loss: 0.8937 - val_accuracy: 0.6398\n",
      "Epoch 4/40\n",
      "5148/5148 - 1s - loss: 0.4860 - accuracy: 0.7949 - val_loss: 0.4473 - val_accuracy: 0.8525\n",
      "Epoch 5/40\n",
      "5148/5148 - 1s - loss: 0.5277 - accuracy: 0.7704 - val_loss: 0.4582 - val_accuracy: 0.7609\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:04:32,860] Trial 156 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:04:36,798] Trial 157 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:04:39,083] Trial 158 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 17.7761 - accuracy: 0.5404 - val_loss: 0.8170 - val_accuracy: 0.7733\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.1160 - accuracy: 0.7146 - val_loss: 0.5326 - val_accuracy: 0.8478\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5110 - accuracy: 0.7704 - val_loss: 0.4537 - val_accuracy: 0.7764\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4980 - accuracy: 0.7768 - val_loss: 0.4848 - val_accuracy: 0.8416\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5041 - accuracy: 0.7756 - val_loss: 0.4467 - val_accuracy: 0.7811\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4989 - accuracy: 0.7751 - val_loss: 0.5482 - val_accuracy: 0.8602\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4510 - accuracy: 0.8098 - val_loss: 0.6345 - val_accuracy: 0.6832\n",
      "Epoch 8/50\n",
      "5148/5148 - 2s - loss: 0.4525 - accuracy: 0.8120 - val_loss: 0.4583 - val_accuracy: 0.8509\n",
      "Epoch 9/50\n",
      "5148/5148 - 2s - loss: 0.4419 - accuracy: 0.8153 - val_loss: 0.4415 - val_accuracy: 0.8571\n",
      "Epoch 10/50\n",
      "5148/5148 - 2s - loss: 0.4365 - accuracy: 0.8174 - val_loss: 0.4307 - val_accuracy: 0.8012\n",
      "Epoch 11/50\n",
      "5148/5148 - 2s - loss: 0.4202 - accuracy: 0.8221 - val_loss: 0.5063 - val_accuracy: 0.8618\n",
      "Epoch 12/50\n",
      "5148/5148 - 2s - loss: 0.4368 - accuracy: 0.8197 - val_loss: 0.4802 - val_accuracy: 0.8634\n",
      "Epoch 13/50\n",
      "5148/5148 - 2s - loss: 0.4213 - accuracy: 0.8252 - val_loss: 0.3972 - val_accuracy: 0.8602\n",
      "Epoch 14/50\n",
      "5148/5148 - 2s - loss: 0.4379 - accuracy: 0.8120 - val_loss: 0.4539 - val_accuracy: 0.8649\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.4276 - accuracy: 0.8129 - val_loss: 0.4375 - val_accuracy: 0.7655\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.4366 - accuracy: 0.8032 - val_loss: 0.4556 - val_accuracy: 0.8183\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.4253 - accuracy: 0.8102 - val_loss: 0.3909 - val_accuracy: 0.8618\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.4216 - accuracy: 0.8160 - val_loss: 0.4238 - val_accuracy: 0.8618\n",
      "Epoch 19/50\n",
      "5148/5148 - 2s - loss: 0.4520 - accuracy: 0.7984 - val_loss: 0.4302 - val_accuracy: 0.8307\n",
      "Epoch 20/50\n",
      "5148/5148 - 2s - loss: 0.4440 - accuracy: 0.8137 - val_loss: 0.3803 - val_accuracy: 0.8292\n",
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.3836 - accuracy: 0.8314 - val_loss: 0.3653 - val_accuracy: 0.8354\n",
      "Epoch 22/50\n",
      "5148/5148 - 2s - loss: 0.3857 - accuracy: 0.8277 - val_loss: 0.3625 - val_accuracy: 0.8354\n",
      "Epoch 23/50\n",
      "5148/5148 - 2s - loss: 0.3713 - accuracy: 0.8361 - val_loss: 0.3801 - val_accuracy: 0.8214\n",
      "Epoch 24/50\n",
      "5148/5148 - 2s - loss: 0.3724 - accuracy: 0.8296 - val_loss: 0.3528 - val_accuracy: 0.8354\n",
      "Epoch 25/50\n",
      "5148/5148 - 2s - loss: 0.3665 - accuracy: 0.8343 - val_loss: 0.3917 - val_accuracy: 0.8307\n",
      "Epoch 26/50\n",
      "5148/5148 - 2s - loss: 0.3572 - accuracy: 0.8446 - val_loss: 0.3657 - val_accuracy: 0.8354\n",
      "Epoch 27/50\n",
      "5148/5148 - 3s - loss: 0.3573 - accuracy: 0.8271 - val_loss: 0.3461 - val_accuracy: 0.8354\n",
      "Epoch 28/50\n",
      "5148/5148 - 3s - loss: 0.3496 - accuracy: 0.8331 - val_loss: 0.3415 - val_accuracy: 0.8680\n",
      "Epoch 29/50\n",
      "5148/5148 - 3s - loss: 0.3459 - accuracy: 0.8395 - val_loss: 0.3474 - val_accuracy: 0.8307\n",
      "Epoch 30/50\n",
      "5148/5148 - 3s - loss: 0.3492 - accuracy: 0.8349 - val_loss: 0.3510 - val_accuracy: 0.8634\n",
      "Epoch 31/50\n",
      "5148/5148 - 3s - loss: 0.3305 - accuracy: 0.8650 - val_loss: 0.3570 - val_accuracy: 0.8634\n",
      "Epoch 32/50\n",
      "5148/5148 - 3s - loss: 0.3266 - accuracy: 0.8642 - val_loss: 0.3604 - val_accuracy: 0.8230\n",
      "Epoch 33/50\n",
      "5148/5148 - 3s - loss: 0.3316 - accuracy: 0.8613 - val_loss: 0.3507 - val_accuracy: 0.8634\n",
      "Epoch 34/50\n",
      "5148/5148 - 3s - loss: 0.3256 - accuracy: 0.8679 - val_loss: 0.3505 - val_accuracy: 0.8649\n",
      "Epoch 35/50\n",
      "5148/5148 - 3s - loss: 0.3181 - accuracy: 0.8662 - val_loss: 0.3378 - val_accuracy: 0.8773\n",
      "Epoch 36/50\n",
      "5148/5148 - 4s - loss: 0.3157 - accuracy: 0.8662 - val_loss: 0.3361 - val_accuracy: 0.8742\n",
      "Epoch 37/50\n",
      "5148/5148 - 4s - loss: 0.3217 - accuracy: 0.8683 - val_loss: 0.3376 - val_accuracy: 0.8711\n",
      "Epoch 38/50\n",
      "5148/5148 - 3s - loss: 0.3206 - accuracy: 0.8681 - val_loss: 0.3377 - val_accuracy: 0.8649\n",
      "Epoch 39/50\n",
      "5148/5148 - 4s - loss: 0.3207 - accuracy: 0.8687 - val_loss: 0.3373 - val_accuracy: 0.8696\n",
      "Epoch 40/50\n",
      "5148/5148 - 4s - loss: 0.3194 - accuracy: 0.8716 - val_loss: 0.3368 - val_accuracy: 0.8680\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3214 - accuracy: 0.8669 - val_loss: 0.3355 - val_accuracy: 0.8758\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3157 - accuracy: 0.8732 - val_loss: 0.3356 - val_accuracy: 0.8696\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3133 - accuracy: 0.8714 - val_loss: 0.3476 - val_accuracy: 0.8634\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3203 - accuracy: 0.8695 - val_loss: 0.3396 - val_accuracy: 0.8680\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3143 - accuracy: 0.8726 - val_loss: 0.3355 - val_accuracy: 0.8665\n",
      "Epoch 46/50\n",
      "5148/5148 - 2s - loss: 0.3146 - accuracy: 0.8683 - val_loss: 0.3353 - val_accuracy: 0.8649\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3161 - accuracy: 0.8702 - val_loss: 0.3379 - val_accuracy: 0.8680\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3152 - accuracy: 0.8691 - val_loss: 0.3354 - val_accuracy: 0.8696\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3116 - accuracy: 0.8745 - val_loss: 0.3357 - val_accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3137 - accuracy: 0.8730 - val_loss: 0.3362 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 3s - loss: 23.8767 - accuracy: 0.5499 - val_loss: 1.8135 - val_accuracy: 0.7453\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 2.8060 - accuracy: 0.6894 - val_loss: 0.7952 - val_accuracy: 0.8571\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5914 - accuracy: 0.7605 - val_loss: 0.5963 - val_accuracy: 0.6988\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4610 - accuracy: 0.7956 - val_loss: 0.4565 - val_accuracy: 0.8494\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5145 - accuracy: 0.7772 - val_loss: 0.4243 - val_accuracy: 0.7888\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4728 - accuracy: 0.7956 - val_loss: 0.4961 - val_accuracy: 0.8587\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4297 - accuracy: 0.8221 - val_loss: 0.6167 - val_accuracy: 0.6988\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4447 - accuracy: 0.8141 - val_loss: 0.4204 - val_accuracy: 0.8494\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4358 - accuracy: 0.8137 - val_loss: 0.4334 - val_accuracy: 0.8478\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4041 - accuracy: 0.8374 - val_loss: 0.4022 - val_accuracy: 0.8478\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3886 - accuracy: 0.8450 - val_loss: 0.4128 - val_accuracy: 0.8571\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4027 - accuracy: 0.8382 - val_loss: 0.5593 - val_accuracy: 0.6786\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3935 - accuracy: 0.8390 - val_loss: 0.3856 - val_accuracy: 0.8525\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3700 - accuracy: 0.8568 - val_loss: 0.3881 - val_accuracy: 0.8556\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3632 - accuracy: 0.8599 - val_loss: 0.4068 - val_accuracy: 0.7873\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3595 - accuracy: 0.8564 - val_loss: 0.3910 - val_accuracy: 0.8261\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3551 - accuracy: 0.8555 - val_loss: 0.3564 - val_accuracy: 0.8618\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3537 - accuracy: 0.8502 - val_loss: 0.3524 - val_accuracy: 0.8587\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3427 - accuracy: 0.8586 - val_loss: 0.3527 - val_accuracy: 0.8401\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.4288 - accuracy: 0.8091 - val_loss: 0.4523 - val_accuracy: 0.7717\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.4092 - accuracy: 0.8331 - val_loss: 0.4191 - val_accuracy: 0.8478\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.4014 - accuracy: 0.8382 - val_loss: 0.4003 - val_accuracy: 0.8571\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3407 - accuracy: 0.8596 - val_loss: 0.3586 - val_accuracy: 0.8385\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3212 - accuracy: 0.8642 - val_loss: 0.3444 - val_accuracy: 0.8649\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3117 - accuracy: 0.8751 - val_loss: 0.3512 - val_accuracy: 0.8618\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3180 - accuracy: 0.8695 - val_loss: 0.3356 - val_accuracy: 0.8727\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3053 - accuracy: 0.8761 - val_loss: 0.3221 - val_accuracy: 0.8680\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3149 - accuracy: 0.8716 - val_loss: 0.3318 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3120 - accuracy: 0.8733 - val_loss: 0.3519 - val_accuracy: 0.8649\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3021 - accuracy: 0.8784 - val_loss: 0.3276 - val_accuracy: 0.8711\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.3297 - val_accuracy: 0.8618\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3034 - accuracy: 0.8803 - val_loss: 0.3352 - val_accuracy: 0.8649\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2897 - accuracy: 0.8786 - val_loss: 0.3119 - val_accuracy: 0.8618\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2868 - accuracy: 0.8817 - val_loss: 0.3142 - val_accuracy: 0.8696\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2845 - accuracy: 0.8836 - val_loss: 0.3092 - val_accuracy: 0.8680\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2826 - accuracy: 0.8829 - val_loss: 0.3054 - val_accuracy: 0.8727\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2870 - accuracy: 0.8825 - val_loss: 0.3060 - val_accuracy: 0.8773\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2864 - accuracy: 0.8807 - val_loss: 0.3041 - val_accuracy: 0.8696\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2868 - accuracy: 0.8815 - val_loss: 0.3108 - val_accuracy: 0.8665\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2874 - accuracy: 0.8823 - val_loss: 0.3032 - val_accuracy: 0.8711\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2839 - accuracy: 0.8854 - val_loss: 0.3065 - val_accuracy: 0.8773\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2846 - accuracy: 0.8850 - val_loss: 0.3129 - val_accuracy: 0.8649\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2880 - accuracy: 0.8790 - val_loss: 0.3202 - val_accuracy: 0.8680\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2761 - accuracy: 0.8833 - val_loss: 0.3162 - val_accuracy: 0.8649\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2764 - accuracy: 0.8827 - val_loss: 0.2996 - val_accuracy: 0.8742\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2766 - accuracy: 0.8844 - val_loss: 0.2991 - val_accuracy: 0.8711\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2778 - accuracy: 0.8844 - val_loss: 0.2999 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2756 - accuracy: 0.8840 - val_loss: 0.3009 - val_accuracy: 0.8758\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2772 - accuracy: 0.8866 - val_loss: 0.3001 - val_accuracy: 0.8696\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2759 - accuracy: 0.8848 - val_loss: 0.2997 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 19.5593 - accuracy: 0.5427 - val_loss: 1.1229 - val_accuracy: 0.8525\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.4620 - accuracy: 0.6962 - val_loss: 0.4543 - val_accuracy: 0.7811\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5053 - accuracy: 0.7727 - val_loss: 0.5238 - val_accuracy: 0.7360\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4665 - accuracy: 0.7943 - val_loss: 0.5431 - val_accuracy: 0.8587\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5000 - accuracy: 0.7828 - val_loss: 0.4101 - val_accuracy: 0.8447\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4561 - accuracy: 0.8046 - val_loss: 0.5561 - val_accuracy: 0.8416\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4281 - accuracy: 0.8226 - val_loss: 0.5558 - val_accuracy: 0.7158\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4356 - accuracy: 0.8155 - val_loss: 0.4258 - val_accuracy: 0.8649\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4181 - accuracy: 0.8275 - val_loss: 0.4039 - val_accuracy: 0.8556\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3983 - accuracy: 0.8413 - val_loss: 0.4155 - val_accuracy: 0.7981\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4049 - accuracy: 0.8277 - val_loss: 0.4614 - val_accuracy: 0.8571\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3906 - accuracy: 0.8388 - val_loss: 0.5087 - val_accuracy: 0.8494\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4186 - accuracy: 0.8226 - val_loss: 0.3997 - val_accuracy: 0.8432\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3942 - accuracy: 0.8430 - val_loss: 0.3815 - val_accuracy: 0.8649\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3571 - accuracy: 0.8570 - val_loss: 0.3620 - val_accuracy: 0.8602\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3559 - accuracy: 0.8601 - val_loss: 0.3578 - val_accuracy: 0.8602\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3478 - accuracy: 0.8627 - val_loss: 0.3524 - val_accuracy: 0.8556\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3480 - accuracy: 0.8599 - val_loss: 0.3553 - val_accuracy: 0.8618\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3843 - accuracy: 0.8310 - val_loss: 0.4167 - val_accuracy: 0.8680\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.4681 - accuracy: 0.7801 - val_loss: 0.4349 - val_accuracy: 0.7904\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.4089 - accuracy: 0.8357 - val_loss: 0.4100 - val_accuracy: 0.8556\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3833 - accuracy: 0.8456 - val_loss: 0.3856 - val_accuracy: 0.8571\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3690 - accuracy: 0.8444 - val_loss: 0.3701 - val_accuracy: 0.8307\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3761 - accuracy: 0.8254 - val_loss: 0.3567 - val_accuracy: 0.8665\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3450 - accuracy: 0.8588 - val_loss: 0.4307 - val_accuracy: 0.7904\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3318 - accuracy: 0.8648 - val_loss: 0.3419 - val_accuracy: 0.8727\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3157 - accuracy: 0.8735 - val_loss: 0.3329 - val_accuracy: 0.8602\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3150 - accuracy: 0.8732 - val_loss: 0.3368 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3151 - accuracy: 0.8735 - val_loss: 0.3661 - val_accuracy: 0.8587\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3079 - accuracy: 0.8691 - val_loss: 0.3256 - val_accuracy: 0.8649\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3078 - accuracy: 0.8741 - val_loss: 0.3173 - val_accuracy: 0.8680\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3079 - accuracy: 0.8724 - val_loss: 0.3330 - val_accuracy: 0.8602\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2988 - accuracy: 0.8733 - val_loss: 0.3226 - val_accuracy: 0.8649\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2958 - accuracy: 0.8759 - val_loss: 0.3257 - val_accuracy: 0.8634\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2934 - accuracy: 0.8794 - val_loss: 0.3140 - val_accuracy: 0.8665\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2885 - accuracy: 0.8790 - val_loss: 0.3151 - val_accuracy: 0.8680\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2934 - accuracy: 0.8770 - val_loss: 0.3131 - val_accuracy: 0.8742\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2915 - accuracy: 0.8772 - val_loss: 0.3088 - val_accuracy: 0.8649\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2931 - accuracy: 0.8739 - val_loss: 0.3115 - val_accuracy: 0.8696\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2949 - accuracy: 0.8751 - val_loss: 0.3106 - val_accuracy: 0.8742\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2920 - accuracy: 0.8767 - val_loss: 0.3118 - val_accuracy: 0.8742\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2904 - accuracy: 0.8749 - val_loss: 0.3179 - val_accuracy: 0.8634\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2943 - accuracy: 0.8763 - val_loss: 0.3167 - val_accuracy: 0.8680\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2858 - accuracy: 0.8776 - val_loss: 0.3148 - val_accuracy: 0.8649\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2871 - accuracy: 0.8755 - val_loss: 0.3054 - val_accuracy: 0.8696\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2857 - accuracy: 0.8784 - val_loss: 0.3042 - val_accuracy: 0.8680\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2869 - accuracy: 0.8805 - val_loss: 0.3073 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2861 - accuracy: 0.8772 - val_loss: 0.3054 - val_accuracy: 0.8665\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2848 - accuracy: 0.8798 - val_loss: 0.3096 - val_accuracy: 0.8665\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2870 - accuracy: 0.8770 - val_loss: 0.3039 - val_accuracy: 0.8665\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 19.6503 - accuracy: 0.5389 - val_loss: 3.3762 - val_accuracy: 0.5512\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.2957 - accuracy: 0.7077 - val_loss: 0.6366 - val_accuracy: 0.7671\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5193 - accuracy: 0.7686 - val_loss: 0.6389 - val_accuracy: 0.6755\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4898 - accuracy: 0.7844 - val_loss: 0.4560 - val_accuracy: 0.8478\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5342 - accuracy: 0.7574 - val_loss: 0.4634 - val_accuracy: 0.8478\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4680 - accuracy: 0.7984 - val_loss: 0.5682 - val_accuracy: 0.8183\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4511 - accuracy: 0.8061 - val_loss: 0.5770 - val_accuracy: 0.6863\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4635 - accuracy: 0.8044 - val_loss: 0.4413 - val_accuracy: 0.8401\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4441 - accuracy: 0.8135 - val_loss: 0.4543 - val_accuracy: 0.8587\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4131 - accuracy: 0.8349 - val_loss: 0.4820 - val_accuracy: 0.7360\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4218 - accuracy: 0.8223 - val_loss: 0.5266 - val_accuracy: 0.8618\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4049 - accuracy: 0.8411 - val_loss: 0.4049 - val_accuracy: 0.8587\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4216 - accuracy: 0.8190 - val_loss: 0.4507 - val_accuracy: 0.7531\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.4293 - accuracy: 0.8186 - val_loss: 0.4286 - val_accuracy: 0.8618\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.4462 - accuracy: 0.8092 - val_loss: 0.5765 - val_accuracy: 0.6879\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.4474 - accuracy: 0.8005 - val_loss: 0.3958 - val_accuracy: 0.8525\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.4405 - accuracy: 0.8017 - val_loss: 0.3863 - val_accuracy: 0.8602\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3846 - accuracy: 0.8331 - val_loss: 0.3797 - val_accuracy: 0.8571\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3841 - accuracy: 0.8312 - val_loss: 0.4063 - val_accuracy: 0.8137\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3748 - accuracy: 0.8310 - val_loss: 0.3702 - val_accuracy: 0.8292\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3632 - accuracy: 0.8463 - val_loss: 0.3614 - val_accuracy: 0.8634\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3616 - accuracy: 0.8362 - val_loss: 0.3512 - val_accuracy: 0.8587\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3454 - accuracy: 0.8429 - val_loss: 0.3643 - val_accuracy: 0.8339\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3458 - accuracy: 0.8479 - val_loss: 0.3510 - val_accuracy: 0.8323\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3312 - accuracy: 0.8590 - val_loss: 0.4139 - val_accuracy: 0.7981\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3476 - accuracy: 0.8483 - val_loss: 0.3635 - val_accuracy: 0.8323\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3242 - accuracy: 0.8603 - val_loss: 0.3532 - val_accuracy: 0.8602\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3141 - accuracy: 0.8730 - val_loss: 0.3268 - val_accuracy: 0.8649\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3165 - accuracy: 0.8667 - val_loss: 0.3298 - val_accuracy: 0.8696\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3139 - accuracy: 0.8654 - val_loss: 0.3275 - val_accuracy: 0.8727\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3097 - accuracy: 0.8712 - val_loss: 0.3345 - val_accuracy: 0.8742\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3149 - accuracy: 0.8652 - val_loss: 0.3344 - val_accuracy: 0.8385\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3080 - accuracy: 0.8642 - val_loss: 0.3477 - val_accuracy: 0.8727\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3050 - accuracy: 0.8702 - val_loss: 0.3253 - val_accuracy: 0.8649\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3070 - accuracy: 0.8710 - val_loss: 0.3200 - val_accuracy: 0.8773\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3038 - accuracy: 0.8716 - val_loss: 0.3233 - val_accuracy: 0.8447\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3062 - accuracy: 0.8702 - val_loss: 0.3178 - val_accuracy: 0.8634\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3043 - accuracy: 0.8702 - val_loss: 0.3221 - val_accuracy: 0.8665\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3075 - accuracy: 0.8689 - val_loss: 0.3287 - val_accuracy: 0.8680\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3074 - accuracy: 0.8673 - val_loss: 0.3289 - val_accuracy: 0.8711\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3087 - accuracy: 0.8720 - val_loss: 0.3156 - val_accuracy: 0.8665\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2976 - accuracy: 0.8733 - val_loss: 0.3152 - val_accuracy: 0.8727\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2967 - accuracy: 0.8716 - val_loss: 0.3190 - val_accuracy: 0.8711\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2990 - accuracy: 0.8745 - val_loss: 0.3328 - val_accuracy: 0.8634\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2949 - accuracy: 0.8753 - val_loss: 0.3090 - val_accuracy: 0.8680\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2949 - accuracy: 0.8751 - val_loss: 0.3091 - val_accuracy: 0.8758\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3009 - accuracy: 0.8749 - val_loss: 0.3094 - val_accuracy: 0.8696\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2909 - accuracy: 0.8765 - val_loss: 0.3084 - val_accuracy: 0.8680\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2949 - accuracy: 0.8759 - val_loss: 0.3085 - val_accuracy: 0.8665\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2969 - accuracy: 0.8745 - val_loss: 0.3080 - val_accuracy: 0.8742\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 5s - loss: 27.6603 - accuracy: 0.5379 - val_loss: 3.0350 - val_accuracy: 0.6739\n",
      "Epoch 2/50\n",
      "5148/5148 - 2s - loss: 3.1198 - accuracy: 0.6941 - val_loss: 0.9807 - val_accuracy: 0.7345\n",
      "Epoch 3/50\n",
      "5148/5148 - 3s - loss: 0.6632 - accuracy: 0.7453 - val_loss: 0.5320 - val_accuracy: 0.7422\n",
      "Epoch 4/50\n",
      "5148/5148 - 3s - loss: 0.5204 - accuracy: 0.7700 - val_loss: 0.4594 - val_accuracy: 0.8339\n",
      "Epoch 5/50\n",
      "5148/5148 - 3s - loss: 0.4994 - accuracy: 0.7809 - val_loss: 0.4482 - val_accuracy: 0.7888\n",
      "Epoch 6/50\n",
      "5148/5148 - 2s - loss: 0.4904 - accuracy: 0.7855 - val_loss: 0.5414 - val_accuracy: 0.8602\n",
      "Epoch 7/50\n",
      "5148/5148 - 3s - loss: 0.4511 - accuracy: 0.8143 - val_loss: 0.6647 - val_accuracy: 0.6646\n",
      "Epoch 8/50\n",
      "5148/5148 - 3s - loss: 0.4351 - accuracy: 0.8228 - val_loss: 0.4234 - val_accuracy: 0.8478\n",
      "Epoch 9/50\n",
      "5148/5148 - 3s - loss: 0.4284 - accuracy: 0.8238 - val_loss: 0.4431 - val_accuracy: 0.8540\n",
      "Epoch 10/50\n",
      "5148/5148 - 3s - loss: 0.4319 - accuracy: 0.8172 - val_loss: 0.4321 - val_accuracy: 0.7842\n",
      "Epoch 11/50\n",
      "5148/5148 - 3s - loss: 0.4164 - accuracy: 0.8308 - val_loss: 0.4780 - val_accuracy: 0.8463\n",
      "Epoch 12/50\n",
      "5148/5148 - 2s - loss: 0.4286 - accuracy: 0.8250 - val_loss: 0.4599 - val_accuracy: 0.8618\n",
      "Epoch 13/50\n",
      "5148/5148 - 3s - loss: 0.4352 - accuracy: 0.8166 - val_loss: 0.4190 - val_accuracy: 0.8540\n",
      "Epoch 14/50\n",
      "5148/5148 - 3s - loss: 0.4264 - accuracy: 0.8263 - val_loss: 0.4705 - val_accuracy: 0.8587\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.4366 - accuracy: 0.8182 - val_loss: 0.4827 - val_accuracy: 0.7360\n",
      "Epoch 16/50\n",
      "5148/5148 - 3s - loss: 0.4471 - accuracy: 0.8110 - val_loss: 0.4339 - val_accuracy: 0.8494\n",
      "Epoch 17/50\n",
      "5148/5148 - 2s - loss: 0.4525 - accuracy: 0.7982 - val_loss: 0.4168 - val_accuracy: 0.8463\n",
      "Epoch 18/50\n",
      "5148/5148 - 3s - loss: 0.4562 - accuracy: 0.8083 - val_loss: 0.4492 - val_accuracy: 0.8618\n",
      "Epoch 19/50\n",
      "5148/5148 - 2s - loss: 0.4124 - accuracy: 0.8333 - val_loss: 0.4328 - val_accuracy: 0.8121\n",
      "Epoch 20/50\n",
      "5148/5148 - 3s - loss: 0.4139 - accuracy: 0.8254 - val_loss: 0.4247 - val_accuracy: 0.8276\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3962 - accuracy: 0.8285 - val_loss: 0.4076 - val_accuracy: 0.8059\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3827 - accuracy: 0.8372 - val_loss: 0.3792 - val_accuracy: 0.8540\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3742 - accuracy: 0.8372 - val_loss: 0.3863 - val_accuracy: 0.8230\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3750 - accuracy: 0.8293 - val_loss: 0.3844 - val_accuracy: 0.8634\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3607 - accuracy: 0.8337 - val_loss: 0.4412 - val_accuracy: 0.7516\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3656 - accuracy: 0.8337 - val_loss: 0.3668 - val_accuracy: 0.8649\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3576 - accuracy: 0.8320 - val_loss: 0.3528 - val_accuracy: 0.8665\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3634 - accuracy: 0.8304 - val_loss: 0.3684 - val_accuracy: 0.8634\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3560 - accuracy: 0.8294 - val_loss: 0.3576 - val_accuracy: 0.8634\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3530 - accuracy: 0.8446 - val_loss: 0.3554 - val_accuracy: 0.8665\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3461 - accuracy: 0.8337 - val_loss: 0.3362 - val_accuracy: 0.8587\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3521 - accuracy: 0.8230 - val_loss: 0.3548 - val_accuracy: 0.8292\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3411 - accuracy: 0.8395 - val_loss: 0.3731 - val_accuracy: 0.8571\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3293 - accuracy: 0.8574 - val_loss: 0.3435 - val_accuracy: 0.8618\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3226 - accuracy: 0.8621 - val_loss: 0.3389 - val_accuracy: 0.8618\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3228 - accuracy: 0.8627 - val_loss: 0.3391 - val_accuracy: 0.8478\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3225 - accuracy: 0.8526 - val_loss: 0.3381 - val_accuracy: 0.8416\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3181 - accuracy: 0.8699 - val_loss: 0.3341 - val_accuracy: 0.8727\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3130 - accuracy: 0.8702 - val_loss: 0.3239 - val_accuracy: 0.8758\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3171 - accuracy: 0.8685 - val_loss: 0.3272 - val_accuracy: 0.8727\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3131 - accuracy: 0.8751 - val_loss: 0.3475 - val_accuracy: 0.8696\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3203 - accuracy: 0.8629 - val_loss: 0.3377 - val_accuracy: 0.8587\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3098 - accuracy: 0.8763 - val_loss: 0.3203 - val_accuracy: 0.8742\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3133 - accuracy: 0.8687 - val_loss: 0.3349 - val_accuracy: 0.8696\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3106 - accuracy: 0.8708 - val_loss: 0.3190 - val_accuracy: 0.8711\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3009 - accuracy: 0.8761 - val_loss: 0.3132 - val_accuracy: 0.8727\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3037 - accuracy: 0.8749 - val_loss: 0.3130 - val_accuracy: 0.8680\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3065 - accuracy: 0.8761 - val_loss: 0.3165 - val_accuracy: 0.8649\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3034 - accuracy: 0.8780 - val_loss: 0.3196 - val_accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2960 - accuracy: 0.8753 - val_loss: 0.3130 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:09:34,092] Trial 159 finished with value: 0.8763974905014038 and parameters: {'units': 100, 'dropout': 0.1, 'learning_rate': 0.007511080260178754, 'epochs': 50, 'batch_size': 30, 'patience': 6, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:09:38,664] Trial 160 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:09:43,413] Trial 161 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:09:46,708] Trial 162 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 3s - loss: 21.3174 - accuracy: 0.5363 - val_loss: 0.7076 - val_accuracy: 0.7702\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.5459 - accuracy: 0.6756 - val_loss: 0.6056 - val_accuracy: 0.8183\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5374 - accuracy: 0.7630 - val_loss: 0.7213 - val_accuracy: 0.6506\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.5133 - accuracy: 0.7807 - val_loss: 0.4802 - val_accuracy: 0.8447\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.6163 - accuracy: 0.7284 - val_loss: 0.4462 - val_accuracy: 0.8587\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.5896 - accuracy: 0.7374 - val_loss: 0.5607 - val_accuracy: 0.8090\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4780 - accuracy: 0.7889 - val_loss: 0.4514 - val_accuracy: 0.7640\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4420 - accuracy: 0.8178 - val_loss: 0.3981 - val_accuracy: 0.8478\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4607 - accuracy: 0.7997 - val_loss: 0.4052 - val_accuracy: 0.8463\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4344 - accuracy: 0.8166 - val_loss: 0.5343 - val_accuracy: 0.6988\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4298 - accuracy: 0.8234 - val_loss: 0.4279 - val_accuracy: 0.8385\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4207 - accuracy: 0.8291 - val_loss: 0.4357 - val_accuracy: 0.8540\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4171 - accuracy: 0.8283 - val_loss: 0.4731 - val_accuracy: 0.8571\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3999 - accuracy: 0.8419 - val_loss: 0.4676 - val_accuracy: 0.8602\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.4035 - accuracy: 0.8359 - val_loss: 0.4328 - val_accuracy: 0.7609\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3927 - accuracy: 0.8425 - val_loss: 0.5333 - val_accuracy: 0.7267\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3845 - accuracy: 0.8442 - val_loss: 0.3783 - val_accuracy: 0.8525\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3762 - accuracy: 0.8487 - val_loss: 0.3719 - val_accuracy: 0.8587\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3698 - accuracy: 0.8491 - val_loss: 0.3655 - val_accuracy: 0.8618\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3670 - accuracy: 0.8514 - val_loss: 0.3805 - val_accuracy: 0.8214\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3570 - accuracy: 0.8619 - val_loss: 0.4194 - val_accuracy: 0.8043\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3559 - accuracy: 0.8599 - val_loss: 0.3502 - val_accuracy: 0.8649\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3420 - accuracy: 0.8632 - val_loss: 0.3508 - val_accuracy: 0.8680\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3378 - accuracy: 0.8623 - val_loss: 0.3925 - val_accuracy: 0.8634\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3348 - accuracy: 0.8648 - val_loss: 0.3818 - val_accuracy: 0.8602\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3355 - accuracy: 0.8621 - val_loss: 0.3580 - val_accuracy: 0.8416\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3308 - accuracy: 0.8621 - val_loss: 0.3706 - val_accuracy: 0.8261\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3412 - accuracy: 0.8448 - val_loss: 0.3660 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3109 - accuracy: 0.8759 - val_loss: 0.3332 - val_accuracy: 0.8587\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3092 - accuracy: 0.8796 - val_loss: 0.3219 - val_accuracy: 0.8665\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3065 - accuracy: 0.8765 - val_loss: 0.3244 - val_accuracy: 0.8680\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3047 - accuracy: 0.8786 - val_loss: 0.3290 - val_accuracy: 0.8711\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2990 - accuracy: 0.8803 - val_loss: 0.3344 - val_accuracy: 0.8587\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3028 - accuracy: 0.8788 - val_loss: 0.3267 - val_accuracy: 0.8634\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3026 - accuracy: 0.8776 - val_loss: 0.3221 - val_accuracy: 0.8758\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3022 - accuracy: 0.8782 - val_loss: 0.3158 - val_accuracy: 0.8680\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3033 - accuracy: 0.8776 - val_loss: 0.3268 - val_accuracy: 0.8696\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3064 - accuracy: 0.8782 - val_loss: 0.3168 - val_accuracy: 0.8665\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3021 - accuracy: 0.8720 - val_loss: 0.3139 - val_accuracy: 0.8680\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3016 - accuracy: 0.8817 - val_loss: 0.3197 - val_accuracy: 0.8727\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2925 - accuracy: 0.8800 - val_loss: 0.3116 - val_accuracy: 0.8773\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2935 - accuracy: 0.8813 - val_loss: 0.3105 - val_accuracy: 0.8665\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2961 - accuracy: 0.8778 - val_loss: 0.3144 - val_accuracy: 0.8773\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2893 - accuracy: 0.8813 - val_loss: 0.3193 - val_accuracy: 0.8634\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2933 - accuracy: 0.8817 - val_loss: 0.3115 - val_accuracy: 0.8727\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2931 - accuracy: 0.8798 - val_loss: 0.3105 - val_accuracy: 0.8773\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2913 - accuracy: 0.8778 - val_loss: 0.3108 - val_accuracy: 0.8680\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2859 - accuracy: 0.8800 - val_loss: 0.3098 - val_accuracy: 0.8696\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2861 - accuracy: 0.8790 - val_loss: 0.3086 - val_accuracy: 0.8711\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2872 - accuracy: 0.8827 - val_loss: 0.3077 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 24.9067 - accuracy: 0.5284 - val_loss: 1.2717 - val_accuracy: 0.7034\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 2.1298 - accuracy: 0.6935 - val_loss: 0.4498 - val_accuracy: 0.7795\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5489 - accuracy: 0.7671 - val_loss: 0.4496 - val_accuracy: 0.7904\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4627 - accuracy: 0.7995 - val_loss: 0.4391 - val_accuracy: 0.8494\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5265 - accuracy: 0.7714 - val_loss: 0.4564 - val_accuracy: 0.7562\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4860 - accuracy: 0.7821 - val_loss: 0.5152 - val_accuracy: 0.8587\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4461 - accuracy: 0.8094 - val_loss: 0.5216 - val_accuracy: 0.7298\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4288 - accuracy: 0.8248 - val_loss: 0.3958 - val_accuracy: 0.8587\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4410 - accuracy: 0.8114 - val_loss: 0.4070 - val_accuracy: 0.8401\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4153 - accuracy: 0.8312 - val_loss: 0.4055 - val_accuracy: 0.7919\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3994 - accuracy: 0.8293 - val_loss: 0.3836 - val_accuracy: 0.8665\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3859 - accuracy: 0.8403 - val_loss: 0.5045 - val_accuracy: 0.8230\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3875 - accuracy: 0.8368 - val_loss: 0.3547 - val_accuracy: 0.8540\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3842 - accuracy: 0.8462 - val_loss: 0.3726 - val_accuracy: 0.8680\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3577 - accuracy: 0.8541 - val_loss: 0.3822 - val_accuracy: 0.8323\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.4277 - accuracy: 0.8157 - val_loss: 0.3904 - val_accuracy: 0.8556\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.4213 - accuracy: 0.8180 - val_loss: 0.3726 - val_accuracy: 0.8634\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3948 - accuracy: 0.8359 - val_loss: 0.3748 - val_accuracy: 0.8540\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.4000 - accuracy: 0.8328 - val_loss: 0.4061 - val_accuracy: 0.8680\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3725 - accuracy: 0.8415 - val_loss: 0.3719 - val_accuracy: 0.8556\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3669 - accuracy: 0.8450 - val_loss: 0.3799 - val_accuracy: 0.8571\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3677 - accuracy: 0.8419 - val_loss: 0.3602 - val_accuracy: 0.8571\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3612 - accuracy: 0.8485 - val_loss: 0.3681 - val_accuracy: 0.8696\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3582 - accuracy: 0.8493 - val_loss: 0.3767 - val_accuracy: 0.8696\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3558 - accuracy: 0.8440 - val_loss: 0.4134 - val_accuracy: 0.8571\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3572 - accuracy: 0.8446 - val_loss: 0.3680 - val_accuracy: 0.8571\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3405 - accuracy: 0.8425 - val_loss: 0.3296 - val_accuracy: 0.8665\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3480 - accuracy: 0.8508 - val_loss: 0.3484 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3422 - accuracy: 0.8465 - val_loss: 0.3488 - val_accuracy: 0.8634\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3220 - accuracy: 0.8438 - val_loss: 0.3216 - val_accuracy: 0.8727\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3110 - accuracy: 0.8491 - val_loss: 0.3179 - val_accuracy: 0.8727\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3171 - accuracy: 0.8477 - val_loss: 0.3279 - val_accuracy: 0.8634\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3092 - accuracy: 0.8450 - val_loss: 0.3207 - val_accuracy: 0.8602\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3060 - accuracy: 0.8485 - val_loss: 0.3258 - val_accuracy: 0.8649\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3050 - accuracy: 0.8467 - val_loss: 0.3395 - val_accuracy: 0.8634\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3006 - accuracy: 0.8489 - val_loss: 0.3111 - val_accuracy: 0.8680\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3034 - accuracy: 0.8452 - val_loss: 0.3154 - val_accuracy: 0.8696\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2967 - accuracy: 0.8512 - val_loss: 0.3148 - val_accuracy: 0.8618\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3003 - accuracy: 0.8607 - val_loss: 0.3086 - val_accuracy: 0.8696\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2976 - accuracy: 0.8739 - val_loss: 0.3097 - val_accuracy: 0.8789\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2996 - accuracy: 0.8743 - val_loss: 0.3053 - val_accuracy: 0.8758\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2979 - accuracy: 0.8780 - val_loss: 0.3126 - val_accuracy: 0.8665\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3032 - accuracy: 0.8728 - val_loss: 0.3103 - val_accuracy: 0.8665\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2970 - accuracy: 0.8751 - val_loss: 0.3264 - val_accuracy: 0.8665\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2970 - accuracy: 0.8780 - val_loss: 0.3049 - val_accuracy: 0.8727\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2932 - accuracy: 0.8741 - val_loss: 0.3039 - val_accuracy: 0.8758\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2981 - accuracy: 0.8786 - val_loss: 0.3051 - val_accuracy: 0.8711\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2919 - accuracy: 0.8811 - val_loss: 0.3095 - val_accuracy: 0.8758\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2924 - accuracy: 0.8823 - val_loss: 0.3099 - val_accuracy: 0.8758\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2942 - accuracy: 0.8778 - val_loss: 0.3029 - val_accuracy: 0.8758\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 21.6378 - accuracy: 0.5247 - val_loss: 0.6496 - val_accuracy: 0.8385\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.5949 - accuracy: 0.6772 - val_loss: 0.6173 - val_accuracy: 0.6196\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5137 - accuracy: 0.7638 - val_loss: 0.4645 - val_accuracy: 0.7578\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4850 - accuracy: 0.7890 - val_loss: 0.4476 - val_accuracy: 0.8416\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5241 - accuracy: 0.7638 - val_loss: 0.4499 - val_accuracy: 0.8416\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4911 - accuracy: 0.7795 - val_loss: 0.5477 - val_accuracy: 0.8587\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4547 - accuracy: 0.8091 - val_loss: 0.7737 - val_accuracy: 0.6475\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4453 - accuracy: 0.8141 - val_loss: 0.4090 - val_accuracy: 0.8416\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4552 - accuracy: 0.8036 - val_loss: 0.4530 - val_accuracy: 0.8463\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4518 - accuracy: 0.8122 - val_loss: 0.4659 - val_accuracy: 0.7640\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4379 - accuracy: 0.8162 - val_loss: 0.4746 - val_accuracy: 0.8509\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4204 - accuracy: 0.8361 - val_loss: 0.4156 - val_accuracy: 0.8509\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4026 - accuracy: 0.8405 - val_loss: 0.4103 - val_accuracy: 0.8556\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3867 - accuracy: 0.8479 - val_loss: 0.4071 - val_accuracy: 0.8509\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3868 - accuracy: 0.8419 - val_loss: 0.4110 - val_accuracy: 0.8463\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3815 - accuracy: 0.8475 - val_loss: 0.4213 - val_accuracy: 0.8012\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3698 - accuracy: 0.8531 - val_loss: 0.3980 - val_accuracy: 0.8587\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3674 - accuracy: 0.8561 - val_loss: 0.3966 - val_accuracy: 0.8649\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3695 - accuracy: 0.8553 - val_loss: 0.4129 - val_accuracy: 0.8168\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3709 - accuracy: 0.8547 - val_loss: 0.3990 - val_accuracy: 0.8634\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3639 - accuracy: 0.8566 - val_loss: 0.4247 - val_accuracy: 0.8602\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3634 - accuracy: 0.8584 - val_loss: 0.3978 - val_accuracy: 0.8634\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3636 - accuracy: 0.8545 - val_loss: 0.4111 - val_accuracy: 0.8214\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3578 - accuracy: 0.8535 - val_loss: 0.3977 - val_accuracy: 0.8214\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3584 - accuracy: 0.8547 - val_loss: 0.3914 - val_accuracy: 0.8261\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3562 - accuracy: 0.8594 - val_loss: 0.3866 - val_accuracy: 0.8727\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3542 - accuracy: 0.8603 - val_loss: 0.3850 - val_accuracy: 0.8525\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3538 - accuracy: 0.8601 - val_loss: 0.3862 - val_accuracy: 0.8711\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3573 - accuracy: 0.8580 - val_loss: 0.3886 - val_accuracy: 0.8245\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3569 - accuracy: 0.8598 - val_loss: 0.3816 - val_accuracy: 0.8665\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8596 - val_loss: 0.3803 - val_accuracy: 0.8401\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3509 - accuracy: 0.8584 - val_loss: 0.3791 - val_accuracy: 0.8525\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3443 - accuracy: 0.8588 - val_loss: 0.3810 - val_accuracy: 0.8339\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3469 - accuracy: 0.8588 - val_loss: 0.3800 - val_accuracy: 0.8478\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3413 - accuracy: 0.8636 - val_loss: 0.3780 - val_accuracy: 0.8432\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3464 - accuracy: 0.8576 - val_loss: 0.3790 - val_accuracy: 0.8432\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3439 - accuracy: 0.8576 - val_loss: 0.3792 - val_accuracy: 0.8447\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3455 - accuracy: 0.8574 - val_loss: 0.3791 - val_accuracy: 0.8696\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3434 - accuracy: 0.8636 - val_loss: 0.3833 - val_accuracy: 0.8711\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3441 - accuracy: 0.8625 - val_loss: 0.3791 - val_accuracy: 0.8634\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3430 - accuracy: 0.8646 - val_loss: 0.3781 - val_accuracy: 0.8665\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3409 - accuracy: 0.8632 - val_loss: 0.3783 - val_accuracy: 0.8665\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3446 - accuracy: 0.8638 - val_loss: 0.3792 - val_accuracy: 0.8696\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3438 - accuracy: 0.8619 - val_loss: 0.3794 - val_accuracy: 0.8696\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3379 - accuracy: 0.8667 - val_loss: 0.3779 - val_accuracy: 0.8602\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3419 - accuracy: 0.8656 - val_loss: 0.3781 - val_accuracy: 0.8618\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3416 - accuracy: 0.8615 - val_loss: 0.3787 - val_accuracy: 0.8696\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3388 - accuracy: 0.8658 - val_loss: 0.3781 - val_accuracy: 0.8680\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3439 - accuracy: 0.8584 - val_loss: 0.3782 - val_accuracy: 0.8665\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3449 - accuracy: 0.8599 - val_loss: 0.3782 - val_accuracy: 0.8680\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 32.7710 - accuracy: 0.5140 - val_loss: 0.8565 - val_accuracy: 0.8292\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 4.2808 - accuracy: 0.6323 - val_loss: 0.8277 - val_accuracy: 0.8463\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.6681 - accuracy: 0.7498 - val_loss: 0.5109 - val_accuracy: 0.8432\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4728 - accuracy: 0.7931 - val_loss: 0.4870 - val_accuracy: 0.8432\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5073 - accuracy: 0.7735 - val_loss: 0.4255 - val_accuracy: 0.8214\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4913 - accuracy: 0.7846 - val_loss: 0.6086 - val_accuracy: 0.7609\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4613 - accuracy: 0.8007 - val_loss: 0.6712 - val_accuracy: 0.6630\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4125 - accuracy: 0.8353 - val_loss: 0.4182 - val_accuracy: 0.8463\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4116 - accuracy: 0.8372 - val_loss: 0.5173 - val_accuracy: 0.7314\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4025 - accuracy: 0.8382 - val_loss: 0.5321 - val_accuracy: 0.7236\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3883 - accuracy: 0.8421 - val_loss: 0.3991 - val_accuracy: 0.8509\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3896 - accuracy: 0.8460 - val_loss: 0.4044 - val_accuracy: 0.8587\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3841 - accuracy: 0.8432 - val_loss: 0.4605 - val_accuracy: 0.8587\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3720 - accuracy: 0.8537 - val_loss: 0.4076 - val_accuracy: 0.8618\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3737 - accuracy: 0.8504 - val_loss: 0.4250 - val_accuracy: 0.7655\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3764 - accuracy: 0.8485 - val_loss: 0.4522 - val_accuracy: 0.7609\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3673 - accuracy: 0.8495 - val_loss: 0.3907 - val_accuracy: 0.8587\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3737 - accuracy: 0.8469 - val_loss: 0.3771 - val_accuracy: 0.8696\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3615 - accuracy: 0.8518 - val_loss: 0.3663 - val_accuracy: 0.8727\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3726 - accuracy: 0.8448 - val_loss: 0.3734 - val_accuracy: 0.8245\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3467 - accuracy: 0.8613 - val_loss: 0.3574 - val_accuracy: 0.8618\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3381 - accuracy: 0.8588 - val_loss: 0.3960 - val_accuracy: 0.8680\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3370 - accuracy: 0.8615 - val_loss: 0.3694 - val_accuracy: 0.8509\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3334 - accuracy: 0.8636 - val_loss: 0.3662 - val_accuracy: 0.8602\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3123 - accuracy: 0.8708 - val_loss: 0.3218 - val_accuracy: 0.8618\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3093 - accuracy: 0.8683 - val_loss: 0.3195 - val_accuracy: 0.8602\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3057 - accuracy: 0.8724 - val_loss: 0.3153 - val_accuracy: 0.8634\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3101 - accuracy: 0.8753 - val_loss: 0.3165 - val_accuracy: 0.8665\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3150 - accuracy: 0.8706 - val_loss: 0.3372 - val_accuracy: 0.8634\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.2931 - accuracy: 0.8767 - val_loss: 0.3160 - val_accuracy: 0.8634\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.2919 - accuracy: 0.8759 - val_loss: 0.3105 - val_accuracy: 0.8634\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.2928 - accuracy: 0.8776 - val_loss: 0.3176 - val_accuracy: 0.8649\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2945 - accuracy: 0.8712 - val_loss: 0.3183 - val_accuracy: 0.8649\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2922 - accuracy: 0.8749 - val_loss: 0.3177 - val_accuracy: 0.8680\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2858 - accuracy: 0.8788 - val_loss: 0.3100 - val_accuracy: 0.8696\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2867 - accuracy: 0.8811 - val_loss: 0.3063 - val_accuracy: 0.8649\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2856 - accuracy: 0.8794 - val_loss: 0.3133 - val_accuracy: 0.8680\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2850 - accuracy: 0.8786 - val_loss: 0.3074 - val_accuracy: 0.8618\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2833 - accuracy: 0.8817 - val_loss: 0.3067 - val_accuracy: 0.8665\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2830 - accuracy: 0.8807 - val_loss: 0.3069 - val_accuracy: 0.8634\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2844 - accuracy: 0.8790 - val_loss: 0.3063 - val_accuracy: 0.8618\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2832 - accuracy: 0.8827 - val_loss: 0.3055 - val_accuracy: 0.8618\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2842 - accuracy: 0.8803 - val_loss: 0.3080 - val_accuracy: 0.8649\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2852 - accuracy: 0.8798 - val_loss: 0.3083 - val_accuracy: 0.8649\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2865 - accuracy: 0.8800 - val_loss: 0.3046 - val_accuracy: 0.8634\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2811 - accuracy: 0.8800 - val_loss: 0.3048 - val_accuracy: 0.8618\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2821 - accuracy: 0.8821 - val_loss: 0.3069 - val_accuracy: 0.8649\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2806 - accuracy: 0.8811 - val_loss: 0.3056 - val_accuracy: 0.8649\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2823 - accuracy: 0.8796 - val_loss: 0.3057 - val_accuracy: 0.8649\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2853 - accuracy: 0.8786 - val_loss: 0.3047 - val_accuracy: 0.8602\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 18.6532 - accuracy: 0.5338 - val_loss: 2.5088 - val_accuracy: 0.5559\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.4606 - accuracy: 0.6500 - val_loss: 0.4670 - val_accuracy: 0.7717\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.4964 - accuracy: 0.7774 - val_loss: 0.4764 - val_accuracy: 0.7531\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4642 - accuracy: 0.7991 - val_loss: 0.5754 - val_accuracy: 0.7438\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5225 - accuracy: 0.7718 - val_loss: 0.4450 - val_accuracy: 0.8416\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4810 - accuracy: 0.7857 - val_loss: 0.5924 - val_accuracy: 0.6786\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4423 - accuracy: 0.8145 - val_loss: 0.5721 - val_accuracy: 0.7127\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4627 - accuracy: 0.7966 - val_loss: 0.4546 - val_accuracy: 0.8587\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4326 - accuracy: 0.8199 - val_loss: 0.4110 - val_accuracy: 0.8478\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3993 - accuracy: 0.8427 - val_loss: 0.4639 - val_accuracy: 0.7547\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4030 - accuracy: 0.8329 - val_loss: 0.5237 - val_accuracy: 0.8571\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4215 - accuracy: 0.8279 - val_loss: 0.4874 - val_accuracy: 0.8571\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4165 - accuracy: 0.8308 - val_loss: 0.4090 - val_accuracy: 0.8106\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3931 - accuracy: 0.8465 - val_loss: 0.4020 - val_accuracy: 0.8602\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3931 - accuracy: 0.8386 - val_loss: 0.4006 - val_accuracy: 0.8680\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3774 - accuracy: 0.8559 - val_loss: 0.4011 - val_accuracy: 0.8230\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3827 - accuracy: 0.8498 - val_loss: 0.3871 - val_accuracy: 0.8447\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3830 - accuracy: 0.8458 - val_loss: 0.3804 - val_accuracy: 0.8478\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3919 - accuracy: 0.8361 - val_loss: 0.4083 - val_accuracy: 0.8494\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3904 - accuracy: 0.8397 - val_loss: 0.3964 - val_accuracy: 0.8245\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3581 - accuracy: 0.8539 - val_loss: 0.4259 - val_accuracy: 0.8587\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8574 - val_loss: 0.3775 - val_accuracy: 0.8711\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3523 - accuracy: 0.8609 - val_loss: 0.3825 - val_accuracy: 0.8292\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3593 - accuracy: 0.8495 - val_loss: 0.3912 - val_accuracy: 0.8276\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3541 - accuracy: 0.8553 - val_loss: 0.3922 - val_accuracy: 0.8261\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3488 - accuracy: 0.8594 - val_loss: 0.3684 - val_accuracy: 0.8401\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3503 - accuracy: 0.8586 - val_loss: 0.3803 - val_accuracy: 0.8711\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3426 - accuracy: 0.8598 - val_loss: 0.3682 - val_accuracy: 0.8727\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3452 - accuracy: 0.8553 - val_loss: 0.3639 - val_accuracy: 0.8354\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3423 - accuracy: 0.8629 - val_loss: 0.3640 - val_accuracy: 0.8711\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8574 - val_loss: 0.3634 - val_accuracy: 0.8680\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3389 - accuracy: 0.8598 - val_loss: 0.3648 - val_accuracy: 0.8339\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3337 - accuracy: 0.8561 - val_loss: 0.3677 - val_accuracy: 0.8742\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3374 - accuracy: 0.8599 - val_loss: 0.3623 - val_accuracy: 0.8339\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3368 - accuracy: 0.8603 - val_loss: 0.3612 - val_accuracy: 0.8711\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3338 - accuracy: 0.8634 - val_loss: 0.3561 - val_accuracy: 0.8478\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3345 - accuracy: 0.8603 - val_loss: 0.3625 - val_accuracy: 0.8370\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3278 - accuracy: 0.8623 - val_loss: 0.3629 - val_accuracy: 0.8649\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3269 - accuracy: 0.8650 - val_loss: 0.3573 - val_accuracy: 0.8727\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3291 - accuracy: 0.8627 - val_loss: 0.3526 - val_accuracy: 0.8447\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3292 - accuracy: 0.8596 - val_loss: 0.3542 - val_accuracy: 0.8634\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3252 - accuracy: 0.8691 - val_loss: 0.3523 - val_accuracy: 0.8649\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3277 - accuracy: 0.8627 - val_loss: 0.3591 - val_accuracy: 0.8665\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3253 - accuracy: 0.8671 - val_loss: 0.3538 - val_accuracy: 0.8696\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3251 - accuracy: 0.8656 - val_loss: 0.3509 - val_accuracy: 0.8509\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3202 - accuracy: 0.8706 - val_loss: 0.3507 - val_accuracy: 0.8649\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3196 - accuracy: 0.8675 - val_loss: 0.3520 - val_accuracy: 0.8696\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3249 - accuracy: 0.8669 - val_loss: 0.3499 - val_accuracy: 0.8649\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3196 - accuracy: 0.8656 - val_loss: 0.3504 - val_accuracy: 0.8711\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3191 - accuracy: 0.8681 - val_loss: 0.3500 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:12:54,712] Trial 163 finished with value: 0.8751552700996399 and parameters: {'units': 60, 'dropout': 0.1, 'learning_rate': 0.005860276269412431, 'epochs': 50, 'batch_size': 30, 'patience': 5, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:12:59,152] Trial 164 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 3s - loss: 31.4114 - accuracy: 0.5163 - val_loss: 0.8065 - val_accuracy: 0.7671\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 3.8215 - accuracy: 0.6272 - val_loss: 1.0348 - val_accuracy: 0.5528\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5754 - accuracy: 0.7574 - val_loss: 0.5224 - val_accuracy: 0.7407\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4993 - accuracy: 0.7791 - val_loss: 0.4525 - val_accuracy: 0.8432\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5560 - accuracy: 0.7648 - val_loss: 0.4210 - val_accuracy: 0.8494\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.5596 - accuracy: 0.7566 - val_loss: 0.5451 - val_accuracy: 0.8587\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4362 - accuracy: 0.8190 - val_loss: 0.4841 - val_accuracy: 0.7655\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.3806 - val_accuracy: 0.8509\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4527 - accuracy: 0.7991 - val_loss: 0.4153 - val_accuracy: 0.8028\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4065 - accuracy: 0.8399 - val_loss: 0.4548 - val_accuracy: 0.7640\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3952 - accuracy: 0.8326 - val_loss: 0.4139 - val_accuracy: 0.7811\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3634 - accuracy: 0.8551 - val_loss: 0.3712 - val_accuracy: 0.8634\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3528 - accuracy: 0.8599 - val_loss: 0.3646 - val_accuracy: 0.8602\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3446 - accuracy: 0.8708 - val_loss: 0.3642 - val_accuracy: 0.8602\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3429 - accuracy: 0.8691 - val_loss: 0.3644 - val_accuracy: 0.8618\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3369 - accuracy: 0.8638 - val_loss: 0.3541 - val_accuracy: 0.8696\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3337 - accuracy: 0.8716 - val_loss: 0.3490 - val_accuracy: 0.8618\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3393 - accuracy: 0.8640 - val_loss: 0.3505 - val_accuracy: 0.8758\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3471 - accuracy: 0.8543 - val_loss: 0.3426 - val_accuracy: 0.8634\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3469 - accuracy: 0.8570 - val_loss: 0.3941 - val_accuracy: 0.8183\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3312 - accuracy: 0.8677 - val_loss: 0.3752 - val_accuracy: 0.8245\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3333 - accuracy: 0.8621 - val_loss: 0.3353 - val_accuracy: 0.8711\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3179 - accuracy: 0.8765 - val_loss: 0.3392 - val_accuracy: 0.8696\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3090 - accuracy: 0.8763 - val_loss: 0.3421 - val_accuracy: 0.8727\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3032 - accuracy: 0.8813 - val_loss: 0.3312 - val_accuracy: 0.8711\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3080 - accuracy: 0.8776 - val_loss: 0.3356 - val_accuracy: 0.8711\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3046 - accuracy: 0.8767 - val_loss: 0.3306 - val_accuracy: 0.8680\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3060 - accuracy: 0.8805 - val_loss: 0.3264 - val_accuracy: 0.8742\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.2959 - accuracy: 0.8834 - val_loss: 0.3213 - val_accuracy: 0.8711\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.2929 - accuracy: 0.8811 - val_loss: 0.3254 - val_accuracy: 0.8618\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.2931 - accuracy: 0.8825 - val_loss: 0.3254 - val_accuracy: 0.8649\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.2945 - accuracy: 0.8844 - val_loss: 0.3220 - val_accuracy: 0.8773\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2928 - accuracy: 0.8823 - val_loss: 0.3214 - val_accuracy: 0.8696\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2935 - accuracy: 0.8809 - val_loss: 0.3240 - val_accuracy: 0.8711\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2918 - accuracy: 0.8879 - val_loss: 0.3275 - val_accuracy: 0.8680\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2897 - accuracy: 0.8852 - val_loss: 0.3197 - val_accuracy: 0.8758\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2947 - accuracy: 0.8844 - val_loss: 0.3272 - val_accuracy: 0.8758\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2891 - accuracy: 0.8838 - val_loss: 0.3194 - val_accuracy: 0.8680\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2858 - accuracy: 0.8875 - val_loss: 0.3187 - val_accuracy: 0.8634\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2880 - accuracy: 0.8854 - val_loss: 0.3167 - val_accuracy: 0.8649\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2873 - accuracy: 0.8823 - val_loss: 0.3192 - val_accuracy: 0.8727\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2874 - accuracy: 0.8838 - val_loss: 0.3182 - val_accuracy: 0.8649\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2865 - accuracy: 0.8858 - val_loss: 0.3225 - val_accuracy: 0.8680\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2851 - accuracy: 0.8848 - val_loss: 0.3177 - val_accuracy: 0.8649\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2848 - accuracy: 0.8842 - val_loss: 0.3173 - val_accuracy: 0.8634\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2849 - accuracy: 0.8850 - val_loss: 0.3161 - val_accuracy: 0.8634\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2816 - accuracy: 0.8838 - val_loss: 0.3178 - val_accuracy: 0.8696\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2837 - accuracy: 0.8864 - val_loss: 0.3159 - val_accuracy: 0.8680\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2859 - accuracy: 0.8854 - val_loss: 0.3167 - val_accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2828 - accuracy: 0.8846 - val_loss: 0.3160 - val_accuracy: 0.8634\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 21.7005 - accuracy: 0.5161 - val_loss: 1.5545 - val_accuracy: 0.6615\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.8706 - accuracy: 0.6597 - val_loss: 0.4962 - val_accuracy: 0.8432\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5043 - accuracy: 0.7787 - val_loss: 0.5385 - val_accuracy: 0.7360\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4728 - accuracy: 0.8005 - val_loss: 0.4482 - val_accuracy: 0.8385\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5522 - accuracy: 0.7409 - val_loss: 0.4765 - val_accuracy: 0.7531\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.5201 - accuracy: 0.7659 - val_loss: 0.6008 - val_accuracy: 0.6584\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4606 - accuracy: 0.8013 - val_loss: 0.6418 - val_accuracy: 0.6910\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4143 - accuracy: 0.8359 - val_loss: 0.4075 - val_accuracy: 0.8432\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4030 - accuracy: 0.8436 - val_loss: 0.4809 - val_accuracy: 0.7562\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8403 - val_loss: 0.4908 - val_accuracy: 0.7345\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3767 - accuracy: 0.8524 - val_loss: 0.4033 - val_accuracy: 0.8525\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3805 - accuracy: 0.8524 - val_loss: 0.3951 - val_accuracy: 0.8447\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3804 - accuracy: 0.8512 - val_loss: 0.4430 - val_accuracy: 0.8556\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3688 - accuracy: 0.8613 - val_loss: 0.3921 - val_accuracy: 0.8602\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3624 - accuracy: 0.8601 - val_loss: 0.4091 - val_accuracy: 0.8292\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3642 - accuracy: 0.8603 - val_loss: 0.4465 - val_accuracy: 0.7516\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3574 - accuracy: 0.8638 - val_loss: 0.3640 - val_accuracy: 0.8618\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3555 - accuracy: 0.8650 - val_loss: 0.3571 - val_accuracy: 0.8602\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3602 - accuracy: 0.8557 - val_loss: 0.3764 - val_accuracy: 0.8478\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3546 - accuracy: 0.8580 - val_loss: 0.4240 - val_accuracy: 0.8059\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3414 - accuracy: 0.8722 - val_loss: 0.4076 - val_accuracy: 0.8261\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3475 - accuracy: 0.8664 - val_loss: 0.3418 - val_accuracy: 0.8665\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3321 - accuracy: 0.8712 - val_loss: 0.3718 - val_accuracy: 0.8602\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3389 - accuracy: 0.8652 - val_loss: 0.3765 - val_accuracy: 0.8540\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3317 - accuracy: 0.8763 - val_loss: 0.3908 - val_accuracy: 0.8634\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3435 - accuracy: 0.8741 - val_loss: 0.3543 - val_accuracy: 0.8634\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3189 - accuracy: 0.8759 - val_loss: 0.3669 - val_accuracy: 0.8432\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3090 - accuracy: 0.8768 - val_loss: 0.3268 - val_accuracy: 0.8680\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3007 - accuracy: 0.8834 - val_loss: 0.3336 - val_accuracy: 0.8649\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3032 - accuracy: 0.8794 - val_loss: 0.3236 - val_accuracy: 0.8711\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.2944 - accuracy: 0.8842 - val_loss: 0.3243 - val_accuracy: 0.8618\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.2981 - accuracy: 0.8821 - val_loss: 0.3271 - val_accuracy: 0.8742\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2957 - accuracy: 0.8811 - val_loss: 0.3345 - val_accuracy: 0.8665\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2941 - accuracy: 0.8831 - val_loss: 0.3343 - val_accuracy: 0.8602\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2997 - accuracy: 0.8801 - val_loss: 0.3173 - val_accuracy: 0.8773\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2921 - accuracy: 0.8794 - val_loss: 0.3167 - val_accuracy: 0.8711\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2944 - accuracy: 0.8784 - val_loss: 0.3244 - val_accuracy: 0.8680\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2965 - accuracy: 0.8807 - val_loss: 0.3248 - val_accuracy: 0.8680\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2928 - accuracy: 0.8815 - val_loss: 0.3172 - val_accuracy: 0.8711\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2977 - accuracy: 0.8823 - val_loss: 0.3225 - val_accuracy: 0.8789\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2927 - accuracy: 0.8792 - val_loss: 0.3221 - val_accuracy: 0.8773\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3068 - accuracy: 0.8819 - val_loss: 0.3177 - val_accuracy: 0.8571\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2907 - accuracy: 0.8829 - val_loss: 0.3120 - val_accuracy: 0.8602\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2964 - accuracy: 0.8794 - val_loss: 0.3129 - val_accuracy: 0.8602\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2945 - accuracy: 0.8823 - val_loss: 0.3109 - val_accuracy: 0.8680\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2819 - accuracy: 0.8813 - val_loss: 0.3020 - val_accuracy: 0.8665\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2829 - accuracy: 0.8825 - val_loss: 0.3025 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2775 - accuracy: 0.8842 - val_loss: 0.3051 - val_accuracy: 0.8665\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2779 - accuracy: 0.8854 - val_loss: 0.3042 - val_accuracy: 0.8727\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2783 - accuracy: 0.8862 - val_loss: 0.3014 - val_accuracy: 0.8665\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 27.7945 - accuracy: 0.5124 - val_loss: 1.0150 - val_accuracy: 0.7640\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 2.9174 - accuracy: 0.6754 - val_loss: 0.6412 - val_accuracy: 0.8463\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5846 - accuracy: 0.7580 - val_loss: 0.4508 - val_accuracy: 0.7950\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4582 - accuracy: 0.8104 - val_loss: 0.4721 - val_accuracy: 0.8478\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5338 - accuracy: 0.7591 - val_loss: 0.4204 - val_accuracy: 0.8385\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.5202 - accuracy: 0.7595 - val_loss: 0.6470 - val_accuracy: 0.6149\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4518 - accuracy: 0.8048 - val_loss: 0.5293 - val_accuracy: 0.7283\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4480 - accuracy: 0.8141 - val_loss: 0.4453 - val_accuracy: 0.7795\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4534 - accuracy: 0.8089 - val_loss: 0.4566 - val_accuracy: 0.8463\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4063 - accuracy: 0.8380 - val_loss: 0.4613 - val_accuracy: 0.7469\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3870 - accuracy: 0.8481 - val_loss: 0.4048 - val_accuracy: 0.8525\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3940 - accuracy: 0.8427 - val_loss: 0.4164 - val_accuracy: 0.8230\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3971 - accuracy: 0.8397 - val_loss: 0.4536 - val_accuracy: 0.8571\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3750 - accuracy: 0.8498 - val_loss: 0.3921 - val_accuracy: 0.8556\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3695 - accuracy: 0.8539 - val_loss: 0.4277 - val_accuracy: 0.7609\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3773 - accuracy: 0.8460 - val_loss: 0.4212 - val_accuracy: 0.7624\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3725 - accuracy: 0.8493 - val_loss: 0.3848 - val_accuracy: 0.8540\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3711 - accuracy: 0.8508 - val_loss: 0.3856 - val_accuracy: 0.8618\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3627 - accuracy: 0.8498 - val_loss: 0.3895 - val_accuracy: 0.8680\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3840 - accuracy: 0.8411 - val_loss: 0.4165 - val_accuracy: 0.8075\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3713 - accuracy: 0.8491 - val_loss: 0.3835 - val_accuracy: 0.8370\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3673 - accuracy: 0.8487 - val_loss: 0.3823 - val_accuracy: 0.8727\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3632 - accuracy: 0.8510 - val_loss: 0.3888 - val_accuracy: 0.8137\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3554 - accuracy: 0.8506 - val_loss: 0.3726 - val_accuracy: 0.8649\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3415 - accuracy: 0.8559 - val_loss: 0.3627 - val_accuracy: 0.8680\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3535 - accuracy: 0.8549 - val_loss: 0.3638 - val_accuracy: 0.8354\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3324 - accuracy: 0.8644 - val_loss: 0.3604 - val_accuracy: 0.8525\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3139 - accuracy: 0.8726 - val_loss: 0.3536 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3127 - accuracy: 0.8749 - val_loss: 0.3696 - val_accuracy: 0.8602\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3124 - accuracy: 0.8749 - val_loss: 0.3347 - val_accuracy: 0.8711\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3113 - accuracy: 0.8755 - val_loss: 0.3481 - val_accuracy: 0.8727\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3064 - accuracy: 0.8726 - val_loss: 0.3370 - val_accuracy: 0.8401\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2964 - accuracy: 0.8794 - val_loss: 0.3279 - val_accuracy: 0.8649\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2945 - accuracy: 0.8805 - val_loss: 0.3264 - val_accuracy: 0.8742\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2972 - accuracy: 0.8821 - val_loss: 0.3250 - val_accuracy: 0.8696\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2881 - accuracy: 0.8813 - val_loss: 0.3217 - val_accuracy: 0.8680\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2909 - accuracy: 0.8819 - val_loss: 0.3215 - val_accuracy: 0.8727\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2913 - accuracy: 0.8825 - val_loss: 0.3204 - val_accuracy: 0.8634\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2867 - accuracy: 0.8813 - val_loss: 0.3176 - val_accuracy: 0.8649\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2830 - accuracy: 0.8829 - val_loss: 0.3163 - val_accuracy: 0.8680\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2858 - accuracy: 0.8813 - val_loss: 0.3180 - val_accuracy: 0.8634\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2828 - accuracy: 0.8831 - val_loss: 0.3153 - val_accuracy: 0.8649\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2858 - accuracy: 0.8827 - val_loss: 0.3243 - val_accuracy: 0.8602\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2835 - accuracy: 0.8836 - val_loss: 0.3220 - val_accuracy: 0.8634\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2813 - accuracy: 0.8838 - val_loss: 0.3128 - val_accuracy: 0.8649\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2799 - accuracy: 0.8856 - val_loss: 0.3121 - val_accuracy: 0.8696\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2825 - accuracy: 0.8831 - val_loss: 0.3162 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2805 - accuracy: 0.8836 - val_loss: 0.3118 - val_accuracy: 0.8649\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2809 - accuracy: 0.8842 - val_loss: 0.3150 - val_accuracy: 0.8665\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2821 - accuracy: 0.8831 - val_loss: 0.3121 - val_accuracy: 0.8634\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 24.6904 - accuracy: 0.5379 - val_loss: 0.8491 - val_accuracy: 0.7640\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 3.2640 - accuracy: 0.6513 - val_loss: 0.9646 - val_accuracy: 0.5606\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5741 - accuracy: 0.7585 - val_loss: 0.4547 - val_accuracy: 0.7686\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4566 - accuracy: 0.8063 - val_loss: 0.5120 - val_accuracy: 0.8587\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5392 - accuracy: 0.7463 - val_loss: 0.4415 - val_accuracy: 0.8478\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4886 - accuracy: 0.7877 - val_loss: 0.5039 - val_accuracy: 0.8602\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4223 - accuracy: 0.8263 - val_loss: 0.4559 - val_accuracy: 0.7671\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4376 - accuracy: 0.8135 - val_loss: 0.4104 - val_accuracy: 0.8649\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4313 - accuracy: 0.8180 - val_loss: 0.3849 - val_accuracy: 0.8478\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3773 - accuracy: 0.8522 - val_loss: 0.4307 - val_accuracy: 0.7888\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3751 - accuracy: 0.8477 - val_loss: 0.4576 - val_accuracy: 0.7407\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3906 - accuracy: 0.8440 - val_loss: 0.5322 - val_accuracy: 0.7873\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4167 - accuracy: 0.8289 - val_loss: 0.4507 - val_accuracy: 0.7593\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3963 - accuracy: 0.8430 - val_loss: 0.4009 - val_accuracy: 0.8587\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3898 - accuracy: 0.8462 - val_loss: 0.4370 - val_accuracy: 0.7686\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3844 - accuracy: 0.8409 - val_loss: 0.4442 - val_accuracy: 0.7671\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3802 - accuracy: 0.8463 - val_loss: 0.3967 - val_accuracy: 0.8509\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3888 - accuracy: 0.8427 - val_loss: 0.3893 - val_accuracy: 0.8540\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3602 - accuracy: 0.8570 - val_loss: 0.3990 - val_accuracy: 0.8168\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3652 - accuracy: 0.8543 - val_loss: 0.3895 - val_accuracy: 0.8665\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3615 - accuracy: 0.8530 - val_loss: 0.4024 - val_accuracy: 0.8587\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3647 - accuracy: 0.8545 - val_loss: 0.3842 - val_accuracy: 0.8665\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8559 - val_loss: 0.3912 - val_accuracy: 0.8214\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3604 - accuracy: 0.8493 - val_loss: 0.3799 - val_accuracy: 0.8463\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3505 - accuracy: 0.8619 - val_loss: 0.4178 - val_accuracy: 0.8012\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3471 - accuracy: 0.8576 - val_loss: 0.3768 - val_accuracy: 0.8696\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3462 - accuracy: 0.8551 - val_loss: 0.3774 - val_accuracy: 0.8354\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3440 - accuracy: 0.8607 - val_loss: 0.3785 - val_accuracy: 0.8680\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3481 - accuracy: 0.8549 - val_loss: 0.3750 - val_accuracy: 0.8385\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3492 - accuracy: 0.8574 - val_loss: 0.3750 - val_accuracy: 0.8540\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3430 - accuracy: 0.8578 - val_loss: 0.3739 - val_accuracy: 0.8711\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3444 - accuracy: 0.8582 - val_loss: 0.3789 - val_accuracy: 0.8292\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3429 - accuracy: 0.8615 - val_loss: 0.3764 - val_accuracy: 0.8742\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3432 - accuracy: 0.8557 - val_loss: 0.3752 - val_accuracy: 0.8696\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3416 - accuracy: 0.8625 - val_loss: 0.3716 - val_accuracy: 0.8696\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3405 - accuracy: 0.8599 - val_loss: 0.3755 - val_accuracy: 0.8354\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3368 - accuracy: 0.8615 - val_loss: 0.3871 - val_accuracy: 0.8199\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3381 - accuracy: 0.8588 - val_loss: 0.3746 - val_accuracy: 0.8696\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3335 - accuracy: 0.8652 - val_loss: 0.3701 - val_accuracy: 0.8696\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3366 - accuracy: 0.8598 - val_loss: 0.3693 - val_accuracy: 0.8401\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3367 - accuracy: 0.8646 - val_loss: 0.3698 - val_accuracy: 0.8416\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3354 - accuracy: 0.8601 - val_loss: 0.3686 - val_accuracy: 0.8494\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3373 - accuracy: 0.8623 - val_loss: 0.3693 - val_accuracy: 0.8711\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3321 - accuracy: 0.8638 - val_loss: 0.3710 - val_accuracy: 0.8711\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3299 - accuracy: 0.8693 - val_loss: 0.3672 - val_accuracy: 0.8463\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3301 - accuracy: 0.8669 - val_loss: 0.3669 - val_accuracy: 0.8494\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3309 - accuracy: 0.8617 - val_loss: 0.3678 - val_accuracy: 0.8696\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3322 - accuracy: 0.8617 - val_loss: 0.3673 - val_accuracy: 0.8665\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3310 - accuracy: 0.8638 - val_loss: 0.3674 - val_accuracy: 0.8696\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3298 - accuracy: 0.8605 - val_loss: 0.3670 - val_accuracy: 0.8665\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 15.9702 - accuracy: 0.5482 - val_loss: 0.7534 - val_accuracy: 0.8401\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.0072 - accuracy: 0.7098 - val_loss: 0.8473 - val_accuracy: 0.4984\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5622 - accuracy: 0.7382 - val_loss: 0.6160 - val_accuracy: 0.6941\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4882 - accuracy: 0.7859 - val_loss: 0.4676 - val_accuracy: 0.8509\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5861 - accuracy: 0.7195 - val_loss: 0.5063 - val_accuracy: 0.7438\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.5029 - accuracy: 0.7753 - val_loss: 0.7221 - val_accuracy: 0.5559\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4662 - accuracy: 0.8023 - val_loss: 0.5950 - val_accuracy: 0.7019\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4619 - accuracy: 0.8092 - val_loss: 0.4270 - val_accuracy: 0.8463\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4273 - accuracy: 0.8219 - val_loss: 0.4096 - val_accuracy: 0.8525\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3966 - accuracy: 0.8397 - val_loss: 0.4188 - val_accuracy: 0.8354\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4031 - accuracy: 0.8357 - val_loss: 0.4779 - val_accuracy: 0.8509\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3819 - accuracy: 0.8508 - val_loss: 0.5461 - val_accuracy: 0.8416\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4327 - accuracy: 0.8258 - val_loss: 0.4264 - val_accuracy: 0.7748\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.4142 - accuracy: 0.8287 - val_loss: 0.5395 - val_accuracy: 0.8183\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3901 - accuracy: 0.8429 - val_loss: 0.3925 - val_accuracy: 0.8634\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3843 - accuracy: 0.8483 - val_loss: 0.3927 - val_accuracy: 0.8261\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3855 - accuracy: 0.8454 - val_loss: 0.3874 - val_accuracy: 0.8680\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3870 - accuracy: 0.8427 - val_loss: 0.4040 - val_accuracy: 0.8587\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3971 - accuracy: 0.8417 - val_loss: 0.3905 - val_accuracy: 0.8245\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3831 - accuracy: 0.8423 - val_loss: 0.3904 - val_accuracy: 0.8261\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3822 - accuracy: 0.8432 - val_loss: 0.3941 - val_accuracy: 0.8261\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3793 - accuracy: 0.8446 - val_loss: 0.3745 - val_accuracy: 0.8401\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3613 - accuracy: 0.8530 - val_loss: 0.3850 - val_accuracy: 0.8261\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3617 - accuracy: 0.8460 - val_loss: 0.3764 - val_accuracy: 0.8385\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3571 - accuracy: 0.8570 - val_loss: 0.3925 - val_accuracy: 0.8245\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3604 - accuracy: 0.8528 - val_loss: 0.3750 - val_accuracy: 0.8385\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3538 - accuracy: 0.8504 - val_loss: 0.3731 - val_accuracy: 0.8665\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3480 - accuracy: 0.8547 - val_loss: 0.3751 - val_accuracy: 0.8727\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3499 - accuracy: 0.8545 - val_loss: 0.3720 - val_accuracy: 0.8339\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3503 - accuracy: 0.8547 - val_loss: 0.3711 - val_accuracy: 0.8649\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3474 - accuracy: 0.8561 - val_loss: 0.3720 - val_accuracy: 0.8354\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3525 - accuracy: 0.8545 - val_loss: 0.3739 - val_accuracy: 0.8307\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3473 - accuracy: 0.8518 - val_loss: 0.3704 - val_accuracy: 0.8618\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3391 - accuracy: 0.8588 - val_loss: 0.3700 - val_accuracy: 0.8416\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3490 - accuracy: 0.8512 - val_loss: 0.3697 - val_accuracy: 0.8432\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3428 - accuracy: 0.8611 - val_loss: 0.3698 - val_accuracy: 0.8401\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3440 - accuracy: 0.8576 - val_loss: 0.3714 - val_accuracy: 0.8307\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3463 - accuracy: 0.8555 - val_loss: 0.3703 - val_accuracy: 0.8634\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3446 - accuracy: 0.8594 - val_loss: 0.3741 - val_accuracy: 0.8727\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3469 - accuracy: 0.8588 - val_loss: 0.3698 - val_accuracy: 0.8634\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3447 - accuracy: 0.8594 - val_loss: 0.3693 - val_accuracy: 0.8634\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3476 - accuracy: 0.8547 - val_loss: 0.3694 - val_accuracy: 0.8494\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3449 - accuracy: 0.8580 - val_loss: 0.3754 - val_accuracy: 0.8711\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3446 - accuracy: 0.8590 - val_loss: 0.3707 - val_accuracy: 0.8680\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3362 - accuracy: 0.8631 - val_loss: 0.3686 - val_accuracy: 0.8432\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3403 - accuracy: 0.8632 - val_loss: 0.3686 - val_accuracy: 0.8494\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3428 - accuracy: 0.8592 - val_loss: 0.3700 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3403 - accuracy: 0.8596 - val_loss: 0.3686 - val_accuracy: 0.8509\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3467 - accuracy: 0.8578 - val_loss: 0.3689 - val_accuracy: 0.8634\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8590 - val_loss: 0.3688 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:16:07,524] Trial 165 finished with value: 0.8754657506942749 and parameters: {'units': 60, 'dropout': 0.1, 'learning_rate': 0.005295287079242772, 'epochs': 50, 'batch_size': 30, 'patience': 5, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 4s - loss: 32.1410 - accuracy: 0.5354 - val_loss: 1.2727 - val_accuracy: 0.8401\n",
      "Epoch 2/50\n",
      "5148/5148 - 2s - loss: 4.1137 - accuracy: 0.6575 - val_loss: 1.4877 - val_accuracy: 0.4984\n",
      "Epoch 3/50\n",
      "5148/5148 - 3s - loss: 0.6060 - accuracy: 0.7584 - val_loss: 0.6298 - val_accuracy: 0.7283\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:16:24,245] Trial 166 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:16:28,737] Trial 167 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:16:33,312] Trial 168 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:16:37,461] Trial 169 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 4s - loss: 32.4662 - accuracy: 0.5297 - val_loss: 0.8367 - val_accuracy: 0.7671\n",
      "Epoch 2/50\n",
      "5148/5148 - 3s - loss: 1.0210 - accuracy: 0.7123 - val_loss: 0.7114 - val_accuracy: 0.5435\n",
      "Epoch 3/50\n",
      "5148/5148 - 3s - loss: 0.5167 - accuracy: 0.7562 - val_loss: 0.4543 - val_accuracy: 0.8416\n",
      "Epoch 4/50\n",
      "5148/5148 - 4s - loss: 0.4905 - accuracy: 0.7795 - val_loss: 0.4750 - val_accuracy: 0.8432\n",
      "Epoch 5/50\n",
      "5148/5148 - 3s - loss: 0.5247 - accuracy: 0.7597 - val_loss: 0.4701 - val_accuracy: 0.7547\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:16:57,582] Trial 170 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 3s - loss: 21.9373 - accuracy: 0.5223 - val_loss: 0.6915 - val_accuracy: 0.7764\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 2.6798 - accuracy: 0.6498 - val_loss: 0.5059 - val_accuracy: 0.8354\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5494 - accuracy: 0.7681 - val_loss: 0.6053 - val_accuracy: 0.6755\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:17:05,407] Trial 171 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:17:09,662] Trial 172 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:17:13,033] Trial 173 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 5s - loss: 12.4673 - accuracy: 0.5464 - val_loss: 0.8005 - val_accuracy: 0.8152\n",
      "Epoch 2/50\n",
      "5148/5148 - 4s - loss: 3.2396 - accuracy: 0.6581 - val_loss: 0.8994 - val_accuracy: 0.8447\n",
      "Epoch 3/50\n",
      "5148/5148 - 4s - loss: 0.9679 - accuracy: 0.7325 - val_loss: 0.6130 - val_accuracy: 0.7516\n",
      "Epoch 4/50\n",
      "5148/5148 - 4s - loss: 0.4955 - accuracy: 0.7865 - val_loss: 0.4832 - val_accuracy: 0.7593\n",
      "Epoch 5/50\n",
      "5148/5148 - 3s - loss: 0.5146 - accuracy: 0.7628 - val_loss: 0.4443 - val_accuracy: 0.7811\n",
      "Epoch 6/50\n",
      "5148/5148 - 3s - loss: 0.4662 - accuracy: 0.7968 - val_loss: 0.5255 - val_accuracy: 0.8602\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4260 - accuracy: 0.8180 - val_loss: 0.6869 - val_accuracy: 0.6770\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4293 - accuracy: 0.8254 - val_loss: 0.4162 - val_accuracy: 0.8509\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4116 - accuracy: 0.8304 - val_loss: 0.4264 - val_accuracy: 0.8556\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3961 - accuracy: 0.8430 - val_loss: 0.4107 - val_accuracy: 0.8152\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3964 - accuracy: 0.8370 - val_loss: 0.5554 - val_accuracy: 0.6879\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3809 - accuracy: 0.8500 - val_loss: 0.5102 - val_accuracy: 0.8618\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3742 - accuracy: 0.8471 - val_loss: 0.3914 - val_accuracy: 0.8618\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3945 - accuracy: 0.8395 - val_loss: 0.4974 - val_accuracy: 0.8649\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3757 - accuracy: 0.8475 - val_loss: 0.4130 - val_accuracy: 0.8012\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3911 - accuracy: 0.8366 - val_loss: 0.3821 - val_accuracy: 0.8556\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3713 - accuracy: 0.8524 - val_loss: 0.3717 - val_accuracy: 0.8556\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3628 - accuracy: 0.8520 - val_loss: 0.3705 - val_accuracy: 0.8307\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3601 - accuracy: 0.8524 - val_loss: 0.3612 - val_accuracy: 0.8571\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3541 - accuracy: 0.8545 - val_loss: 0.3510 - val_accuracy: 0.8602\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3413 - accuracy: 0.8625 - val_loss: 0.4231 - val_accuracy: 0.8602\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3184 - accuracy: 0.8720 - val_loss: 0.3419 - val_accuracy: 0.8649\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3107 - accuracy: 0.8743 - val_loss: 0.3400 - val_accuracy: 0.8385\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3167 - accuracy: 0.8644 - val_loss: 0.3443 - val_accuracy: 0.8370\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3117 - accuracy: 0.8730 - val_loss: 0.3885 - val_accuracy: 0.8168\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3248 - accuracy: 0.8588 - val_loss: 0.3437 - val_accuracy: 0.8634\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3163 - accuracy: 0.8533 - val_loss: 0.3381 - val_accuracy: 0.8727\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3226 - accuracy: 0.8564 - val_loss: 0.3349 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3127 - accuracy: 0.8582 - val_loss: 0.3760 - val_accuracy: 0.8602\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3084 - accuracy: 0.8629 - val_loss: 0.3221 - val_accuracy: 0.8789\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3005 - accuracy: 0.8669 - val_loss: 0.3237 - val_accuracy: 0.8773\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3083 - accuracy: 0.8594 - val_loss: 0.3341 - val_accuracy: 0.8463\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2985 - accuracy: 0.8671 - val_loss: 0.3594 - val_accuracy: 0.8649\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3032 - accuracy: 0.8611 - val_loss: 0.3308 - val_accuracy: 0.8680\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3008 - accuracy: 0.8697 - val_loss: 0.3259 - val_accuracy: 0.8618\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3009 - accuracy: 0.8675 - val_loss: 0.3109 - val_accuracy: 0.8711\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3084 - accuracy: 0.8644 - val_loss: 0.3156 - val_accuracy: 0.8711\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2909 - accuracy: 0.8658 - val_loss: 0.3141 - val_accuracy: 0.8649\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2920 - accuracy: 0.8675 - val_loss: 0.3145 - val_accuracy: 0.8711\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2921 - accuracy: 0.8685 - val_loss: 0.3219 - val_accuracy: 0.8696\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2919 - accuracy: 0.8658 - val_loss: 0.3265 - val_accuracy: 0.8711\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2935 - accuracy: 0.8669 - val_loss: 0.3381 - val_accuracy: 0.8571\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2955 - accuracy: 0.8693 - val_loss: 0.3237 - val_accuracy: 0.8665\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2907 - accuracy: 0.8671 - val_loss: 0.3287 - val_accuracy: 0.8602\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2852 - accuracy: 0.8648 - val_loss: 0.3088 - val_accuracy: 0.8665\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2823 - accuracy: 0.8704 - val_loss: 0.3083 - val_accuracy: 0.8711\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2862 - accuracy: 0.8666 - val_loss: 0.3093 - val_accuracy: 0.8680\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2843 - accuracy: 0.8660 - val_loss: 0.3126 - val_accuracy: 0.8665\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2811 - accuracy: 0.8722 - val_loss: 0.3132 - val_accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2855 - accuracy: 0.8652 - val_loss: 0.3089 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 20.8007 - accuracy: 0.5470 - val_loss: 1.5207 - val_accuracy: 0.8556\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 6.3949 - accuracy: 0.6313 - val_loss: 1.6333 - val_accuracy: 0.8540\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 2.5755 - accuracy: 0.6941 - val_loss: 0.8147 - val_accuracy: 0.7795\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.8619 - accuracy: 0.7589 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.4620 - accuracy: 0.8087 - val_loss: 0.4188 - val_accuracy: 0.8463\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4251 - accuracy: 0.8287 - val_loss: 0.4462 - val_accuracy: 0.8463\n",
      "Epoch 7/50\n",
      "5148/5148 - 2s - loss: 0.4061 - accuracy: 0.8364 - val_loss: 0.6550 - val_accuracy: 0.6848\n",
      "Epoch 8/50\n",
      "5148/5148 - 2s - loss: 0.4055 - accuracy: 0.8386 - val_loss: 0.4043 - val_accuracy: 0.8401\n",
      "Epoch 9/50\n",
      "5148/5148 - 2s - loss: 0.3795 - accuracy: 0.8553 - val_loss: 0.4138 - val_accuracy: 0.8261\n",
      "Epoch 10/50\n",
      "5148/5148 - 2s - loss: 0.3683 - accuracy: 0.8599 - val_loss: 0.4164 - val_accuracy: 0.8075\n",
      "Epoch 11/50\n",
      "5148/5148 - 2s - loss: 0.3605 - accuracy: 0.8634 - val_loss: 0.3900 - val_accuracy: 0.8587\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3614 - accuracy: 0.8662 - val_loss: 0.3829 - val_accuracy: 0.8509\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3593 - accuracy: 0.8594 - val_loss: 0.4255 - val_accuracy: 0.8634\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3508 - accuracy: 0.8699 - val_loss: 0.3848 - val_accuracy: 0.8571\n",
      "Epoch 15/50\n",
      "5148/5148 - 2s - loss: 0.3477 - accuracy: 0.8679 - val_loss: 0.4065 - val_accuracy: 0.8075\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3474 - accuracy: 0.8650 - val_loss: 0.3895 - val_accuracy: 0.8168\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3392 - accuracy: 0.8712 - val_loss: 0.3665 - val_accuracy: 0.8618\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3416 - accuracy: 0.8644 - val_loss: 0.3674 - val_accuracy: 0.8602\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3397 - accuracy: 0.8609 - val_loss: 0.3535 - val_accuracy: 0.8649\n",
      "Epoch 20/50\n",
      "5148/5148 - 2s - loss: 0.3444 - accuracy: 0.8596 - val_loss: 0.3964 - val_accuracy: 0.8199\n",
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.3335 - accuracy: 0.8724 - val_loss: 0.3632 - val_accuracy: 0.8618\n",
      "Epoch 22/50\n",
      "5148/5148 - 2s - loss: 0.3303 - accuracy: 0.8716 - val_loss: 0.3382 - val_accuracy: 0.8649\n",
      "Epoch 23/50\n",
      "5148/5148 - 2s - loss: 0.3172 - accuracy: 0.8726 - val_loss: 0.3509 - val_accuracy: 0.8649\n",
      "Epoch 24/50\n",
      "5148/5148 - 2s - loss: 0.3250 - accuracy: 0.8658 - val_loss: 0.3469 - val_accuracy: 0.8665\n",
      "Epoch 25/50\n",
      "5148/5148 - 2s - loss: 0.3065 - accuracy: 0.8753 - val_loss: 0.3426 - val_accuracy: 0.8665\n",
      "Epoch 26/50\n",
      "5148/5148 - 2s - loss: 0.3164 - accuracy: 0.8724 - val_loss: 0.3804 - val_accuracy: 0.8711\n",
      "Epoch 27/50\n",
      "5148/5148 - 2s - loss: 0.3299 - accuracy: 0.8625 - val_loss: 0.3931 - val_accuracy: 0.7981\n",
      "Epoch 28/50\n",
      "5148/5148 - 2s - loss: 0.3206 - accuracy: 0.8617 - val_loss: 0.3524 - val_accuracy: 0.8602\n",
      "Epoch 29/50\n",
      "5148/5148 - 2s - loss: 0.3218 - accuracy: 0.8685 - val_loss: 0.3361 - val_accuracy: 0.8634\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3199 - accuracy: 0.8761 - val_loss: 0.3339 - val_accuracy: 0.8556\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3116 - accuracy: 0.8728 - val_loss: 0.3780 - val_accuracy: 0.8447\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3232 - accuracy: 0.8712 - val_loss: 0.3370 - val_accuracy: 0.8634\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3157 - accuracy: 0.8782 - val_loss: 0.3337 - val_accuracy: 0.8587\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2972 - accuracy: 0.8842 - val_loss: 0.3371 - val_accuracy: 0.8618\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2931 - accuracy: 0.8848 - val_loss: 0.3307 - val_accuracy: 0.8665\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2867 - accuracy: 0.8852 - val_loss: 0.3324 - val_accuracy: 0.8727\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2887 - accuracy: 0.8838 - val_loss: 0.3363 - val_accuracy: 0.8665\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2874 - accuracy: 0.8821 - val_loss: 0.3275 - val_accuracy: 0.8634\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2895 - accuracy: 0.8838 - val_loss: 0.3238 - val_accuracy: 0.8649\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2906 - accuracy: 0.8823 - val_loss: 0.3256 - val_accuracy: 0.8696\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2843 - accuracy: 0.8840 - val_loss: 0.3215 - val_accuracy: 0.8742\n",
      "Epoch 42/50\n",
      "5148/5148 - 2s - loss: 0.2931 - accuracy: 0.8848 - val_loss: 0.3171 - val_accuracy: 0.8696\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2860 - accuracy: 0.8831 - val_loss: 0.3168 - val_accuracy: 0.8665\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2867 - accuracy: 0.8827 - val_loss: 0.3193 - val_accuracy: 0.8680\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2825 - accuracy: 0.8850 - val_loss: 0.3171 - val_accuracy: 0.8696\n",
      "Epoch 46/50\n",
      "5148/5148 - 2s - loss: 0.2850 - accuracy: 0.8833 - val_loss: 0.3123 - val_accuracy: 0.8758\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2866 - accuracy: 0.8811 - val_loss: 0.3151 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2777 - accuracy: 0.8854 - val_loss: 0.3070 - val_accuracy: 0.8742\n",
      "Epoch 49/50\n",
      "5148/5148 - 2s - loss: 0.2772 - accuracy: 0.8862 - val_loss: 0.3139 - val_accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "5148/5148 - 2s - loss: 0.2795 - accuracy: 0.8856 - val_loss: 0.3140 - val_accuracy: 0.8789\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 3s - loss: 19.1227 - accuracy: 0.5402 - val_loss: 1.6290 - val_accuracy: 0.8463\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 5.4448 - accuracy: 0.6589 - val_loss: 3.5960 - val_accuracy: 0.5155\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 1.9250 - accuracy: 0.7249 - val_loss: 1.3457 - val_accuracy: 0.6972\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.7250 - accuracy: 0.7587 - val_loss: 0.5027 - val_accuracy: 0.8525\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5037 - accuracy: 0.7900 - val_loss: 0.4190 - val_accuracy: 0.8401\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4709 - accuracy: 0.7982 - val_loss: 0.5218 - val_accuracy: 0.8587\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4212 - accuracy: 0.8273 - val_loss: 0.6503 - val_accuracy: 0.6910\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4243 - accuracy: 0.8310 - val_loss: 0.4076 - val_accuracy: 0.8509\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4103 - accuracy: 0.8328 - val_loss: 0.4144 - val_accuracy: 0.8478\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.3936 - accuracy: 0.8469 - val_loss: 0.4338 - val_accuracy: 0.7655\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.3973 - accuracy: 0.8357 - val_loss: 0.4529 - val_accuracy: 0.8587\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3929 - accuracy: 0.8450 - val_loss: 0.5301 - val_accuracy: 0.8354\n",
      "Epoch 13/50\n",
      "5148/5148 - 2s - loss: 0.3743 - accuracy: 0.8498 - val_loss: 0.4022 - val_accuracy: 0.8540\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3510 - accuracy: 0.8629 - val_loss: 0.3916 - val_accuracy: 0.8571\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3457 - accuracy: 0.8644 - val_loss: 0.3838 - val_accuracy: 0.8339\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3454 - accuracy: 0.8648 - val_loss: 0.3802 - val_accuracy: 0.8261\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3429 - accuracy: 0.8685 - val_loss: 0.3691 - val_accuracy: 0.8696\n",
      "Epoch 18/50\n",
      "5148/5148 - 2s - loss: 0.3491 - accuracy: 0.8561 - val_loss: 0.3655 - val_accuracy: 0.8711\n",
      "Epoch 19/50\n",
      "5148/5148 - 2s - loss: 0.3592 - accuracy: 0.8533 - val_loss: 0.3704 - val_accuracy: 0.8602\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3543 - accuracy: 0.8555 - val_loss: 0.4559 - val_accuracy: 0.7609\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3354 - accuracy: 0.8693 - val_loss: 0.3681 - val_accuracy: 0.8307\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3346 - accuracy: 0.8625 - val_loss: 0.3553 - val_accuracy: 0.8680\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3303 - accuracy: 0.8613 - val_loss: 0.3564 - val_accuracy: 0.8665\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3352 - accuracy: 0.8590 - val_loss: 0.3593 - val_accuracy: 0.8618\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3194 - accuracy: 0.8640 - val_loss: 0.3568 - val_accuracy: 0.8634\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3109 - accuracy: 0.8702 - val_loss: 0.3433 - val_accuracy: 0.8634\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3081 - accuracy: 0.8683 - val_loss: 0.3390 - val_accuracy: 0.8742\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3121 - accuracy: 0.8671 - val_loss: 0.3494 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3076 - accuracy: 0.8735 - val_loss: 0.3759 - val_accuracy: 0.8618\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3050 - accuracy: 0.8720 - val_loss: 0.3371 - val_accuracy: 0.8696\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3044 - accuracy: 0.8751 - val_loss: 0.3441 - val_accuracy: 0.8665\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3040 - accuracy: 0.8732 - val_loss: 0.3382 - val_accuracy: 0.8571\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.2929 - accuracy: 0.8755 - val_loss: 0.3427 - val_accuracy: 0.8556\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.2957 - accuracy: 0.8786 - val_loss: 0.3256 - val_accuracy: 0.8618\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.2909 - accuracy: 0.8813 - val_loss: 0.3235 - val_accuracy: 0.8742\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.2861 - accuracy: 0.8833 - val_loss: 0.3237 - val_accuracy: 0.8665\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.2869 - accuracy: 0.8823 - val_loss: 0.3263 - val_accuracy: 0.8727\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.2892 - accuracy: 0.8792 - val_loss: 0.3232 - val_accuracy: 0.8634\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.2876 - accuracy: 0.8809 - val_loss: 0.3209 - val_accuracy: 0.8727\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.2851 - accuracy: 0.8829 - val_loss: 0.3206 - val_accuracy: 0.8696\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2864 - accuracy: 0.8800 - val_loss: 0.3234 - val_accuracy: 0.8696\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2834 - accuracy: 0.8803 - val_loss: 0.3160 - val_accuracy: 0.8696\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2811 - accuracy: 0.8842 - val_loss: 0.3248 - val_accuracy: 0.8618\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2853 - accuracy: 0.8844 - val_loss: 0.3261 - val_accuracy: 0.8618\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2804 - accuracy: 0.8834 - val_loss: 0.3149 - val_accuracy: 0.8727\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.2792 - accuracy: 0.8829 - val_loss: 0.3132 - val_accuracy: 0.8696\n",
      "Epoch 47/50\n",
      "5148/5148 - 3s - loss: 0.2797 - accuracy: 0.8856 - val_loss: 0.3144 - val_accuracy: 0.8649\n",
      "Epoch 48/50\n",
      "5148/5148 - 3s - loss: 0.2795 - accuracy: 0.8846 - val_loss: 0.3144 - val_accuracy: 0.8680\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2770 - accuracy: 0.8864 - val_loss: 0.3136 - val_accuracy: 0.8649\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2779 - accuracy: 0.8864 - val_loss: 0.3127 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 17.2739 - accuracy: 0.5389 - val_loss: 1.6588 - val_accuracy: 0.6258\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 4.8358 - accuracy: 0.6480 - val_loss: 2.8068 - val_accuracy: 0.5124\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 1.4438 - accuracy: 0.7409 - val_loss: 1.1763 - val_accuracy: 0.6925\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.5692 - accuracy: 0.7813 - val_loss: 0.4725 - val_accuracy: 0.8401\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5131 - accuracy: 0.7708 - val_loss: 0.4617 - val_accuracy: 0.7609\n",
      "Epoch 6/50\n",
      "5148/5148 - 3s - loss: 0.4976 - accuracy: 0.7803 - val_loss: 0.7189 - val_accuracy: 0.5621\n",
      "Epoch 7/50\n",
      "5148/5148 - 2s - loss: 0.4293 - accuracy: 0.8242 - val_loss: 0.6467 - val_accuracy: 0.6879\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4442 - accuracy: 0.8124 - val_loss: 0.4321 - val_accuracy: 0.8571\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4391 - accuracy: 0.8102 - val_loss: 0.4364 - val_accuracy: 0.8556\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4096 - accuracy: 0.8380 - val_loss: 0.4430 - val_accuracy: 0.7516\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4187 - accuracy: 0.8267 - val_loss: 0.5528 - val_accuracy: 0.8276\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4006 - accuracy: 0.8401 - val_loss: 0.5649 - val_accuracy: 0.8571\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3957 - accuracy: 0.8421 - val_loss: 0.3989 - val_accuracy: 0.8618\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3978 - accuracy: 0.8390 - val_loss: 0.5838 - val_accuracy: 0.7453\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3993 - accuracy: 0.8384 - val_loss: 0.4784 - val_accuracy: 0.7484\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3968 - accuracy: 0.8366 - val_loss: 0.3878 - val_accuracy: 0.8665\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3996 - accuracy: 0.8405 - val_loss: 0.3942 - val_accuracy: 0.8665\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3828 - accuracy: 0.8386 - val_loss: 0.3820 - val_accuracy: 0.8727\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3854 - accuracy: 0.8413 - val_loss: 0.3918 - val_accuracy: 0.8354\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.3854 - accuracy: 0.8403 - val_loss: 0.3873 - val_accuracy: 0.8245\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3778 - accuracy: 0.8489 - val_loss: 0.4169 - val_accuracy: 0.8587\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3783 - accuracy: 0.8479 - val_loss: 0.3900 - val_accuracy: 0.8618\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.4162 - accuracy: 0.8244 - val_loss: 0.4081 - val_accuracy: 0.8587\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.4040 - accuracy: 0.8328 - val_loss: 0.4287 - val_accuracy: 0.8587\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3806 - accuracy: 0.8475 - val_loss: 0.4787 - val_accuracy: 0.8587\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3610 - accuracy: 0.8537 - val_loss: 0.3820 - val_accuracy: 0.8602\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3505 - accuracy: 0.8627 - val_loss: 0.3753 - val_accuracy: 0.8292\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3455 - accuracy: 0.8627 - val_loss: 0.3974 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3473 - accuracy: 0.8580 - val_loss: 0.3912 - val_accuracy: 0.8571\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3361 - accuracy: 0.8619 - val_loss: 0.3743 - val_accuracy: 0.8587\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3322 - accuracy: 0.8629 - val_loss: 0.3619 - val_accuracy: 0.8556\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3275 - accuracy: 0.8638 - val_loss: 0.3475 - val_accuracy: 0.8634\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3109 - accuracy: 0.8718 - val_loss: 0.3450 - val_accuracy: 0.8618\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3090 - accuracy: 0.8726 - val_loss: 0.3422 - val_accuracy: 0.8649\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3070 - accuracy: 0.8751 - val_loss: 0.3505 - val_accuracy: 0.8665\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3047 - accuracy: 0.8768 - val_loss: 0.3507 - val_accuracy: 0.8665\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3047 - accuracy: 0.8753 - val_loss: 0.3454 - val_accuracy: 0.8307\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3061 - accuracy: 0.8753 - val_loss: 0.3381 - val_accuracy: 0.8618\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3016 - accuracy: 0.8765 - val_loss: 0.3347 - val_accuracy: 0.8711\n",
      "Epoch 40/50\n",
      "5148/5148 - 2s - loss: 0.2964 - accuracy: 0.8759 - val_loss: 0.3341 - val_accuracy: 0.8556\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.2990 - accuracy: 0.8751 - val_loss: 0.3319 - val_accuracy: 0.8727\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.2970 - accuracy: 0.8788 - val_loss: 0.3360 - val_accuracy: 0.8649\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.2977 - accuracy: 0.8823 - val_loss: 0.3395 - val_accuracy: 0.8602\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.2937 - accuracy: 0.8790 - val_loss: 0.3370 - val_accuracy: 0.8649\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.2928 - accuracy: 0.8796 - val_loss: 0.3252 - val_accuracy: 0.8665\n",
      "Epoch 46/50\n",
      "5148/5148 - 2s - loss: 0.2915 - accuracy: 0.8800 - val_loss: 0.3255 - val_accuracy: 0.8711\n",
      "Epoch 47/50\n",
      "5148/5148 - 2s - loss: 0.2873 - accuracy: 0.8807 - val_loss: 0.3266 - val_accuracy: 0.8649\n",
      "Epoch 48/50\n",
      "5148/5148 - 2s - loss: 0.2884 - accuracy: 0.8782 - val_loss: 0.3238 - val_accuracy: 0.8680\n",
      "Epoch 49/50\n",
      "5148/5148 - 2s - loss: 0.2875 - accuracy: 0.8827 - val_loss: 0.3241 - val_accuracy: 0.8634\n",
      "Epoch 50/50\n",
      "5148/5148 - 3s - loss: 0.2853 - accuracy: 0.8844 - val_loss: 0.3228 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 2s - loss: 20.7431 - accuracy: 0.5385 - val_loss: 1.1937 - val_accuracy: 0.7671\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 6.3250 - accuracy: 0.6239 - val_loss: 3.6533 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 2.1707 - accuracy: 0.6997 - val_loss: 2.1556 - val_accuracy: 0.6227\n",
      "Epoch 4/50\n",
      "5148/5148 - 2s - loss: 0.7232 - accuracy: 0.7576 - val_loss: 0.7315 - val_accuracy: 0.5978\n",
      "Epoch 5/50\n",
      "5148/5148 - 2s - loss: 0.6452 - accuracy: 0.7242 - val_loss: 0.5537 - val_accuracy: 0.8602\n",
      "Epoch 6/50\n",
      "5148/5148 - 2s - loss: 0.6149 - accuracy: 0.7500 - val_loss: 0.8091 - val_accuracy: 0.5559\n",
      "Epoch 7/50\n",
      "5148/5148 - 2s - loss: 0.4408 - accuracy: 0.8188 - val_loss: 0.5244 - val_accuracy: 0.7236\n",
      "Epoch 8/50\n",
      "5148/5148 - 2s - loss: 0.4472 - accuracy: 0.8155 - val_loss: 0.4271 - val_accuracy: 0.7904\n",
      "Epoch 9/50\n",
      "5148/5148 - 2s - loss: 0.4405 - accuracy: 0.8102 - val_loss: 0.4193 - val_accuracy: 0.8540\n",
      "Epoch 10/50\n",
      "5148/5148 - 2s - loss: 0.3970 - accuracy: 0.8438 - val_loss: 0.5602 - val_accuracy: 0.7205\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4094 - accuracy: 0.8324 - val_loss: 0.5023 - val_accuracy: 0.7236\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.3923 - accuracy: 0.8392 - val_loss: 0.4322 - val_accuracy: 0.8602\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.3614 - accuracy: 0.8561 - val_loss: 0.3854 - val_accuracy: 0.8509\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.3462 - accuracy: 0.8652 - val_loss: 0.3729 - val_accuracy: 0.8571\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.3456 - accuracy: 0.8632 - val_loss: 0.3940 - val_accuracy: 0.8214\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8632 - val_loss: 0.3963 - val_accuracy: 0.8168\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.3449 - accuracy: 0.8603 - val_loss: 0.3705 - val_accuracy: 0.8571\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.3512 - accuracy: 0.8580 - val_loss: 0.3648 - val_accuracy: 0.8509\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.3434 - accuracy: 0.8549 - val_loss: 0.3545 - val_accuracy: 0.8696\n",
      "Epoch 20/50\n",
      "5148/5148 - 2s - loss: 0.3488 - accuracy: 0.8549 - val_loss: 0.3819 - val_accuracy: 0.8199\n",
      "Epoch 21/50\n",
      "5148/5148 - 2s - loss: 0.3353 - accuracy: 0.8666 - val_loss: 0.3885 - val_accuracy: 0.8214\n",
      "Epoch 22/50\n",
      "5148/5148 - 2s - loss: 0.3504 - accuracy: 0.8535 - val_loss: 0.3706 - val_accuracy: 0.8478\n",
      "Epoch 23/50\n",
      "5148/5148 - 2s - loss: 0.3403 - accuracy: 0.8582 - val_loss: 0.3680 - val_accuracy: 0.8292\n",
      "Epoch 24/50\n",
      "5148/5148 - 2s - loss: 0.3479 - accuracy: 0.8508 - val_loss: 0.3637 - val_accuracy: 0.8634\n",
      "Epoch 25/50\n",
      "5148/5148 - 2s - loss: 0.3272 - accuracy: 0.8607 - val_loss: 0.3711 - val_accuracy: 0.8618\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3524 - val_accuracy: 0.8385\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3144 - accuracy: 0.8671 - val_loss: 0.3441 - val_accuracy: 0.8696\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3144 - accuracy: 0.8722 - val_loss: 0.3674 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3111 - accuracy: 0.8739 - val_loss: 0.3705 - val_accuracy: 0.8602\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3088 - accuracy: 0.8702 - val_loss: 0.3378 - val_accuracy: 0.8711\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3074 - accuracy: 0.8743 - val_loss: 0.3449 - val_accuracy: 0.8649\n",
      "Epoch 32/50\n",
      "5148/5148 - 2s - loss: 0.3080 - accuracy: 0.8689 - val_loss: 0.3455 - val_accuracy: 0.8385\n",
      "Epoch 33/50\n",
      "5148/5148 - 2s - loss: 0.2964 - accuracy: 0.8755 - val_loss: 0.3429 - val_accuracy: 0.8696\n",
      "Epoch 34/50\n",
      "5148/5148 - 2s - loss: 0.3027 - accuracy: 0.8714 - val_loss: 0.3334 - val_accuracy: 0.8696\n",
      "Epoch 35/50\n",
      "5148/5148 - 2s - loss: 0.2979 - accuracy: 0.8706 - val_loss: 0.3349 - val_accuracy: 0.8680\n",
      "Epoch 36/50\n",
      "5148/5148 - 2s - loss: 0.2971 - accuracy: 0.8755 - val_loss: 0.3362 - val_accuracy: 0.8385\n",
      "Epoch 37/50\n",
      "5148/5148 - 2s - loss: 0.2982 - accuracy: 0.8753 - val_loss: 0.3384 - val_accuracy: 0.8385\n",
      "Epoch 38/50\n",
      "5148/5148 - 2s - loss: 0.2916 - accuracy: 0.8761 - val_loss: 0.3221 - val_accuracy: 0.8711\n",
      "Epoch 39/50\n",
      "5148/5148 - 2s - loss: 0.2884 - accuracy: 0.8768 - val_loss: 0.3253 - val_accuracy: 0.8711\n",
      "Epoch 40/50\n",
      "5148/5148 - 2s - loss: 0.2897 - accuracy: 0.8792 - val_loss: 0.3207 - val_accuracy: 0.8711\n",
      "Epoch 41/50\n",
      "5148/5148 - 3s - loss: 0.2896 - accuracy: 0.8745 - val_loss: 0.3299 - val_accuracy: 0.8649\n",
      "Epoch 42/50\n",
      "5148/5148 - 3s - loss: 0.2902 - accuracy: 0.8772 - val_loss: 0.3260 - val_accuracy: 0.8680\n",
      "Epoch 43/50\n",
      "5148/5148 - 3s - loss: 0.2866 - accuracy: 0.8774 - val_loss: 0.3313 - val_accuracy: 0.8696\n",
      "Epoch 44/50\n",
      "5148/5148 - 2s - loss: 0.2857 - accuracy: 0.8823 - val_loss: 0.3253 - val_accuracy: 0.8711\n",
      "Epoch 45/50\n",
      "5148/5148 - 3s - loss: 0.2816 - accuracy: 0.8817 - val_loss: 0.3161 - val_accuracy: 0.8696\n",
      "Epoch 46/50\n",
      "5148/5148 - 2s - loss: 0.2830 - accuracy: 0.8778 - val_loss: 0.3165 - val_accuracy: 0.8680\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.2821 - accuracy: 0.8817 - val_loss: 0.3157 - val_accuracy: 0.8665\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.2764 - accuracy: 0.8834 - val_loss: 0.3155 - val_accuracy: 0.8665\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.2815 - accuracy: 0.8819 - val_loss: 0.3136 - val_accuracy: 0.8711\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.2772 - accuracy: 0.8823 - val_loss: 0.3126 - val_accuracy: 0.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:22:36,815] Trial 174 finished with value: 0.8751552700996399 and parameters: {'units': 100, 'dropout': 0.05, 'learning_rate': 0.005453691482423045, 'epochs': 50, 'batch_size': 30, 'patience': 7, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:22:40,549] Trial 175 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:22:42,791] Trial 176 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:22:47,842] Trial 177 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:22:52,487] Trial 178 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:22:56,397] Trial 179 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:23:00,245] Trial 180 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 4s - loss: 28.4721 - accuracy: 0.5276 - val_loss: 1.2675 - val_accuracy: 0.8075\n",
      "Epoch 2/45\n",
      "5148/5148 - 3s - loss: 4.2160 - accuracy: 0.6529 - val_loss: 3.1904 - val_accuracy: 0.4984\n",
      "Epoch 3/45\n",
      "5148/5148 - 3s - loss: 0.7586 - accuracy: 0.7578 - val_loss: 0.4669 - val_accuracy: 0.7655\n",
      "Epoch 4/45\n",
      "5148/5148 - 4s - loss: 0.4949 - accuracy: 0.7943 - val_loss: 0.4564 - val_accuracy: 0.8447\n",
      "Epoch 5/45\n",
      "5148/5148 - 3s - loss: 0.5362 - accuracy: 0.7677 - val_loss: 0.5261 - val_accuracy: 0.8587\n",
      "Epoch 6/45\n",
      "5148/5148 - 3s - loss: 0.5093 - accuracy: 0.7813 - val_loss: 0.5855 - val_accuracy: 0.8587\n",
      "Epoch 7/45\n",
      "5148/5148 - 3s - loss: 0.4496 - accuracy: 0.8131 - val_loss: 0.5526 - val_accuracy: 0.7174\n",
      "Epoch 8/45\n",
      "5148/5148 - 3s - loss: 0.4340 - accuracy: 0.8159 - val_loss: 0.4826 - val_accuracy: 0.7329\n",
      "Epoch 9/45\n",
      "5148/5148 - 3s - loss: 0.4379 - accuracy: 0.8125 - val_loss: 0.4521 - val_accuracy: 0.8602\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.4066 - accuracy: 0.8399 - val_loss: 0.4214 - val_accuracy: 0.7904\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.4232 - accuracy: 0.8162 - val_loss: 0.4643 - val_accuracy: 0.8463\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4159 - accuracy: 0.8298 - val_loss: 0.4473 - val_accuracy: 0.8618\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.4069 - accuracy: 0.8376 - val_loss: 0.4540 - val_accuracy: 0.7562\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.4195 - accuracy: 0.8225 - val_loss: 0.4127 - val_accuracy: 0.8556\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.4585 - accuracy: 0.7964 - val_loss: 0.5890 - val_accuracy: 0.6724\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.4379 - accuracy: 0.8135 - val_loss: 0.4250 - val_accuracy: 0.8556\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.4405 - accuracy: 0.8104 - val_loss: 0.4380 - val_accuracy: 0.7655\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.4552 - accuracy: 0.8032 - val_loss: 0.4788 - val_accuracy: 0.8416\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4584 - accuracy: 0.8225 - val_loss: 0.4201 - val_accuracy: 0.8618\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4624 - accuracy: 0.7978 - val_loss: 0.4088 - val_accuracy: 0.8602\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.4064 - accuracy: 0.8366 - val_loss: 0.4017 - val_accuracy: 0.8292\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.3973 - accuracy: 0.8394 - val_loss: 0.4021 - val_accuracy: 0.8649\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3879 - accuracy: 0.8430 - val_loss: 0.3968 - val_accuracy: 0.8292\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3858 - accuracy: 0.8407 - val_loss: 0.3926 - val_accuracy: 0.8401\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.3763 - accuracy: 0.8401 - val_loss: 0.3918 - val_accuracy: 0.8276\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3801 - accuracy: 0.8442 - val_loss: 0.3857 - val_accuracy: 0.8339\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3699 - accuracy: 0.8531 - val_loss: 0.3942 - val_accuracy: 0.8276\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3733 - accuracy: 0.8454 - val_loss: 0.4927 - val_accuracy: 0.8602\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3800 - accuracy: 0.8442 - val_loss: 0.3735 - val_accuracy: 0.8649\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3680 - accuracy: 0.8454 - val_loss: 0.4504 - val_accuracy: 0.8649\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3608 - accuracy: 0.8520 - val_loss: 0.3728 - val_accuracy: 0.8602\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3600 - accuracy: 0.8522 - val_loss: 0.3761 - val_accuracy: 0.8307\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3558 - accuracy: 0.8502 - val_loss: 0.3704 - val_accuracy: 0.8587\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3543 - accuracy: 0.8508 - val_loss: 0.3708 - val_accuracy: 0.8602\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3572 - accuracy: 0.8512 - val_loss: 0.3717 - val_accuracy: 0.8680\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3504 - accuracy: 0.8543 - val_loss: 0.3719 - val_accuracy: 0.8276\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3514 - accuracy: 0.8528 - val_loss: 0.3902 - val_accuracy: 0.8276\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3497 - accuracy: 0.8555 - val_loss: 0.3700 - val_accuracy: 0.8339\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3554 - accuracy: 0.8528 - val_loss: 0.3742 - val_accuracy: 0.8696\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3529 - accuracy: 0.8541 - val_loss: 0.3838 - val_accuracy: 0.8323\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3547 - accuracy: 0.8473 - val_loss: 0.3861 - val_accuracy: 0.8323\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3612 - accuracy: 0.8498 - val_loss: 0.3849 - val_accuracy: 0.8680\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3538 - accuracy: 0.8489 - val_loss: 0.3684 - val_accuracy: 0.8323\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3531 - accuracy: 0.8528 - val_loss: 0.3688 - val_accuracy: 0.8587\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3584 - accuracy: 0.8498 - val_loss: 0.3681 - val_accuracy: 0.8587\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 27.3603 - accuracy: 0.5272 - val_loss: 2.4970 - val_accuracy: 0.6755\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 3.7061 - accuracy: 0.6591 - val_loss: 0.6849 - val_accuracy: 0.8494\n",
      "Epoch 3/45\n",
      "5148/5148 - 2s - loss: 0.5809 - accuracy: 0.7753 - val_loss: 0.4599 - val_accuracy: 0.7671\n",
      "Epoch 4/45\n",
      "5148/5148 - 2s - loss: 0.4823 - accuracy: 0.8044 - val_loss: 0.4295 - val_accuracy: 0.7857\n",
      "Epoch 5/45\n",
      "5148/5148 - 2s - loss: 0.5690 - accuracy: 0.7339 - val_loss: 0.4412 - val_accuracy: 0.7795\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.5031 - accuracy: 0.7787 - val_loss: 0.6641 - val_accuracy: 0.6413\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.4252 - accuracy: 0.8205 - val_loss: 0.4172 - val_accuracy: 0.8043\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4172 - accuracy: 0.8318 - val_loss: 0.4028 - val_accuracy: 0.8478\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4101 - accuracy: 0.8306 - val_loss: 0.3919 - val_accuracy: 0.8525\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.3944 - accuracy: 0.8423 - val_loss: 0.4673 - val_accuracy: 0.7516\n",
      "Epoch 11/45\n",
      "5148/5148 - 2s - loss: 0.4352 - accuracy: 0.8085 - val_loss: 0.4233 - val_accuracy: 0.8525\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4252 - accuracy: 0.8234 - val_loss: 0.5300 - val_accuracy: 0.7950\n",
      "Epoch 13/45\n",
      "5148/5148 - 2s - loss: 0.3952 - accuracy: 0.8462 - val_loss: 0.4048 - val_accuracy: 0.8618\n",
      "Epoch 14/45\n",
      "5148/5148 - 2s - loss: 0.4166 - accuracy: 0.8217 - val_loss: 0.3823 - val_accuracy: 0.8587\n",
      "Epoch 15/45\n",
      "5148/5148 - 2s - loss: 0.4322 - accuracy: 0.8155 - val_loss: 0.4227 - val_accuracy: 0.8261\n",
      "Epoch 16/45\n",
      "5148/5148 - 2s - loss: 0.3938 - accuracy: 0.8355 - val_loss: 0.3790 - val_accuracy: 0.8602\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.4042 - accuracy: 0.8271 - val_loss: 0.3764 - val_accuracy: 0.8618\n",
      "Epoch 18/45\n",
      "5148/5148 - 2s - loss: 0.3947 - accuracy: 0.8355 - val_loss: 0.3936 - val_accuracy: 0.8571\n",
      "Epoch 19/45\n",
      "5148/5148 - 2s - loss: 0.4041 - accuracy: 0.8357 - val_loss: 0.4461 - val_accuracy: 0.8556\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4002 - accuracy: 0.8374 - val_loss: 0.3626 - val_accuracy: 0.8571\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.3735 - accuracy: 0.8460 - val_loss: 0.3575 - val_accuracy: 0.8571\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.3590 - accuracy: 0.8436 - val_loss: 0.3536 - val_accuracy: 0.8571\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3538 - accuracy: 0.8469 - val_loss: 0.3608 - val_accuracy: 0.8571\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3467 - accuracy: 0.8551 - val_loss: 0.3463 - val_accuracy: 0.8649\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.3423 - accuracy: 0.8605 - val_loss: 0.4496 - val_accuracy: 0.7484\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3467 - accuracy: 0.8430 - val_loss: 0.3929 - val_accuracy: 0.8525\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3402 - accuracy: 0.8477 - val_loss: 0.3489 - val_accuracy: 0.8711\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3491 - accuracy: 0.8409 - val_loss: 0.3520 - val_accuracy: 0.8587\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3390 - accuracy: 0.8448 - val_loss: 0.3382 - val_accuracy: 0.8587\n",
      "Epoch 30/45\n",
      "5148/5148 - 2s - loss: 0.3372 - accuracy: 0.8432 - val_loss: 0.3493 - val_accuracy: 0.8602\n",
      "Epoch 31/45\n",
      "5148/5148 - 2s - loss: 0.3265 - accuracy: 0.8493 - val_loss: 0.3647 - val_accuracy: 0.8711\n",
      "Epoch 32/45\n",
      "5148/5148 - 2s - loss: 0.3394 - accuracy: 0.8450 - val_loss: 0.3343 - val_accuracy: 0.8711\n",
      "Epoch 33/45\n",
      "5148/5148 - 2s - loss: 0.3284 - accuracy: 0.8430 - val_loss: 0.3259 - val_accuracy: 0.8727\n",
      "Epoch 34/45\n",
      "5148/5148 - 3s - loss: 0.3298 - accuracy: 0.8491 - val_loss: 0.3365 - val_accuracy: 0.8649\n",
      "Epoch 35/45\n",
      "5148/5148 - 3s - loss: 0.3213 - accuracy: 0.8631 - val_loss: 0.3204 - val_accuracy: 0.8665\n",
      "Epoch 36/45\n",
      "5148/5148 - 2s - loss: 0.3247 - accuracy: 0.8563 - val_loss: 0.3260 - val_accuracy: 0.8773\n",
      "Epoch 37/45\n",
      "5148/5148 - 2s - loss: 0.3266 - accuracy: 0.8555 - val_loss: 0.3308 - val_accuracy: 0.8665\n",
      "Epoch 38/45\n",
      "5148/5148 - 3s - loss: 0.3272 - accuracy: 0.8572 - val_loss: 0.3685 - val_accuracy: 0.8571\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3223 - accuracy: 0.8584 - val_loss: 0.3274 - val_accuracy: 0.8696\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3142 - accuracy: 0.8566 - val_loss: 0.3218 - val_accuracy: 0.8758\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3199 - accuracy: 0.8530 - val_loss: 0.3079 - val_accuracy: 0.8758\n",
      "Epoch 42/45\n",
      "5148/5148 - 2s - loss: 0.3278 - accuracy: 0.8564 - val_loss: 0.3078 - val_accuracy: 0.8711\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3159 - accuracy: 0.8627 - val_loss: 0.3872 - val_accuracy: 0.8649\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3165 - accuracy: 0.8634 - val_loss: 0.3595 - val_accuracy: 0.8696\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.2992 - accuracy: 0.8708 - val_loss: 0.3232 - val_accuracy: 0.8727\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 18.8529 - accuracy: 0.5451 - val_loss: 7.4495 - val_accuracy: 0.4922\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 2.2832 - accuracy: 0.6774 - val_loss: 1.0927 - val_accuracy: 0.5093\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.5393 - accuracy: 0.7609 - val_loss: 0.4473 - val_accuracy: 0.7780\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.4839 - accuracy: 0.7883 - val_loss: 0.4469 - val_accuracy: 0.7733\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5488 - accuracy: 0.7486 - val_loss: 0.4186 - val_accuracy: 0.8416\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.4732 - accuracy: 0.8009 - val_loss: 0.5920 - val_accuracy: 0.7453\n",
      "Epoch 7/45\n",
      "5148/5148 - 2s - loss: 0.4397 - accuracy: 0.8184 - val_loss: 0.4432 - val_accuracy: 0.7811\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4253 - accuracy: 0.8250 - val_loss: 0.5122 - val_accuracy: 0.7267\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4332 - accuracy: 0.8211 - val_loss: 0.4508 - val_accuracy: 0.8463\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.4188 - accuracy: 0.8308 - val_loss: 0.4729 - val_accuracy: 0.7500\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.4365 - accuracy: 0.8125 - val_loss: 0.4249 - val_accuracy: 0.8540\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4001 - accuracy: 0.8328 - val_loss: 0.4672 - val_accuracy: 0.8587\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.3937 - accuracy: 0.8419 - val_loss: 0.4286 - val_accuracy: 0.8556\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.3870 - accuracy: 0.8425 - val_loss: 0.5229 - val_accuracy: 0.8649\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.3932 - accuracy: 0.8277 - val_loss: 0.5077 - val_accuracy: 0.6863\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.4292 - accuracy: 0.8112 - val_loss: 0.4025 - val_accuracy: 0.8618\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.4274 - accuracy: 0.8151 - val_loss: 0.4675 - val_accuracy: 0.7609\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.4158 - accuracy: 0.8028 - val_loss: 0.3791 - val_accuracy: 0.8571\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4220 - accuracy: 0.8289 - val_loss: 0.4295 - val_accuracy: 0.8540\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4721 - accuracy: 0.7766 - val_loss: 0.4795 - val_accuracy: 0.8649\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.4799 - accuracy: 0.7941 - val_loss: 0.4419 - val_accuracy: 0.8323\n",
      "Epoch 22/45\n",
      "5148/5148 - 2s - loss: 0.4816 - accuracy: 0.7918 - val_loss: 0.4095 - val_accuracy: 0.8556\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.4208 - accuracy: 0.8287 - val_loss: 0.4207 - val_accuracy: 0.8292\n",
      "Epoch 24/45\n",
      "5148/5148 - 2s - loss: 0.4175 - accuracy: 0.8281 - val_loss: 0.3841 - val_accuracy: 0.8680\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4226 - accuracy: 0.8294 - val_loss: 0.4284 - val_accuracy: 0.8245\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4148 - accuracy: 0.8306 - val_loss: 0.3980 - val_accuracy: 0.8307\n",
      "Epoch 27/45\n",
      "5148/5148 - 3s - loss: 0.4156 - accuracy: 0.8252 - val_loss: 0.3910 - val_accuracy: 0.8323\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.4125 - accuracy: 0.8275 - val_loss: 0.4130 - val_accuracy: 0.8618\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.4149 - accuracy: 0.8316 - val_loss: 0.4044 - val_accuracy: 0.8323\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.4044 - accuracy: 0.8285 - val_loss: 0.4399 - val_accuracy: 0.8618\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.4026 - accuracy: 0.8304 - val_loss: 0.3819 - val_accuracy: 0.8354\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3871 - accuracy: 0.8380 - val_loss: 0.3948 - val_accuracy: 0.8370\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3624 - accuracy: 0.8485 - val_loss: 0.3865 - val_accuracy: 0.8571\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3653 - accuracy: 0.8440 - val_loss: 0.3878 - val_accuracy: 0.8649\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3574 - accuracy: 0.8531 - val_loss: 0.3792 - val_accuracy: 0.8370\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8520 - val_loss: 0.3809 - val_accuracy: 0.8370\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3561 - accuracy: 0.8473 - val_loss: 0.3967 - val_accuracy: 0.8307\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3580 - accuracy: 0.8495 - val_loss: 0.3759 - val_accuracy: 0.8509\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3526 - accuracy: 0.8495 - val_loss: 0.3772 - val_accuracy: 0.8354\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3559 - accuracy: 0.8493 - val_loss: 0.3824 - val_accuracy: 0.8339\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3494 - accuracy: 0.8454 - val_loss: 0.3757 - val_accuracy: 0.8323\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3532 - accuracy: 0.8475 - val_loss: 0.3706 - val_accuracy: 0.8339\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3425 - accuracy: 0.8533 - val_loss: 0.3696 - val_accuracy: 0.8307\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3507 - accuracy: 0.8502 - val_loss: 0.3751 - val_accuracy: 0.8618\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3432 - accuracy: 0.8545 - val_loss: 0.3720 - val_accuracy: 0.8370\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 3s - loss: 20.7453 - accuracy: 0.5486 - val_loss: 1.2063 - val_accuracy: 0.7717\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 3.0364 - accuracy: 0.6698 - val_loss: 1.7496 - val_accuracy: 0.4984\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.6582 - accuracy: 0.7442 - val_loss: 0.4589 - val_accuracy: 0.7717\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.4804 - accuracy: 0.7962 - val_loss: 0.4273 - val_accuracy: 0.8370\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5652 - accuracy: 0.7533 - val_loss: 0.4096 - val_accuracy: 0.8385\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.4862 - accuracy: 0.7887 - val_loss: 0.5085 - val_accuracy: 0.8602\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.3959 - accuracy: 0.8417 - val_loss: 0.4089 - val_accuracy: 0.8075\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4051 - accuracy: 0.8357 - val_loss: 0.4362 - val_accuracy: 0.7748\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4202 - accuracy: 0.8287 - val_loss: 0.3974 - val_accuracy: 0.8494\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.4123 - accuracy: 0.8312 - val_loss: 0.4629 - val_accuracy: 0.7469\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.4202 - accuracy: 0.8166 - val_loss: 0.4861 - val_accuracy: 0.8602\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.3955 - accuracy: 0.8425 - val_loss: 0.4755 - val_accuracy: 0.8602\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.4093 - accuracy: 0.8304 - val_loss: 0.4033 - val_accuracy: 0.8618\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.4208 - accuracy: 0.8275 - val_loss: 0.4020 - val_accuracy: 0.8556\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.4134 - accuracy: 0.8322 - val_loss: 0.4087 - val_accuracy: 0.8401\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.4123 - accuracy: 0.8328 - val_loss: 0.3950 - val_accuracy: 0.8556\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.4027 - accuracy: 0.8329 - val_loss: 0.4121 - val_accuracy: 0.8447\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.4034 - accuracy: 0.8329 - val_loss: 0.3744 - val_accuracy: 0.8587\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4016 - accuracy: 0.8359 - val_loss: 0.4279 - val_accuracy: 0.8494\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4003 - accuracy: 0.8345 - val_loss: 0.3655 - val_accuracy: 0.8556\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.3863 - accuracy: 0.8444 - val_loss: 0.3847 - val_accuracy: 0.8618\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.3704 - accuracy: 0.8438 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3602 - accuracy: 0.8456 - val_loss: 0.3674 - val_accuracy: 0.8680\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3519 - accuracy: 0.8539 - val_loss: 0.3561 - val_accuracy: 0.8665\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8559 - val_loss: 0.4160 - val_accuracy: 0.8261\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8498 - val_loss: 0.3686 - val_accuracy: 0.8571\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3401 - accuracy: 0.8603 - val_loss: 0.3407 - val_accuracy: 0.8634\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3446 - accuracy: 0.8553 - val_loss: 0.3727 - val_accuracy: 0.8618\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3508 - accuracy: 0.8463 - val_loss: 0.3588 - val_accuracy: 0.8602\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3443 - accuracy: 0.8450 - val_loss: 0.3412 - val_accuracy: 0.8727\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3374 - accuracy: 0.8434 - val_loss: 0.3574 - val_accuracy: 0.8680\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3337 - accuracy: 0.8483 - val_loss: 0.3327 - val_accuracy: 0.8742\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3315 - accuracy: 0.8473 - val_loss: 0.3298 - val_accuracy: 0.8727\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3368 - accuracy: 0.8495 - val_loss: 0.3383 - val_accuracy: 0.8634\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3267 - accuracy: 0.8586 - val_loss: 0.3455 - val_accuracy: 0.8758\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3204 - accuracy: 0.8658 - val_loss: 0.3269 - val_accuracy: 0.8789\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3266 - accuracy: 0.8471 - val_loss: 0.3166 - val_accuracy: 0.8711\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3298 - accuracy: 0.8483 - val_loss: 0.3550 - val_accuracy: 0.8618\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3410 - accuracy: 0.8467 - val_loss: 0.3646 - val_accuracy: 0.8587\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3443 - accuracy: 0.8454 - val_loss: 0.3372 - val_accuracy: 0.8649\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3348 - accuracy: 0.8475 - val_loss: 0.3379 - val_accuracy: 0.8711\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3408 - accuracy: 0.8438 - val_loss: 0.3328 - val_accuracy: 0.8618\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3354 - accuracy: 0.8479 - val_loss: 0.3302 - val_accuracy: 0.8602\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3376 - accuracy: 0.8473 - val_loss: 0.3424 - val_accuracy: 0.8587\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3236 - accuracy: 0.8463 - val_loss: 0.3321 - val_accuracy: 0.8602\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 25.6770 - accuracy: 0.5361 - val_loss: 2.0474 - val_accuracy: 0.7345\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 4.2326 - accuracy: 0.6618 - val_loss: 1.0670 - val_accuracy: 0.8509\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.7830 - accuracy: 0.7465 - val_loss: 0.4465 - val_accuracy: 0.7888\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.4651 - accuracy: 0.8056 - val_loss: 0.4362 - val_accuracy: 0.7873\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5399 - accuracy: 0.7584 - val_loss: 0.4372 - val_accuracy: 0.7795\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.5170 - accuracy: 0.7712 - val_loss: 0.7120 - val_accuracy: 0.5528\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.4264 - accuracy: 0.8230 - val_loss: 0.4219 - val_accuracy: 0.7935\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4073 - accuracy: 0.8337 - val_loss: 0.3982 - val_accuracy: 0.8432\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4459 - accuracy: 0.8019 - val_loss: 0.4259 - val_accuracy: 0.7919\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.4039 - accuracy: 0.8388 - val_loss: 0.4449 - val_accuracy: 0.7826\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.3632 - accuracy: 0.8662 - val_loss: 0.4002 - val_accuracy: 0.8602\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.3648 - accuracy: 0.8660 - val_loss: 0.3734 - val_accuracy: 0.8509\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.3558 - accuracy: 0.8677 - val_loss: 0.3909 - val_accuracy: 0.8618\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.3583 - accuracy: 0.8700 - val_loss: 0.3769 - val_accuracy: 0.8618\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.3533 - accuracy: 0.8697 - val_loss: 0.3818 - val_accuracy: 0.8540\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.3462 - accuracy: 0.8720 - val_loss: 0.3599 - val_accuracy: 0.8571\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.3447 - accuracy: 0.8737 - val_loss: 0.3587 - val_accuracy: 0.8634\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.3450 - accuracy: 0.8706 - val_loss: 0.3727 - val_accuracy: 0.8711\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.3575 - accuracy: 0.8601 - val_loss: 0.3823 - val_accuracy: 0.8571\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.3722 - accuracy: 0.8491 - val_loss: 0.3790 - val_accuracy: 0.8447\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.3535 - accuracy: 0.8609 - val_loss: 0.3878 - val_accuracy: 0.8634\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.3596 - accuracy: 0.8588 - val_loss: 0.3654 - val_accuracy: 0.8649\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3479 - accuracy: 0.8632 - val_loss: 0.3591 - val_accuracy: 0.8587\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3402 - accuracy: 0.8652 - val_loss: 0.3520 - val_accuracy: 0.8634\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.3346 - accuracy: 0.8677 - val_loss: 0.3911 - val_accuracy: 0.8525\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3323 - accuracy: 0.8683 - val_loss: 0.3651 - val_accuracy: 0.8571\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3090 - accuracy: 0.8780 - val_loss: 0.3311 - val_accuracy: 0.8602\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3144 - accuracy: 0.8733 - val_loss: 0.3313 - val_accuracy: 0.8587\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3065 - accuracy: 0.8788 - val_loss: 0.3688 - val_accuracy: 0.8587\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3049 - accuracy: 0.8796 - val_loss: 0.3282 - val_accuracy: 0.8618\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3044 - accuracy: 0.8784 - val_loss: 0.3271 - val_accuracy: 0.8680\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3059 - accuracy: 0.8774 - val_loss: 0.3362 - val_accuracy: 0.8665\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.2994 - accuracy: 0.8815 - val_loss: 0.3526 - val_accuracy: 0.8665\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3018 - accuracy: 0.8776 - val_loss: 0.3203 - val_accuracy: 0.8587\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.2901 - accuracy: 0.8836 - val_loss: 0.3227 - val_accuracy: 0.8587\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.2872 - accuracy: 0.8840 - val_loss: 0.3199 - val_accuracy: 0.8680\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.2864 - accuracy: 0.8860 - val_loss: 0.3182 - val_accuracy: 0.8680\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.2872 - accuracy: 0.8836 - val_loss: 0.3138 - val_accuracy: 0.8587\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.2860 - accuracy: 0.8854 - val_loss: 0.3198 - val_accuracy: 0.8665\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.2871 - accuracy: 0.8840 - val_loss: 0.3125 - val_accuracy: 0.8680\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.2867 - accuracy: 0.8840 - val_loss: 0.3158 - val_accuracy: 0.8665\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.2904 - accuracy: 0.8834 - val_loss: 0.3201 - val_accuracy: 0.8602\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.2841 - accuracy: 0.8862 - val_loss: 0.3222 - val_accuracy: 0.8634\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.2803 - accuracy: 0.8846 - val_loss: 0.3167 - val_accuracy: 0.8634\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.2783 - accuracy: 0.8850 - val_loss: 0.3101 - val_accuracy: 0.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:27:36,932] Trial 181 finished with value: 0.8729813694953918 and parameters: {'units': 100, 'dropout': 0.1, 'learning_rate': 0.004981517423447115, 'epochs': 45, 'batch_size': 25, 'patience': 8, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:27:39,470] Trial 182 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:27:42,627] Trial 183 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:27:46,011] Trial 184 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 13.6869 - accuracy: 0.5674 - val_loss: 1.1324 - val_accuracy: 0.8307\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 2.3441 - accuracy: 0.6851 - val_loss: 1.2547 - val_accuracy: 0.5637\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.6155 - accuracy: 0.7799 - val_loss: 0.5324 - val_accuracy: 0.7469\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:27:53,111] Trial 185 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:27:56,303] Trial 186 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:28:01,222] Trial 187 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n",
      "5148/5148 - 4s - loss: 30.2247 - accuracy: 0.5150 - val_loss: 1.0455 - val_accuracy: 0.8354\n",
      "Epoch 2/30\n",
      "5148/5148 - 2s - loss: 3.1046 - accuracy: 0.6636 - val_loss: 0.4988 - val_accuracy: 0.7826\n",
      "Epoch 3/30\n",
      "5148/5148 - 2s - loss: 0.6147 - accuracy: 0.7335 - val_loss: 0.4723 - val_accuracy: 0.8432\n",
      "Epoch 4/30\n",
      "5148/5148 - 2s - loss: 0.4806 - accuracy: 0.7842 - val_loss: 0.4646 - val_accuracy: 0.8463\n",
      "Epoch 5/30\n",
      "5148/5148 - 3s - loss: 0.5409 - accuracy: 0.7494 - val_loss: 0.4729 - val_accuracy: 0.8509\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:28:16,660] Trial 188 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:28:20,371] Trial 189 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:28:24,973] Trial 190 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:28:29,189] Trial 191 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 4s - loss: 23.1089 - accuracy: 0.5274 - val_loss: 1.0747 - val_accuracy: 0.8307\n",
      "Epoch 2/45\n",
      "5148/5148 - 2s - loss: 2.4922 - accuracy: 0.6892 - val_loss: 0.6647 - val_accuracy: 0.8494\n",
      "Epoch 3/45\n",
      "5148/5148 - 2s - loss: 0.5138 - accuracy: 0.7774 - val_loss: 0.4484 - val_accuracy: 0.7733\n",
      "Epoch 4/45\n",
      "5148/5148 - 2s - loss: 0.4846 - accuracy: 0.7842 - val_loss: 0.4553 - val_accuracy: 0.8432\n",
      "Epoch 5/45\n",
      "5148/5148 - 3s - loss: 0.5116 - accuracy: 0.7747 - val_loss: 0.4392 - val_accuracy: 0.8385\n",
      "Epoch 6/45\n",
      "5148/5148 - 2s - loss: 0.4786 - accuracy: 0.7925 - val_loss: 0.5283 - val_accuracy: 0.8587\n",
      "Epoch 7/45\n",
      "5148/5148 - 2s - loss: 0.4418 - accuracy: 0.8131 - val_loss: 0.5816 - val_accuracy: 0.7143\n",
      "Epoch 8/45\n",
      "5148/5148 - 2s - loss: 0.4535 - accuracy: 0.8108 - val_loss: 0.4394 - val_accuracy: 0.8525\n",
      "Epoch 9/45\n",
      "5148/5148 - 2s - loss: 0.4370 - accuracy: 0.8149 - val_loss: 0.4552 - val_accuracy: 0.8556\n",
      "Epoch 10/45\n",
      "5148/5148 - 2s - loss: 0.4202 - accuracy: 0.8310 - val_loss: 0.4373 - val_accuracy: 0.7593\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.4173 - accuracy: 0.8244 - val_loss: 0.4657 - val_accuracy: 0.8525\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4428 - accuracy: 0.8137 - val_loss: 0.4884 - val_accuracy: 0.8571\n",
      "Epoch 13/45\n",
      "5148/5148 - 3s - loss: 0.4084 - accuracy: 0.8399 - val_loss: 0.4134 - val_accuracy: 0.8525\n",
      "Epoch 14/45\n",
      "5148/5148 - 4s - loss: 0.4190 - accuracy: 0.8291 - val_loss: 0.4746 - val_accuracy: 0.8571\n",
      "Epoch 15/45\n",
      "5148/5148 - 5s - loss: 0.3801 - accuracy: 0.8512 - val_loss: 0.3927 - val_accuracy: 0.8494\n",
      "Epoch 16/45\n",
      "5148/5148 - 5s - loss: 0.3734 - accuracy: 0.8574 - val_loss: 0.3916 - val_accuracy: 0.8540\n",
      "Epoch 17/45\n",
      "5148/5148 - 4s - loss: 0.3688 - accuracy: 0.8576 - val_loss: 0.3857 - val_accuracy: 0.8525\n",
      "Epoch 18/45\n",
      "5148/5148 - 3s - loss: 0.3601 - accuracy: 0.8580 - val_loss: 0.3747 - val_accuracy: 0.8571\n",
      "Epoch 19/45\n",
      "5148/5148 - 2s - loss: 0.3737 - accuracy: 0.8465 - val_loss: 0.3713 - val_accuracy: 0.8602\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.3612 - accuracy: 0.8506 - val_loss: 0.3741 - val_accuracy: 0.8463\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.3600 - accuracy: 0.8553 - val_loss: 0.3699 - val_accuracy: 0.8339\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.3559 - accuracy: 0.8588 - val_loss: 0.3633 - val_accuracy: 0.8618\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3433 - accuracy: 0.8599 - val_loss: 0.3680 - val_accuracy: 0.8276\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3440 - accuracy: 0.8580 - val_loss: 0.3568 - val_accuracy: 0.8416\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.3405 - accuracy: 0.8598 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3366 - accuracy: 0.8632 - val_loss: 0.3827 - val_accuracy: 0.8276\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3301 - accuracy: 0.8669 - val_loss: 0.3365 - val_accuracy: 0.8665\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3263 - accuracy: 0.8580 - val_loss: 0.3408 - val_accuracy: 0.8680\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3233 - accuracy: 0.8656 - val_loss: 0.3835 - val_accuracy: 0.8649\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3274 - accuracy: 0.8669 - val_loss: 0.3378 - val_accuracy: 0.8587\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3205 - accuracy: 0.8669 - val_loss: 0.3297 - val_accuracy: 0.8649\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3302 - accuracy: 0.8563 - val_loss: 0.3277 - val_accuracy: 0.8416\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3182 - accuracy: 0.8644 - val_loss: 0.3172 - val_accuracy: 0.8634\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3136 - accuracy: 0.8685 - val_loss: 0.3234 - val_accuracy: 0.8665\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3173 - accuracy: 0.8681 - val_loss: 0.3223 - val_accuracy: 0.8540\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3036 - accuracy: 0.8770 - val_loss: 0.3255 - val_accuracy: 0.8665\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.2936 - accuracy: 0.8763 - val_loss: 0.3160 - val_accuracy: 0.8711\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.2982 - accuracy: 0.8718 - val_loss: 0.3095 - val_accuracy: 0.8727\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.2969 - accuracy: 0.8739 - val_loss: 0.3064 - val_accuracy: 0.8680\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.2981 - accuracy: 0.8782 - val_loss: 0.3106 - val_accuracy: 0.8711\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.2941 - accuracy: 0.8768 - val_loss: 0.3126 - val_accuracy: 0.8711\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3022 - accuracy: 0.8702 - val_loss: 0.3171 - val_accuracy: 0.8696\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.2954 - accuracy: 0.8695 - val_loss: 0.3077 - val_accuracy: 0.8711\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.2974 - accuracy: 0.8735 - val_loss: 0.3143 - val_accuracy: 0.8587\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.2931 - accuracy: 0.8792 - val_loss: 0.3131 - val_accuracy: 0.8680\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 26.5674 - accuracy: 0.5278 - val_loss: 1.3471 - val_accuracy: 0.7314\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 3.6434 - accuracy: 0.6583 - val_loss: 1.2365 - val_accuracy: 0.5714\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.7295 - accuracy: 0.7312 - val_loss: 0.5117 - val_accuracy: 0.7391\n",
      "Epoch 4/45\n",
      "5148/5148 - 2s - loss: 0.4892 - accuracy: 0.7929 - val_loss: 0.4726 - val_accuracy: 0.8463\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5875 - accuracy: 0.7508 - val_loss: 0.4690 - val_accuracy: 0.7655\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.5064 - accuracy: 0.7793 - val_loss: 0.7134 - val_accuracy: 0.5994\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.4451 - accuracy: 0.8114 - val_loss: 0.5480 - val_accuracy: 0.7205\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4523 - accuracy: 0.8098 - val_loss: 0.4141 - val_accuracy: 0.8494\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4283 - accuracy: 0.8238 - val_loss: 0.4159 - val_accuracy: 0.8478\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.3927 - accuracy: 0.8463 - val_loss: 0.4275 - val_accuracy: 0.7842\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.3896 - accuracy: 0.8405 - val_loss: 0.4537 - val_accuracy: 0.8540\n",
      "Epoch 12/45\n",
      "5148/5148 - 2s - loss: 0.3931 - accuracy: 0.8440 - val_loss: 0.4462 - val_accuracy: 0.8602\n",
      "Epoch 13/45\n",
      "5148/5148 - 2s - loss: 0.3973 - accuracy: 0.8337 - val_loss: 0.4145 - val_accuracy: 0.7950\n",
      "Epoch 14/45\n",
      "5148/5148 - 2s - loss: 0.4249 - accuracy: 0.8260 - val_loss: 0.4439 - val_accuracy: 0.8556\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.4088 - accuracy: 0.8318 - val_loss: 0.4446 - val_accuracy: 0.7547\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.3991 - accuracy: 0.8349 - val_loss: 0.3772 - val_accuracy: 0.8463\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.3851 - accuracy: 0.8434 - val_loss: 0.3821 - val_accuracy: 0.8587\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.3948 - accuracy: 0.8359 - val_loss: 0.4473 - val_accuracy: 0.8618\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4069 - accuracy: 0.8339 - val_loss: 0.3838 - val_accuracy: 0.8571\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4043 - accuracy: 0.8205 - val_loss: 0.3808 - val_accuracy: 0.8649\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.3914 - accuracy: 0.8326 - val_loss: 0.4131 - val_accuracy: 0.8634\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.4042 - accuracy: 0.8298 - val_loss: 0.3536 - val_accuracy: 0.8634\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3719 - accuracy: 0.8364 - val_loss: 0.4230 - val_accuracy: 0.8494\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3559 - accuracy: 0.8425 - val_loss: 0.4009 - val_accuracy: 0.8540\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.3414 - accuracy: 0.8462 - val_loss: 0.3391 - val_accuracy: 0.8696\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3468 - accuracy: 0.8427 - val_loss: 0.3505 - val_accuracy: 0.8587\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3497 - accuracy: 0.8407 - val_loss: 0.3322 - val_accuracy: 0.8680\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3630 - accuracy: 0.8446 - val_loss: 0.3692 - val_accuracy: 0.8525\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3521 - accuracy: 0.8405 - val_loss: 0.3586 - val_accuracy: 0.8618\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3572 - accuracy: 0.8355 - val_loss: 0.3240 - val_accuracy: 0.8696\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.4032 - accuracy: 0.8314 - val_loss: 0.3656 - val_accuracy: 0.8556\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3534 - accuracy: 0.8421 - val_loss: 0.3300 - val_accuracy: 0.8587\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3425 - accuracy: 0.8454 - val_loss: 0.3480 - val_accuracy: 0.8587\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3214 - accuracy: 0.8489 - val_loss: 0.3595 - val_accuracy: 0.8587\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3244 - accuracy: 0.8458 - val_loss: 0.3196 - val_accuracy: 0.8727\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3167 - accuracy: 0.8458 - val_loss: 0.3143 - val_accuracy: 0.8711\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3290 - accuracy: 0.8415 - val_loss: 0.3116 - val_accuracy: 0.8742\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3130 - accuracy: 0.8530 - val_loss: 0.3410 - val_accuracy: 0.8571\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3215 - accuracy: 0.8462 - val_loss: 0.3246 - val_accuracy: 0.8634\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3289 - accuracy: 0.8473 - val_loss: 0.3212 - val_accuracy: 0.8696\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3137 - accuracy: 0.8487 - val_loss: 0.3116 - val_accuracy: 0.8696\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3304 - accuracy: 0.8502 - val_loss: 0.3187 - val_accuracy: 0.8618\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3244 - accuracy: 0.8452 - val_loss: 0.3037 - val_accuracy: 0.8665\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3129 - accuracy: 0.8497 - val_loss: 0.3043 - val_accuracy: 0.8649\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3228 - accuracy: 0.8469 - val_loss: 0.3126 - val_accuracy: 0.8696\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 4s - loss: 27.8314 - accuracy: 0.5270 - val_loss: 2.0734 - val_accuracy: 0.7391\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 4.1395 - accuracy: 0.6737 - val_loss: 0.9778 - val_accuracy: 0.8370\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 1.0237 - accuracy: 0.7240 - val_loss: 0.5424 - val_accuracy: 0.7438\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.4829 - accuracy: 0.7937 - val_loss: 0.4866 - val_accuracy: 0.8463\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5209 - accuracy: 0.7739 - val_loss: 0.4285 - val_accuracy: 0.8385\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.4876 - accuracy: 0.7875 - val_loss: 0.5102 - val_accuracy: 0.8587\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.4418 - accuracy: 0.8145 - val_loss: 0.7313 - val_accuracy: 0.6568\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4525 - accuracy: 0.8157 - val_loss: 0.4178 - val_accuracy: 0.8416\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4222 - accuracy: 0.8228 - val_loss: 0.4334 - val_accuracy: 0.8494\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.4058 - accuracy: 0.8380 - val_loss: 0.4368 - val_accuracy: 0.7748\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.4181 - accuracy: 0.8267 - val_loss: 0.4427 - val_accuracy: 0.8587\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4006 - accuracy: 0.8436 - val_loss: 0.5175 - val_accuracy: 0.8618\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.3855 - accuracy: 0.8465 - val_loss: 0.3961 - val_accuracy: 0.8494\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.4105 - accuracy: 0.8324 - val_loss: 0.4184 - val_accuracy: 0.8634\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.3952 - accuracy: 0.8423 - val_loss: 0.4575 - val_accuracy: 0.7345\n",
      "Epoch 16/45\n",
      "5148/5148 - 2s - loss: 0.3829 - accuracy: 0.8450 - val_loss: 0.3727 - val_accuracy: 0.8494\n",
      "Epoch 17/45\n",
      "5148/5148 - 2s - loss: 0.3846 - accuracy: 0.8384 - val_loss: 0.3645 - val_accuracy: 0.8540\n",
      "Epoch 18/45\n",
      "5148/5148 - 2s - loss: 0.3741 - accuracy: 0.8425 - val_loss: 0.4165 - val_accuracy: 0.8665\n",
      "Epoch 19/45\n",
      "5148/5148 - 2s - loss: 0.3913 - accuracy: 0.8337 - val_loss: 0.4218 - val_accuracy: 0.8494\n",
      "Epoch 20/45\n",
      "5148/5148 - 2s - loss: 0.3984 - accuracy: 0.8289 - val_loss: 0.3672 - val_accuracy: 0.8556\n",
      "Epoch 21/45\n",
      "5148/5148 - 2s - loss: 0.4029 - accuracy: 0.8271 - val_loss: 0.6613 - val_accuracy: 0.5652\n",
      "Epoch 22/45\n",
      "5148/5148 - 2s - loss: 0.4248 - accuracy: 0.8098 - val_loss: 0.3947 - val_accuracy: 0.8571\n",
      "Epoch 23/45\n",
      "5148/5148 - 2s - loss: 0.3806 - accuracy: 0.8419 - val_loss: 0.3705 - val_accuracy: 0.8602\n",
      "Epoch 24/45\n",
      "5148/5148 - 2s - loss: 0.3774 - accuracy: 0.8395 - val_loss: 0.4386 - val_accuracy: 0.8494\n",
      "Epoch 25/45\n",
      "5148/5148 - 2s - loss: 0.3801 - accuracy: 0.8392 - val_loss: 0.3832 - val_accuracy: 0.8571\n",
      "Epoch 26/45\n",
      "5148/5148 - 3s - loss: 0.3839 - accuracy: 0.8384 - val_loss: 0.4138 - val_accuracy: 0.8494\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3522 - accuracy: 0.8423 - val_loss: 0.3312 - val_accuracy: 0.8587\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3415 - accuracy: 0.8454 - val_loss: 0.3290 - val_accuracy: 0.8649\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3350 - accuracy: 0.8545 - val_loss: 0.3627 - val_accuracy: 0.8556\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3284 - accuracy: 0.8498 - val_loss: 0.3424 - val_accuracy: 0.8571\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3336 - accuracy: 0.8524 - val_loss: 0.3539 - val_accuracy: 0.8587\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3345 - accuracy: 0.8463 - val_loss: 0.3349 - val_accuracy: 0.8696\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3343 - accuracy: 0.8491 - val_loss: 0.3384 - val_accuracy: 0.8602\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3302 - accuracy: 0.8463 - val_loss: 0.3547 - val_accuracy: 0.8556\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3279 - accuracy: 0.8444 - val_loss: 0.3125 - val_accuracy: 0.8649\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3150 - accuracy: 0.8528 - val_loss: 0.3127 - val_accuracy: 0.8711\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3324 - accuracy: 0.8465 - val_loss: 0.3143 - val_accuracy: 0.8696\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3288 - accuracy: 0.8421 - val_loss: 0.3159 - val_accuracy: 0.8634\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3274 - accuracy: 0.8465 - val_loss: 0.3135 - val_accuracy: 0.8680\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3244 - accuracy: 0.8500 - val_loss: 0.3099 - val_accuracy: 0.8742\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3263 - accuracy: 0.8452 - val_loss: 0.3152 - val_accuracy: 0.8649\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3562 - accuracy: 0.8479 - val_loss: 0.4101 - val_accuracy: 0.8556\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3242 - accuracy: 0.8485 - val_loss: 0.3177 - val_accuracy: 0.8680\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3265 - accuracy: 0.8473 - val_loss: 0.3120 - val_accuracy: 0.8618\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3286 - accuracy: 0.8444 - val_loss: 0.3251 - val_accuracy: 0.8618\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 18.8852 - accuracy: 0.5447 - val_loss: 2.3732 - val_accuracy: 0.6770\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 2.1198 - accuracy: 0.6983 - val_loss: 0.4954 - val_accuracy: 0.8432\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.5836 - accuracy: 0.7451 - val_loss: 0.6376 - val_accuracy: 0.6910\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.5083 - accuracy: 0.7743 - val_loss: 0.4585 - val_accuracy: 0.8478\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5516 - accuracy: 0.7566 - val_loss: 0.4281 - val_accuracy: 0.8416\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.4605 - accuracy: 0.7991 - val_loss: 0.5273 - val_accuracy: 0.8602\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.4203 - accuracy: 0.8296 - val_loss: 0.6316 - val_accuracy: 0.7065\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4394 - accuracy: 0.8174 - val_loss: 0.4319 - val_accuracy: 0.8602\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4208 - accuracy: 0.8221 - val_loss: 0.4016 - val_accuracy: 0.8478\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.3883 - accuracy: 0.8514 - val_loss: 0.4206 - val_accuracy: 0.7780\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.3904 - accuracy: 0.8366 - val_loss: 0.4601 - val_accuracy: 0.8540\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4059 - accuracy: 0.8306 - val_loss: 0.4661 - val_accuracy: 0.8509\n",
      "Epoch 13/45\n",
      "5148/5148 - 2s - loss: 0.3998 - accuracy: 0.8345 - val_loss: 0.4316 - val_accuracy: 0.8587\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.4240 - accuracy: 0.8228 - val_loss: 0.4050 - val_accuracy: 0.8618\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.4026 - accuracy: 0.8349 - val_loss: 0.4469 - val_accuracy: 0.7795\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.4048 - accuracy: 0.8341 - val_loss: 0.3829 - val_accuracy: 0.8602\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.3819 - accuracy: 0.8463 - val_loss: 0.3620 - val_accuracy: 0.8587\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.3845 - accuracy: 0.8394 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.3750 - accuracy: 0.8432 - val_loss: 0.4366 - val_accuracy: 0.8680\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.3844 - accuracy: 0.8395 - val_loss: 0.4192 - val_accuracy: 0.8571\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.3853 - accuracy: 0.8386 - val_loss: 0.4033 - val_accuracy: 0.8540\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.3997 - accuracy: 0.8374 - val_loss: 0.3670 - val_accuracy: 0.8680\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.3980 - accuracy: 0.8349 - val_loss: 0.3715 - val_accuracy: 0.8665\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.3894 - accuracy: 0.8394 - val_loss: 0.4695 - val_accuracy: 0.8478\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4011 - accuracy: 0.8469 - val_loss: 0.3784 - val_accuracy: 0.8680\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.3789 - accuracy: 0.8444 - val_loss: 0.3601 - val_accuracy: 0.8587\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.3685 - accuracy: 0.8458 - val_loss: 0.3987 - val_accuracy: 0.8447\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.3504 - accuracy: 0.8526 - val_loss: 0.3462 - val_accuracy: 0.8696\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3423 - accuracy: 0.8473 - val_loss: 0.3726 - val_accuracy: 0.8525\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.3445 - accuracy: 0.8397 - val_loss: 0.3393 - val_accuracy: 0.8602\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.3408 - accuracy: 0.8438 - val_loss: 0.3321 - val_accuracy: 0.8680\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.3391 - accuracy: 0.8448 - val_loss: 0.3436 - val_accuracy: 0.8680\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3356 - accuracy: 0.8495 - val_loss: 0.3487 - val_accuracy: 0.8602\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3390 - accuracy: 0.8454 - val_loss: 0.3376 - val_accuracy: 0.8587\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3343 - accuracy: 0.8463 - val_loss: 0.3253 - val_accuracy: 0.8649\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3263 - accuracy: 0.8462 - val_loss: 0.3227 - val_accuracy: 0.8711\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3381 - accuracy: 0.8407 - val_loss: 0.3328 - val_accuracy: 0.8711\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3302 - accuracy: 0.8497 - val_loss: 0.3365 - val_accuracy: 0.8602\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3317 - accuracy: 0.8463 - val_loss: 0.3193 - val_accuracy: 0.8649\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3275 - accuracy: 0.8475 - val_loss: 0.3305 - val_accuracy: 0.8696\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3265 - accuracy: 0.8475 - val_loss: 0.3282 - val_accuracy: 0.8711\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3382 - accuracy: 0.8524 - val_loss: 0.3169 - val_accuracy: 0.8665\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3205 - accuracy: 0.8475 - val_loss: 0.3266 - val_accuracy: 0.8602\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3233 - accuracy: 0.8506 - val_loss: 0.3126 - val_accuracy: 0.8680\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3172 - accuracy: 0.8469 - val_loss: 0.3124 - val_accuracy: 0.8711\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n",
      "5148/5148 - 2s - loss: 25.8267 - accuracy: 0.5218 - val_loss: 1.2871 - val_accuracy: 0.7640\n",
      "Epoch 2/45\n",
      "5148/5148 - 1s - loss: 3.0549 - accuracy: 0.6797 - val_loss: 1.4734 - val_accuracy: 0.5248\n",
      "Epoch 3/45\n",
      "5148/5148 - 1s - loss: 0.6227 - accuracy: 0.7539 - val_loss: 0.4290 - val_accuracy: 0.8401\n",
      "Epoch 4/45\n",
      "5148/5148 - 1s - loss: 0.4487 - accuracy: 0.8100 - val_loss: 0.4614 - val_accuracy: 0.8525\n",
      "Epoch 5/45\n",
      "5148/5148 - 1s - loss: 0.5086 - accuracy: 0.7714 - val_loss: 0.4170 - val_accuracy: 0.8152\n",
      "Epoch 6/45\n",
      "5148/5148 - 1s - loss: 0.4588 - accuracy: 0.8009 - val_loss: 0.5344 - val_accuracy: 0.8587\n",
      "Epoch 7/45\n",
      "5148/5148 - 1s - loss: 0.4057 - accuracy: 0.8287 - val_loss: 0.4919 - val_accuracy: 0.7345\n",
      "Epoch 8/45\n",
      "5148/5148 - 1s - loss: 0.4207 - accuracy: 0.8269 - val_loss: 0.4246 - val_accuracy: 0.8587\n",
      "Epoch 9/45\n",
      "5148/5148 - 1s - loss: 0.4353 - accuracy: 0.8195 - val_loss: 0.4287 - val_accuracy: 0.8571\n",
      "Epoch 10/45\n",
      "5148/5148 - 1s - loss: 0.4102 - accuracy: 0.8337 - val_loss: 0.5092 - val_accuracy: 0.7158\n",
      "Epoch 11/45\n",
      "5148/5148 - 1s - loss: 0.4341 - accuracy: 0.8143 - val_loss: 0.4601 - val_accuracy: 0.8618\n",
      "Epoch 12/45\n",
      "5148/5148 - 1s - loss: 0.4103 - accuracy: 0.8343 - val_loss: 0.5859 - val_accuracy: 0.6366\n",
      "Epoch 13/45\n",
      "5148/5148 - 1s - loss: 0.4170 - accuracy: 0.8236 - val_loss: 0.4623 - val_accuracy: 0.7593\n",
      "Epoch 14/45\n",
      "5148/5148 - 1s - loss: 0.4122 - accuracy: 0.8351 - val_loss: 0.5005 - val_accuracy: 0.8634\n",
      "Epoch 15/45\n",
      "5148/5148 - 1s - loss: 0.4137 - accuracy: 0.8248 - val_loss: 0.3971 - val_accuracy: 0.8214\n",
      "Epoch 16/45\n",
      "5148/5148 - 1s - loss: 0.4103 - accuracy: 0.8252 - val_loss: 0.3798 - val_accuracy: 0.8214\n",
      "Epoch 17/45\n",
      "5148/5148 - 1s - loss: 0.3930 - accuracy: 0.8296 - val_loss: 0.3839 - val_accuracy: 0.8339\n",
      "Epoch 18/45\n",
      "5148/5148 - 1s - loss: 0.4140 - accuracy: 0.8102 - val_loss: 0.4042 - val_accuracy: 0.8634\n",
      "Epoch 19/45\n",
      "5148/5148 - 1s - loss: 0.4584 - accuracy: 0.8192 - val_loss: 0.4788 - val_accuracy: 0.8649\n",
      "Epoch 20/45\n",
      "5148/5148 - 1s - loss: 0.4270 - accuracy: 0.8005 - val_loss: 0.4358 - val_accuracy: 0.8618\n",
      "Epoch 21/45\n",
      "5148/5148 - 1s - loss: 0.4492 - accuracy: 0.8127 - val_loss: 0.4020 - val_accuracy: 0.8292\n",
      "Epoch 22/45\n",
      "5148/5148 - 1s - loss: 0.4438 - accuracy: 0.8087 - val_loss: 0.3908 - val_accuracy: 0.8602\n",
      "Epoch 23/45\n",
      "5148/5148 - 1s - loss: 0.4210 - accuracy: 0.8219 - val_loss: 0.3842 - val_accuracy: 0.8307\n",
      "Epoch 24/45\n",
      "5148/5148 - 1s - loss: 0.4304 - accuracy: 0.8190 - val_loss: 0.4051 - val_accuracy: 0.8587\n",
      "Epoch 25/45\n",
      "5148/5148 - 1s - loss: 0.4163 - accuracy: 0.8217 - val_loss: 0.4062 - val_accuracy: 0.8292\n",
      "Epoch 26/45\n",
      "5148/5148 - 1s - loss: 0.4278 - accuracy: 0.8168 - val_loss: 0.3982 - val_accuracy: 0.8587\n",
      "Epoch 27/45\n",
      "5148/5148 - 1s - loss: 0.4122 - accuracy: 0.8269 - val_loss: 0.4554 - val_accuracy: 0.7686\n",
      "Epoch 28/45\n",
      "5148/5148 - 1s - loss: 0.4065 - accuracy: 0.8265 - val_loss: 0.3976 - val_accuracy: 0.8587\n",
      "Epoch 29/45\n",
      "5148/5148 - 1s - loss: 0.3958 - accuracy: 0.8328 - val_loss: 0.3860 - val_accuracy: 0.8665\n",
      "Epoch 30/45\n",
      "5148/5148 - 1s - loss: 0.4108 - accuracy: 0.8217 - val_loss: 0.3789 - val_accuracy: 0.8680\n",
      "Epoch 31/45\n",
      "5148/5148 - 1s - loss: 0.4091 - accuracy: 0.8300 - val_loss: 0.3917 - val_accuracy: 0.8370\n",
      "Epoch 32/45\n",
      "5148/5148 - 1s - loss: 0.4110 - accuracy: 0.8246 - val_loss: 0.3917 - val_accuracy: 0.8370\n",
      "Epoch 33/45\n",
      "5148/5148 - 1s - loss: 0.3937 - accuracy: 0.8314 - val_loss: 0.3808 - val_accuracy: 0.8680\n",
      "Epoch 34/45\n",
      "5148/5148 - 1s - loss: 0.3884 - accuracy: 0.8345 - val_loss: 0.4036 - val_accuracy: 0.8587\n",
      "Epoch 35/45\n",
      "5148/5148 - 1s - loss: 0.3794 - accuracy: 0.8370 - val_loss: 0.3915 - val_accuracy: 0.8602\n",
      "Epoch 36/45\n",
      "5148/5148 - 1s - loss: 0.3723 - accuracy: 0.8481 - val_loss: 0.3821 - val_accuracy: 0.8634\n",
      "Epoch 37/45\n",
      "5148/5148 - 1s - loss: 0.3715 - accuracy: 0.8471 - val_loss: 0.3932 - val_accuracy: 0.8307\n",
      "Epoch 38/45\n",
      "5148/5148 - 1s - loss: 0.3738 - accuracy: 0.8463 - val_loss: 0.3998 - val_accuracy: 0.8618\n",
      "Epoch 39/45\n",
      "5148/5148 - 1s - loss: 0.3665 - accuracy: 0.8518 - val_loss: 0.3718 - val_accuracy: 0.8665\n",
      "Epoch 40/45\n",
      "5148/5148 - 1s - loss: 0.3563 - accuracy: 0.8594 - val_loss: 0.3903 - val_accuracy: 0.8339\n",
      "Epoch 41/45\n",
      "5148/5148 - 1s - loss: 0.3662 - accuracy: 0.8477 - val_loss: 0.3778 - val_accuracy: 0.8307\n",
      "Epoch 42/45\n",
      "5148/5148 - 1s - loss: 0.3665 - accuracy: 0.8481 - val_loss: 0.3940 - val_accuracy: 0.8665\n",
      "Epoch 43/45\n",
      "5148/5148 - 1s - loss: 0.3568 - accuracy: 0.8526 - val_loss: 0.3722 - val_accuracy: 0.8665\n",
      "Epoch 44/45\n",
      "5148/5148 - 1s - loss: 0.3583 - accuracy: 0.8564 - val_loss: 0.3705 - val_accuracy: 0.8649\n",
      "Epoch 45/45\n",
      "5148/5148 - 1s - loss: 0.3603 - accuracy: 0.8545 - val_loss: 0.3765 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:32:31,383] Trial 192 finished with value: 0.8723602294921875 and parameters: {'units': 100, 'dropout': 0.1, 'learning_rate': 0.006038729217862853, 'epochs': 45, 'batch_size': 30, 'patience': 8, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:32:33,986] Trial 193 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:32:37,151] Trial 194 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:32:39,108] Trial 195 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/40\n",
      "5148/5148 - 4s - loss: 15.8629 - accuracy: 0.5344 - val_loss: 0.8043 - val_accuracy: 0.8323\n",
      "Epoch 2/40\n",
      "5148/5148 - 3s - loss: 1.8795 - accuracy: 0.6558 - val_loss: 0.5563 - val_accuracy: 0.7531\n",
      "Epoch 3/40\n",
      "5148/5148 - 3s - loss: 0.5656 - accuracy: 0.7551 - val_loss: 0.4609 - val_accuracy: 0.7655\n",
      "Epoch 4/40\n",
      "5148/5148 - 3s - loss: 0.4618 - accuracy: 0.8046 - val_loss: 0.4450 - val_accuracy: 0.8432\n",
      "Epoch 5/40\n",
      "5148/5148 - 3s - loss: 0.5146 - accuracy: 0.7815 - val_loss: 0.4188 - val_accuracy: 0.8416\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:32:56,315] Trial 196 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:32:58,589] Trial 197 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 11.5565 - accuracy: 0.5732 - val_loss: 1.2864 - val_accuracy: 0.7795\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 1.8559 - accuracy: 0.7111 - val_loss: 0.8352 - val_accuracy: 0.6460\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.5294 - accuracy: 0.7822 - val_loss: 0.4417 - val_accuracy: 0.7826\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4224 - accuracy: 0.8277 - val_loss: 0.5071 - val_accuracy: 0.8602\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4836 - accuracy: 0.7854 - val_loss: 0.4860 - val_accuracy: 0.8587\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4414 - accuracy: 0.8075 - val_loss: 0.5174 - val_accuracy: 0.8618\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4128 - accuracy: 0.8322 - val_loss: 0.6005 - val_accuracy: 0.7081\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4331 - accuracy: 0.8137 - val_loss: 0.4123 - val_accuracy: 0.8494\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4294 - accuracy: 0.8195 - val_loss: 0.4187 - val_accuracy: 0.8618\n",
      "Epoch 10/25\n",
      "5148/5148 - 2s - loss: 0.3929 - accuracy: 0.8440 - val_loss: 0.4030 - val_accuracy: 0.8447\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.4069 - accuracy: 0.8343 - val_loss: 0.5551 - val_accuracy: 0.7795\n",
      "Epoch 12/25\n",
      "5148/5148 - 2s - loss: 0.3941 - accuracy: 0.8442 - val_loss: 0.4103 - val_accuracy: 0.8618\n",
      "Epoch 13/25\n",
      "5148/5148 - 2s - loss: 0.4027 - accuracy: 0.8341 - val_loss: 0.4491 - val_accuracy: 0.7593\n",
      "Epoch 14/25\n",
      "5148/5148 - 2s - loss: 0.4260 - accuracy: 0.8261 - val_loss: 0.6675 - val_accuracy: 0.6429\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.3706 - accuracy: 0.8481 - val_loss: 0.3868 - val_accuracy: 0.8727\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.3603 - accuracy: 0.8586 - val_loss: 0.3931 - val_accuracy: 0.8183\n",
      "Epoch 17/25\n",
      "5148/5148 - 1s - loss: 0.3639 - accuracy: 0.8502 - val_loss: 0.3800 - val_accuracy: 0.8727\n",
      "Epoch 18/25\n",
      "5148/5148 - 2s - loss: 0.3656 - accuracy: 0.8475 - val_loss: 0.3768 - val_accuracy: 0.8696\n",
      "Epoch 19/25\n",
      "5148/5148 - 2s - loss: 0.3841 - accuracy: 0.8386 - val_loss: 0.3832 - val_accuracy: 0.8649\n",
      "Epoch 20/25\n",
      "5148/5148 - 2s - loss: 0.3650 - accuracy: 0.8504 - val_loss: 0.3968 - val_accuracy: 0.8183\n",
      "Epoch 21/25\n",
      "5148/5148 - 2s - loss: 0.3514 - accuracy: 0.8592 - val_loss: 0.3906 - val_accuracy: 0.8183\n",
      "Epoch 22/25\n",
      "5148/5148 - 2s - loss: 0.3498 - accuracy: 0.8553 - val_loss: 0.3747 - val_accuracy: 0.8742\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3501 - accuracy: 0.8586 - val_loss: 0.3713 - val_accuracy: 0.8370\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3542 - accuracy: 0.8530 - val_loss: 0.3754 - val_accuracy: 0.8696\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3415 - accuracy: 0.8601 - val_loss: 0.3770 - val_accuracy: 0.8354\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 15.3205 - accuracy: 0.5645 - val_loss: 6.1955 - val_accuracy: 0.5730\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 3.8656 - accuracy: 0.6803 - val_loss: 1.4452 - val_accuracy: 0.7748\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.9055 - accuracy: 0.7537 - val_loss: 0.4459 - val_accuracy: 0.7919\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4464 - accuracy: 0.8166 - val_loss: 0.5310 - val_accuracy: 0.8587\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4833 - accuracy: 0.7958 - val_loss: 0.5714 - val_accuracy: 0.8618\n",
      "Epoch 6/25\n",
      "5148/5148 - 1s - loss: 0.4606 - accuracy: 0.7960 - val_loss: 0.5074 - val_accuracy: 0.8587\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4177 - accuracy: 0.8287 - val_loss: 0.6841 - val_accuracy: 0.6801\n",
      "Epoch 8/25\n",
      "5148/5148 - 1s - loss: 0.4180 - accuracy: 0.8312 - val_loss: 0.4053 - val_accuracy: 0.8463\n",
      "Epoch 9/25\n",
      "5148/5148 - 1s - loss: 0.4050 - accuracy: 0.8339 - val_loss: 0.4082 - val_accuracy: 0.8540\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.3875 - accuracy: 0.8467 - val_loss: 0.4256 - val_accuracy: 0.7609\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3952 - accuracy: 0.8415 - val_loss: 0.5166 - val_accuracy: 0.8634\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4156 - accuracy: 0.8291 - val_loss: 0.4317 - val_accuracy: 0.8618\n",
      "Epoch 13/25\n",
      "5148/5148 - 2s - loss: 0.4033 - accuracy: 0.8374 - val_loss: 0.4471 - val_accuracy: 0.7562\n",
      "Epoch 14/25\n",
      "5148/5148 - 2s - loss: 0.4040 - accuracy: 0.8364 - val_loss: 0.3965 - val_accuracy: 0.8540\n",
      "Epoch 15/25\n",
      "5148/5148 - 2s - loss: 0.4174 - accuracy: 0.8240 - val_loss: 0.4578 - val_accuracy: 0.7562\n",
      "Epoch 16/25\n",
      "5148/5148 - 2s - loss: 0.4117 - accuracy: 0.8273 - val_loss: 0.3861 - val_accuracy: 0.8556\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.3947 - accuracy: 0.8390 - val_loss: 0.4128 - val_accuracy: 0.7640\n",
      "Epoch 18/25\n",
      "5148/5148 - 2s - loss: 0.3804 - accuracy: 0.8462 - val_loss: 0.3754 - val_accuracy: 0.8696\n",
      "Epoch 19/25\n",
      "5148/5148 - 1s - loss: 0.3763 - accuracy: 0.8407 - val_loss: 0.3620 - val_accuracy: 0.8665\n",
      "Epoch 20/25\n",
      "5148/5148 - 1s - loss: 0.4148 - accuracy: 0.8269 - val_loss: 0.4642 - val_accuracy: 0.8634\n",
      "Epoch 21/25\n",
      "5148/5148 - 2s - loss: 0.4144 - accuracy: 0.8213 - val_loss: 0.4613 - val_accuracy: 0.8618\n",
      "Epoch 22/25\n",
      "5148/5148 - 3s - loss: 0.4315 - accuracy: 0.8359 - val_loss: 0.4001 - val_accuracy: 0.8370\n",
      "Epoch 23/25\n",
      "5148/5148 - 3s - loss: 0.4259 - accuracy: 0.8258 - val_loss: 0.3773 - val_accuracy: 0.8665\n",
      "Epoch 24/25\n",
      "5148/5148 - 3s - loss: 0.3954 - accuracy: 0.8405 - val_loss: 0.4008 - val_accuracy: 0.8587\n",
      "Epoch 25/25\n",
      "5148/5148 - 3s - loss: 0.3825 - accuracy: 0.8462 - val_loss: 0.4121 - val_accuracy: 0.8602\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 2s - loss: 11.4476 - accuracy: 0.5637 - val_loss: 2.3803 - val_accuracy: 0.6398\n",
      "Epoch 2/25\n",
      "5148/5148 - 1s - loss: 1.7587 - accuracy: 0.7024 - val_loss: 0.6329 - val_accuracy: 0.8525\n",
      "Epoch 3/25\n",
      "5148/5148 - 1s - loss: 0.5061 - accuracy: 0.7920 - val_loss: 0.5597 - val_accuracy: 0.7081\n",
      "Epoch 4/25\n",
      "5148/5148 - 1s - loss: 0.4600 - accuracy: 0.8054 - val_loss: 0.4704 - val_accuracy: 0.8478\n",
      "Epoch 5/25\n",
      "5148/5148 - 1s - loss: 0.4981 - accuracy: 0.7764 - val_loss: 0.4743 - val_accuracy: 0.8509\n",
      "Epoch 6/25\n",
      "5148/5148 - 2s - loss: 0.4622 - accuracy: 0.7976 - val_loss: 0.5280 - val_accuracy: 0.8602\n",
      "Epoch 7/25\n",
      "5148/5148 - 1s - loss: 0.4381 - accuracy: 0.8112 - val_loss: 0.7207 - val_accuracy: 0.6646\n",
      "Epoch 8/25\n",
      "5148/5148 - 2s - loss: 0.4430 - accuracy: 0.8215 - val_loss: 0.4181 - val_accuracy: 0.8478\n",
      "Epoch 9/25\n",
      "5148/5148 - 2s - loss: 0.4160 - accuracy: 0.8289 - val_loss: 0.4447 - val_accuracy: 0.8649\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.3937 - accuracy: 0.8434 - val_loss: 0.4065 - val_accuracy: 0.8385\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3751 - accuracy: 0.8493 - val_loss: 0.4079 - val_accuracy: 0.8540\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.3671 - accuracy: 0.8576 - val_loss: 0.4848 - val_accuracy: 0.8571\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.4134 - accuracy: 0.8285 - val_loss: 0.6448 - val_accuracy: 0.6708\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4401 - accuracy: 0.8166 - val_loss: 0.4598 - val_accuracy: 0.8571\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4367 - accuracy: 0.8151 - val_loss: 0.4358 - val_accuracy: 0.7578\n",
      "Epoch 16/25\n",
      "5148/5148 - 1s - loss: 0.4213 - accuracy: 0.8258 - val_loss: 0.4098 - val_accuracy: 0.8509\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.4414 - accuracy: 0.8131 - val_loss: 0.4673 - val_accuracy: 0.8478\n",
      "Epoch 18/25\n",
      "5148/5148 - 2s - loss: 0.3859 - accuracy: 0.8508 - val_loss: 0.4024 - val_accuracy: 0.8540\n",
      "Epoch 19/25\n",
      "5148/5148 - 2s - loss: 0.3923 - accuracy: 0.8442 - val_loss: 0.4038 - val_accuracy: 0.8556\n",
      "Epoch 20/25\n",
      "5148/5148 - 2s - loss: 0.3743 - accuracy: 0.8541 - val_loss: 0.4120 - val_accuracy: 0.8059\n",
      "Epoch 21/25\n",
      "5148/5148 - 2s - loss: 0.3616 - accuracy: 0.8592 - val_loss: 0.3990 - val_accuracy: 0.8199\n",
      "Epoch 22/25\n",
      "5148/5148 - 2s - loss: 0.3631 - accuracy: 0.8563 - val_loss: 0.3868 - val_accuracy: 0.8665\n",
      "Epoch 23/25\n",
      "5148/5148 - 2s - loss: 0.3583 - accuracy: 0.8537 - val_loss: 0.3734 - val_accuracy: 0.8401\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3517 - accuracy: 0.8539 - val_loss: 0.4097 - val_accuracy: 0.8540\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3407 - accuracy: 0.8599 - val_loss: 0.3841 - val_accuracy: 0.8230\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 9.9181 - accuracy: 0.5686 - val_loss: 1.2966 - val_accuracy: 0.7329\n",
      "Epoch 2/25\n",
      "5148/5148 - 2s - loss: 1.4328 - accuracy: 0.7148 - val_loss: 0.4938 - val_accuracy: 0.8447\n",
      "Epoch 3/25\n",
      "5148/5148 - 2s - loss: 0.4778 - accuracy: 0.7914 - val_loss: 0.4910 - val_accuracy: 0.7531\n",
      "Epoch 4/25\n",
      "5148/5148 - 2s - loss: 0.4282 - accuracy: 0.8258 - val_loss: 0.4569 - val_accuracy: 0.8556\n",
      "Epoch 5/25\n",
      "5148/5148 - 3s - loss: 0.4954 - accuracy: 0.7793 - val_loss: 0.4363 - val_accuracy: 0.8602\n",
      "Epoch 6/25\n",
      "5148/5148 - 3s - loss: 0.4343 - accuracy: 0.8186 - val_loss: 0.5797 - val_accuracy: 0.8230\n",
      "Epoch 7/25\n",
      "5148/5148 - 2s - loss: 0.4238 - accuracy: 0.8254 - val_loss: 0.4923 - val_accuracy: 0.7376\n",
      "Epoch 8/25\n",
      "5148/5148 - 3s - loss: 0.4226 - accuracy: 0.8244 - val_loss: 0.3975 - val_accuracy: 0.8587\n",
      "Epoch 9/25\n",
      "5148/5148 - 3s - loss: 0.4295 - accuracy: 0.8205 - val_loss: 0.3958 - val_accuracy: 0.8602\n",
      "Epoch 10/25\n",
      "5148/5148 - 3s - loss: 0.3732 - accuracy: 0.8535 - val_loss: 0.3915 - val_accuracy: 0.8525\n",
      "Epoch 11/25\n",
      "5148/5148 - 3s - loss: 0.3728 - accuracy: 0.8479 - val_loss: 0.5501 - val_accuracy: 0.6863\n",
      "Epoch 12/25\n",
      "5148/5148 - 3s - loss: 0.4199 - accuracy: 0.8120 - val_loss: 0.4609 - val_accuracy: 0.8587\n",
      "Epoch 13/25\n",
      "5148/5148 - 3s - loss: 0.3993 - accuracy: 0.8370 - val_loss: 0.4571 - val_accuracy: 0.7624\n",
      "Epoch 14/25\n",
      "5148/5148 - 2s - loss: 0.3577 - accuracy: 0.8563 - val_loss: 0.3828 - val_accuracy: 0.8696\n",
      "Epoch 15/25\n",
      "5148/5148 - 3s - loss: 0.3632 - accuracy: 0.8526 - val_loss: 0.4250 - val_accuracy: 0.7764\n",
      "Epoch 16/25\n",
      "5148/5148 - 3s - loss: 0.3607 - accuracy: 0.8531 - val_loss: 0.4339 - val_accuracy: 0.7717\n",
      "Epoch 17/25\n",
      "5148/5148 - 3s - loss: 0.3622 - accuracy: 0.8530 - val_loss: 0.3784 - val_accuracy: 0.8385\n",
      "Epoch 18/25\n",
      "5148/5148 - 3s - loss: 0.3643 - accuracy: 0.8481 - val_loss: 0.3766 - val_accuracy: 0.8494\n",
      "Epoch 19/25\n",
      "5148/5148 - 3s - loss: 0.3763 - accuracy: 0.8405 - val_loss: 0.3915 - val_accuracy: 0.8307\n",
      "Epoch 20/25\n",
      "5148/5148 - 3s - loss: 0.3663 - accuracy: 0.8489 - val_loss: 0.3976 - val_accuracy: 0.8245\n",
      "Epoch 21/25\n",
      "5148/5148 - 3s - loss: 0.3458 - accuracy: 0.8594 - val_loss: 0.3880 - val_accuracy: 0.8261\n",
      "Epoch 22/25\n",
      "5148/5148 - 3s - loss: 0.3507 - accuracy: 0.8555 - val_loss: 0.3697 - val_accuracy: 0.8602\n",
      "Epoch 23/25\n",
      "5148/5148 - 2s - loss: 0.3331 - accuracy: 0.8580 - val_loss: 0.3706 - val_accuracy: 0.8276\n",
      "Epoch 24/25\n",
      "5148/5148 - 2s - loss: 0.3344 - accuracy: 0.8576 - val_loss: 0.3731 - val_accuracy: 0.8276\n",
      "Epoch 25/25\n",
      "5148/5148 - 3s - loss: 0.3285 - accuracy: 0.8644 - val_loss: 0.3795 - val_accuracy: 0.8307\n",
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 4s - loss: 14.9539 - accuracy: 0.5598 - val_loss: 3.2124 - val_accuracy: 0.6708\n",
      "Epoch 2/25\n",
      "5148/5148 - 3s - loss: 2.5324 - accuracy: 0.7152 - val_loss: 0.8521 - val_accuracy: 0.8416\n",
      "Epoch 3/25\n",
      "5148/5148 - 2s - loss: 0.7143 - accuracy: 0.7640 - val_loss: 0.5400 - val_accuracy: 0.7407\n",
      "Epoch 4/25\n",
      "5148/5148 - 3s - loss: 0.4612 - accuracy: 0.8007 - val_loss: 0.5045 - val_accuracy: 0.8602\n",
      "Epoch 5/25\n",
      "5148/5148 - 3s - loss: 0.4798 - accuracy: 0.7896 - val_loss: 0.4345 - val_accuracy: 0.8525\n",
      "Epoch 6/25\n",
      "5148/5148 - 3s - loss: 0.4461 - accuracy: 0.8073 - val_loss: 0.5645 - val_accuracy: 0.8401\n",
      "Epoch 7/25\n",
      "5148/5148 - 3s - loss: 0.4343 - accuracy: 0.8174 - val_loss: 0.7761 - val_accuracy: 0.6615\n",
      "Epoch 8/25\n",
      "5148/5148 - 3s - loss: 0.4317 - accuracy: 0.8267 - val_loss: 0.4140 - val_accuracy: 0.8494\n",
      "Epoch 9/25\n",
      "5148/5148 - 3s - loss: 0.4124 - accuracy: 0.8341 - val_loss: 0.4167 - val_accuracy: 0.8556\n",
      "Epoch 10/25\n",
      "5148/5148 - 1s - loss: 0.4064 - accuracy: 0.8333 - val_loss: 0.4162 - val_accuracy: 0.8121\n",
      "Epoch 11/25\n",
      "5148/5148 - 1s - loss: 0.3921 - accuracy: 0.8374 - val_loss: 0.5239 - val_accuracy: 0.8618\n",
      "Epoch 12/25\n",
      "5148/5148 - 1s - loss: 0.4248 - accuracy: 0.8240 - val_loss: 0.4288 - val_accuracy: 0.8571\n",
      "Epoch 13/25\n",
      "5148/5148 - 1s - loss: 0.4119 - accuracy: 0.8300 - val_loss: 0.5209 - val_accuracy: 0.7189\n",
      "Epoch 14/25\n",
      "5148/5148 - 1s - loss: 0.4076 - accuracy: 0.8361 - val_loss: 0.4206 - val_accuracy: 0.8649\n",
      "Epoch 15/25\n",
      "5148/5148 - 1s - loss: 0.4159 - accuracy: 0.8312 - val_loss: 0.4650 - val_accuracy: 0.7500\n",
      "Epoch 16/25\n",
      "5148/5148 - 2s - loss: 0.4223 - accuracy: 0.8162 - val_loss: 0.3835 - val_accuracy: 0.8540\n",
      "Epoch 17/25\n",
      "5148/5148 - 2s - loss: 0.3811 - accuracy: 0.8378 - val_loss: 0.3947 - val_accuracy: 0.8323\n",
      "Epoch 18/25\n",
      "5148/5148 - 2s - loss: 0.3805 - accuracy: 0.8326 - val_loss: 0.3610 - val_accuracy: 0.8602\n",
      "Epoch 19/25\n",
      "5148/5148 - 2s - loss: 0.3759 - accuracy: 0.8411 - val_loss: 0.4932 - val_accuracy: 0.7407\n",
      "Epoch 20/25\n",
      "5148/5148 - 3s - loss: 0.3727 - accuracy: 0.8442 - val_loss: 0.3566 - val_accuracy: 0.8602\n",
      "Epoch 21/25\n",
      "5148/5148 - 3s - loss: 0.3481 - accuracy: 0.8557 - val_loss: 0.4150 - val_accuracy: 0.8634\n",
      "Epoch 22/25\n",
      "5148/5148 - 1s - loss: 0.3520 - accuracy: 0.8568 - val_loss: 0.3542 - val_accuracy: 0.8634\n",
      "Epoch 23/25\n",
      "5148/5148 - 1s - loss: 0.3162 - accuracy: 0.8650 - val_loss: 0.3334 - val_accuracy: 0.8618\n",
      "Epoch 24/25\n",
      "5148/5148 - 1s - loss: 0.3166 - accuracy: 0.8631 - val_loss: 0.3335 - val_accuracy: 0.8711\n",
      "Epoch 25/25\n",
      "5148/5148 - 1s - loss: 0.3119 - accuracy: 0.8671 - val_loss: 0.3534 - val_accuracy: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:36:41,910] Trial 198 finished with value: 0.8701863288879395 and parameters: {'units': 100, 'dropout': 0.05, 'learning_rate': 0.008220066292519198, 'epochs': 25, 'batch_size': 30, 'patience': 8, 'factor': 0.4}. Best is trial 159 with value: 0.8763974905014038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/25\n",
      "5148/5148 - 3s - loss: 13.7098 - accuracy: 0.5796 - val_loss: 1.2024 - val_accuracy: 0.7780\n",
      "Epoch 2/25\n",
      "5148/5148 - 2s - loss: 1.7363 - accuracy: 0.7232 - val_loss: 0.8414 - val_accuracy: 0.6553\n",
      "Epoch 3/25\n",
      "5148/5148 - 2s - loss: 0.5097 - accuracy: 0.7910 - val_loss: 0.4554 - val_accuracy: 0.8354\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 23:36:49,883] Trial 199 pruned. Trial was pruned at epoch 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Best trial: 0.8763974905014038',\n",
       " \"Best hyperparameters: {'units': 100, 'dropout': 0.1, 'learning_rate': 0.007511080260178754, 'epochs': 50, 'batch_size': 30, 'patience': 6, 'factor': 0.4}\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializes a Sequential Model (linear stack of layers)\n",
    "# Simplest way to build a model in Keras, where you can just keep adding layers sequentially\n",
    "\n",
    "input_size = x_train.shape[1] # 10 input features in our data \n",
    "# hidden_layer_size = 50 # start off with 50 neurons per hidden layer\n",
    "output_size = 1 # because 2 possible classifications denoted by 0 and 1 in a single output; DNN calculates probability the exoplanet is 0 or 1 and the higher probability is the output \n",
    "\n",
    "# dropout_rate = 0.05 # dropout rate we will use in the model as a measure to prevent overfitting\n",
    "\n",
    "def create_dnn(trial):\n",
    "\n",
    "    # since we use optuna, we have to toss in the values we want it to test during the optimization process\n",
    "\n",
    "    # units = neurons in the hidden later, 32 to 512 jumping 32 at a time \n",
    "    units = trial.suggest_int('units', 10, 100, step=5)\n",
    "\n",
    "    # dropout rate is self explanatory\n",
    "    dropout_rate = trial.suggest_float('dropout', 0.0, 0.5, step=0.05)\n",
    "\n",
    "    # define our learning rate which impacts the final performance of our model, optimal LR is very beneficial in finding the right patterns\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True) # Log scale is better search \n",
    "    \n",
    "    dnn_model = Sequential([\n",
    "    # input layer for the input data; 10 features so 10 inputs for the first dense layer \n",
    "    # in a dense layer, each feature becomes an input to the next layer, which consists of neurons\n",
    "    # the line below defines the input layer and creates the first dense layer consisting of 50 neurons\n",
    "    # we use Rectified Linear Unit (ReLU) as the activation function because ReLU helps mitigate the vanishing gradient problem\n",
    "# and allows the model to learn complex paterns\n",
    "    tf.keras.layers.Dense(units, activation='relu', input_shape = (input_size,)),\n",
    "\n",
    "# add a dropout layer with dropout rate of 0.1 \n",
    "# This essentially just means 10% of the neurons will be randomly set to 0 during training\n",
    "# Dropout is a regularization technique used to prevent overfitting \n",
    "# This helps prevent the model from overfitting by randomly dropping neurons during training\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    \n",
    "# we only use 1 hidden layer of neurons because 2 lowers validation accuracy;\n",
    "    \n",
    "    # output layer with 1 neuron for binary classification\n",
    "    tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
    "    ])\n",
    "# next, choose the optimizer and loss function\n",
    "# adam is usually the most optimal\n",
    "# loss will be binary_crossentropy for binary classification\n",
    "# the metric we care about is accuracy\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    dnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return dnn_model\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # define kfold cross-validation\n",
    "    # data is split into 5 folds; each fold is used once as a validatiton set while the other 4 are for training\n",
    "    # data is randomly shuffled with the True boolean before being split into folds\n",
    "    \n",
    "    kfold= KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # store validation accuracies in a list\n",
    "    \n",
    "    val_accuracies = []\n",
    "\n",
    "    # cross validation loop \n",
    "    # loop iterates each of the 5 folds and creates train and validatiton splits for each iteration\n",
    "    for train_index, val_index in kfold.split(x_train_nparr):\n",
    "        x_train_fold, x_val_fold = x_train_nparr[train_index], x_train_nparr[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_nparr[train_index], y_train_nparr[val_index]\n",
    "\n",
    "    \n",
    "        model = create_dnn(trial)\n",
    "    \n",
    "    \n",
    "        # suggest number of epochs and batch size\n",
    "        epochs = trial.suggest_int('epochs', 5, 50, step=5)\n",
    "        batch_size = trial.suggest_int('batch_size', 5,30,step=5)\n",
    "    \n",
    "    \n",
    "        # learning rate scheduler parameters\n",
    "        patience = trial.suggest_int('patience', 2, 10, step=1)\n",
    "        factor = trial.suggest_float('factor', 0.1, 0.5, step=0.1)\n",
    "    \n",
    "    \n",
    "        # Reduce LR on plateau LR scheduler\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', patience=patience, factor=factor, min_lr=1e-7)\n",
    "        \n",
    "        training = model.fit(\n",
    "                x_train_nparr, \n",
    "                y_train_nparr, \n",
    "                epochs=epochs, \n",
    "                batch_size=batch_size, \n",
    "                validation_data=(x_val_nparr, y_val_nparr), \n",
    "                callbacks=[TFKerasPruningCallback(trial, 'val_accuracy'), lr_scheduler], \n",
    "                verbose=2\n",
    "        )\n",
    "        val_accuracy = max(training.history['val_accuracy'])\n",
    "\n",
    "        # stores val accuracy for the current fold\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # after the loop we return the average val_accuracy across all folds to evaluate the effectivenes of the hyperparameters\n",
    "    return np.mean(val_accuracies)\n",
    "    \n",
    "# create a study and optimize the objective function\n",
    "study = opt.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "\n",
    "(f'Best trial: {study.best_trial.value}', f'Best hyperparameters: {study.best_trial.params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the best hyperparameters determined by Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'units': 100,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.007511080260178754,\n",
       "  'epochs': 50,\n",
       "  'batch_size': 30,\n",
       "  'patience': 6,\n",
       "  'factor': 0.4},\n",
       " 'Highest validation accuracy achieved: 0.8763974905014038')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_trial = study.best_trial.value\n",
    "best_params, f'Highest validation accuracy achieved: {best_trial}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new DNN using the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the parameters using keys (study best trial params is a dictionary)\n",
    "\n",
    "\n",
    "best_dnn = Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(units= best_params['units'], activation='relu', input_shape = (input_size,)),\n",
    "\n",
    "    tf.keras.layers.Dropout(best_params['dropout']),\n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "best_optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n",
    "best_dnn.compile(optimizer=best_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "best_scheduler = ReduceLROnPlateau(monitor='val_accuracy', patience=best_params['patience'], factor=best_params['factor'], min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 644 samples\n",
      "Epoch 1/50\n",
      "5148/5148 - 4s - loss: 17.3498 - accuracy: 0.5585 - val_loss: 1.0509 - val_accuracy: 0.7764\n",
      "Epoch 2/50\n",
      "5148/5148 - 1s - loss: 1.6308 - accuracy: 0.6857 - val_loss: 0.4868 - val_accuracy: 0.7764\n",
      "Epoch 3/50\n",
      "5148/5148 - 1s - loss: 0.5003 - accuracy: 0.7855 - val_loss: 0.5109 - val_accuracy: 0.7407\n",
      "Epoch 4/50\n",
      "5148/5148 - 1s - loss: 0.4825 - accuracy: 0.7865 - val_loss: 0.4515 - val_accuracy: 0.8432\n",
      "Epoch 5/50\n",
      "5148/5148 - 1s - loss: 0.5291 - accuracy: 0.7659 - val_loss: 0.4393 - val_accuracy: 0.8432\n",
      "Epoch 6/50\n",
      "5148/5148 - 1s - loss: 0.4857 - accuracy: 0.7809 - val_loss: 0.5882 - val_accuracy: 0.7003\n",
      "Epoch 7/50\n",
      "5148/5148 - 1s - loss: 0.4652 - accuracy: 0.7982 - val_loss: 0.6380 - val_accuracy: 0.6801\n",
      "Epoch 8/50\n",
      "5148/5148 - 1s - loss: 0.4393 - accuracy: 0.8159 - val_loss: 0.4143 - val_accuracy: 0.8432\n",
      "Epoch 9/50\n",
      "5148/5148 - 1s - loss: 0.4360 - accuracy: 0.8155 - val_loss: 0.4269 - val_accuracy: 0.8447\n",
      "Epoch 10/50\n",
      "5148/5148 - 1s - loss: 0.4247 - accuracy: 0.8293 - val_loss: 0.4375 - val_accuracy: 0.7826\n",
      "Epoch 11/50\n",
      "5148/5148 - 1s - loss: 0.4121 - accuracy: 0.8275 - val_loss: 0.5256 - val_accuracy: 0.8618\n",
      "Epoch 12/50\n",
      "5148/5148 - 1s - loss: 0.4305 - accuracy: 0.8238 - val_loss: 0.4407 - val_accuracy: 0.8634\n",
      "Epoch 13/50\n",
      "5148/5148 - 1s - loss: 0.4377 - accuracy: 0.8195 - val_loss: 0.6755 - val_accuracy: 0.6755\n",
      "Epoch 14/50\n",
      "5148/5148 - 1s - loss: 0.4396 - accuracy: 0.8190 - val_loss: 0.4049 - val_accuracy: 0.8540\n",
      "Epoch 15/50\n",
      "5148/5148 - 1s - loss: 0.4951 - accuracy: 0.7743 - val_loss: 0.5574 - val_accuracy: 0.6708\n",
      "Epoch 16/50\n",
      "5148/5148 - 1s - loss: 0.5284 - accuracy: 0.7819 - val_loss: 0.4904 - val_accuracy: 0.7857\n",
      "Epoch 17/50\n",
      "5148/5148 - 1s - loss: 0.4658 - accuracy: 0.8178 - val_loss: 0.4472 - val_accuracy: 0.8370\n",
      "Epoch 18/50\n",
      "5148/5148 - 1s - loss: 0.4609 - accuracy: 0.8184 - val_loss: 0.4182 - val_accuracy: 0.8540\n",
      "Epoch 19/50\n",
      "5148/5148 - 1s - loss: 0.4445 - accuracy: 0.8228 - val_loss: 0.4293 - val_accuracy: 0.8587\n",
      "Epoch 20/50\n",
      "5148/5148 - 1s - loss: 0.4162 - accuracy: 0.8436 - val_loss: 0.4243 - val_accuracy: 0.8463\n",
      "Epoch 21/50\n",
      "5148/5148 - 1s - loss: 0.3955 - accuracy: 0.8489 - val_loss: 0.4070 - val_accuracy: 0.8556\n",
      "Epoch 22/50\n",
      "5148/5148 - 1s - loss: 0.3950 - accuracy: 0.8446 - val_loss: 0.4118 - val_accuracy: 0.8587\n",
      "Epoch 23/50\n",
      "5148/5148 - 1s - loss: 0.3856 - accuracy: 0.8487 - val_loss: 0.4059 - val_accuracy: 0.8665\n",
      "Epoch 24/50\n",
      "5148/5148 - 1s - loss: 0.3956 - accuracy: 0.8390 - val_loss: 0.3934 - val_accuracy: 0.8680\n",
      "Epoch 25/50\n",
      "5148/5148 - 1s - loss: 0.3767 - accuracy: 0.8518 - val_loss: 0.4001 - val_accuracy: 0.8214\n",
      "Epoch 26/50\n",
      "5148/5148 - 1s - loss: 0.3840 - accuracy: 0.8460 - val_loss: 0.3896 - val_accuracy: 0.8696\n",
      "Epoch 27/50\n",
      "5148/5148 - 1s - loss: 0.3842 - accuracy: 0.8419 - val_loss: 0.4027 - val_accuracy: 0.8245\n",
      "Epoch 28/50\n",
      "5148/5148 - 1s - loss: 0.3693 - accuracy: 0.8516 - val_loss: 0.4225 - val_accuracy: 0.8587\n",
      "Epoch 29/50\n",
      "5148/5148 - 1s - loss: 0.3815 - accuracy: 0.8473 - val_loss: 0.3839 - val_accuracy: 0.8339\n",
      "Epoch 30/50\n",
      "5148/5148 - 1s - loss: 0.3721 - accuracy: 0.8462 - val_loss: 0.4039 - val_accuracy: 0.8602\n",
      "Epoch 31/50\n",
      "5148/5148 - 1s - loss: 0.3688 - accuracy: 0.8543 - val_loss: 0.3823 - val_accuracy: 0.8292\n",
      "Epoch 32/50\n",
      "5148/5148 - 1s - loss: 0.3700 - accuracy: 0.8465 - val_loss: 0.3847 - val_accuracy: 0.8665\n",
      "Epoch 33/50\n",
      "5148/5148 - 1s - loss: 0.3524 - accuracy: 0.8528 - val_loss: 0.3744 - val_accuracy: 0.8696\n",
      "Epoch 34/50\n",
      "5148/5148 - 1s - loss: 0.3591 - accuracy: 0.8522 - val_loss: 0.3778 - val_accuracy: 0.8727\n",
      "Epoch 35/50\n",
      "5148/5148 - 1s - loss: 0.3539 - accuracy: 0.8504 - val_loss: 0.3730 - val_accuracy: 0.8618\n",
      "Epoch 36/50\n",
      "5148/5148 - 1s - loss: 0.3493 - accuracy: 0.8586 - val_loss: 0.3741 - val_accuracy: 0.8339\n",
      "Epoch 37/50\n",
      "5148/5148 - 1s - loss: 0.3576 - accuracy: 0.8498 - val_loss: 0.4033 - val_accuracy: 0.8245\n",
      "Epoch 38/50\n",
      "5148/5148 - 1s - loss: 0.3558 - accuracy: 0.8508 - val_loss: 0.3713 - val_accuracy: 0.8540\n",
      "Epoch 39/50\n",
      "5148/5148 - 1s - loss: 0.3511 - accuracy: 0.8543 - val_loss: 0.3800 - val_accuracy: 0.8711\n",
      "Epoch 40/50\n",
      "5148/5148 - 1s - loss: 0.3558 - accuracy: 0.8522 - val_loss: 0.3783 - val_accuracy: 0.8307\n",
      "Epoch 41/50\n",
      "5148/5148 - 1s - loss: 0.3510 - accuracy: 0.8549 - val_loss: 0.3806 - val_accuracy: 0.8323\n",
      "Epoch 42/50\n",
      "5148/5148 - 1s - loss: 0.3442 - accuracy: 0.8570 - val_loss: 0.3744 - val_accuracy: 0.8416\n",
      "Epoch 43/50\n",
      "5148/5148 - 1s - loss: 0.3444 - accuracy: 0.8580 - val_loss: 0.3722 - val_accuracy: 0.8323\n",
      "Epoch 44/50\n",
      "5148/5148 - 1s - loss: 0.3509 - accuracy: 0.8516 - val_loss: 0.3731 - val_accuracy: 0.8665\n",
      "Epoch 45/50\n",
      "5148/5148 - 1s - loss: 0.3431 - accuracy: 0.8598 - val_loss: 0.3716 - val_accuracy: 0.8602\n",
      "Epoch 46/50\n",
      "5148/5148 - 1s - loss: 0.3489 - accuracy: 0.8508 - val_loss: 0.3706 - val_accuracy: 0.8432\n",
      "Epoch 47/50\n",
      "5148/5148 - 1s - loss: 0.3439 - accuracy: 0.8547 - val_loss: 0.3704 - val_accuracy: 0.8432\n",
      "Epoch 48/50\n",
      "5148/5148 - 1s - loss: 0.3491 - accuracy: 0.8530 - val_loss: 0.3716 - val_accuracy: 0.8587\n",
      "Epoch 49/50\n",
      "5148/5148 - 1s - loss: 0.3451 - accuracy: 0.8582 - val_loss: 0.3712 - val_accuracy: 0.8370\n",
      "Epoch 50/50\n",
      "5148/5148 - 1s - loss: 0.3460 - accuracy: 0.8516 - val_loss: 0.3708 - val_accuracy: 0.8370\n"
     ]
    }
   ],
   "source": [
    "best_dnn_model = best_dnn.fit(\n",
    "        x_train_nparr, \n",
    "        y_train_nparr, \n",
    "        epochs=best_params['epochs'], \n",
    "        batch_size=best_params['batch_size'], \n",
    "        validation_data=(x_val_nparr, y_val_nparr), \n",
    "        callbacks=[best_scheduler],\n",
    "        verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .evaluate to examine model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 107us/sample - loss: 0.4778 - accuracy: 0.8463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Test accuracy:', 0.8462733)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_dnn.evaluate(x_test_nparr, y_test_nparr)\n",
    "('Test loss:',test_loss),\n",
    "('Test accuracy:',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .predict to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we actually make the predictions on the test set\n",
    "# model outputs the probability for the positive class\n",
    "# also convert the probabilities to binary class predictions with a threshold of 0.5\n",
    "\n",
    "# gives us the probability the exoplanet belongs to each class\n",
    "y_pred_prob = best_dnn.predict(x_test_nparr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual class predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use these probabilities for calculating the ROC-AUC score and other performance metrics that require probabilities\n",
    "# ravel() flattens the matrix to a 1D array of probabilities\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[274  60]\n",
      " [ 39 271]] \n",
      "DNN Accuracy on Test Set: 0.8462732919254659 \n",
      "DNN Classification Report on Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       334\n",
      "           1       0.82      0.87      0.85       310\n",
      "\n",
      "    accuracy                           0.85       644\n",
      "   macro avg       0.85      0.85      0.85       644\n",
      "weighted avg       0.85      0.85      0.85       644\n",
      " \n",
      "DNN ROC AUC Score on Test Set:\n",
      " 0.9357060073401585\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_nparr, y_pred)\n",
    "dnn_accuracy = accuracy_score(y_test_nparr, y_pred)\n",
    "classif_report = classification_report(y_test_nparr, y_pred)\n",
    "roc_score = roc_auc_score(y_test_nparr, y_pred_prob)\n",
    "\n",
    "print(\n",
    "    cm,\n",
    "    '\\nDNN Accuracy on Test Set:', dnn_accuracy,\n",
    "    '\\nDNN Classification Report on Test Set:\\n', classif_report,\n",
    "    '\\nDNN ROC AUC Score on Test Set:\\n', roc_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Validation and Training Metrics for visual presentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# training accuracy over epochs\n",
    "plt.plot(best_dnn_model.history['accuracy'])\n",
    "\n",
    "# validation accuracy over epochs\n",
    "plt.plot(best_dnn_model.history['val_accuracy'])\n",
    "\n",
    "plt.title('Exoplanet DNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABilElEQVR4nO3deXhU5eH28fvMPoEk7CRhRzZZBAHZXEAREJWCy09cAbWidalovaSiKKg12rpVcXmtIloXEEGkalWoiAtoQUHRUosaAYGIoCQQkklm5nn/mMyEIQshhNn4fq7rXDNnnefMOeLceZZjGWOMAAAAAACHxBbvAgAAAABAKiBcAQAAAEA9IFwBAAAAQD0gXAEAAABAPSBcAQAAAEA9IFwBAAAAQD0gXAEAAABAPSBcAQAAAEA9IFwBAAAAQD0gXAFADMyZM0eWZVU7vf/++/EuooYNG6Zhw4bFuxiSpL1792rGjBm1/l5++OGHqO/T6XSqadOmOu6443TDDTfo66+/rrTP+++/H9l+5cqVldZPmjRJDRs2jFo2bNgwWZal0047rdoy3H///Qcsb/hzJ02aVOX6O++8M7LNDz/8cMDj1dakSZPUvn37Ou1b2/tj2LBh6tmzZ50+AwCSHeEKAGLo2Wef1cqVKytNffv2jXfREsrevXs1c+bMgw6d1113nVauXKnly5fr73//u8aNG6fFixerd+/e+stf/lLtfjfffPNBfc4777yj995776D22V96errmz5+v3bt3Ry03xmjOnDnKyMg4pOMDAGKPcAUAMdSzZ08NGjSo0sQP6frRtm1bDRo0SEOGDNHpp5+uW2+9VV999ZVGjBihm2++Wf/85z8r7XPaaafpo48+0j/+8Y9afUaXLl3UsWNH3XzzzTLG1LmsY8eOlTFGc+fOjVr+3nvvKS8vT+PHj6/zsQEA8UG4AoAEMnfuXFmWpVmzZkUtv+OOO2S327VkyZLIssWLF2vw4MFKS0tTenq6RowYUal524wZM2RZltasWaOzzz5bGRkZyszM1MUXX6yff/75gOWZOXOmBg4cqCZNmigjI0N9+/bVM888UylUtG/fXmeeeabefvtt9e3bV16vV926ddPs2bMrHTM/P19XXnmlWrduLZfLpQ4dOmjmzJny+/2SQs3rmjdvHvn8AzWhOxCv16tnnnlGTqezytqrSZMmqXv37rrlllsUCAQOeDyn06k//elP+uyzzzRv3rw6lUmSMjMzddZZZ1X6jmbPnq3jjz9eXbp0qXK/2bNnq3fv3vJ4PGrSpInOOussrV+/vtJ2c+bMUdeuXeV2u3X00Ufr+eefr/J4paWluvvuu9WtWze53W41b95cl156aa3uj7oKBoP685//HPnMFi1aaMKECfrxxx+jtluzZo3OPPNMtWjRQm63Wzk5OTrjjDOitps/f74GDhyozMxMpaWlqWPHjrrssssOW9kBoCaEKwCIoUAgIL/fHzXt+4P+/PPP11VXXaU//OEPWr16taRQTcbdd9+tadOmacSIEZKkl156SWPHjlVGRoZefvllPfPMM/r11181bNgwffTRR5U+96yzzlKnTp306quvasaMGVq0aJFGjRqlsrKyGsv7ww8/6Morr9Qrr7yihQsX6uyzz9Z1112nu+66q9K2X3zxhf7whz/ohhtu0Ouvv65jjjlGl19+uT744IPINvn5+RowYIDeeecd3X777frnP/+pyy+/XLm5ubriiiskSdnZ2Xr77bclSZdffnmk6eT06dMP8tuukJOTo379+mnFihWREBdmt9uVm5urr7/+Ws8991ytjjd+/Hj169dPt9122wG/w5pcfvnl+uSTTyLhaNeuXVq4cKEuv/zyKrfPzc3V5Zdfrh49emjhwoX661//qi+//FKDBw/Whg0bItvNmTNHl156qY4++mgtWLBAt912m+66665KTRmDwaDGjh2re++9VxdeeKHefPNN3XvvvVqyZImGDRum4uLiOp9bTX73u99p6tSpGjFihBYvXqy77rpLb7/9toYMGaIdO3ZIkoqKijRixAj99NNPeuyxx7RkyRI9/PDDatu2baQp5cqVKzV+/Hh17NhRc+fO1Ztvvqnbb7+90jUGgJgxAIDD7tlnnzWSqpzsdnvUtiUlJebYY481HTp0MP/5z39My5YtzdChQ43f7zfGGBMIBExOTo7p1auXCQQCkf12795tWrRoYYYMGRJZdscddxhJ5oYbboj6jBdffNFIMi+88EJk2dChQ83QoUOrPYdAIGDKysrMnXfeaZo2bWqCwWBkXbt27YzH4zEbN26MLCsuLjZNmjQxV155ZWTZlVdeaRo2bBi1nTHG3H///UaS+frrr40xxvz8889GkrnjjjuqLc++8vLyjCTzl7/8pdptxo8fbySZn376yRhjzLJly4wkM3/+fGOMMSeccIJp3bq1KS4uNsYYM3HiRNOgQYOoYwwdOtT06NHDGGPM0qVLjSTz6KOP1roMYZLMNddcY4LBoOnQoYO56aabjDHGPPbYY6Zhw4Zm9+7d5i9/+YuRZPLy8owxxvz666/G6/Wa008/PepYmzZtMm6321x44YXGmIr7o2/fvlHX6IcffjBOp9O0a9cusuzll182ksyCBQuijrlq1SojyTz++ONR517T/VHVd1SV9evXG0nm6quvjlr+6aefGklm2rRpxhhjVq9ebSSZRYsWVXus8H2za9euA5YLAGKBmisAiKHnn39eq1atipo+/fTTqG3cbrdeeeUV7dy5U3379pUxRi+//LLsdrsk6ZtvvtHWrVt1ySWXyGar+Ge8YcOGOuecc/TJJ59o7969Uce86KKLoubPO+88ORwOLVu2rMbyvvfeezr11FOVmZkpu90up9Op22+/XTt37tT27dujtu3Tp4/atm0bmfd4POrSpYs2btwYWfbGG2/o5JNPVk5OTlTt3ejRoyVJy5cvP9BXWGfmAP2j7rvvPv3444/661//WqvjDR8+XCNHjtSdd95ZaVCK2go3d/z73/8uv9+vZ555Ruedd16lUQqlUC1NcXFxpeaRbdq00SmnnKJ//etfkirujwsvvFCWZUW2a9eunYYMGRK17xtvvKFGjRppzJgxUdejT58+ysrKOiyjWIbvuf3PY8CAATr66KMj59GpUyc1btxYU6dO1ZNPPqn//Oc/lY513HHHSQrdz6+88oq2bNlS7+UFgINBuAKAGDr66KPVv3//qKlfv36VtuvUqZNOPPFElZSU6KKLLlJ2dnZk3c6dOyUpallYTk6OgsGgfv3116jlWVlZUfMOh0NNmzaNHKsq//73vzVy5EhJ0t/+9jd9/PHHWrVqlW699VZJqtRkrGnTppWO4Xa7o7b76aef9I9//ENOpzNq6tGjhyRFmoQdDhs3bpTb7VaTJk2qXD9kyBCNGzdO9957b6Xvrzr33XefduzYUavh16sT7t90zz336PPPP6+2SeCBrnt4ffh1/2te1bKffvpJu3btksvlqnRN8vPzD8v1qO15ZGZmavny5erTp4+mTZumHj16KCcnR3fccUekKeZJJ52kRYsWye/3a8KECWrdurV69uypl19+ud7LDQC14Yh3AQAAlT399NN68803NWDAAM2aNUvjx4/XwIEDJVWEmG3btlXab+vWrbLZbGrcuHHU8vz8fLVq1Soy7/f7tXPnzioDUdjcuXPldDr1xhtvyOPxRJYvWrSozufVrFkzHXPMMfrTn/5U5fqcnJw6H7smW7Zs0WeffaahQ4fK4aj+f325ubnq2bOn7rnnnlodt0+fPrrgggv04IMP6vTTT69T2dq0aaNTTz1VM2fOVNeuXSvVLoUd6Lo3a9Ysarv8/PxK2+2/rFmzZmratGmkj9v+0tPTa38itbTvebRu3Tpq3b7nIUm9evXS3LlzZYzRl19+qTlz5ujOO++U1+vVH//4R0mhURfHjh0rn8+nTz75RLm5ubrwwgvVvn17DR48uN7LDwA1oeYKABLMunXr9Pvf/14TJkzQhx9+qGOOOUbjx4+P1KZ07dpVrVq10ksvvRTV1K2oqEgLFiyIjCC4rxdffDFq/pVXXpHf76/xobCWZcnhcESaI0qh2qq///3vdT63M888U1999ZWOOuqoSjV4/fv3j4Qrt9sd+bxDVVxcrN/+9rfy+/0HfJ5Vt27ddNlll+nRRx/Vpk2banX8u+++W6WlpZo5c2ady/iHP/xBY8aMqXHQjsGDB8vr9eqFF16IWv7jjz/qvffe0/DhwyWF7o/s7Gy9/PLLUffHxo0btWLFiqh9zzzzTO3cuVOBQKDK69G1a9c6n1N1TjnlFEmqdB6rVq3S+vXrI+exL8uy1Lt3bz300ENq1KiRPv/880rbuN1uDR06VPfdd5+k0EiDABBr1FwBQAx99dVXVY5kdtRRR6l58+YqKirSeeedpw4dOujxxx+Xy+XSK6+8or59++rSSy/VokWLZLPZ9Oc//1kXXXSRzjzzTF155ZXy+Xz6y1/+ol27dunee++tdPyFCxfK4XBoxIgR+vrrrzV9+nT17t1b5513XrVlPeOMM/Tggw/qwgsv1OTJk7Vz507df//9keBTF3feeaeWLFmiIUOG6Pe//726du2qkpIS/fDDD3rrrbf05JNPqnXr1kpPT1e7du30+uuva/jw4WrSpImaNWum9u3b13j8TZs26ZNPPlEwGFRBQYHWrFmj2bNna+PGjXrggQcizRxrMmPGDL344otatmyZGjRocMDtO3TooN/97ne17qtVlZEjRx6wbI0aNdL06dM1bdo0TZgwQRdccIF27typmTNnyuPx6I477pAk2Ww23XXXXfrtb3+rs846S1dccYV27dqlGTNmVGoWeP755+vFF1/U6aefruuvv14DBgyQ0+nUjz/+qGXLlmns2LE666yzDvp8CgsL9eqrr1Za3rx5cw0dOlSTJ0/Wo48+KpvNptGjR+uHH37Q9OnT1aZNG91www2SQv3BHn/8cY0bN04dO3aUMUYLFy7Url27IqNm3n777frxxx81fPhwtW7dWrt27dJf//pXOZ1ODR069KDLDQCHLJ6jaQDAkaKm0QIlmb/97W/GGGMuvvhik5aWFhk1L2z+/PlGknnooYciyxYtWmQGDhxoPB6PadCggRk+fLj5+OOPo/YLjxb42WefmTFjxpiGDRua9PR0c8EFF0RGzQurajS42bNnm65duxq32206duxocnNzzTPPPBM1ip0xodECzzjjjErnXdUxf/75Z/P73//edOjQwTidTtOkSRPTr18/c+utt5o9e/ZEtlu6dKk59thjjdvtNpLMxIkTq/1+wyP1hSe73W4aN25s+vXrZ6ZMmVLp+zSm8miB+5o2bZqRVONogfufU0ZGxkGPFliT/UcLDHv66afNMcccY1wul8nMzDRjx46t8vyefvpp07lzZ+NyuUyXLl3M7NmzzcSJE6NGCzTGmLKyMnP//feb3r17G4/HYxo2bGi6detmrrzySrNhw4aoc6/taIHV3efh/QOBgLnvvvtMly5djNPpNM2aNTMXX3yx2bx5c+Q4//3vf80FF1xgjjrqKOP1ek1mZqYZMGCAmTNnTmSbN954w4wePdq0atXKuFwu06JFC3P66aebDz/88IDlBIDDwTLmEB4vDwBIaDNmzNDMmTP1888/R/VlAQAA9Y8+VwAAAABQDwhXAAAAAFAPaBYIAAAAAPWAmisAAAAAqAeEKwAAAACoB4QrAAAAAKgHPES4CsFgUFu3blV6erosy4p3cQAAAADEiTFGu3fvVk5Ojmy2muumCFdV2Lp1q9q0aRPvYgAAAABIEJs3b1br1q1r3IZwVYX09HRJoS8wIyMjzqUBAAAAEC+FhYVq06ZNJCPUhHBVhXBTwIyMDMIVAAAAgFp1F2JACwAAAACoB4QrAAAAAKgHhCsAAAAAqAf0uaojY4z8fr8CgUC8i4J6YLfb5XA4GHofAAAAdUa4qoPS0lJt27ZNe/fujXdRUI/S0tKUnZ0tl8sV76IAAAAgCRGuDlIwGFReXp7sdrtycnLkcrmo7UhyxhiVlpbq559/Vl5enjp37nzAB8QBAAAA+yNcHaTS0lIFg0G1adNGaWlp8S4O6onX65XT6dTGjRtVWloqj8cT7yIBAAAgyfDn+TqiZiP1cE0BAABwKPg1CQAAAAD1gHAFAAAAAPUgruHqgw8+0JgxY5STkyPLsrRo0aKo9ZZlVTn95S9/qfaYc+bMqXKfkpKSw3w2R6Zhw4ZpypQp8S4GAAAAEHdxHdCiqKhIvXv31qWXXqpzzjmn0vpt27ZFzf/zn//U5ZdfXuW2+8rIyNA333wTtexIH6DgQCMaTpw4UXPmzDno4y5cuFBOp7OOpQIAAABSR1zD1ejRozV69Ohq12dlZUXNv/766zr55JPVsWPHGo9rWValfY90+wbVefPm6fbbb48KoF6vN2r7srKyWoWmJk2a1F8hAQAAgCSWNH2ufvrpJ7355pu6/PLLD7jtnj171K5dO7Vu3Vpnnnmm1qxZU+P2Pp9PhYWFUdPBMMZob6k/LpMxplZlzMrKikyZmZmRAJqVlaWSkhI1atRIr7zyioYNGyaPx6MXXnhBO3fu1AUXXKDWrVsrLS1NvXr10ssvvxx13P2bBbZv31733HOPLrvsMqWnp6tt27Z66qmnDur7BAAAAJJR0jzn6rnnnlN6errOPvvsGrfr1q2b5syZo169eqmwsFB//etfdfzxx+uLL75Q586dq9wnNzdXM2fOrHPZissC6n77O3Xe/1D8585RSnPVz2WcOnWqHnjgAT377LNyu90qKSlRv379NHXqVGVkZOjNN9/UJZdcoo4dO2rgwIHVHueBBx7QXXfdpWnTpunVV1/V7373O5100knq1q1bvZQTAAAASERJU3M1e/ZsXXTRRQfsOzVo0CBdfPHF6t27t0488US98sor6tKlix599NFq97nllltUUFAQmTZv3lzfxU8KU6ZM0dlnn60OHTooJydHrVq10k033aQ+ffqoY8eOuu666zRq1CjNnz+/xuOcfvrpuvrqq9WpUydNnTpVzZo10/vvvx+bkwAAAADiJClqrj788EN98803mjdv3kHva7PZdNxxx2nDhg3VbuN2u+V2u+tcPq/Trv/cOarO+9ekpCwgX1lQLodNXpe9ys+uL/3794+aDwQCuvfeezVv3jxt2bJFPp9PPp9PDRo0qPE4xxxzTOR9uPnh9u3b662cAAAAQCJKinD1zDPPqF+/furdu/dB72uM0dq1a9WrV6/DULIQy7LqrWne/gr2lunnPT41T3erqavuAbA29g9NDzzwgB566CE9/PDD6tWrlxo0aKApU6aotLS0xuPsPxCGZVkKBoP1Xl4AAAAgkcQ1XO3Zs0fffvttZD4vL09r165VkyZN1LZtW0lSYWGh5s+frwceeKDKY0yYMEGtWrVSbm6uJGnmzJkaNGiQOnfurMLCQj3yyCNau3atHnvsscN/QodBeAj1YO3GrahXH374ocaOHauLL744VIZgUBs2bNDRRx8d+8IAAAAACS6u4Wr16tU6+eSTI/M33nijpOhnLs2dO1fGGF1wwQVVHmPTpk2y2Sq6ju3atUuTJ09Wfn6+MjMzdeyxx+qDDz7QgAEDDt+JHEa28sdTmTikq06dOmnBggVasWKFGjdurAcffFD5+fmEKwAAAKAKcQ1Xw4YNO+BQ4pMnT9bkyZOrXb//QAkPPfSQHnroofooXkKIZ83V9OnTlZeXp1GjRiktLU2TJ0/WuHHjVFBQEPvCAAAAAAnOMrV9UNIRpLCwUJmZmSooKFBGRkbUupKSEuXl5alDhw4HHLmwPuzc49OWXcXK8DjVvlnNA0ng0MT62gIAACDx1ZQN9pc0Q7EfqWyRmisyMAAAAJDICFcJLtLnimwFAAAAJDTCVYKzqLkCAAAAkgLhKsHZ4jigBQAAAIDaI1wluIpmgaQrAAAAIJERrhJcPIdiBwAAAFB7hKsER80VAAAAkBwIVwmOPlcAAABAciBcJTgrXHMlw4iBAAAAQAIjXCW4cM2VFP+mgcOGDdOUKVMi8+3bt9fDDz9c4z6WZWnRokWH/Nn1dRwAAADgcCFcJbh9stUhNQ0cM2aMTj311CrXrVy5UpZl6fPPPz+oY65atUqTJ0+ue6GqMGPGDPXp06fS8m3btmn06NH1+lkAAABAfSJcJTjLsvbpd1X3dHX55Zfrvffe08aNGyutmz17tvr06aO+ffse1DGbN2+utLS0OpfpYGRlZcntdsfkswAAAIC6IFzVB2Ok0qLDNtn9xbLK9sr4qlhfy8B15plnqkWLFpozZ07U8r1792revHkaN26cLrjgArVu3VppaWnq1auXXn755RqPuX+zwA0bNuikk06Sx+NR9+7dtWTJkkr7TJ06VV26dFFaWpo6duyo6dOnq6ysTJI0Z84czZw5U1988YUsy5JlWZHy7t8scN26dTrllFPk9XrVtGlTTZ48WXv27ImsnzRpksaNG6f7779f2dnZatq0qa655prIZwEAAAD1zRHvAqSEsr3SPTmH7fBH17Ry2lbJ1eCAx3A4HJowYYLmzJmj22+/PfL8rPnz56u0tFS//e1v9fLLL2vq1KnKyMjQm2++qUsuuUQdO3bUwIEDD3j8YDCos88+W82aNdMnn3yiwsLCqP5ZYenp6ZozZ45ycnK0bt06XXHFFUpPT9fNN9+s8ePH66uvvtLbb7+tpUuXSpIyMzMrHWPv3r067bTTNGjQIK1atUrbt2/Xb3/7W1177bVR4XHZsmXKzs7WsmXL9O2332r8+PHq06ePrrjiigOeDwAAAHCwqLk6glx22WX64Ycf9P7770eWzZ49W2effbZatWqlm266SX369FHHjh113XXXadSoUZo/f36tjr106VKtX79ef//739WnTx+ddNJJuueeeyptd9ttt2nIkCFq3769xowZoz/84Q965ZVXJEler1cNGzaUw+FQVlaWsrKy5PV6Kx3jxRdfVHFxsZ5//nn17NlTp5xyimbNmqW///3v+umnnyLbNW7cWLNmzVK3bt105pln6owzztC//vWvg/zWAAAAgNqh5qo+ONNCNUiHybfb96i4LKD2TdOU7nFW/uxa6tatm4YMGaLZs2fr5JNP1nfffacPP/xQ7777rgKBgO69917NmzdPW7Zskc/nk8/nU4MGB64Vk6T169erbdu2at26dWTZ4MGDK2336quv6uGHH9a3336rPXv2yO/3KyMjo9bnEP6s3r17R5Xt+OOPVzAY1DfffKOWLVtKknr06CG73R7ZJjs7W+vWrTuozwIAAABqi5qr+mBZoaZ5h3EyzjQFnVWs23c4wVq4/PLLtWDBAhUWFurZZ59Vu3btNHz4cD3wwAN66KGHdPPNN+u9997T2rVrNWrUKJWWltbquFUNE2/tV7ZPPvlE559/vkaPHq033nhDa9as0a233lrrz9j3s/Y/dlWf6XQ6K60LBoMH9VkAAABAbRGukoAt/CDhenjO1XnnnSe73a6XXnpJzz33nC699FJZlqUPP/xQY8eO1cUXX6zevXurY8eO2rBhQ62P2717d23atElbt1bU4K1cuTJqm48//ljt2rXTrbfeqv79+6tz586VRi90uVwKBAIH/Ky1a9eqqKgo6tg2m01dunSpdZkBAACA+kS4SgL1MRR7WMOGDTV+/HhNmzZNW7du1aRJkyRJnTp10pIlS7RixQqtX79eV155pfLz82t93FNPPVVdu3bVhAkT9MUXX+jDDz/UrbfeGrVNp06dtGnTJs2dO1ffffedHnnkEb322mtR27Rv3155eXlau3atduzYIZ/PV+mzLrroInk8Hk2cOFFfffWVli1bpuuuu06XXHJJpEkgAAAAEGuEqyQQbul2KA8R3tfll1+uX3/9Vaeeeqratm0rSZo+fbr69u2rUaNGadiwYcrKytK4ceNqfUybzabXXntNPp9PAwYM0G9/+1v96U9/itpm7NixuuGGG3TttdeqT58+WrFihaZPnx61zTnnnKPTTjtNJ598spo3b17lcPBpaWl655139Msvv+i4447Tueeeq+HDh2vWrFkH/2UAAAAA9cQy9dHWLMUUFhYqMzNTBQUFlQZbKCkpUV5enjp06CCPxxOT8mz+Za9+3VuqrEyPWqTH5jOPRPG4tgAAAEhsNWWD/VFzlQQq+lzFtxwAAAAAqke4SgL12ecKAAAAwOFBuEoCViRcxbkgAAAAAKpFuEoCkWaBpCsAAAAgYRGu6iiW44BQcxUbjO0CAACAQ0G4OkhOp1OStHfv3ph9pi0yFDs//g+n8DUNX2MAAADgYDjiXYBkY7fb1ahRI23fvl1S6JlL4Zqlw8VfWirjL1VZaUAlJfbD+llHImOM9u7dq+3bt6tRo0ay2/mOAQAAcPAIV3WQlZUlSZGAdbgVlwa0s6hUbodN/gJ3TD7zSNSoUaPItQUAAAAOFuGqDizLUnZ2tlq0aKGysrLD/nmffr9TM5atU5eW6Xri4m6H/fOORE6nkxorAAAAHBLC1SGw2+0x+UHucnu0ZXdAXq9fHo/nsH8eAAAAgIPHgBZJwOMMXaaSskCcSwIAAACgOoSrJOB1hWrHCFcAAABA4iJcJQGPIxyugnEuCQAAAIDqEK6SgMcZClfF1FwBAAAACYtwlQS85eEqEDQqC1B7BQAAACQiwlUScDsrLhO1VwAAAEBiIlwlAbfDJssKvWdQCwAAACAxEa6SgGVZFYNalNIsEAAAAEhEhKskERmO3U/NFQAAAJCICFdJwuPgQcIAAABAIiNcJQlPec1VcSnhCgAAAEhEhKskEelz5afPFQAAAJCICFdJwkvNFQAAAJDQCFdJwlP+rCsfA1oAAAAACYlwlSS8TmquAAAAgERGuEoS7vJwxWiBAAAAQGIiXCWJSM1VGQNaAAAAAImIcJUkwn2uqLkCAAAAEhPhKkl4aRYIAAAAJLS4hqsPPvhAY8aMUU5OjizL0qJFi6LWT5o0SZZlRU2DBg064HEXLFig7t27y+12q3v37nrttdcO0xnEjodwBQAAACS0uIaroqIi9e7dW7Nmzap2m9NOO03btm2LTG+99VaNx1y5cqXGjx+vSy65RF988YUuueQSnXfeefr000/ru/gx5Yn0uSJcAQAAAInIEc8PHz16tEaPHl3jNm63W1lZWbU+5sMPP6wRI0bolltukSTdcsstWr58uR5++GG9/PLLh1TeeKqouWJACwAAACARJXyfq/fff18tWrRQly5ddMUVV2j79u01br9y5UqNHDkyatmoUaO0YsWKavfx+XwqLCyMmhKNl5orAAAAIKEldLgaPXq0XnzxRb333nt64IEHtGrVKp1yyiny+XzV7pOfn6+WLVtGLWvZsqXy8/Or3Sc3N1eZmZmRqU2bNvV2DvWF0QIBAACAxBbXZoEHMn78+Mj7nj17qn///mrXrp3efPNNnX322dXuZ1lW1LwxptKyfd1yyy268cYbI/OFhYUJF7AYLRAAAABIbAkdrvaXnZ2tdu3aacOGDdVuk5WVVamWavv27ZVqs/bldrvldrvrrZyHA32uAAAAgMSW0M0C97dz505t3rxZ2dnZ1W4zePBgLVmyJGrZu+++qyFDhhzu4h1WjBYIAAAAJLa41lzt2bNH3377bWQ+Ly9Pa9euVZMmTdSkSRPNmDFD55xzjrKzs/XDDz9o2rRpatasmc4666zIPhMmTFCrVq2Um5srSbr++ut10kkn6b777tPYsWP1+uuva+nSpfroo49ifn71iT5XAAAAQGKLa7havXq1Tj755Mh8uN/TxIkT9cQTT2jdunV6/vnntWvXLmVnZ+vkk0/WvHnzlJ6eHtln06ZNstkqKuCGDBmiuXPn6rbbbtP06dN11FFHad68eRo4cGDsTuww8LrocwUAAAAkMssYY+JdiERTWFiozMxMFRQUKCMjI97FkST9sKNIw+5/Xw3dDn01c1S8iwMAAAAcEQ4mGyRVn6sjGX2uAAAAgMRGuEoS4aHYA0GjsgAjBgIAAACJhnCVJNzOiktF7RUAAACQeAhXScLtsCn8HGQGtQAAAAASD+EqSViWJY+jfMTAUpoFAgAAAImGcJVEIsOx+6m5AgAAABIN4SqJeBw8SBgAAABIVISrJOIpr7kqLiVcAQAAAImGcJVEIn2u/PS5AgAAABIN4SqJeKm5AgAAABIW4SqJeMqfdeVjQAsAAAAg4RCukojXSc0VAAAAkKgIV0nEXR6uGC0QAAAASDyEqyQSqbkqY0ALAAAAINEQrpJIuM8VNVcAAABA4iFcJREvzQIBAACAhEW4SiIewhUAAACQsAhXScQT6XNFuAIAAAASDeEqiVTUXDGgBQAAAJBoCFdJxEvNFQAAAJCwCFdJhNECAQAAgMRFuEoijBYIAAAAJC7CVRKhzxUAAACQuAhXSYTRAgEAAIDERbhKIvS5AgAAABIX4SqJeF30uQIAAAASFeEqiXgc9LkCAAAAEhXhKomEa67ocwUAAAAkHsJVEgnXXAWCRmUBaq8AAACAREK4SiJuZ8XlovYKAAAASCyEqyTidthkWaH3DGoBAAAAJBbCVRKxLCvSNNDHoBYAAABAQiFcJRkGtQAAAAASE+EqyXgcPEgYAAAASESEqyTjCddclRKuAAAAgERCuEoykQcJ++lzBQAAACQSwlWS8VJzBQAAACQkwlWS8ZQ/68rnJ1wBAAAAiYRwlWS8TmquAAAAgEREuEoy7vJwxWiBAAAAQGIhXCWZSM0VDxEGAAAAEgrhKsmE+1xRcwUAAAAkFsJVkvHSLBAAAABISISrJOMhXAEAAAAJiXCVZDyRPleEKwAAACCREK6STEXNFQNaAAAAAImEcJVkvNRcAQAAAAmJcJVkGC0QAAAASEyEqyTDaIEAAABAYiJcJRn6XAEAAACJiXCVZBgtEAAAAEhMcQ1XH3zwgcaMGaOcnBxZlqVFixZF1pWVlWnq1Knq1auXGjRooJycHE2YMEFbt26t8Zhz5syRZVmVppKSksN8NrFBnysAAAAgMcU1XBUVFal3796aNWtWpXV79+7V559/runTp+vzzz/XwoUL9b///U+/+c1vDnjcjIwMbdu2LWryeDyH4xRizuuizxUAAACQiBzx/PDRo0dr9OjRVa7LzMzUkiVLopY9+uijGjBggDZt2qS2bdtWe1zLspSVlVXrcvh8Pvl8vsh8YWFhrfeNNY+DPlcAAABAIkqqPlcFBQWyLEuNGjWqcbs9e/aoXbt2at26tc4880ytWbOmxu1zc3OVmZkZmdq0aVOPpa5f4Zor+lwBAAAAiSVpwlVJSYn++Mc/6sILL1RGRka123Xr1k1z5szR4sWL9fLLL8vj8ej444/Xhg0bqt3nlltuUUFBQWTavHnz4TiFehGuuQoEjcoC1F4BAAAAiSKuzQJrq6ysTOeff76CwaAef/zxGrcdNGiQBg0aFJk//vjj1bdvXz366KN65JFHqtzH7XbL7XbXa5kPF4+rIg8XlwXktCdNPgYAAABSWsL/Mi8rK9N5552nvLw8LVmypMZaq6rYbDYdd9xxNdZcJROX3SbLCr1nUAsAAAAgcSR0uAoHqw0bNmjp0qVq2rTpQR/DGKO1a9cqOzv7MJQw9izLijQN9DGoBQAAAJAw4toscM+ePfr2228j83l5eVq7dq2aNGminJwcnXvuufr888/1xhtvKBAIKD8/X5LUpEkTuVwuSdKECRPUqlUr5ebmSpJmzpypQYMGqXPnziosLNQjjzyitWvX6rHHHov9CR4mXpddxWUBBrUAAAAAEkhcw9Xq1at18sknR+ZvvPFGSdLEiRM1Y8YMLV68WJLUp0+fqP2WLVumYcOGSZI2bdokm62iAm7Xrl2aPHmy8vPzlZmZqWOPPVYffPCBBgwYcHhPJoY8Dh4kDAAAACQayxhj4l2IRFNYWKjMzEwVFBQcdB+vWDjlgff1/c9Fmjd5kAZ2PPimkgAAAABq52CyQUL3uULVIg8S9tPnCgAAAEgUhKskFHmQcCnNAgEAAIBEQbhKQh5n6LL5/IQrAAAAIFEQrpKQ10nNFQAAAJBoCFdJyF0erhgtEAAAAEgchKskFKm54iHCAAAAQMIgXCWhcJ8raq4AAACAxEG4SkJemgUCAAAACYdwlYQ8hCsAAAAg4RCukpAn0ueKcAUAAAAkCsJVEqqouWJACwAAACBREK6SkJeaKwAAACDhEK6SEKMFAgAAAImHcJWEGC0QAAAASDyEqyREnysAAAAg8RCukhCjBQIAAACJh3CVhOhzBQAAACQewlUS8rrocwUAAAAkGsJVEvI46HMFAAAAJBrCVRIK11zR5woAAABIHISrJBSuuQoEjcoC1F4BAAAAiYBwlYQ8rorLRr8rAAAAIDEQrpKQy26TZYXe0zQQAAAASAyEqyRkWZa85c+68jGoBQAAAJAQCFdJigcJAwAAAImFcJWkPA4eJAwAAAAkEsJVkvKEh2MvJVwBAAAAiYBwlaQiDxL20+cKAAAASASEqyTlpeYKAAAASCiEqyTlcYYunc9PuAIAAAASAeEqSYWHYqfmCgAAAEgMhKsk5S4PV4wWCAAAACQGwlWSitRc8RBhAAAAICEQrpJUuM8VNVcAAABAYiBcJSkvzQIBAACAhEK4SlIewhUAAACQUAhXScoT6XNFuAIAAAASAeEqSVXUXDGgBQAAAJAICFdJykvNFQAAAJBQCFdJitECAQAAgMRCuEpSjBYIAAAAJBbCVZKizxUAAACQWAhXSYrRAgEAAIDEQrhKUvS5AgAAABIL4SpJeV30uQIAAAASCeEqSXkc9LkCAAAAEgnhKklRcwUAAAAkFsJVkgrXXPmDRmUBaq8AAACAeCNcJSmPq+LSUXsFAAAAxB/hKkm57DZZVug9w7EDAAAA8RfXcPXBBx9ozJgxysnJkWVZWrRoUdR6Y4xmzJihnJwceb1eDRs2TF9//fUBj7tgwQJ1795dbrdb3bt312uvvXaYziB+LMuSt/xZVz4GtQAAAADiLq7hqqioSL1799asWbOqXP/nP/9ZDz74oGbNmqVVq1YpKytLI0aM0O7du6s95sqVKzV+/Hhdcskl+uKLL3TJJZfovPPO06effnq4TiNueJAwAAAAkDgsY4yJdyGkUE3Ma6+9pnHjxkkK1Vrl5ORoypQpmjp1qiTJ5/OpZcuWuu+++3TllVdWeZzx48ersLBQ//znPyPLTjvtNDVu3Fgvv/xyrcpSWFiozMxMFRQUKCMj49BO7DA6/t73tGVXsRZfe7yOad0o3sUBAAAAUs7BZIOE7XOVl5en/Px8jRw5MrLM7XZr6NChWrFiRbX7rVy5MmofSRo1alSN+/h8PhUWFkZNycDtDF2+4lJqrgAAAIB4S9hwlZ+fL0lq2bJl1PKWLVtG1lW338Huk5ubq8zMzMjUpk2bQyh57EQeJOynzxUAAAAQbwkbrsKs8JB45YwxlZYd6j633HKLCgoKItPmzZvrXuAYCj9ImJorAAAAIP4c8S5AdbKysiSFaqKys7Mjy7dv316pZmr//favpTrQPm63W263+xBLHHue8maBPj/hCgAAAIi3hK256tChg7KysrRkyZLIstLSUi1fvlxDhgypdr/BgwdH7SNJ7777bo37JKvwUOzUXAEAAADxF9eaqz179ujbb7+NzOfl5Wnt2rVq0qSJ2rZtqylTpuiee+5R586d1blzZ91zzz1KS0vThRdeGNlnwoQJatWqlXJzcyVJ119/vU466STdd999Gjt2rF5//XUtXbpUH330UczP73Bzl4erEoZiBwAAAOIuruFq9erVOvnkkyPzN954oyRp4sSJmjNnjm6++WYVFxfr6quv1q+//qqBAwfq3XffVXp6emSfTZs2yWarqIAbMmSI5s6dq9tuu03Tp0/XUUcdpXnz5mngwIGxO7EYidRc8RBhAAAAIO4S5jlXiSRZnnN126J1euGTTbp+eGfdMKJLvIsDAAAApJyUeM4VDsxLs0AAAAAgYRCukpiHcAUAAAAkDMJVEvNE+lwRrgAAAIB4I1wlsYqaKwa0AAAAAOKNcJXEvNRcAQAAAAmDcJXEPM7Q5aPPFQAAABB/hKskxmiBAAAAQOIgXCUx+lwBAAAAiYNwlcQYLRAAAABIHISrJEafKwAAACBx1Clcbd68WT/++GNk/t///remTJmip556qt4KhgPzuuhzBQAAACSKOoWrCy+8UMuWLZMk5efna8SIEfr3v/+tadOm6c4776zXAqJ6Hgd9rgAAAIBEUadw9dVXX2nAgAGSpFdeeUU9e/bUihUr9NJLL2nOnDn1WT7UgJorAAAAIHHUKVyVlZXJ7XZLkpYuXarf/OY3kqRu3bpp27Zt9Vc61Chcc+UPGpUFqL0CAAAA4qlO4apHjx568skn9eGHH2rJkiU67bTTJElbt25V06ZN67WAqJ7HVXH5qL0CAAAA4qtO4eq+++7T//t//0/Dhg3TBRdcoN69e0uSFi9eHGkuiMPPZbfJskLvGY4dAAAAiC9HXXYaNmyYduzYocLCQjVu3DiyfPLkyUpLS6u3wqFmlmXJ67Rrb2lAPga1AAAAAOKqTjVXxcXF8vl8kWC1ceNGPfzww/rmm2/UokWLei0gasaDhAEAAIDEUKdwNXbsWD3//POSpF27dmngwIF64IEHNG7cOD3xxBP1WkDUzOtkxEAAAAAgEdQpXH3++ec68cQTJUmvvvqqWrZsqY0bN+r555/XI488Uq8FRM3cztAlLC4lXAEAAADxVKdwtXfvXqWnp0uS3n33XZ199tmy2WwaNGiQNm7cWK8FRM0iDxL20+cKAAAAiKc6hatOnTpp0aJF2rx5s9555x2NHDlSkrR9+3ZlZGTUawFRs/CDhKm5AgAAAOKrTuHq9ttv10033aT27dtrwIABGjx4sKRQLdaxxx5brwVEzTzlzQJ9fsIVAAAAEE91Gor93HPP1QknnKBt27ZFnnElScOHD9dZZ51Vb4XDgYUHtKDmCgAAAIivOoUrScrKylJWVpZ+/PFHWZalVq1a8QDhOHAzWiAAAACQEOrULDAYDOrOO+9UZmam2rVrp7Zt26pRo0a66667FAwysEIsRWqueIgwAAAAEFd1qrm69dZb9cwzz+jee+/V8ccfL2OMPv74Y82YMUMlJSX605/+VN/lRDXCfa6ouQIAAADiq07h6rnnntPTTz+t3/zmN5FlvXv3VqtWrXT11VcTrmKIhwgDAAAAiaFOzQJ/+eUXdevWrdLybt266ZdffjnkQqH2PIQrAAAAICHUKVz17t1bs2bNqrR81qxZOuaYYw65UKg9T6TPFeEKAAAAiKc6NQv885//rDPOOENLly7V4MGDZVmWVqxYoc2bN+utt96q7zKiBhU1VwxoAQAAAMRTnWquhg4dqv/9738666yztGvXLv3yyy86++yz9fXXX+vZZ5+t7zKiBl5qrgAAAICEUOfnXOXk5FQauOKLL77Qc889p9mzZx9ywVA7jBYIAAAAJIY61VwhcTBaIAAAAJAYCFdJjj5XAAAAQGIgXCU5RgsEAAAAEsNB9bk6++yza1y/a9euQykL6oA+VwAAAEBiOKhwlZmZecD1EyZMOKQC4eB4XTQLBAAAABLBQYUrhllPPB4HA1oAAAAAiYA+V0muouaKcAUAAADEE+EqyYVrrvxBo7IATQMBAACAeCFcJTmPq+ISUnsFAAAAxA/hKsm57DZZVug9w7EDAAAA8UO4SnKWZclb/qwrHyMGAgAAAHFDuEoBPEgYAAAAiD/CVQoI11zR5woAAACIH8JVCnA7Q5exuJRwBQAAAMQL4SoFRGqu/PS5AgAAAOKFcJUCIn2uqLkCAAAA4oZwlQI85c0CfX7CFQAAABAvhKsU4KXmCgAAAIi7hA9X7du3l2VZlaZrrrmmyu3ff//9Krf/73//G+OSx46b0QIBAACAuHPEuwAHsmrVKgUCFaHhq6++0ogRI/R///d/Ne73zTffKCMjIzLfvHnzw1bGeIvUXPEQYQAAACBuEj5c7R+K7r33Xh111FEaOnRojfu1aNFCjRo1OowlSxzhPlfUXAEAAADxk/DNAvdVWlqqF154QZdddpksy6px22OPPVbZ2dkaPny4li1bVuO2Pp9PhYWFUVMy4SHCAAAAQPwlVbhatGiRdu3apUmTJlW7TXZ2tp566iktWLBACxcuVNeuXTV8+HB98MEH1e6Tm5urzMzMyNSmTZvDUPrDx0O4AgAAAOLOMsaYeBeitkaNGiWXy6V//OMfB7XfmDFjZFmWFi9eXOV6n88nn88XmS8sLFSbNm1UUFAQ1W8rUT227Fv95Z1vdF7/1vrzub3jXRwAAAAgZRQWFiozM7NW2SDh+1yFbdy4UUuXLtXChQsPet9BgwbphRdeqHa92+2W2+0+lOLFVUXNFQNaAAAAAPGSNM0Cn332WbVo0UJnnHHGQe+7Zs0aZWdnH4ZSJYaK0QJpFggAAADES1LUXAWDQT377LOaOHGiHI7oIt9yyy3asmWLnn/+eUnSww8/rPbt26tHjx6RATAWLFigBQsWxKPoMcFogQAAAED8JUW4Wrp0qTZt2qTLLrus0rpt27Zp06ZNkfnS0lLddNNN2rJli7xer3r06KE333xTp59+eiyLHFOMFggAAADEX1INaBErB9NpLREs++92XTpnlXq1ytQ/rjsh3sUBAAAAUsbBZIOk6XOF6nnocwUAAADEHeEqBdDnCgAAAIg/wlUK8LoYih0AAACIN8JVCvA4GNACAAAAiDfCVQqoqLkiXAEAAADxQrhKAeGaK3/QqCxA00AAAAAgHghXKcDjqriM1F4BAAAA8UG4SgEuu02WFXrPcOwAAABAfBCuUoBlWfKWP+vKx4iBAAAAQFwQrlIEDxIGAAAA4otwlSLCNVf0uQIAAADig3CVItzO0KUsLiVcAQAAAPFAuEoRkZorP32uAAAAgHggXKWISJ8raq4AAACAuCBcpYjIaIF+whUAAAAQD4SrFOGhzxUAAAAQV4SrFOFmtEAAAAAgrghXKcIbec4VA1oAAAAA8UC4ShHhZoHUXAEAAADxQbhKETxEGAAAAIgvwlWK8BCuAAAAgLgiXKWIyHOuCFcAAABAXBCuUkRFzRUDWgAAAADxQLhKEV5qrgAAAIC4IlylCEYLBAAAAOKLcJUiGC0QAAAAiC/CVYqgzxUAAAAQX4SrFMFQ7AAAAEB8Ea5SRLjPFQNaAAAAAPFBuEoRXhfNAgEAAIB4IlylCI+DZoEAAABAPBGuUkRFzRXhCgAAAIgHwlWKCNdc+YNGZQGaBgIAAACxRrhKER5XxaWk9goAAACIPcJVinDZbbKs0HtGDAQAAABij3CVIizLkrf8WVc+RgwEAAAAYo5wlULCDxKm5goAAACIPcJVCgnXXNHnCgAAAIg9wlUKcTtDl7O4lHAFAAAAxBrhKoVEaq789LkCAAAAYo1wlUIifa6ouQIAAABijnCVQiKjBfoJVwAAAECsEa5SiIc+VwAAAEDcEK5SiIfRAgEAAIC4IVylkIrnXDGgBQAAABBrhKsUEm4WSM0VAAAAEHuEqxTCQ4QBAACA+CFcpRD6XAEAAADxQ7hKIRV9rghXAAAAQKwRrlJIRc0VA1oAAAAAsUa4SiFeaq4AAACAuEnocDVjxgxZlhU1ZWVl1bjP8uXL1a9fP3k8HnXs2FFPPvlkjEobf4wWCAAAAMSPI94FOJAePXpo6dKlkXm73V7ttnl5eTr99NN1xRVX6IUXXtDHH3+sq6++Ws2bN9c555wTi+LGVbjmykezQAAAACDmEj5cORyOA9ZWhT355JNq27atHn74YUnS0UcfrdWrV+v+++8/IsIVA1oAAAAA8ZPQzQIlacOGDcrJyVGHDh10/vnn6/vvv69225UrV2rkyJFRy0aNGqXVq1errKys2v18Pp8KCwujpmTEUOwAAABA/CR0uBo4cKCef/55vfPOO/rb3/6m/Px8DRkyRDt37qxy+/z8fLVs2TJqWcuWLeX3+7Vjx45qPyc3N1eZmZmRqU2bNvV6HrES7nNFzRUAAAAQewkdrkaPHq1zzjlHvXr10qmnnqo333xTkvTcc89Vu49lWVHzxpgql+/rlltuUUFBQWTavHlzPZQ+9rwuhmIHAAAA4iXh+1ztq0GDBurVq5c2bNhQ5fqsrCzl5+dHLdu+fbscDoeaNm1a7XHdbrfcbne9ljUePA6aBQIAAADxktA1V/vz+Xxav369srOzq1w/ePBgLVmyJGrZu+++q/79+8vpdMaiiHFVUXNFuAIAAABiLaHD1U033aTly5crLy9Pn376qc4991wVFhZq4sSJkkLN+SZMmBDZ/qqrrtLGjRt14403av369Zo9e7aeeeYZ3XTTTfE6hZgK11z5g0ZlAZoGAgAAALGU0M0Cf/zxR11wwQXasWOHmjdvrkGDBumTTz5Ru3btJEnbtm3Tpk2bItt36NBBb731lm644QY99thjysnJ0SOPPHJEDMMuSR5XRVYuKQvIaU/o7AwAAACkFMuER3xARGFhoTIzM1VQUKCMjIx4F6fWjDHqOO0tGSP9+9bhapHuiXeRAAAAgKR2MNmAqo0UYlmWvOXPuvIxYiAAAAAQU4SrFBN+kDDPugIAAABii3CVYsI1V4wYCAAAAMQW4SrFuJ2hS1pcSrgCAAAAYolwlWIiNVd++lwBAAAAsUS4SjGRPlfUXAEAAAAxRbhKMZHRAv2EKwAAACCWCFcpxkOfKwAAACAuCFcpxsNogQAAAEBcEK5STMVzrhjQAgAAAIglwlWK4TlXAAAAQHwQrlJMuM8V4QoAAACILcJViqHPFQAAABAfhKsUU9HninAFAAAAxBLhKsVU1FwxoAUAAAAQS4SrFOOl5goAAACIC8JVimFACwAAACA+CFcpJlxz5aNZIAAAABBThKsUw4AWAAAAQHwQrlIMQ7EDAAAA8UG4SjHhPlfUXAEAAACxRbhKMV4XQ7EDAAAA8UC4SjEeB80CAQAAgHggXKWYiporwhUAAAAQS4SrFBOuufIHjcoCNA0EAAAAYoVwlWI8ropLSu0VAAAAEDuEqxTjsttkWaH3jBgIAAAAxA7hKsVYliVv+bOufIwYCAAAAMQM4SoFhR8kTM0VAAAAEDuEqxQUrrmizxUAAAAQO4SrFOR2hi5rcSnhCgAAAIgVwlUKitRc+elzBQAAAMQK4SoFRfpcUXMFAAAAxAzhKgVFRgv0E64AAACAWCFcpSAPfa4AAACAmCNcpSAPowUCAAAAMUe4SkEVz7liQAsAAAAgVghXKYjnXAEAAACxR7hKQeE+V4QrAAAAIHYIVymIPlcAAABA7BGuUlBFnyvCFQAAABArhKsUVFFzxYAWAAAAQKwQrlIQA1oAAAAAsUe4SkGRhwgTrgAAAICYIVyloHDNlY9mgQAAAEDMEK5SEANaAAAAALFHuEpBDMUOAAAAxB7hKgXR5woAAACIPcJVCvK6GIodAAAAiDXCVQryOGgWCAAAAMQa4SoFVdRcEa4AAACAWEnocJWbm6vjjjtO6enpatGihcaNG6dvvvmmxn3ef/99WZZVafrvf/8bo1LHX7jmyh80KgvQNBAAAACIhYQOV8uXL9c111yjTz75REuWLJHf79fIkSNVVFR0wH2/+eYbbdu2LTJ17tw5BiVODB5XxWWl9goAAACIDUe8C1CTt99+O2r+2WefVYsWLfTZZ5/ppJNOqnHfFi1aqFGjRrX6HJ/PJ5/PF5kvLCw86LImEpfdJsuSjAmNGJjucca7SAAAAEDKS+iaq/0VFBRIkpo0aXLAbY899lhlZ2dr+PDhWrZsWY3b5ubmKjMzMzK1adOmXsobL5ZlyVv+rCsfIwYCAAAAMZE04coYoxtvvFEnnHCCevbsWe122dnZeuqpp7RgwQItXLhQXbt21fDhw/XBBx9Uu88tt9yigoKCyLR58+bDcQoxFX6QMM+6AgAAAGIjoZsF7uvaa6/Vl19+qY8++qjG7bp27aquXbtG5gcPHqzNmzfr/vvvr7Ypodvtltvtrtfyxlu45oo+VwAAAEBsJEXN1XXXXafFixdr2bJlat269UHvP2jQIG3YsOEwlCxxuZ2hS1tcSrgCAAAAYiGha66MMbruuuv02muv6f3331eHDh3qdJw1a9YoOzu7nkuX2CI1V376XAEAAACxkNDh6pprrtFLL72k119/Xenp6crPz5ckZWZmyuv1Sgr1l9qyZYuef/55SdLDDz+s9u3bq0ePHiotLdULL7ygBQsWaMGCBXE7j3iI9Lmi5goAAACIiYQOV0888YQkadiwYVHLn332WU2aNEmStG3bNm3atCmyrrS0VDfddJO2bNkir9erHj166M0339Tpp58eq2InhMhogX7CFQAAABALCR2ujDEH3GbOnDlR8zfffLNuvvnmw1Si5OGhzxUAAAAQU0kxoAUOnofRAgEAAICYIlylqIrnXDGgBQAAABALhKsUxXOuAAAAgNgiXKWocJ8rwhUAAAAQG4SrFEXNFQAAABBbhKsU5Y70uSJcAQAAALFAuEpRFaMFMqAFAAAAEAuEqxRFs0AAAAAgtghXKSryEGHCFQAAABAThKsUFa658tEsEAAAAIgJwlWK8jCgBQAAABBThKsU5aHPFQAAABBThKsURZ8rAAAAILYIVynK6wrVXO0u8SsQNHEuDQAAAJD6CFcpqm2TNGV4HCooLtMbX26Nd3EAAACAlEe4SlFpLoeuHHqUJOmhJf+TP8CogQAAAMDhRLhKYZOGtFeTBi79sHOvFn6+Jd7FAQAAAFIa4SqFNXA79Lvy2qu//muDSv3UXgEAAACHC+EqxV08qJ1apLu1ZVex5q3eHO/iAAAAACmLcJXivC67rj2lkyRp1nsbeO4VAAAAcJgQro4A449ro1aNvPqp0KcXPtkY7+IAAAAAKYlwdQRwO+z6/fBQ7dUT73+nIp8/ziUCAAAAUg/h6ghxdt/Wat80TTuLSjVnxQ/xLg4AAACQcghXRwin3abrT+0sSXrqg+9VWFIW5xIBAAAAqYVwdQT5Te9W6tSioQqKy/TMh3nxLg4AAACQUghXRxC7zdKNI7pIkp75KE+/FpXGuUQAAABA6iBcJYOSwno71Gk9stQ9O0N7fH79vw++r7fjAgAAAEc6wlWi+26Z9HAv6dt/1cvhbDZLfxgZqr2asyJP23eX1MtxAQAAgCMd4SrRff6cVLJLevl86Zu36+WQp3RroT5tGqmkLKgn3v+uXo4JAAAAHOkIV4nurKeko8dIgVJp3kXSf14/5ENalqWbRnaVJL34ySZtKyg+5GMCAAAARzrCVaJzuKRz50g9z5WCfmn+pdKX8w/5sMd3aqoBHZqoNBDUrPe+PfRyAgAAAEc4wlUysDuks5+S+lwkmYC08AppzQuHdEjLsvSH8pED563arM2/7K2PkgIAAABHLMJVsrDZpd/MkvpdKslIr18jrZ59SIcc2LGpTuzcTP6g0V//taF+ygkAAAAcoQhXycRmk858SBr4u9D8GzdInzxxSIf8Q3nfq4Wf/6jvft5zqCUEAAAAjliEq2RjWdJpudLx14fm3/6j9NFDdT5cnzaNdOrRLRU00sNLqb0CAAAA6opwlYwsSzp1pjR0amh+6Qzp/XslY+p0uBvL+17944ut+m9+/T2wGAAAADiSEK6SlWVJJ0+Tht8emn8/V/rXnXUKWN1zMnTGMdmSpIeW/K8+S4kjjW+PtPZlac2LUmlRvEsDAAAQU454FwCH6MQ/SA6P9M406aMHJX+JNOqeUPg6CDec2ln/XLdN73z9k9b9WKBerTMPU4FjLBgMPYS5aIdU9PM+0w6p+BepxdFSz3MkT4qcb7zkr5NWPyt9+YpUuju07N3bpAGTQ1ODpvEtHwAAQAxYxtSxLVkKKywsVGZmpgoKCpSRkRHv4tTOv/8mvXVT6H3/y6XT7w8NgHEQbpy3VgvXbNGwrs0159IBh6GQ9SwYlLb/R9q6RiraXh6gdlSEp6Kfpb07Qs8Hq4nDK3UfKx17sdT+hIMOpkes0r3S1wtDoWrL6orlTY4KPTLg1x9C88406dhLpCHXSo3axqWoAAAAdXUw2YBwVYWkDFeS9Pnz0uLfSzKhoDDmkdAQ7rW0cWeRTnlguQJBo1evGqz+7ZscvrLWhTHSjg1S3nLphw+lHz6S9u6s3b6eTKlB8/KpWejV1VDa8K70838rtmvcQTr2Iqn3hVJmq8NzHslu+/pQoPpiruQrCC2zOaSjx4QeFdDhJCkYkNa/Ln30sJT/ZWgbyx6qJTz+eimrZ/2UpXiXtPFjaeOKUCjObCNltJIyW4emtKaEZQAAcEgIV4coacOVJH0xT1p0lWSCUq//k8Y9GXoIsST5S6WyIqmsOFTrUFY+lZYvK9urhZ/+T1/9kK92TbwaObC3rIxs2TNz5MjMljutoVx2mxz22tWIBYNGu4rL9EtRadT0695S7dxT/lpUql/Llxtj1CjNpcYNnKFXr0Pt7T+ra/FatSv8TC13rpK7ZHv0hzgbSK37h35Uh0NTg+ahZmjh92nNJIer6kIaI235LBRMv1pY0aTNsklHDQ+F1K6nV79/IgkGpcIt0s4N0o5vQ687v5X2/iI1bi81PUpq2ilUs9T0qIMLHmUl0n9elz57Vtq0smJ5o3ZSv0mh76lhi8r7GSN9vywUsvKWVyzvNEI6YYrU7viDCz9lxdLmT6Xvl4eOt3VN6F6vht/m1h53SxW4WuoXe3P9bGumbWqmLcEm2hRoqrzSRtpreZSV4VHLDI+yM8OvXmVlupWV6VWLdLectbznAQBA6iFcHaKkDleS9PVr0oLfhprDeRuHahHK9h64edwBFJo0/WQa6yc11g6riX6xmuhXe1PtcjRVoaOZdjuba7eziX71WfqlqFS79pYqeJB3V7Z2arDtaw2x/0eDbP9Ra2tH1HqfcWp1sItWBrvrU/XUJndXNWjglcdhl8dpk8dpL59s8jjscjv3WR61TejV67QrzeVQmtuuBpZPzTa9rYz1c+X8cZ8AkdZUOmZ8KEC07HFI32G9KCkIhaZwgNpRHqJ2fif5i2t/HE9mRdDaN3Q1PaqiD9qODeW1VC9Jxb+Glll2qetoqf9lUseTa9/8dOuaUMhav7giELXqHwpZXc+odBx/IKhfdu/V7rzVsr5frgZbP1bTX9bIYUqjtssz2fo40F0+uZRj7VC2tVM51i9qYe2qVbEKjVe7TEP9qvTy14b61VS836V0BTxN5ExvKnd6c6U3bq7GjRqrZaZXLodNNkuyW5Ysy5LNkmyWJZtNsixLdssKzVuqWG+z5LBZcjlscjtsctntcjttctltcjlCk8MWOh4AAIg/wtUhSvpwJUn/fUuaP0kK+Cqvs+ySq0GoL4zTW+n9d7sC+u7nIjUJ/qJm5le10C9Ks6o4TjX8xqYyOVQmu8rkUMByKGg5FLQ5Q83HbE5ZDpcsu1N2h0s2p0sOp0uewh/kLvwh6lgB2ZXn7a4vHb30qempT0s76qdiS8VlgUP7fg6gvbVN/2dfrv+zf6gW1q+R5RscXfRhw9O0Pn2QJJucoTOUU3455JfDBEKvkXm/nAqEvwk5jV92KyiX5ZdTwdB+VjByDLsVlMP45VBAdgVCr8YvuwJKK/lJDfb8IHfJjmrLbWxOBRq1V6DJUVKTzlKzTrLSmirwS57Mzu9k++U72X/9Xs49W2o8/2JnY+11NVHTou8iywpcWVrb/Df6vOmZKnA0U9AYBYJGQWPkDxgFjFEwaBQwUtAYyUhGRsZUDGJpZNSsdItG7npFQ/a8I6cpkyRtc7TR25nn6QPvyXIVblSnPavVp+xLDbT9RxlWdGDMN431cbCHVgR6akWwh7YpNFiGy25TusehdI9DDT0ONXYZtXbsUmvbTmVrp5oHf1bTwM/KLNuudF++vMX5cpbtPpjbIsJnHNqlhtpjvCqSR0XGqyK5VSSviowntEyefdaHl4XWB2WLXF+nAnJYofvEEV5m+eWxGXnsQXlsocltC8plM3I47HI6HHI67HI6nHI67XI5HHI5HHI6HXI5nXI7HXI57XI5nHK7HHI7nXK53XK60uRwe+Rye2U5PZLdLTn2ncqXHWR/zSjGhMKzMaEaYMuiaebBCAZDAxP5S0I1tZH3JaE/nvh9oX+vvY0kT6PQq9Mb50IDQGojXB2ilAhXklS0Uyr8MdR0zlUenpwNJLvz4H7sGCN/cYHKdm1VoGCbAgVbFSzcJu3eJtuefNmLfpKj6Ce5in+SLVh2aGW2bFLOsVL7E0N9d9oOCoW//ZSUBbRrb5l+3VuqguIylZQFVFIWlM8fiLyPvO6zzFcWKJ8Prd9bGlBxaUB7y/za6yuf3ye42RXQSbYvdZ79fZ1q+1xO6/CGutrabhrpe5Ot74PZ+s5k63uTozyTpc2mhQI6cD87t0rVzvpJHax8dbC2qb2Vrw62fHWw8qNqfALG0nvBY/VSYLiWB3srWI9Pb2iuXZrkeFuX2Jcqw9orSSo1drn2+44L1UBfOY/Rd+n9lN90oNS0s5qne9Qiw6Pm6W61SHerWUO3GrjrMPhpSaG056dQ08niXyq9mr2/qGzPTgWLdkrFv8jp2yV7sPTAx01yfjnkt5zy21wKWnZZxsimoCwFZRkTepWRZcpf91luU+X/pQRlk7FsMuHX/d7Lspe/huaD5X+QCVjO8leH/OWvAWufP19YDvlll18OlckhI5scNiOnFZTDMvtMQdnDrzKyW0HZFZpsCi0zlk1Bm0PGcipo2RW0OUKv4T8OWfbQH4pkLy9T6NUYIytYJts+kxUsk834K96Hlxu/bMHSyLw96JM94JM9UCJbwBea6nB/GbtbQU+mgu5MBd2N5HdlyO/KVJkzQ2WuDJU6M+VzpCtoc8kR9MlhfHIGfOWfXyK7KQ29RspRIps/9N7yl8gKloVCt9NT/v+RNFlOr+T0Rl7lKH+NzHtCIdCyKfSXFnMQr+VsjtBkd4b6D9uc5e8d+61zRE9See24qQj72if0Rz4rGL1eVvkfBGz7/GHAVv1ks5f/vzT8/9PwX5H2+28gMr//ehNqVeLbE2qeX7q7/P2e8tfdoeWRZbtDr6VFoRYp7vTyKWOf9+WTJ7PyMndG6P+nxoRasgT9oeME/aFBiPZfFnlfPh/5b9uKPu/w+8jPin3Wh39rVLrOir4GVd0L4WPZ7KE/CtvC3729fNn+720V20Z9fhXlOdD6qGtYxXWrdG33UeV3E/5yangf2X6f+QMtq48/XJkqzq/ae7YalcpRRbkOWNYa1ifAH+kIV4coZcJVrBkTajrmL5ECZaF/jAOl5e/LQq/Vvi8N9Y9qOyjuw6IHg0bF5cFrb6m//DWgssKf1Ojb15Tz/avK2P2tApYjVFNkOWRsFT8EgzZn6L3NoeA+Pw4DtvJ6CStULxX5YWhsFT8Qy9+Xlb8vM3aVlr/+amVok9VKG60cFQY98geMSgNB+QNGZYFg1Ht/Fe0xLUtyO0LNId0Om9yO8ldnxXuP064MW4laB7eqWfBn/dSgm/a4s2S3hZq32W2hZm12K9S0LfzeZrNk3+e9rfz/s5Zlhf5NLC+AVV4OS1bk30ln2R512vyquuT9XWm+7QrY3SrOGiB1HCpv1+Gy5/Q+qIFZDitT/mMoHMKq+lFUWlTxI6i6H00mGP2j0O6UsYXuo6DlVNBmVzBS62uPhIqAseQPBBUIBhQIhKZgIKBAIKhgMBCaAqFXY4IywdByBUM1oG6VyaWy0KtV/iq/PCqVzeJ/BYmmzNjlk1MlcqlELvmMU6VyyiufMqwiZapIdq4bgBRX/Pv/ytskO65lIFwdIsIVDsiYuP8VpSbGGJUFjPzBoAJBI7fDLqc9wfvx+H2hfmNNjwo1UUO9Ct8T4Zpc3761u2V++Up98pUUq8xXojJfsfylxfKXligYKCuvZbKX11fZZKzQqyybjKxQrY+x9lluKWAsBYNBmfIgaIJ+BYIBmXAQDPhDITAYCG0XDoXBUNNItxWQ0xaQSwG5rIBc8stZ/uoIv4ab5FqhJreWCYSaJRtLZUFLpUFLZcZSaUCheWPJF7BUGpRKA5Z8QUu+gFQakBxWUE4rIKeCctlCzTWdkWWh96Emm4HypryhppySFfpDiRVqHByw7PLLWf7Hk9Dy0B9T9l0Wet1rnCoKOrU36FBRwKk9AYd2B5zaE7BrT8Cp4oClQI0dV40aqliZKlKmVaQm9r1qYturxra9amwrUiPtVaYVWpeuPXKagHyWSyWmPLAZp4rDr8ap4qBLxcahvcalvcHQNj6FAp1LZfKqVF7LJ49KI1Novkxe+eS2SuUNLy9fZ8mU/+07VMcZqpOo/F7h98YK1yHJZpU3nVZADoW+c3t5c2q7FSxvch2IvIab1YaPGQz9OUf71K9GfXa4nnXf+tbyOtXymlpTzXyw3kJtiXFqT6Q5sVd75NFe49GeSHPj6PfhJsZB2dRAxUq3itVQxWpY/hqZr2JZdc37A8ZSQLbQfSq7ArKVf9M2+WVTwISWBWVFrpYVdVUla5/vw4q6qiq/Bypf76CxarwXwvvawrXM1j7vVVH7bMlE1URHrhl/eEgZO676Ss2y2sS1DAeTDXiIMFAXiRxSFKoxcjksueqxGd9h53BLLbvHuxQpK3JPOGzK8DjjXRzUUiBYUTNd6g+qLBCUzbLktNvksFty2mxy2kM1x/X5xxNjjIJGKguE/kBjFOpLGWpVF3oNmtDyyLJ9tgm/hlW0Yqooo7X/uvAPaiu0f6k/KJ8/KF9ZUHv9gYp5f6D8Nbw+oNJAaDufPxgaZCZS225F17xXWlZR465I+Y0CwX3fh76L8DmF+pcGQ99RMKBgIFgeDI0C2ndbq7wfqhX5PsPrggqtCw9wY99vcpSXz2Gz5LBbamJZar7POssqjzflX3L4Ouw2RoWRaxheXh6Egn7ZA8UKGisSogLlcSRYXr5QOSvOIVh+7oGgiQzOY7OFWh5E5vcZ0Cf8Xe67PlyW/Y8Z/n6D4e80fO/ss37fvr2BYMV1CQT36ee77/p9ziF8P8nsG98UFeUq7kNT3rTZyLLZZC+/hyzLFrlXLJsle/n528LLbRWDGhlJ/mCoxYA/aGSCRv6gUcAEFQwEI+UNlv/RMxgMLZMx5QMghT/TyB4ZECnUGtIe+d6tUANom1UedaP/ewsGjYIyoVYLCn+XFdc2vI3C18ayIucZmS8/V1m2SBksK3SuFffVvp9b0bc6NB+MXG8Tua4m6mfT/v/th5dZ2v/nVWhmZnoVoxEnMMIVAAAJKvRjOzQKaixV/NhLkCa5AJAkkujP2gAAAACQuAhXAAAAAFAPkiJcPf744+rQoYM8Ho/69eunDz/8sMbtly9frn79+snj8ahjx4568sknY1RSAAAAAEeqhA9X8+bN05QpU3TrrbdqzZo1OvHEEzV69Ght2rSpyu3z8vJ0+umn68QTT9SaNWs0bdo0/f73v9eCBQtiXHIAAAAAR5KEH4p94MCB6tu3r5544onIsqOPPlrjxo1Tbm5upe2nTp2qxYsXa/369ZFlV111lb744gutXLmyVp/JUOwAAAAApIPLBgldc1VaWqrPPvtMI0eOjFo+cuRIrVixosp9Vq5cWWn7UaNGafXq1SorK6tyH5/Pp8LCwqgJAAAAAA5GQoerHTt2KBAIqGXLllHLW7Zsqfz8/Cr3yc/Pr3J7v9+vHTt2VLlPbm6uMjMzI1ObNvF9UBkAAACA5JPQ4Sps/wcjmvIHrh3M9lUtD7vllltUUFAQmTZv3nyIJQYAAABwpEnohwg3a9ZMdru9Ui3V9u3bK9VOhWVlZVW5vcPhUNOmTavcx+12y+1210+hAQAAAByRErrmyuVyqV+/flqyZEnU8iVLlmjIkCFV7jN48OBK27/77rvq37+/nE7nYSsrAAAAgCNbQocrSbrxxhv19NNPa/bs2Vq/fr1uuOEGbdq0SVdddZWkUJO+CRMmRLa/6qqrtHHjRt14441av369Zs+erWeeeUY33XRTvE4BAAAAwBEgoZsFStL48eO1c+dO3Xnnndq2bZt69uypt956S+3atZMkbdu2LeqZVx06dNBbb72lG264QY899phycnL0yCOP6JxzzonXKQAAAAA4AiT8c67igedcAQAAAJBS6DlXAAAAAJAsCFcAAAAAUA8IVwAAAABQDwhXAAAAAFAPCFcAAAAAUA8Sfij2eAgPoFhYWBjnkgAAAACIp3AmqM0g64SrKuzevVuS1KZNmziXBAAAAEAi2L17tzIzM2vchudcVSEYDGrr1q1KT0+XZVnxLo4KCwvVpk0bbd68medu4aBw7+BQcP/gUHD/4FBw/6CuDse9Y4zR7t27lZOTI5ut5l5V1FxVwWazqXXr1vEuRiUZGRn8A4M64d7BoeD+waHg/sGh4P5BXdX3vXOgGqswBrQAAAAAgHpAuAIAAACAekC4SgJut1t33HGH3G53vIuCJMO9g0PB/YNDwf2DQ8H9g7qK973DgBYAAAAAUA+ouQIAAACAekC4AgAAAIB6QLgCAAAAgHpAuAIAAACAekC4SnCPP/64OnToII/Ho379+unDDz+Md5GQgD744AONGTNGOTk5sixLixYtilpvjNGMGTOUk5Mjr9erYcOG6euvv45PYZFQcnNzddxxxyk9PV0tWrTQuHHj9M0330Rtw/2D6jzxxBM65phjIg/rHDx4sP75z39G1nPvoLZyc3NlWZamTJkSWcb9g5rMmDFDlmVFTVlZWZH18bp/CFcJbN68eZoyZYpuvfVWrVmzRieeeKJGjx6tTZs2xbtoSDBFRUXq3bu3Zs2aVeX6P//5z3rwwQc1a9YsrVq1SllZWRoxYoR2794d45Ii0SxfvlzXXHONPvnkEy1ZskR+v18jR45UUVFRZBvuH1SndevWuvfee7V69WqtXr1ap5xyisaOHRv5AcO9g9pYtWqVnnrqKR1zzDFRy7l/cCA9evTQtm3bItO6desi6+J2/xgkrAEDBpirrroqalm3bt3MH//4xziVCMlAknnttdci88Fg0GRlZZl77703sqykpMRkZmaaJ598Mg4lRCLbvn27kWSWL19ujOH+wcFr3Lixefrpp7l3UCu7d+82nTt3NkuWLDFDhw41119/vTGGf3twYHfccYfp3bt3levief9Qc5WgSktL9dlnn2nkyJFRy0eOHKkVK1bEqVRIRnl5ecrPz4+6l9xut4YOHcq9hEoKCgokSU2aNJHE/YPaCwQCmjt3roqKijR48GDuHdTKNddcozPOOEOnnnpq1HLuH9TGhg0blJOTow4dOuj888/X999/Lym+94/jsB4ddbZjxw4FAgG1bNkyannLli2Vn58fp1IhGYXvl6rupY0bN8ajSEhQxhjdeOONOuGEE9SzZ09J3D84sHXr1mnw4MEqKSlRw4YN9dprr6l79+6RHzDcO6jO3Llz9fnnn2vVqlWV1vFvDw5k4MCBev7559WlSxf99NNPuvvuuzVkyBB9/fXXcb1/CFcJzrKsqHljTKVlQG1wL+FArr32Wn355Zf66KOPKq3j/kF1unbtqrVr12rXrl1asGCBJk6cqOXLl0fWc++gKps3b9b111+vd999Vx6Pp9rtuH9QndGjR0fe9+rVS4MHD9ZRRx2l5557ToMGDZIUn/uHZoEJqlmzZrLb7ZVqqbZv314phQM1CY+cw72Emlx33XVavHixli1bptatW0eWc//gQFwulzp16qT+/fsrNzdXvXv31l//+lfuHdTos88+0/bt29WvXz85HA45HA4tX75cjzzyiBwOR+Qe4f5BbTVo0EC9evXShg0b4vrvD+EqQblcLvXr109LliyJWr5kyRINGTIkTqVCMurQoYOysrKi7qXS0lItX76cewkyxujaa6/VwoUL9d5776lDhw5R67l/cLCMMfL5fNw7qNHw4cO1bt06rV27NjL1799fF110kdauXauOHTty/+Cg+Hw+rV+/XtnZ2XH994dmgQnsxhtv1CWXXKL+/ftr8ODBeuqpp7Rp0yZdddVV8S4aEsyePXv07bffRubz8vK0du1aNWnSRG3bttWUKVN0zz33qHPnzurcubPuuecepaWl6cILL4xjqZEIrrnmGr300kt6/fXXlZ6eHvkrX2Zmprxeb+S5M9w/qMq0adM0evRotWnTRrt379bcuXP1/vvv6+233+beQY3S09MjfTvDGjRooKZNm0aWc/+gJjfddJPGjBmjtm3bavv27br77rtVWFioiRMnxvffn8M6FiEO2WOPPWbatWtnXC6X6du3b2R4ZGBfy5YtM5IqTRMnTjTGhIYkveOOO0xWVpZxu93mpJNOMuvWrYtvoZEQqrpvJJlnn302sg33D6pz2WWXRf4f1bx5czN8+HDz7rvvRtZz7+Bg7DsUuzHcP6jZ+PHjTXZ2tnE6nSYnJ8ecffbZ5uuvv46sj9f9YxljzOGNbwAAAACQ+uhzBQAAAAD1gHAFAAAAAPWAcAUAAAAA9YBwBQAAAAD1gHAFAAAAAPWAcAUAAAAA9YBwBQAAAAD1gHAFAAAAAPWAcAUAQD2zLEuLFi2KdzEAADFGuAIApJRJkybJsqxK02mnnRbvogEAUpwj3gUAAKC+nXbaaXr22Wejlrnd7jiVBgBwpKDmCgCQctxut7KysqKmxo0bSwo12XviiSc0evRoeb1edejQQfPnz4/af926dTrllFPk9XrVtGlTTZ48WXv27InaZvbs2erRo4fcbreys7N17bXXRq3fsWOHzjrrLKWlpalz585avHjx4T1pAEDcEa4AAEec6dOn65xzztEXX3yhiy++WBdccIHWr18vSdq7d69OO+00NW7cWKtWrdL8+fO1dOnSqPD0xBNP6JprrtHkyZO1bt06LV68WJ06dYr6jJkzZ+q8887Tl19+qdNPP10XXXSRfvnll5ieJwAgtixjjIl3IQAAqC+TJk3SCy+8II/HE7V86tSpmj59uizL0lVXXaUnnngism7QoEHq27evHn/8cf3tb3/T1KlTtXnzZjVo0ECS9NZbb2nMmDHaunWrWrZsqVatWunSSy/V3XffXWUZLMvSbbfdprvuukuSVFRUpPT0dL311lv0/QKAFEafKwBAyjn55JOjwpMkNWnSJPJ+8ODBUesGDx6stWvXSpLWr1+v3r17R4KVJB1//PEKBoP65ptvZFmWtm7dquHDh9dYhmOOOSbyvkGDBkpPT9f27dvrekoAgCRAuAIApJwGDRpUaqZ3IJZlSZKMMZH3VW3j9XprdTyn01lp32AweFBlAgAkF/pcAQCOOJ988kml+W7dukmSunfvrrVr16qoqCiy/uOPP5bNZlOXLl2Unp6u9u3b61//+ldMywwASHzUXAEAUo7P51N+fn7UMofDoWbNmkmS5s+fr/79++uEE07Qiy++qH//+9965plnJEkXXXSR7rjjDk2cOFEzZszQzz//rOuuu06XXHKJWrZsKUmaMWOGrrrqKrVo0UKjR4/W7t279fHHH+u6666L7YkCABIK4QoAkHLefvttZWdnRy3r2rWr/vvf/0oKjeQ3d+5cXX311crKytKLL76o7t27S5LS0tL0zjvv6Prrr9dxxx2ntLQ0nXPOOXrwwQcjx5o4caJKSkr00EMP6aabblKzZs107rnnxu4EAQAJidECAQBHFMuy9Nprr2ncuHHxLgoAIMXQ5woAAAAA6gHhCgAAAADqAX2uAABHFFrDAwAOF2quAAAAAKAeEK4AAAAAoB4QrgAAAACgHhCuAAAAAKAeEK4AAAAAoB4QrgAAAACgHhCuAAAAAKAeEK4AAAAAoB78f+w+cVewoDCYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display loss separately \n",
    "# Loss is a fundamental measure of how well a machine learning model's predictions match the actual outcomes\n",
    "# Loss quantifies the difference between pred values and actual values \n",
    "# Goal of training a model is to MINIMIZE LOSS\n",
    "# By minimizing loss we can improve the model's accuracy and predictive power\n",
    "# Loss guides hyperparamter tuning\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# training loss over epochs\n",
    "plt.plot(best_dnn_model.history['loss'])\n",
    "\n",
    "# validation loss over epochs\n",
    "plt.plot(best_dnn_model.history['val_loss'])\n",
    "\n",
    "plt.title('Exoplanet DNN Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights from the input layer\n",
    "weights = best_dnn.layers[0].get_weights()[0]\n",
    "\n",
    "# calculate importance of each feature\n",
    "feature_importance = np.sum(np.abs(weights), axis=1)\n",
    "\n",
    "# normalize\n",
    "feature_importance /= np.sum(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Normalized Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Photometry Time Series</td>\n",
       "      <td>0.252339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecliptic Latitude [deg]</td>\n",
       "      <td>0.216743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ecliptic Longitude [deg]</td>\n",
       "      <td>0.168281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Galactic Longitude [deg]</td>\n",
       "      <td>0.078873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Planets</td>\n",
       "      <td>0.071416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of Stars</td>\n",
       "      <td>0.064203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Galactic Latitude [deg]</td>\n",
       "      <td>0.059591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Transmission Spectroscopy Measurements</td>\n",
       "      <td>0.051281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Emission Spectroscopy Measurements</td>\n",
       "      <td>0.025976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Discovery Year</td>\n",
       "      <td>0.011297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Feature  Normalized Weight\n",
       "6                  Number of Photometry Time Series           0.252339\n",
       "4                           Ecliptic Latitude [deg]           0.216743\n",
       "5                          Ecliptic Longitude [deg]           0.168281\n",
       "3                          Galactic Longitude [deg]           0.078873\n",
       "1                                 Number of Planets           0.071416\n",
       "0                                   Number of Stars           0.064203\n",
       "2                           Galactic Latitude [deg]           0.059591\n",
       "8  Number of Transmission Spectroscopy Measurements           0.051281\n",
       "7      Number of Emission Spectroscopy Measurements           0.025976\n",
       "9                                    Discovery Year           0.011297"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = features.keys()\n",
    "feature_weights_df = pd.DataFrame({'Feature': feature_names, 'Normalized Weight': feature_importance})\n",
    "\n",
    "feature_weights_df = feature_weights_df.sort_values(by='Normalized Weight', ascending=False)\n",
    "feature_weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot features and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.barh(feature_weights_df['Feature'], feature_weights_df['Normalized Weight'])\n",
    "plt.xlabel('Feature Weight')\n",
    "plt.title('Feature Importance by the DNN')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves model to hdf5 file\n",
    "# best_dnn_model.save('best_exopldm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
